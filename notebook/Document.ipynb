{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dccda5db",
   "metadata": {},
   "source": [
    "data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8296d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179baa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'exmaple.txt', 'pages': 1, 'author': 'Krish Naik', 'date_created': '2025-01-01'}, page_content='this is the main text content I am using to create RAG')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"this is the main text content I am using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\":\"exmaple.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"Krish Naik\",\n",
    "        \"date_created\":\"2025-01-01\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22559c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple txt file \n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e469f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"✅ Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15eef747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "## text loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document=loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b36957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5114e001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 0}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 1}, page_content='Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 2}, page_content='C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 3}, page_content='C O N T E N T S\\n1\\nintroduction\\n1\\n2\\npython and required packages\\n5\\n2.1\\nA note on Python & OpenCV Versions . . . .\\n6\\n2.2\\nNumPy and SciPy . . . . . . . . . . . . . . . .\\n7\\n2.2.1\\nWindows . . . . . . . . . . . . . . . . .\\n7\\n2.2.2\\nOSX\\n. . . . . . . . . . . . . . . . . . .\\n7\\n2.2.3\\nLinux . . . . . . . . . . . . . . . . . . .\\n8\\n2.3\\nMatplotlib\\n. . . . . . . . . . . . . . . . . . . .\\n8\\n2.3.1\\nAll Platforms . . . . . . . . . . . . . .\\n8\\n2.4\\nOpenCV . . . . . . . . . . . . . . . . . . . . . .\\n9\\n2.4.1\\nLinux and OSX . . . . . . . . . . . . .\\n9\\n2.4.2\\nWindows . . . . . . . . . . . . . . . . .\\n10\\n2.5\\nMahotas . . . . . . . . . . . . . . . . . . . . . .\\n10\\n2.5.1\\nAll Platforms . . . . . . . . . . . . . .\\n10\\n2.6\\nscikit-learn . . . . . . . . . . . . . . . . . . . .\\n11\\n2.6.1\\nAll Platforms . . . . . . . . . . . . . .\\n11\\n2.7\\nscikit-image . . . . . . . . . . . . . . . . . . . .\\n11\\n2.8\\nSkip the Installation . . . . . . . . . . . . . . .\\n12\\n3\\nloading, displaying, and saving\\n14\\n4\\nimage basics\\n19\\n4.1\\nSo, What’s a Pixel?\\n. . . . . . . . . . . . . . .\\n19\\n4.2\\nOverview of the Coordinate System\\n. . . . .\\n22\\n4.3\\nAccessing and Manipulating Pixels . . . . . .\\n22\\n5\\ndrawing\\n31\\n5.1\\nLines and Rectangles . . . . . . . . . . . . . .\\n31\\n5.2\\nCircles\\n. . . . . . . . . . . . . . . . . . . . . .\\n36\\n6\\nimage processing\\n42\\n6.1\\nImage Transformations . . . . . . . . . . . . .\\n42\\niii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 4}, page_content='Contents\\n6.1.1\\nTranslation . . . . . . . . . . . . . . . .\\n43\\n6.1.2\\nRotation . . . . . . . . . . . . . . . . .\\n48\\n6.1.3\\nResizing . . . . . . . . . . . . . . . . .\\n53\\n6.1.4\\nFlipping . . . . . . . . . . . . . . . . .\\n59\\n6.1.5\\nCropping\\n. . . . . . . . . . . . . . . .\\n62\\n6.2\\nImage Arithmetic\\n. . . . . . . . . . . . . . . .\\n64\\n6.3\\nBitwise Operations\\n. . . . . . . . . . . . . . .\\n71\\n6.4\\nMasking\\n. . . . . . . . . . . . . . . . . . . . .\\n74\\n6.5\\nSplitting and Merging Channels . . . . . . . .\\n81\\n6.6\\nColor Spaces . . . . . . . . . . . . . . . . . . .\\n85\\n7\\nhistograms\\n89\\n7.1\\nUsing OpenCV to Compute Histograms . . .\\n90\\n7.2\\nGrayscale Histograms . . . . . . . . . . . . . .\\n91\\n7.3\\nColor Histograms . . . . . . . . . . . . . . . .\\n93\\n7.4\\nHistogram Equalization . . . . . . . . . . . . .\\n99\\n7.5\\nHistograms and Masks . . . . . . . . . . . . . 101\\n8\\nsmoothing and blurring\\n108\\n8.1\\nAveraging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2\\nGaussian\\n. . . . . . . . . . . . . . . . . . . . . 112\\n8.3\\nMedian . . . . . . . . . . . . . . . . . . . . . . 113\\n8.4\\nBilateral . . . . . . . . . . . . . . . . . . . . . . 116\\n9\\nthresholding\\n119\\n9.1\\nSimple Thresholding\\n. . . . . . . . . . . . . . 119\\n9.2\\nAdaptive Thresholding . . . . . . . . . . . . . 123\\n9.3\\nOtsu and Riddler-Calvard\\n. . . . . . . . . . . 127\\n10\\ngradients and edge detection\\n132\\n10.1\\nLaplacian and Sobel . . . . . . . . . . . . . . . 133\\n10.2\\nCanny Edge Detector . . . . . . . . . . . . . . 138\\n11\\ncontours\\n142\\n11.1\\nCounting Coins\\n. . . . . . . . . . . . . . . . . 142\\n11.2\\nContours and OpenCV Version Caveats . . . 149\\n12\\nwhere to now?\\n153\\niv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 5}, page_content='C O M PA N I O N W E B S I T E & S U P P L E M E N TA RY\\nM AT E R I A L\\nThank you for picking up a copy of the 4th edition of\\nPractical Python and OpenCV!\\nIn this latest edition, I’m excited to announce the creation\\nof a companion website which includes supplementary mate-\\nrial that I could not ﬁt inside the book.\\nAt the end of nearly every chapter inside Practical Python\\nand OpenCV + Case Studies, you’ll ﬁnd a link to a supplemen-\\ntary webpage that includes additional information, such as\\nmy commentary on methods to extend your knowledge,\\ndiscussions of common error messages, recommendations\\non various algorithms to try, and optional quizzes to test\\nyour knowledge.\\nRegistration to the companion website is free with your\\npurchase of Practical Python and OpenCV.\\nTo create your companion website account, just use this\\nlink:\\nhttp://pyimg.co/o1y7e\\nTake a second to create your account now so you’ll have\\naccess to the supplementary materials as you work through\\nthe book.\\nv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 6}, page_content='P R E FA C E\\nWhen I ﬁrst set out to write this book, I wanted it to be\\nas hands-on as possible. I wanted lots of visual examples\\nwith lots of code. I wanted to write something that you\\ncould easily learn from, without all the rigor and detail of\\nmathematics associated with college level computer vision\\nand image processing courses.\\nI know from all my years spent in the classroom that the\\nway I learned best was from simply opening up an editor\\nand writing some code. Sure, the theory and examples in\\nmy textbooks gave me a solid starting point. But I never\\nreally “learned” something until I did it myself. I was very\\nhands-on. And that’s exactly how I wanted this book to be.\\nVery hands-on, with all the code easily modiﬁable and well\\ndocumented so you could play with it on your own. That’s\\nwhy I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers.\\nI remember when I ﬁrst\\nstarted learning computer vision – it was a daunting task.\\nBut I learned a lot. And I had a lot of fun.\\nI hope this book helps you in your journey into computer\\nvision. I had a blast writing it. If you have any questions,\\nsuggestions, or comments, or if you simply want to say\\nhello, shoot me an email at adrian@pyimagesearch.com, or\\nvi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 7}, page_content='Contents\\nyou can visit my website at www.PyImageSearch.com and\\nleave a comment. I look forward to hearing from you soon!\\n-Adrian Rosebrock\\nvii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 8}, page_content='P R E R E Q U I S I T E S\\nIn order to make the most of this, you will need to have\\na little bit of programming experience. All examples in this\\nbook are in the Python programming language. Familiarity\\nwith Python or other scripting languages is suggested, but\\nnot required.\\nYou’ll also need to know some basic mathematics. This\\nbook is hands-on and example driven: lots of examples and\\nlots of code, so even if your math skills are not up to par,\\ndo not worry! The examples are very detailed and heavily\\ndocumented to help you follow along.\\nviii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 9}, page_content='C O N V E N T I O N S U S E D I N T H I S B O O K\\nThis book includes many code listings and terms to aid\\nyou in your journey to learn computer vision and image\\nprocessing. Below are the typographical conventions used\\nin this book:\\nItalic\\nIndicates key terms and important information that\\nyou should take note of. May also denote mathemati-\\ncal equations or formulas based on connotation.\\nBold\\nImportant information that you should take note of.\\nConstant width\\nUsed for source code listings, as well as paragraphs\\nthat make reference to the source code, such as func-\\ntion and method names.\\nix'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 10}, page_content='U S I N G T H E C O D E E X A M P L E S\\nThis book is meant to be a hands-on approach to com-\\nputer vision and machine learning. The code included in\\nthis book, along with the source code distributed with this\\nbook, are free for you to modify, explore, and share as you\\nwish.\\nIn general, you do not need to contact me for permis-\\nsion if you are using the source code in this book. Writing\\na script that uses chunks of code from this book is totally\\nand completely okay with me.\\nHowever, selling or distributing the code listings in this\\nbook, whether as information product or in your product’s\\ndocumentation, does require my permission.\\nIf you have any questions regarding the fair use of the\\ncode examples in this book, please feel free to shoot me an\\nemail. You can reach me at adrian@pyimagesearch.com.\\nx'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 11}, page_content='H O W TO C O N TA C T M E\\nWant to ﬁnd me online? Look no further:\\nWebsite:\\nwww.PyImageSearch.com\\nEmail:\\nadrian@pyimagesearch.com\\nTwitter:\\n@PyImageSearch\\nGoogle+:\\n+AdrianRosebrock\\nLinkedIn:\\nAdrian Rosebrock\\nxi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 12}, page_content='1\\nI N T R O D U C T I O N\\nThe goal of computer vision is to understand the story\\nunfolding in a picture. As humans, this is quite simple. But\\nfor computers, the task is extremely difﬁcult.\\nSo why bother learning computer vision?\\nWell, images are everywhere!\\nWhether it be personal photo albums on your smartphone,\\npublic photos on Facebook, or videos on YouTube, we now\\nhave more images than ever – and we need methods to an-\\nalyze, categorize, and quantify the contents of these images.\\nFor example, have you recently tagged a photo of your-\\nself or a friend on Facebook lately? How does Facebook\\nseem to “know” where the faces are in an image?\\nFacebook has implemented facial recognition algorithms\\ninto their website, meaning that they cannot only ﬁnd faces\\nin an image, they can also identify whose face it is as well!\\nFacial recognition is an application of computer vision in\\nthe real world.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 13}, page_content='introduction\\nWhat other types of useful applications of computer vi-\\nsion are there?\\nWell, we could build representations of our 3D world us-\\ning public image repositories like Flickr. We could down-\\nload thousands and thousands of pictures of Manhattan,\\ntaken by citizens with their smartphones and cameras, and\\nthen analyze them and organize them to construct a 3D rep-\\nresentation of the city. We would then virtually navigate\\nthis city through our computers. Sound cool?\\nAnother popular application of computer vision is surveil-\\nlance.\\nWhile surveillance tends to have a negative connotation\\nof sorts, there are many different types. One type of surveil-\\nlance is related to analyzing security videos, looking for\\npossible suspects after a robbery.\\nBut a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.\\nOn your last visit to your favorite clothing retailer, did\\nyou stop to examine the spring’s latest jeans trends? How\\nlong did you look at the jeans? What was your facial expres-\\nsion as you looked at the jeans? Did you then pick up a pair\\nand head to the dressing room? These are all types of ques-\\ntions that computer vision surveillance systems can answer.\\nComputer vision can also be applied to the medical ﬁeld.\\nA year ago, I consulted with the National Cancer Institute\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 14}, page_content='introduction\\nto develop methods to automatically analyze breast histol-\\nogy images for cancer risk factors. Normally, a task like\\nthis would require a trained pathologist with years of expe-\\nrience – and it would be extremely time consuming!\\nOur research demonstrated that computer vision algo-\\nrithms could be applied to these images and could auto-\\nmatically analyze and quantify cellular structures – without\\nhuman intervention! Now, we can analyze breast histology\\nimages for cancer risk factors much faster.\\nOf course, computer vision can also be applied to other\\nareas of the medical ﬁeld. Analyzing X-rays, MRI scans,\\nand cellular structures all can be performed using computer\\nvision algorithms.\\nPerhaps the biggest success computer vision success story\\nyou may have heard of is the X-Box 360 Kinect. The Kinect\\ncan use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.\\nThe list doesn’t stop there.\\nComputer vision is now prevalent in many areas of your\\nlife, whether you realize it or not. We apply computer vi-\\nsion algorithms to analyze movies, football games, hand\\ngesture recognition (for sign language), license plates (just\\nin case you were driving too fast), medicine, surgery, mili-\\ntary, and retail.\\nWe even use computer visions in space! NASA’s Mars\\nRover includes capabilities to model the terrain of the planet,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 15}, page_content='introduction\\ndetect obstacles in its path, and stitch together panoramic\\nimages.\\nThis list will continue to grow in the coming years.\\nCertainly, computer vision is an exciting ﬁeld with end-\\nless possibilities.\\nWith this in mind, ask yourself: what does your imagina-\\ntion want to build? Let it run wild. And let the computer\\nvision techniques introduced in this book help you build it.\\nFurther Reading\\nWelcome to the supplementary material portion of the\\nchapter! If you haven’t already registered and created\\nyour account for the companion website, please do so\\nusing the following link:\\nhttp://pyimg.co/o1y7e\\nFrom there, you can ﬁnd the Chapter 1 supplemen-\\ntary material page here:\\nhttp://pyimg.co/rhsgi\\nThis page serves as an introduction to the companion\\nwebsite and details how to use it and what to expect\\nas you work through the rest of Practical Python and\\nOpenCV.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 16}, page_content='2\\nP Y T H O N A N D R E Q U I R E D PA C K A G E S\\nIn order to explore the world of computer vision, we’ll\\nﬁrst need to install some packages and libraries. As a ﬁrst-\\ntimer in computer vision, installing some of these packages\\n(especially OpenCV) can be quite tedious, depending on\\nwhat operating system you are using. I’ve tried to consoli-\\ndate the installation instructions into a short how-to guide,\\nbut as you know, projects change, websites change, and in-\\nstallation instructions change! If you run into problems, be\\nsure to consult the package’s website for the most up-to-\\ndate installation instructions.\\nI highly recommend that you use either easy_install or\\npip to manage the installation of your packages.\\nIt will\\nmake your life much easier! You can read more about pip\\nhere: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image\\nprocessing packages you need to run the examples in this\\nbook pre-installed! Using this virtual machine allows you\\nto jump right in to the examples in this book, without hav-\\ning to worry about package managers, installation instruc-\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 17}, page_content='2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1\\na note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4.\\nFurthermore, all code examples will run in both the\\nPython 2.7 and the Python 3+ environments!\\nIf you are looking for the OpenCV 2.4.X and Python 2.7\\nversion of this book, please look in the download directory\\nassociated with your purchase – inside you will ﬁnd the\\nOpenCV 2.4.X + Python 2.7 edition.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 18}, page_content='2.2 numpy and scipy\\n2.2\\nnumpy and scipy\\nNumPy is a library for the Python programming language\\nthat (among other things) provides support for large, multi-\\ndimensional arrays. Why is that important? Using NumPy,\\nwe can express images as multi-dimensional arrays. Repre-\\nsenting images as NumPy arrays is not only computation-\\nally and resource efﬁcient, many other image processing\\nand machine learning libraries use NumPy array represen-\\ntations as well. Furthermore, by using NumPy’s built-in\\nhigh-level mathematical functions, we can quickly and eas-\\nily perform numerical analysis on an image.\\nGoing hand-in-hand with NumPy, we also have SciPy.\\nSciPy adds further support for scientiﬁc and technical com-\\nputing.\\n2.2.1\\nWindows\\nBy far, the easiest way to install NumPy and SciPy on your\\nWindows system is to download and install the binary dis-\\ntribution from: http://www.scipy.org/install.html.\\n2.2.2\\nOSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.\\nYou can also install NumPy and SciPy using pip:\\nListing 2.1: Install NumPy and SciPy on OSX\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 19}, page_content='2.3 matplotlib\\n$ pip install numpy\\n$ pip install scipy\\n2.2.3\\nLinux\\nOn many Linux distributions, such as Ubuntu, NumPy comes\\npre-installed and conﬁgured.\\nIf you want the latest versions of NumPy and SciPy, you\\ncan build the libraries from source, but the easiest method\\nis to use a pip:\\nListing 2.2: Install NumPy and SciPy on Linux\\n$ pip install numpy\\n$ pip install scipy\\n2.3\\nmatplotlib\\nSimply put, matplotlib is a plotting library. If you’ve ever\\nused MATLAB before, you’ll probably feel very comfort-\\nable in the matplotlib environment. When analyzing im-\\nages, we’ll make use of matplotlib. Whether plotting image\\nhistograms or simply viewing the image itself, matplotlib\\nis a great tool to have in your toolbox.\\n2.3.1\\nAll Platforms\\nMatplotlib is available from http://matplotlib.org/.\\nThe\\nmatplotlib package is also pip-installable:\\nListing 2.3: Install matplotlib\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 20}, page_content='2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4\\nopencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1\\nLinux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in\\nprevious years, but has luckily gotten much easier. I have\\naccumulated OpenCV installation instructions on the PyIm-\\nageSearch blog for Debian-based Linux distributions (such\\nas Ubuntu) and OSX here:\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 21}, page_content='2.5 mahotas\\nhttp://pyimg.co/vvlpy\\nJust scroll down the “Install OpenCV 3 and Python” and\\n“Install OpenCV 4 and Python” sections, select the oper-\\nating system and Python version that you want to install\\nOpenCV for, and you’ll be on your way!\\n2.4.2\\nWindows\\nThe OpenCV Docs provide fantastic tutorials on how to in-\\nstall OpenCV in Windows using binary distributions. You\\ncan check out the installation instructions here:\\nhttp://pyimg.co/l2q6s\\n2.5\\nmahotas\\nMahotas, just like OpenCV, relies on NumPy arrays. Much\\nof the functionality implemented in Mahotas can be found\\nin OpenCV, but in some cases, the Mahotas interface is just\\neasier to use. We’ll use Mahotas to complement OpenCV.\\n2.5.1\\nAll Platforms\\nInstalling Mahotas is extremely easy on all platforms. As-\\nsuming you already have NumPy and SciPy installed, all\\nyou need is a single call to the pip command:\\nListing 2.4: Install Mahotas\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 22}, page_content='2.6 scikit-learn\\n$ pip install mahotas\\n2.6\\nscikit-learn\\nAlright, you got me, scikit-learn isn’t an image processing\\nor computer vision library – it’s a machine learning library.\\nThat said, you can’t have advanced computer vision tech-\\nniques without some sort of machine learning, whether it\\nbe clustering, vector quantization, classiﬁcation models, etc.\\nScikit-learn also includes a handful of image feature extrac-\\ntion functions as well. We don’t use the scikit-learn library\\nin Practical Python and OpenCV, but it’s heavily used in Case\\nStudies.\\n2.6.1\\nAll Platforms\\nInstalling scikit-learn on all platforms is dead-simple using\\npip:\\nListing 2.5: Install scikit-learn\\n$ pip install scikit-learn\\n2.7\\nscikit-image\\nThe algorithms included in scikit-image (I would argue) fol-\\nlow closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-\\nrithms, you need to have developed some rigor and under-\\nstanding in the computer vision ﬁeld. If you already have\\nsome experience in computer vision and image processing,\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 23}, page_content='2.8 skip the installation\\ndeﬁnitely check out scikit-image; otherwise, I would con-\\ntinue working with OpenCV to start. Again, scikit-image\\nwon’t be used in of Practical Python and OpenCV, but it will\\nbe used in Case Studies, especially when we perform hand-\\nwritten digit recognition.\\nAssuming you already have NumPy and SciPy installed,\\nyou can install scikit-image using pip:\\nListing 2.6: Install scikit-image\\n$ pip install -U scikit-image\\nNow that we have all our packages installed, let’s start\\nexploring the world of computer vision!\\n2.8\\nskip the installation\\nAs I’ve mentioned above, installing all these packages can\\nbe time consuming and tedious. If you want to skip the\\ninstallation process and jump right into the world of im-\\nage processing and computer vision, I have set up a pre-\\nconﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 24}, page_content='2.8 skip the installation\\nFurther Reading\\nTo learn more about installing OpenCV, Python virtual\\nenvironments, and choosing a code editor, please see\\nthe Chapter 2 supplementary material webpage:\\nhttp://pyimg.co/f0sxq\\nIn particular, I think you’ll be interested in learning\\nhow the PyCharm IDE can be utilized with Python vir-\\ntual environments to create the perfect computer vision\\ndevelopment environment.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 25}, page_content='3\\nL O A D I N G , D I S P L AY I N G , A N D S AV I N G\\nThis book is meant to be a hands-on, how-to guide to get-\\nting started with computer vision using Python and OpenCV.\\nWith that said, let’s not waste any time. We’ll get our feet\\nwet by writing some simple code to load an image off disk,\\ndisplay it on our screen, and write it to ﬁle in a different\\nformat.\\nWhen executed, our Python script should show\\nour image on screen, like in Figure 3.1.\\nFirst, let’s create a ﬁle named load_display_save.py to\\ncontain our code. Now we can start writing some code:\\nListing 3.1: load_display_save.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\nThe ﬁrst thing we are going to do is import the packages\\nwe will need for this example.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 26}, page_content='loading, displaying, and saving\\nFigure 3.1: Example of loading and displaying\\na Tyrannosaurus Rex image on our\\nscreen.\\nThroughout this book you’ll see us importing the print_\\nfunction from the __future__ package. We’ll be using the\\nactual print() function rather than the print statement so\\nthat our code will work with both Python 2.7 and Python\\n3 – just something to keep in mind as we work through the\\nexamples!\\nWe’ll use argparse to handle parsing our command line\\narguments. Then, cv2 is imported – cv2 is our OpenCV li-\\nbrary and contains our image processing functions.\\nFrom there, Lines 5-8 handle parsing the command line\\narguments. The only argument we need is --image: the\\npath to our image on disk. Finally, we parse the arguments\\nand store them in a dictionary.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 27}, page_content='loading, displaying, and saving\\nListing 3.2: load_display_save.py\\n9 image = cv2.imread(args[\"image\"])\\n10 print(\"width: {} pixels\".format(image.shape[1]))\\n11 print(\"height: {} pixels\".format(image.shape[0]))\\n12 print(\"channels: {}\".format(image.shape[2]))\\n13\\n14 cv2.imshow(\"Image\", image)\\n15 cv2.waitKey(0)\\nNow that we have the path to the image, we can load it\\noff the disk using the cv2.imread function on Line 9. The\\ncv2.imread function returns a NumPy array representing\\nthe image.\\nLines 10-12 examine the dimensions of the image. Again,\\nsince images are represented as NumPy arrays, we can sim-\\nply use the shape attribute to examine the width, height,\\nand the number of channels.\\nFinally, Lines 14 and 15 handle displaying the actual\\nimage on our screen. The ﬁrst parameter is a string, the\\n“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until\\nwe press a key on our keyboard. Using a parameter of 0\\nindicates that any keypress will un-pause the execution.\\nThe last thing we are going to do is write our image to\\nﬁle in JPG format:\\nListing 3.3: load_display_save.py\\n16\\ncv2.imwrite(\"newimage.jpg\", image)\\nAll we are doing here is providing the path to the ﬁle\\n(the ﬁrst argument) and then the image we want to save\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 28}, page_content='loading, displaying, and saving\\n(the second argument). It’s that simple.\\nTo run our script and display our image, we simply open\\nup a terminal window and execute the following command:\\nListing 3.4: load_display_save.py\\n$ python load_display_save.py --image ../images/trex.png\\nIf everything has worked correctly, you should see the T-\\nRex on your screen as in Figure 3.1. To stop the script from\\nexecuting, simply click on the image window and press any\\nkey.\\nExamining the output of the script, you should also see\\nsome basic information on our image. You’ll note that the\\nimage has a width of 350 pixels, a height of 228 pixels, and 3\\nchannels (the RGB components of the image). Represented\\nas a NumPy array, our image has a shape of (228,350,3).\\nThe NumPy shape may seem reversed to you (specifying\\nthe height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).\\nHere, our image has a height of 228 pixels (the number of\\nrows) and a width of 350 pixels (the number of columns) –\\nthus, the NumPy shape makes sense (although it may seen\\na bit confusing at ﬁrst).\\nFinally, note the contents of your directory. You’ll see a\\nnew ﬁle there: newimage.jpg. OpenCV has automatically\\nconverted our PNG image to JPG for us! No further effort\\nis needed on our part to convert between image formats.\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 29}, page_content='loading, displaying, and saving\\nNext up, we’ll explore how to access and manipulate the\\npixel values in an image.\\nFurther Reading\\nYou can ﬁnd the Chapter 3 supplementary material, re-\\nsources, and quizzes here:\\nhttp://pyimg.co/xh73h\\nSpeciﬁcally, I discuss some common “gotchas” that may\\ntrip you up when utilizing OpenCV for the ﬁrst time –\\nthese tips and tricks are especially useful if this is your\\nﬁrst exposure to OpenCV.\\nBe sure to take the quiz to test your knowledge after\\nreading this chapter!\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 30}, page_content='4\\nI M A G E B A S I C S\\nIn this chapter we are going to review the building blocks\\nof an image – the pixel. We’ll discuss exactly what a pixel\\nis, how pixels are used to form an image, and then how to\\naccess and manipulate pixels in OpenCV.\\n4.1\\nso, what’s a pixel?\\nEvery image consists of a set of pixels. Pixels are the raw\\nbuilding blocks of an image. There is no ﬁner granularity\\nthan the pixel.\\nNormally, we think of a pixel as the “color” or the “inten-\\nsity” of light that appears in a given place in our image.\\nIf we think of an image as a grid, each square in the grid\\ncontains a single pixel.\\nFor example, let’s pretend we have an image with a res-\\nolution of 500 × 300. This means that our image is repre-\\nsented as a grid of pixels, with 500 rows and 300 columns.\\nOverall, there are 500 × 300 = 150, 000 pixels in our image.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 31}, page_content='4.1 so, what’s a pixel?\\nMost pixels are represented in two ways: grayscale and\\ncolor. In a grayscale image, each pixel has a value between\\n0 and 255, where zero corresponds to “black” and 255 cor-\\nresponds to “white”. The values in between 0 and 255 are\\nvarying shades of gray, where values closer to 0 are darker\\nand values closer to 255 are lighter.\\nColor pixels are normally represented in the RGB color\\nspace – one value for the Red component, one for Green,\\nand one for Blue. Other color spaces exist, but let’s start\\nwith the basics and move our way up from there.\\nEach of the three colors is represented by an integer in\\nthe range 0 to 255, which indicates how “much” of the color\\nthere is. Given that the pixel value only needs to be in the\\nrange [0, 255], we normally use an 8-bit unsigned integer to\\nrepresent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.\\nTo construct a white color, we would ﬁll up each of the\\nred, green, and blue buckets completely, like this: (255,\\n255,255).\\nThen, to create a black color, we would empty each of the\\nbuckets out: (0,0,0).\\nTo create a pure red color, we would ﬁll up the red bucket\\n(and only the red bucket) up completely: (255,0,0).\\nAre you starting to see a pattern?\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 32}, page_content='4.1 so, what’s a pixel?\\nFor your reference, here are some common colors repre-\\nsented as RGB tuples:\\n• Black: (0,0,0)\\n• White: (255,255,255)\\n• Red: (255,0,0)\\n• Green: (0,255,0)\\n• Blue: (0,0,255)\\n• Aqua: (0,255,255)\\n• Fuchsia: (255,0,255)\\n• Maroon: (128,0,0)\\n• Navy: (0,0,128)\\n• Olive: (128,128,0)\\n• Purple: (128,0,128)\\n• Teal: (0,128,128)\\n• Yellow: (255,255,0)\\nNow that we have a good understanding of pixels, let’s\\nhave a quick review of the coordinate system.\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 33}, page_content='4.2 overview of the coordinate system\\n4.2\\noverview of the coordinate system\\nAs I mentioned above, an image is represented as a grid of\\npixels. Imagine our grid as a piece of graph paper. Using\\nthis graph paper, the point (0, 0) corresponds to the upper\\nleft corner of the image. As we move down and to the right,\\nboth the x and y values increase.\\nLet’s take a look at the image in Figure 4.1 to make this\\npoint clearer.\\nHere we have the letter “I” on a piece of graph paper. We\\nsee that we have an 8 × 8 grid with a total of 64 pixels.\\nThe point (0, 0) corresponds to the top left pixel in our\\nimage, whereas the point (7, 7) corresponds to the bottom\\nright corner.\\nFinally, the point (3, 4) is the pixel three columns to the\\nright and four rows down, once again keeping in mind that\\nwe start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.\\n4.3\\naccessing and manipulating pixels\\nAdmittedly, the example from Chapter 3 wasn’t very excit-\\ning. All we did was load an image off disk, display it, and\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 34}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.1: The letter “I” placed on a piece of\\ngraph paper. Pixels are accessed by\\ntheir (x, y) coordinates, where we go\\nx columns to the right and y rows\\ndown, keeping in mind that Python\\nis zero-indexed:\\nwe start counting\\nfrom zero rather than one.\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 35}, page_content='4.3 accessing and manipulating pixels\\nthen write it back to disk in a different image ﬁle format.\\nLet’s do something a little more exciting and see how we\\ncan access and manipulate the pixels in an image:\\nListing 4.1: getting_and_setting.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nSimilar to our example in the previous chapter, Lines 1-8\\nhandle importing the packages we need, along with setting\\nup our argument parser. There is only one command line\\nargument needed: the path to the image we are going to\\nwork with.\\nLines 10 and 11 handle loading the actual image off disk\\nand displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.\\nConceptually, we can think of this representation as a ma-\\ntrix, as discussed in Section 4.1 above. In order to access a\\npixel value, we just need to supply the x and y coordinates\\nof the pixel we are interested in. From there, we are given\\na tuple representing the Red, Green, and Blue components\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 36}, page_content='4.3 accessing and manipulating pixels\\nof the image.\\nHowever, it’s important to note that OpenCV stores RGB\\nchannels in reverse order. While we normally think in terms\\nof Red, Green, and Blue, OpenCV actually stores them in\\nthe order of Blue, Green, and Red. This is important to\\nnote since it could cause some confusion later.\\nAlright, let’s explore some code that can be used to ac-\\ncess and manipulate pixels:\\nListing 4.2: getting_and_setting.py\\n12 (b, g, r) = image[0, 0]\\n13 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\n14\\n15 image[0, 0] = (0, 0, 255)\\n16 (b, g, r) = image[0, 0]\\n17 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\nOn Line 12, we grab the pixel located at (0, 0) – the top-\\nleft corner of the image. This pixel is represented as a tuple.\\nAgain, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out\\nthe values of each channel to our console.\\nAs you can see, accessing pixel values is quite easy! Num-\\nPy takes care of all the hard work for us. All we are doing\\nis providing indexes into the array.\\nJust as NumPy makes it easy to access pixel values, it also\\nmakes it easy to manipulate pixel values.\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 37}, page_content='4.3 accessing and manipulating pixels\\nOn Line 15 we manipulate the top-left pixel in the im-\\nage, which is located at coordinate (0, 0) and set it to have\\na value of (0, 0, 255). If we were reading this pixel value\\nin RGB format, we would have a value of 0 for red, 0 for\\ngreen, and 255 for blue, thus making it a pure blue color.\\nHowever, as I mentioned above, we need to take special\\ncare when working with OpenCV. Our pixels are actually\\nstored in BGR format, not RGB format.\\nWe actually read this pixel as 255 for red, 0 for green, and\\n0 for blue, making it a red color, not a blue color.\\nAfter setting the top-left pixel to have a red color on Line\\n15, we then grab the pixel value and print it back to con-\\nsole on Lines 16 and 17, just to demonstrate that we have\\nindeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-\\nbilities to access larger rectangular portions of the image?\\nThe code below demonstrates how we can do this:\\nListing 4.3: getting_and_setting.py\\n18 corner = image[0:100, 0:100]\\n19 cv2.imshow(\"Corner\", corner)\\n20\\n21 image[0:100, 0:100] = (0, 255, 0)\\n22\\n23 cv2.imshow(\"Updated\", image)\\n24 cv2.waitKey(0)\\nOn Line 18 we grab a 100 × 100 pixel region of the image.\\nIn fact, this is the top-left corner of the image! In order to\\ngrab chunks of an image, NumPy expects we provide four\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 38}, page_content='4.3 accessing and manipulating pixels\\nindexes:\\n1. Start y: The ﬁrst value is the starting y coordinate.\\nThis is where our array slice will start along the y-axis.\\nIn our example above, our slice starts at y = 0.\\n2. End y: Just as we supplied a starting y value, we must\\nprovide an ending y value. Our slice stops along the\\ny-axis when y = 100.\\n3. Start x: The third value we must supply is the starting\\nx coordinate for the slice. In order to grab the top-left\\nregion of the image, we start at x = 0.\\n4. End x: Finally, we need to provide an x-axis value for\\nour slice to stop. We stop when x = 100.\\nOnce we have extracted the top-left corner of the image,\\nLine 19 shows us the result of the cropping. Notice how\\nour image is just the 100 × 100 pixel region from the top-\\nleft corner of our original image.\\nThe last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the\\nimage; however, this time we are setting this region to have\\na value of (0, 255, 0) (green).\\nLines 23 and 24 then show us the results of our work.\\nSo how do we run our Python script?\\nAssuming you have downloaded the source code listings\\nfor this book, simply navigate to the chapter-04 directory\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 39}, page_content='4.3 accessing and manipulating pixels\\nand execute the command below:\\nListing 4.4: getting_and_setting.py\\n$ python getting_and_setting.py --image ../images/trex.png\\nOnce our script starts running, you should see some out-\\nput printed to your console (Line 13). The ﬁrst line of out-\\nput tells us that the pixel located at (0, 0) has a value of\\n254 for all three red, green, and blue channels. This pixel\\nappears to be almost pure white.\\nThe second line of output shows us that we have success-\\nfully changed the pixel located at (0, 0) to be red rather than\\nwhite (Lines 15-17).\\nListing 4.5: getting_and_setting.py\\nPixel at (0, 0) - Red: 254, Green: 254, Blue: 254\\nPixel at (0, 0) - Red: 255, Green: 0, Blue: 0\\nWe can see the results of our work in Figure 4.2. The Top-\\nLeft image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if\\nyou look closely, you can see that the top-left pixel located\\nat (0, 0) is red!\\nFinally, the bottom image shows that we have successfully\\ndrawn a green square on our image.\\nIn this chapter, we have explored how to access and ma-\\nnipulate the pixels in an image using NumPy’s built-in ar-\\nray slicing functionality. We were even able to draw a green\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 40}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.2: Top-Left:\\nOur original image.\\nTop-\\nRight:\\nCropping our image using\\nNumPy array slicing. Bottom: Draw-\\ning a 100 × 100 pixel green square on\\nour image by using basic NumPy in-\\ndexing.\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 41}, page_content='4.3 accessing and manipulating pixels\\nsquare using nothing but NumPy array manipulation!\\nHowever, we won’t get very far using only NumPy func-\\ntions. The next chapter will show you how to draw lines,\\nrectangles, and circles using OpenCV methods.\\nFurther Reading\\nOne of the most common errors I see with developers\\njust starting to learn OpenCV is the (x, y)-coordinate\\nordering passed into images. I also tend to see a lot of\\nconfusion regarding the BGR versus RGB channel or-\\ndering.\\nTo learn more about these common errors (and how\\nyou can avoid) then, be sure to refer to the Chapter 4\\nsupplementary material:\\nhttp://pyimg.co/mtemn\\nI’ve also included a quiz that you can use to test your\\nknowledge on image basics.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 42}, page_content='5\\nD R AW I N G\\nUsing NumPy array slices in Chapter 4, we were able to\\ndraw a green square on our image. But what if we wanted\\nto draw a single line? Or a circle? NumPy does not provide\\nthat type of functionality – it’s only a numerical processing\\nlibrary after all!\\nLuckily, OpenCV provides convenient, easy-to-use meth-\\nods to draw shapes on an image. In this chapter, we’ll re-\\nview the three most basic methods to draw shapes: cv2.\\nline, cv2.rectangle, and cv2.circle.\\nWhile this chapter is by no means a complete, exhaus-\\ntive overview of the drawing capabilities of OpenCV, it will\\nnonetheless provide a quick, hands-on approach to get you\\nstarted drawing immediately.\\n5.1\\nlines and rectangles\\nBefore we start exploring the the drawing capabilities of\\nOpenCV, let’s ﬁrst deﬁne our canvas in which we will draw\\nour masterpieces.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 43}, page_content='5.1 lines and rectangles\\nUp until this point, we have only loaded images off disk.\\nHowever, we can also deﬁne our images manually using\\nNumPy arrays. Given that OpenCV interprets an image as\\na NumPy array, there is no reason why we can’t manually\\ndeﬁne the image ourselves!\\nIn order to initialize our image, let’s examine the code\\nbelow:\\nListing 5.1: drawing.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\nLines 1 and 2 imports the packages we will be using.\\nAs a shortcut, we’ll create an alias for numpy as np. We’ll\\ncontinue this convention throughout the rest of the book.\\nIn fact, you’ll commonly see this convention in the Python\\ncommunity as well! We’ll also import cv2, so we can have\\naccess to the OpenCV library.\\nInitializing our image is handled on Line 4. We construct\\na NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,\\nrespectively. As the name suggests, the zeros method ﬁlls\\nevery element in the array with an initial value of zero.\\nIt’s important to draw your attention to the second argu-\\nment of the np.zeros method: the data type, dtype. Since\\nwe are representing our image as an RGB image with pixels\\nin the range [0, 255], it’s important that we use an 8-bit un-\\nsigned integer, or uint8. There are many other data types\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 44}, page_content='5.1 lines and rectangles\\nthat we can use (common ones include 32-bit integers, and\\n32-bit or 64-bit ﬂoats), but we’ll mainly be using uint8 for\\nthe majority of the examples in this book.\\nNow that we have our canvas initialized, we can do some\\ndrawing:\\nListing 5.2: drawing.py\\n5 green = (0, 255, 0)\\n6 cv2.line(canvas, (0, 0), (300, 300), green)\\n7 cv2.imshow(\"Canvas\", canvas)\\n8 cv2.waitKey(0)\\n9\\n10 red = (0, 0, 255)\\n11 cv2.line(canvas, (300, 0), (0, 300), red, 3)\\n12 cv2.imshow(\"Canvas\", canvas)\\n13 cv2.waitKey(0)\\nThe ﬁrst thing we do on Line 5 is deﬁne a tuple used to\\nrepresent the color “green”. Then, we draw a green line\\nfrom point (0, 0) (the top-left corner of the image) to point\\n(300, 300), the bottom-right corner of the image on Line 6.\\nIn order to draw the line, we make use of the cv2.line\\nmethod. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose\\nto start our line from the top-left corner of the image, at\\npoint (0, 0). We also need to supply an ending point for the\\nline (the third argument). We deﬁne our ending point to be\\n(300, 300), the bottom-right corner of the image. The last ar-\\ngument is the color of our line, which, in this case, is green.\\nLines 7 and 8 show our image and then wait for a keypress.\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 45}, page_content='5.1 lines and rectangles\\nFigure 5.1: Examples of drawing lines and rect-\\nangles using OpenCV.\\nAs you can see, drawing a line is quite simple!\\nBut\\nthere is one other important argument to consider in the\\ncv2.line method: the thickness.\\nOn Lines 10-13 we deﬁne a red color as a tuple (again,\\nin BGR rather than RGB format). We then draw a red line\\nfrom the top-right corner of the image to the bottom left.\\nThe last parameter to the method controls the thickness of\\nthe line – we decide to make the thickness 3 pixels. Again,\\nwe show our image and wait for a keypress.\\nDrawing a line was simple enough. Now we can move on\\nto drawing rectangles. Check out the code below for more\\ndetails:\\nListing 5.3: drawing.py\\n14 cv2.rectangle(canvas, (10, 10), (60, 60), green)\\n15 cv2.imshow(\"Canvas\", canvas)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 46}, page_content='5.1 lines and rectangles\\n16 cv2.waitKey(0)\\n17\\n18 cv2.rectangle(canvas, (50, 200), (200, 225), red, 5)\\n19 cv2.imshow(\"Canvas\", canvas)\\n20 cv2.waitKey(0)\\n21\\n22 blue = (255, 0, 0)\\n23 cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)\\n24 cv2.imshow(\"Canvas\", canvas)\\n25 cv2.waitKey(0)\\nOn Line 14 we make use of the cv2.rectangle method.\\nThe signature of this method is identical to the cv2.line\\nmethod above, but let’s explore each argument anyway.\\nThe ﬁrst argument is the image we want to draw our rect-\\nangle on. We want to draw on our canvas, so we pass it into\\nthe method. The second argument is the starting (x, y) po-\\nsition of our rectangle – here, we are starting our rectangle\\nat point (10, 10). Then, we must provide an ending (x, y)\\npoint for the rectangle. We decide to end our rectangle at\\n(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also\\ncontrol the thickness of a rectangle. Line 18 provides one\\nadded argument: the thickness. Here, we draw a red rect-\\nangle that is 5 pixels thick, starting from point (50, 200) and\\nending at (200, 225).\\nAt this point, we have only drawn the outline of a rect-\\nangle. How do we draw a rectangle that is “ﬁlled in”, like\\nwhen using NumPy array slices in Chapter 4?\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 47}, page_content='5.2 circles\\nFigure 5.2: Drawing a simple bullseye with the\\ncv2.circle function.\\nSimple. We just pass in a negative value for the thickness\\nargument.\\nLine 23 demonstrates how to draw a rectangle of a solid\\ncolor. We draw a blue rectangle, starting from (200, 50) and\\nending at (225, 125). By specifying -1 as the thickness, our\\nrectangle is drawn as a solid blue.\\nCongratulations! You now have a solid grasp of drawing\\nrectangles. In the next section, we’ll move on to drawing\\ncircles.\\n5.2\\ncircles\\nDrawing circles is just as simple as drawing rectangles, but\\nthe function arguments are a little different. Let’s go ahead\\nand get started:\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 48}, page_content='5.2 circles\\nListing 5.4: drawing.py\\n26 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\n27 (centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\\n28 white = (255, 255, 255)\\n29\\n30 for r in range(0, 175, 25):\\n31\\ncv2.circle(canvas, (centerX, centerY), r, white)\\n32\\n33 cv2.imshow(\"Canvas\", canvas)\\n34 cv2.waitKey(0)\\nOn Line 26 we re-initialize our canvas to be blank. The\\nrectangles are gone! We need a fresh canvas to draw our\\ncircles.\\nLine 27 calculates two variables: centerX and centerY.\\nThese two variables represent the (x, y) coordinates of the\\ncenter of the image. We calculate the center by examining\\nthe shape of our NumPy array, and then dividing by two.\\nThe height of the image can be found in canvas.shape[0]\\nand the width in canvas.shape[1]. Finally, Line 28 deﬁnes\\na white pixel.\\nNow, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.\\nLine 31 handles the actual drawing of the circle. The ﬁrst\\nparameter is our canvas, the image we want to draw the\\ncircle on. We then need to supply the point in which our\\ncircle will be drawn around. We pass in a tuple of (centerX,\\ncenterY) so that our circles will be centered at the middle\\nof the image. The third argument is the radius of the circle\\nwe wish to draw. Finally, we pass in the color of our circle,\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 49}, page_content='5.2 circles\\nin this case, white.\\nLines 33 and 34 then show our image and wait for a key-\\npress.\\nSo what does our image look like?\\nCheck out Figure 5.2 and you will see that we have drawn\\na simple bullseye! The “dot” in the very center of the image\\nis drawn with a radius of 0. The larger circles are drawn\\nwith every increasing radii sizes from our for loop.\\nNot too bad. But what else can we do?\\nLet’s do some abstract drawing:\\nListing 5.5: drawing.py\\n35 for i in range(0, 25):\\n36\\nradius = np.random.randint(5, high = 200)\\n37\\ncolor = np.random.randint(0, high = 256, size = (3,)).tolist\\n()\\n38\\npt = np.random.randint(0, high = 300, size = (2,))\\n39\\n40\\ncv2.circle(canvas, tuple(pt), radius, color, -1)\\n41\\n42 cv2.imshow(\"Canvas\", canvas)\\n43 cv2.waitKey(0)\\nOur code starts off on Line 35 with more looping. This\\ntime we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through the np.random.\\nrandint function.\\nIn order to draw a random circle, we need to generate\\nthree values: the radius of the circle, the color of the circle,\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 50}, page_content='5.2 circles\\nFigure 5.3: The results of our masterpiece. No-\\ntice that each circle is randomly\\nplaced on the canvas with a random\\ncolor.\\nand the pt – the (x, y) coordinate of where the circle will be\\ndrawn.\\nWe generate a radius value in the range [5, 200) on Line\\n36. This value controls how large our circle will be.\\nNext, we randomly generate a color on Line 37. As we\\nknow, the color of an RGB pixel consists of three values in\\nthe range [0, 255]. In order to get three random integers\\nrather than only one integer, we pass the keyword argu-\\nment size=(3,), instructing NumPy to return a list of three\\nnumbers.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 51}, page_content='5.2 circles\\nFinally, we need an (x, y) point to draw our circle. We’ll\\ngenerate a point in the range [0, 300), again using NumPy’s\\nnp.random.randint function.\\nThe drawing of our circle then takes place on Line 40,\\nusing the radius, color, and pt that we randomly gener-\\nated. Notice how we use a thickness of -1, so our circles\\nare drawn as a solid color and not just an outline.\\nOur masterpiece is then shown to us on Lines 42 and 43.\\nYou can check out our work in Figure 5.3. Notice how\\neach circle has a different size, color, and placement on our\\ncanvas.\\nIn this chapter, you were introduced to basic drawing\\nfunctions using OpenCV. We explored how to draw shapes\\nusing the cv2.line, cv2.rectangle, and cv2.circle meth-\\nods.\\nWhile these functions seem extremely basic and simple,\\nmake sure you understand them! They are essential build-\\ning blocks that will come in handy later in this book.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 52}, page_content='5.2 circles\\nFurther Reading\\nWhy are we bothering learning how to draw rectangles,\\ncircles, and lines in a book on computer vision and im-\\nage processing?\\nIsn’t the point of computer vision to write software that\\nunderstands the contents of an image? And if so, why\\nin the world do we need to know how to draw various\\nshapes on images?\\nThese are excellent questions – and I address each of\\nthem (and provide examples of how drawing methods\\nare used in object detection and extraction) in side the\\nChapter 5 supplementary material:\\nhttp://pyimg.co/rlpak\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 53}, page_content='6\\nI M A G E P R O C E S S I N G\\nNow that you have a solid foundation to build upon, we\\ncan start to exploring simple image processing techniques.\\nFirst, we’ll start off with basic image transformations,\\nsuch as translation, rotation, resizing, ﬂipping, and crop-\\nping. Then, we’ll explore other types of image processing\\ntechniques, including image arithmetic, bitwise operations,\\nand masking.\\nFinally, we’ll explore how to split an image into its re-\\nspective channels and then merge them back together again.\\nWe’ll conclude this chapter with a discussion of different\\ncolor spaces that OpenCV supports and the beneﬁts and\\nlimitations of each of them.\\n6.1\\nimage transformations\\nIn this section, we’ll cover basic image transformations. These\\nare common techniques that you’ll likely apply to images,\\nincluding translation, rotation, resizing, ﬂipping, and crop-\\nping. We’ll explore each of these techniques in detail.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 54}, page_content='6.1 image transformations\\nMake sure you have a good grasp of these methods! They\\nare important in nearly all areas of computer vision.\\n6.1.1\\nTranslation\\nThe ﬁrst method we are going to explore is translation.\\nTranslation is the shifting of an image along the x and y\\naxis. Using translation, we can shift an image up, down,\\nleft, or right, along with any combination of the above!\\nThis concept is better explained through some code:\\nListing 6.1: translation.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8\\nhelp = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 M = np.float32([[1, 0, 25], [0, 1, 50]])\\n15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])\\n19 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n20 cv2.imshow(\"Shifted Up and Left\", shifted)\\nOn Lines 1-4, we simply import the packages we will\\nmake use of.\\nAt this point, using numpy, argparse, and\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 55}, page_content='6.1 image transformations\\ncv2 should feel commonplace already. However, I am intro-\\nducing a new package here: imutils. This isn’t a package\\nincluded in NumPy or OpenCV. Rather, it’s a library that\\nwe are going to write ourselves and create “convenience”\\nmethods to do common tasks like translation, rotation, and\\nresizing.\\nAfter we have the necessary packages imported, we con-\\nstruct our argument parser and load our image on Lines\\n6-12.\\nThe actual translation takes place on Lines 14-16. We ﬁrst\\ndeﬁne our translation matrix M. This matrix tells us how\\nmany pixels to the left or right, and up or down, the image\\nwill be shifted.\\nOur translation matrix M is deﬁned as a ﬂoating point\\narray – this is important because OpenCV expects this ma-\\ntrix to be of ﬂoating point type. The ﬁrst row of the matrix\\nis [1, 0, tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to\\nthe right.\\nThen, we deﬁne the second row of the matrix as [0, 1, ty],\\nwhere ty is the number of pixels we will shift the image up\\nor down. Negative value of ty will shift the image up and\\npositive values will shift the image down.\\nUsing this notation, we can see on Line 14 that tx = 25\\nand ty = 50, implying that we are shifting the image 25 pix-\\nels to the right and 50 pixels down.\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 56}, page_content='6.1 image transformations\\nNow that we have our translation matrix deﬁned, the\\nactual translation takes place on Line 15 using the cv2.\\nwarpAffine function. The ﬁrst argument is the image we\\nwish to shift and the second argument is our translation ma-\\ntrix M. Finally, we manually supply the dimensions (width\\nand height) of our image as the third argument. Line 16\\nshows the results of the translation.\\nMoving on to Lines 18-20, we perform another transla-\\ntion. Here, we set tx = −50 and ty = −90, implying that\\nwe are shifting the image 50 pixels to the left and 90 pixels\\nup. The image is shifted left and up rather than right and\\ndown, because we are providing a negative values for both\\ntx and ty.\\nHowever, manually constructing this translation matrix\\nand calling the cv2.warpAffine method takes a fair amount\\nof code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently\\ncall them without writing a lot of code.\\nThe ﬁrst method we are going to deﬁne is a translate\\nfunction:\\nListing 6.2: imutils.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 def translate(image, x, y):\\n5\\nM = np.float32([[1, 0, x], [0, 1, y]])\\n6\\nshifted = cv2.warpAffine(image, M, (image.shape[1], image.\\nshape[0]))\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 57}, page_content='6.1 image transformations\\n7\\n8\\nreturn shifted\\nOur translate method takes three parameters: the image\\nwe are going to translate, the number of pixels that we are\\ngoing to shift along the x-axis, and the number of pixels we\\nare going to shift along the y-axis.\\nThis method then deﬁnes our translation matrix M on\\nLine 5 and then applies the actual shift on Line 6. Finally,\\nwe return the shifted image on Line 8.\\nLet’s apply our translate method and compare to the\\nmethods discussed above:\\nListing 6.3: translation.py\\n21 shifted = imutils.translate(image, 0, 100)\\n22 cv2.imshow(\"Shifted Down\", shifted)\\n23 cv2.waitKey(0)\\nUsing our convenience translate method, we are able\\nto shift the image 100 pixels down using a single line of\\ncode. Furthermore, this translate method is much easier\\nto use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.\\nOur original image is on the top-left. On the top-right, we\\nshift our image 25 pixels to the right and 50 pixels down.\\nNext, we translate our image 50 pixels to the left and 90\\npixels up by using negative values for tx and ty. Finally, on\\nthe bottom-right, we shift our T-Rex 100 pixels down using\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 58}, page_content='6.1 image transformations\\nFigure 6.1: Top-Left: Our original T-Rex image.\\nTop-Right: Translating our image 25\\npixels to the right and 50 pixels\\ndown.\\nBottom-Left:\\nShifting T-Rex\\n50 pixels to the left and 90 pix-\\nels up.\\nBottom-Right:\\nShifting the\\nT-Rex down using our convenience\\nmethod.\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 59}, page_content='6.1 image transformations\\nour convenient translate method deﬁned above.\\nIn this section we explored how to shift an image up,\\ndown, left, and right. Next up, we’ll explore how to rotate\\nan image.\\n6.1.2\\nRotation\\nRotation is exactly what it sounds like: rotating an image\\nby some angle θ. In this section, we’ll explore how to rotate\\nan image. We’ll use θ to represent by how many degrees\\nwe are rotating the image. Later, I’ll provide another con-\\nvenience method, rotate, to make performing rotations on\\nimages easier.\\nListing 6.4: rotate.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8\\nhelp = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))\\n19 cv2.imshow(\"Rotated by 45 Degrees\", rotated)\\n20\\n21 M = cv2.getRotationMatrix2D(center, -90, 1.0)\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 60}, page_content='6.1 image transformations\\n22 rotated = cv2.warpAffine(image, M, (w, h))\\n23 cv2.imshow(\"Rotated by -90 Degrees\", rotated)\\nLines 1-4 again import the packages we need. You should\\ntake note of imutils. Once again, we will be deﬁning a con-\\nvenience method to make our lives easier.\\nLines 6-12 construct our argument parser. We only need\\none argument: the path to the image we are going to use.\\nWe then load our image off disk and display it.\\nWhen we rotate an image, we need to specify around\\nwhich point we want to rotate. In most cases, you will want\\nto rotate around the center of an image; however, OpenCV\\nallows you to specify any arbitrary point you want to rotate\\naround. Let’s just go ahead and rotate around the center of\\nthe image. Lines 14 and 15 grabs the width and height of\\nthe image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “//”\\nto ensure we receive whole integer numbers.\\nJust as we deﬁned a matrix to translate an image, we\\nalso deﬁne a matrix to rotate the image. Instead of manu-\\nally constructing the matrix using NumPy, we’ll just make\\na call to the cv2.getRotationMatrix2D method on Line 17.\\nThe cv2.getRotationMatrix2D function takes three argu-\\nments: the point at which we want to rotate the image\\naround (in this case, the center of the image). We then\\nspecify θ, the number of degrees we are going to rotate the\\nimage by. In this case, we are going to rotate the image 45\\ndegrees. The last argument is the scale of the image. We\\nhaven’t discussed resizing an image yet, but here you can\\nspecify a ﬂoating point value, where 1.0 means the same di-\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 61}, page_content='6.1 image transformations\\nmensions of the image are used. However, if you speciﬁed\\na value of 2.0 the image would be doubled in size. Similarly,\\na value of 0.5 halves the size of the image.\\nOnce we have our rotation matrix M from the cv2.getRot\\nationMatrix2D function, we can apply the rotation to our\\nimage using the cv2.warpAffine method on Line 18. The\\nﬁrst argument to this function is the image we want to ro-\\ntate. We then specify our rotation matrix M along with the\\noutput dimensions (width and height) of our image. Line\\n19 then shows our image rotated by 45 degrees. Check out\\nFigure 6.2 Top-Right to see our rotated image.\\nLet’s not waste any time. We’ll go ahead and jump into\\nsome code to perform rotations:\\nOn Lines 21-23, we perform another rotation. The code\\nis identical to that in Lines 17-19, only this time we are ro-\\ntating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-\\nage isn’t the most pretty and Pythonic. Let’s change that\\nand deﬁne our own custom rotate method:\\nListing 6.5: imutils.py\\n27 def rotate(image, angle, center = None, scale = 1.0):\\n28\\n(h, w) = image.shape[:2]\\n29\\n30\\nif center is None:\\n31\\ncenter = (w // 2, h // 2)\\n32\\n33\\nM = cv2.getRotationMatrix2D(center, angle, scale)\\n34\\nrotated = cv2.warpAffine(image, M, (w, h))\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 62}, page_content='6.1 image transformations\\nFigure 6.2: Top-Left: Our original T-Rex image.\\nTop-Right: Rotating the image by 45\\ndegrees.\\nBottom-Left:\\nRotating the\\nimage by −90 degrees. Bottom-Right:\\nFlipping T-Rex upside down by rotat-\\ning the image by 180 degrees.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 63}, page_content='6.1 image transformations\\n35\\n36\\nreturn rotated\\nOur rotate method takes four arguments. The ﬁrst is\\nour image. The second is the angle θ in which we want\\nto rotate the image. We provide two optional keyword ar-\\nguments, center and scale. The center parameter is the\\npoint which we wish to rotate our image around. If a value\\nof None is provided, the method automatically determines\\nthe center of the image on Lines 30-31. Finally, the scale\\nparameter is used to handle if the size of the image should\\nbe changed during the rotation. The scale parameter has\\na default value of 1.0, implying that no resizing should be\\ndone.\\nThe actual rotation of the image takes place on Lines 33\\nand 34, where we construct our rotation matrix M and ap-\\nply it to the image. Finally, our image is returned on Line\\n36.\\nNow that we have deﬁned our rotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)\\nHere, we are rotating our image by 180 degrees.\\nFig-\\nure 6.2 Bottom-Right shows that our T-Rex has indeed been\\nﬂipped upside down. The code for our rotate method is\\nmuch easier to read and maintain than making calls to\\ncv2.getRotationMatrix2D and cv2.warpAffine each time\\nwe want to rotate an image.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 64}, page_content='6.1 image transformations\\n6.1.3\\nResizing\\nSo far we’ve covered two image transformations: transla-\\ntion and rotation. Now, we are going to explore how to\\nresize an image. We’ll also deﬁne one last method for our\\nimutils.py ﬁle, a convenience method to help us resize im-\\nages with ease.\\nPerhaps, not surprisingly, we will be using the cv2.resize\\nfunction to resize our images. But we need to keep in mind\\nthe aspect ratio of the image when we are using this func-\\ntion. Before we get too deep into the details, let’s jump right\\ninto an example:\\nListing 6.7: resize.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8\\nhelp = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n18 cv2.imshow(\"Resized (Width)\", resized)\\nLines 1-12 should start to feel quite redundant at this\\npoint. We are importing our packages, setting up our argu-\\nment parser, and ﬁnally loading our image and displaying\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 65}, page_content='6.1 image transformations\\nit.\\nThe actual interesting code doesn’t start until Lines 14\\nand 15. When resizing an image, we need to keep in mind\\nthe aspect ratio of the image. The aspect ratio is the propor-\\ntional relationship of the width and the height of the image.\\nIf we aren’t mindful of the aspect ratio, our resizing will\\nreturn results that don’t look correct.\\nComputing the aspect ratio is handled on Line 14. In\\nthis line of code, we deﬁne our new image width to be 150\\npixels. In order to compute the ratio of the new height to\\nthe old height, we simply deﬁne our ratio r to be the new\\nwidth (150 pixels) divided by the old width, which we ac-\\ncess using image.shape[1].\\nNow that we have our ratio, we can compute the new di-\\nmensions of the image on Line 15. Again, the width of the\\nnew image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.\\nThe ﬁrst argument is the image we wish to resize and the\\nsecond is our computed dimensions for the new image.The\\nlast parameter is our interpolation method, which is the\\nalgorithm working behind the scenes to handle how the\\nactual image is resized. In general, I ﬁnd that using cv2.\\nINTER_AREA obtains the best results when resizing; how-\\never, other appropriate choices include cv2.INTER_LINEAR,\\ncv2.INTER_CUBIC, and cv2.INTER_NEAREST.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 66}, page_content='6.1 image transformations\\nFinally, we show our resized image on Line 18.\\nIn the example we just explored, we only resized the im-\\nage by specifying the width.\\nBut what if we wanted to\\nresize the image by specifying the height? All that requires\\nis a change to computing the aspect ratio:\\nListing 6.8: resize.py\\n19 r = 50.0 / image.shape[0]\\n20 dim = (int(image.shape[1] * r), 50)\\n21\\n22 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n23 cv2.imshow(\"Resized (Height)\", resized)\\n24 cv2.waitKey(0)\\nOn Line 19 we deﬁne our ratio r. Our new image will\\nhave a height of 50 pixels. To determine the ratio of the new\\nheight to the old height, we divide 50 by the old height.\\nThen, we deﬁne the dimensions of our new image. We\\nalready know that the new image will have a height of 50\\npixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.\\nResizing an image is simple enough, but having to com-\\npute the aspect ratio, deﬁne the dimensions of the new im-\\nage, and then perform the resizing takes three lines of code.\\nThis looks like the perfect time to deﬁne a resize method\\nin our imutils.py ﬁle:\\nListing 6.9: resize.py\\n25 resized = imutils.resize(image, width = 100)\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 67}, page_content='6.1 image transformations\\n26 cv2.imshow(\"Resized via Function\", resized)\\n27 cv2.waitKey(0)\\nIn this example, you can see that the resizing of the im-\\nage is handled by a single function: imutils.resize. The\\nﬁrst argument we pass in is the image we want to resize.\\nThen, we specify the keyword argument width, which is\\nthe width of our new image. The function then handles the\\nresizing for us.\\nOf course, we can also resize via the height of the image\\nby changing the function call to:\\nListing 6.10: resize.py\\n1\\nresized = imutils.resize(image, height = 50)\\nLet’s take this function apart and see what’s going on un-\\nder the hood:\\nListing 6.11: imutils.py\\n9 def resize(image, width = None, height = None, inter = cv2.\\nINTER_AREA):\\n10\\ndim = None\\n11\\n(h, w) = image.shape[:2]\\n12\\n13\\nif width is None and height is None:\\n14\\nreturn image\\n15\\n16\\nif width is None:\\n17\\nr = height / float(h)\\n18\\ndim = (int(w * r), height)\\n19\\n20\\nelse:\\n21\\nr = width / float(w)\\n22\\ndim = (width, int(h * r))\\n23\\n24\\nresized = cv2.resize(image, dim, interpolation = inter)\\n25\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 68}, page_content='6.1 image transformations\\n26\\nreturn resized\\nAs you can see, we have deﬁned our resize function.\\nThe ﬁrst argument is the image we want to resize. Then, we\\ndeﬁne two keyword arguments, width and height. Both of\\nthese arguments cannot be None, otherwise we won’t know\\nhow to resize the image. We also provide inter, which is\\nour interpolation method and defaults to cv2.INTER_AREA.\\nOn Lines 10 and 11, we deﬁne the dimensions of our new,\\nresized image and grab the dimensions of the original im-\\nage.\\nWe perform a quick check on Lines 13-14 to ensure that\\na numerical value has been provided for either the width\\nor the height.\\nThe computation of the ratio and new, resized image di-\\nmensions are handled on Lines 16-22, depending on whether\\nwe are resizing via width or via height.\\nLine 24 handles the actual resizing of the image, then\\nLine 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.\\nThen, on the Top-Right we have our T-Rex resized to have a\\nwidth of 150 pixels. The Middle-Right image then shows our\\nimage resized to have a height of 50 pixels. Finally, Bottom-\\nRight shows the output of our resize function – the T-Rex\\nis now resized to have a width of 100 pixels using only a\\nsingle line of code.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 69}, page_content='6.1 image transformations\\nFigure 6.3: Top-Left: Our original T-Rex image.\\nTop-Right: The T-Rex resized to have\\na width of 150 pixels. Middle-Right:\\nOur image resized to have a height\\nof 50 pixels. Bottom-Right: Resizing\\nour image to have a width of 100 pix-\\nels using our helper function. In all\\ncases, the aspect ratio of the image is\\nmaintained.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 70}, page_content='6.1 image transformations\\nTranslation, rotation, and resizing are certainly the more\\nchallenging and involved image transformation tasks. The\\nnext two we will explore, ﬂipping and cropping, are sub-\\nstantially easier.\\n6.1.4\\nFlipping\\nNext up on our image transformations to explore is ﬂip-\\nping an image. We can ﬂip an image around either the x or\\ny axis, or even both.\\nIn fact, I think explaining how to ﬂip an image is better\\nexplained by viewing the output of an image ﬂip, before\\nwe get into the code. Check out Figure 6.4 to see our T-Rex\\nimage ﬂipped horizontally, vertically, and both horizontally\\nand vertically at the same time.\\nNow that you see what an image ﬂip looks like, we can\\nexplore the code:\\nListing 6.12: ﬂipping.py\\n1 import argparse\\n2 import cv2\\n3\\n4 ap = argparse.ArgumentParser()\\n5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6\\nhelp = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11\\n12 flipped = cv2.flip(image, 1)\\n13 cv2.imshow(\"Flipped Horizontally\", flipped)\\n14\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 71}, page_content='6.1 image transformations\\nFigure 6.4: Top-Left: Our original T-Rex image.\\nTop-Right: Flipping the T-Rex image\\nhorizontally.\\nBottom-Left:\\nFlipping\\nthe T-Rex vertically.\\nBottom-Right:\\nFlipping the image both horizontally\\nand vertically.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 72}, page_content='6.1 image transformations\\n15 flipped = cv2.flip(image, 0)\\n16 cv2.imshow(\"Flipped Vertically\", flipped)\\n17\\n18 flipped = cv2.flip(image, -1)\\n19 cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\\n20 cv2.waitKey(0)\\nLines 1-10 handle our standard procedure of importing\\nour packages, parsing arguments, and loading our image\\nfrom disk.\\nFlipping an image is accomplished by making a call to\\nthe cv2.flip function on Line 12. The cv2.flip method\\nrequires two arguments: the image we want to ﬂip and a\\nﬂip code that is used to determine how we are going to ﬂip\\nthe image.\\nUsing a ﬂip code value of 1 indicates that we are going\\nto ﬂip the image horizontally, around the y-axis (Line 12).\\nSpecifying a ﬂip code of 0 indicates that we want to ﬂip the\\nimage vertically, around the x-axis (Line 15). Finally, using\\na negative ﬂip code (Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-\\nzontally, vertically, and around both axes.\\nFlipping an image is very simple, perhaps one of the sim-\\nplest examples in this book! Next up, we’ll go over crop-\\nping an image and how to extract regions of an image using\\nNumPy array slices.\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 73}, page_content='6.1 image transformations\\nFigure 6.5: Top: Our original T-Rex image. Bot-\\ntom: Cropping the face of the T-Rex\\nusing NumPy array slices.\\n6.1.5\\nCropping\\nWhen we crop an image, we want to remove the outer parts\\nof the image that we are not interested in. We can accom-\\nplish image cropping by using NumPy array slicing. In fact,\\nwe already performed image cropping in Chapter 4!\\nHowever, let’s review it again and make sure we under-\\nstand what is going on:\\nListing 6.13: crop.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 74}, page_content='6.1 image transformations\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 cropped = image[30:120 , 240:335]\\n14 cv2.imshow(\"T-Rex Face\", cropped)\\n15 cv2.waitKey(0)\\nLines 1-11 handle importing our packages, parsing our\\narguments, and loading our images. For our cropping ex-\\nample, we will use our T-Rex image.\\nThe actual cropping takes place on a single line of code:\\nLine 13. We are supplying NumPy array slices to extract\\na rectangular region of the image, starting at (240, 30) and\\nending at (335, 120).\\nThe order in which we supply the\\nindexes to the crop may seem counterintuitive; however, re-\\nmember that OpenCV represents images as NumPy arrays\\nwith the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:\\n1. Start y: The starting y coordinate. In this case, we\\nstart at y = 30.\\n2. End y: The ending y coordinate. We will end our crop\\nat y = 120.\\n3. Start x: The starting x coordinate of the slice. We start\\nthe crop at x = 240.\\n63'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 75}, page_content='6.2 image arithmetic\\n4. End x: The ending x-axis coordinate of the slice. Our\\nslice ends at x = 335.\\nExecuting our code detailed above, we will see from Fig-\\nure 6.5 that we have cropped out the face of our T-Rex!\\nWhile the T-Rex might seem a little scary, cropping sure\\nisn’t! In fact, it’s quite simple when you consider all we are\\ndoing is performing array slices on NumPy arrays.\\n6.2\\nimage arithmetic\\nWe all know basic arithmetic operations like addition and\\nsubtraction. But when working with images, we need to\\nkeep in mind the limits of our color space and data type.\\nFor example, RGB images have pixels that fall within the\\nrange [0, 255]. So what happens if we are examining a pixel\\nwith intensity 250 and we try to add 10 to it?\\nUnder normal arithmetic rules, we would end up with a\\nvalue of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check\\nof some sort to ensure no pixel falls outside the range of\\n[0, 255], thus clipping all pixels to have a minimum value of\\n0 and a maximum value of 255?\\nOr do we apply a modulus operation, and “wrap around”?\\nUnder modulus rules, adding 10 to 250 would simply wrap\\naround to a value of 4.\\n64'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 76}, page_content='6.2 image arithmetic\\nWhich way is the “correct” way to handle image addi-\\ntions and subtractions that fall outside the range of [0, 255]?\\nThe answer is there is no correct way – it simply depends\\non how you are manipulate your pixels and what you want\\nthe desired results to be.\\nHowever, be sure to keep in mind that there is a differ-\\nence between OpenCV and NumPy addition. NumPy will\\nperform modulo arithmetic and “wrap around”. OpenCV,\\non the other hand, will perform clipping and ensure pixel\\nvalues never fall outside the range [0, 255].\\nBut don’t worry! These nuances will become clearer as\\nwe explore some code below.\\nListing 6.14: arithmetic.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8\\nhelp = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 print(\"max of 255: {}\".format(cv2.add(np.uint8([200]), np.uint8\\n([100]))))\\n15 print(\"min of 0: {}\".format(cv2.subtract(np.uint8([50]), np.uint8\\n([100]))))\\n16\\n17 print(\"wrap around: {}\".format(np.uint8([200]) + np.uint8([100]))\\n)\\n18 print(\"wrap around: {}\".format(np.uint8([50]) - np.uint8([100])))\\n65'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 77}, page_content='6.2 image arithmetic\\nWe are going to perform our standard procedure on Lines\\n1-12 by importing our packages, setting up our argument\\nparser, and loading our image.\\nRemember how I mentioned the difference between OpenCV\\nand NumPy addition above? Well, now we are going to ex-\\nplore it further and provide a concrete example to ensure\\nwe fully understand it.\\nOn Line 14, we deﬁne two NumPy arrays that are 8-\\nbit unsigned integers. The ﬁrst array has one element: a\\nvalue of 200. The second array also has only one element,\\nbut with a value of 100. We then use OpenCV’s cv2.add\\nmethod to add the values together.\\nWhat do you think the output is going to be?\\nWell, according to standard arithmetic rules, we would\\nthink the result should be 300, but, remember that we are\\nworking with 8-bit unsigned integers that only have a range\\nbetween [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-\\necute this code, we can see the result on the ﬁrst line of\\nListing 6.15. Sure enough, the addition returned a value of\\n255.\\nLine 15 then performs subtraction using cv2.subtract.\\nAgain, we deﬁne two NumPy arrays, each with a single ele-\\nment, and of the 8-bit unsigned integer data type. The ﬁrst\\narray has a value of 50 and the second a value of 100.\\n66'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 78}, page_content='6.2 image arithmetic\\nAccording to our arithmetic rules, the subtraction should\\nreturn a value of −50; however, OpenCV once again per-\\nforms clipping for us. We ﬁnd that the value is clipped to a\\nvalue of 0. The second line of Listing 6.15 veriﬁes this: sub-\\ntracting 100 from 50 using cv2.subtract returns a value of\\n0.\\nListing 6.15: arithmetic.py\\nmax of 255: [[255]]\\nmin of 0: [[0]]\\nBut what happens if we use NumPy to perform the arith-\\nmetic instead of OpenCV?\\nLine 17 and 18 explore this question.\\nFirst, we deﬁne two NumPy arrays, each with a single\\nelement, and of the 8-bit unsigned integer data type. The\\nﬁrst array has a value of 200, and the second has a value\\nof 100. Using the cv2.add function, our addition would be\\nclipped and a value of 255 returned.\\nHowever, NumPy does not perform clipping – it instead\\nperforms modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been\\nreached. You can see this is true via the ﬁrst line of output\\non Listing 6.16.\\nThen, we deﬁne two more NumPy arrays: one has a value\\nof 50 and the other 100. Using the cv2.subtract method,\\nthis subtraction would be clipped to return a value of 0.\\nHowever, we know that NumPy performs modulo arith-\\n67'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 79}, page_content='6.2 image arithmetic\\nmetic rather than clipping. Instead, once 0 is reached dur-\\ning the subtraction, the modulos operations wraps around\\nand starts counting backwards from 255 – thus the result\\non the second line of output on Listing 6.16.\\nListing 6.16: arithmetic.py\\nwrap around: [44]\\nwrap around: [206]\\nWhen performing integer arithmetic, it is important to\\nkeep in mind your desired output.\\nDo you want all values to be clipped if they fall outside\\nthe range [0, 255]? Then use OpenCV’s built-in methods for\\nimage arithmetic.\\nDo you want modulus arithmetic operations and have\\nvalues wrap around if they fall outside the range of [0, 255]?\\nThen simply add and subtract the NumPy arrays as you\\nnormally would.\\nNow that we have explored the caveats of image arith-\\nmetic in OpenCV and NumPy, let’s perform the arithmetic\\non actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)\\n22\\n23 M = np.ones(image.shape, dtype = \"uint8\") * 50\\n24 subtracted = cv2.subtract(image, M)\\n25 cv2.imshow(\"Subtracted\", subtracted)\\n26 cv2.waitKey(0)\\n68'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 80}, page_content='6.2 image arithmetic\\nFigure 6.6: Top-Left: Our original T-Rex image.\\nTop-Right: Adding 100 to every pixel\\nin the image. Notice how the image\\nlooks more “washed out” and is sub-\\nstantially brighter than the original.\\nBottom:\\nSubtracting 50 from every\\npixel in the image. Notice that the\\nimage is now darker than the origi-\\nnal.\\n69'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 81}, page_content='6.2 image arithmetic\\nLine 19 deﬁnes a NumPy array of ones, with the same\\nsize as our image. Again, we are sure to use 8-bit unsigned\\nintegers as our data type. In order to ﬁll our matrix with\\nvalues of 100’s rather than 1’s, we simply multiply our ma-\\ntrix of 1’s by 100. Finally, we use the cv2.add function to\\nadd our matrix of 100’s to the original image – thus increas-\\ning every pixel intensity in the image by 100, but ensuring\\nall values are clipped to the range [0, 255] if they attempt to\\nexceed 255.\\nThe result of our operation can be found in Figure 6.6\\nTop-Right. Notice how the image looks more “washed out”\\nand is substantially brighter than the original. This is be-\\ncause we are increasing the pixel intensities by adding 100\\nto them and pushing them towards brighter colors.\\nWe then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image\\nin Figure 6.6 shows the results of this subtraction. Our im-\\nage now looks considerably darker than the original T-Rex.\\nPixels that were once white now look gray. This is because\\nwe are subtracting 50 from the pixels and pushing them to-\\nwards the darker regions of the RGB color space.\\nIn this section, we explored the peculiarities of image\\narithmetic using OpenCV and NumPy. These caveats are\\nimportant to keep in mind, otherwise you may get unwanted\\nresults when performing arithmetic operations on your im-\\nages.\\n70'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 82}, page_content='6.3 bitwise operations\\n6.3\\nbitwise operations\\nNow we will review four bitwise operations: AND, OR,\\nXOR, and NOT. These four operations, while very basic\\nand low level, are paramount to image processing, espe-\\ncially when we start working with masks in Section 6.4.\\nBitwise operations operate in a binary manner and are\\nrepresented as grayscale images. A given pixel is turned\\n“off” if it has a value of zero, and it is turned “on” if the\\npixel has a value greater than zero.\\nLet’s go ahead and jump into some code:\\nListing 6.18: bitwise.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 rectangle = np.zeros((300, 300), dtype = \"uint8\")\\n5 cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\\n6 cv2.imshow(\"Rectangle\", rectangle)\\n7\\n8 circle = np.zeros((300, 300), dtype = \"uint8\")\\n9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2.\\nWe initialize our rectangle image\\nas a 300 × 300 NumPy array on Line 4. We then draw a\\n250 × 250 white rectangle at the center of the image.\\nSimilarly, on Line 8, we initialize another image to con-\\ntain our circle, which we draw on Line 9, again centered at\\nthe center of the image, with a radius of 150 pixels.\\n71'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 83}, page_content='6.3 bitwise operations\\nFigure 6.7: Left: Our rectangle image. Right: Our\\ncircle image.\\nWe will explore how\\nthese two images can be combined\\nusing bitwise operations.\\nFigure 6.7 shows our two shapes. We will make use of\\nthese shapes to demonstrate our bitwise operations:\\nListing 6.19: bitwise.py\\n11 bitwiseAnd = cv2.bitwise_and(rectangle, circle)\\n12 cv2.imshow(\"AND\", bitwiseAnd)\\n13 cv2.waitKey(0)\\n14\\n15 bitwiseOr = cv2.bitwise_or(rectangle, circle)\\n16 cv2.imshow(\"OR\", bitwiseOr)\\n17 cv2.waitKey(0)\\n18\\n19 bitwiseXor = cv2.bitwise_xor(rectangle, circle)\\n20 cv2.imshow(\"XOR\", bitwiseXor)\\n21 cv2.waitKey(0)\\n22\\n23 bitwiseNot = cv2.bitwise_not(circle)\\n24 cv2.imshow(\"NOT\", bitwiseNot)\\n25 cv2.waitKey(0)\\n72'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 84}, page_content='6.3 bitwise operations\\nAs I mentioned above, a given pixel is turned “on” if it\\nhas a value greater than zero, and it is turned “off” if it has\\na value of zero. Bitwise functions operate on these binary\\nconditions.\\nIn order to utilize bitwise functions, we assume (in most\\ncases) that we are comparing two pixels (the only exception\\nis the NOT function). We’ll compare each of the pixels and\\nthen construct our bitwise representation.\\nLet’s quickly review our binary operations:\\n1. AND: A bitwise AND is true if and only if both pixels\\nare greater than zero.\\n2. OR: A bitwise OR is true if either of the two pixels\\nare greater than zero.\\n3. XOR: A bitwise XOR is true if and only if either of the\\ntwo pixels are greater than zero, but not both.\\n4. NOT: A bitwise NOT inverts the “on” and “off” pixels\\nin an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if\\nboth pixels are greater than zero. The output of our bitwise\\nAND can be seen in Figure 6.8 Top-Left. We can see that\\nedges of our square are lost – this makes sense because our\\nrectangle does not cover as large of an area as the circle,\\nand thus both pixels are not “on”.\\n73'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 85}, page_content='6.4 masking\\nWe then apply a bitwise OR on Line 15 using the cv2.\\nbitwise_or function. A bitwise OR is true if either of the\\ntwo pixels are greater than zero. Figure 6.8 Top-Right shows\\nthe output of our bitwise OR. In this case, our square and\\nrectangle have been combined together.\\nNext up is the bitwise XOR function, applied on Line 19\\nusing the cv2.bitwise_xor function.\\nAn XOR operation\\nis true if both pixels are greater than zero, but both pixels\\ncannot be greater than zero. The output of the XOR oper-\\nation is displayed on Figure 6.8 Bottom-Right. Here we see\\nthat the center of the square has been removed. Again, this\\nmakes sense because an XOR operation cannot have both\\npixels greater than zero.\\nFinally, we apply the NOT function on Line 23 using the\\ncv2.bitwise_not function.\\nEssentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are\\nset to 255. Figure 6.8 Bottom-Right ﬂips our white circle to a\\nblack circle.\\nOverall, bitwise functions are extremely simple, yet very\\npowerful. And they are absolutely essential when we start\\nto discuss masking in Section 6.4.\\n6.4\\nmasking\\nIn the previous section, we explored bitwise functions. Now\\nwe are ready to explore masking, an extremely powerful\\nand useful technique in computer vision and image pro-\\n74'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 86}, page_content='6.4 masking\\nFigure 6.8: Top-Left: Applying a bitwise AND to\\nour rectangle and circle image. Top-\\nRight: A bitwise OR applied to our\\nsquare and circle.\\nBottom-Left: An\\nXOR applied to our shapes. Bottom-\\nRight: Flipping pixel values of our\\ncircle using a bitwise NOT.\\n75'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 87}, page_content='6.4 masking\\ncessing.\\nUsing a mask allows us to focus only on the portions of\\nthe image that interests us.\\nFor example, let’s say that we were building a computer\\nvision system to recognize faces. The only part of the image\\nwe are interested in ﬁnding and describing are the parts of\\nthe image that contain faces – we simply don’t care about\\nthe rest of the content of the image. Provided that we could\\nﬁnd the faces in the image, we might construct a mask to\\nshow only the faces in the image.\\nLet’s make this example a little more concrete.\\nIn Figure 6.9, we have an image of a beach on the Top-Left.\\nBut I’m not interested in the beach in the image. I’m only\\ninterested in the sky and the palm tree. We could apply a\\ncropping to extract that region of the image. Or, we could\\napply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-\\ning our rectangle mask, we have focused only on the sky\\nand palm tree in the image.\\nLet’s examine the code to accomplish the masking in Fig-\\nure 6.9:\\nListing 6.20: masking.py\\n1 import numpy as np\\n76'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 88}, page_content='6.4 masking\\nFigure 6.9: Top-Left:\\nOur image of a peaceful\\nbeach scene. Top-Right: Our mask im-\\nage – a white rectangle at the center\\nof the image. Bottom: Applying the\\nrectangular mask to the beach image.\\nOnly the parts of the image where\\nthe mask pixels are greater than zero\\nare shown.\\n77'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 89}, page_content='6.4 masking\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n14 (cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\\n15 cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255,\\n-1)\\n16 cv2.imshow(\"Mask\", mask)\\n17\\n18 masked = cv2.bitwise_and(image, image, mask = mask)\\n19 cv2.imshow(\"Mask Applied to Image\", masked)\\n20 cv2.waitKey(0)\\nOn Lines 1-11 we import the packages we need, parse\\nour arguments, and load our image.\\nWe then construct a NumPy array, ﬁlled with zeros, with\\nthe same width and height as our beach image on Line 13.\\nIn order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-\\nsion. Finally, we draw our white rectangle on Line 15.\\nRemember reviewing the cv2.bitwise_and function in\\nthe previous section? It’s a function that is used extensively\\nwhen applying masks to images.\\nWe apply our mask on Line 18 using the cv2.bitwise_\\nand function.\\nThe ﬁrst two parameters are the image it-\\nself. Obviously, the AND function will be True for all pix-\\nels in the image; however, the important part of this func-\\n78'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 90}, page_content='6.4 masking\\ntion is the mask keyword argument. By supplying a mask,\\nthe cv2.bitwise_and function only examines pixels that are\\n“on” in the mask. In this case, only pixels that are part of\\nthe white rectangle.\\nLet’s look at another example:\\nListing 6.21: masking.py\\n21 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n22 cv2.circle(mask, (cX, cY), 100, 255, -1)\\n23 masked = cv2.bitwise_and(image, image, mask = mask)\\n24 cv2.imshow(\"Mask\", mask)\\n25 cv2.imshow(\"Mask Applied to Image\", masked)\\n26 cv2.waitKey(0)\\nOn Line 21 we re-initialize our mask to be ﬁlled with ze-\\nros and the same dimensions as our beach image. Then, we\\ndraw a white circle on our mask image, starting at the cen-\\nter of the image and a radius of 100 pixels. Applying the\\ncircular mask is then performed on Line 23, again using the\\ncv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on\\nthe Bottom. Instead of a rectangular region of the beach be-\\ning shown, we now have a circular region.\\nRight now masking may not seem very interesting. But\\nwe’ll return to it once we start computing histograms in\\nChapter 7. Again, the key point of masks is that they allow\\nus to focus our computation only on regions of the image\\nthat interests us.\\n79'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 91}, page_content='6.4 masking\\nFigure 6.10: Applying the circular mask to the\\nbeach image.\\nOnly pixels within\\nthe circular white region are shown.\\n80'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 92}, page_content='6.5 splitting and merging channels\\n6.5\\nsplitting and merging channels\\nA color image consists of multiple channels: a Red, a Green,\\nand a Blue component. We have seen that we can access\\nthese components via indexing into NumPy arrays.\\nBut\\nwhat if we wanted to split an image into its respective com-\\nponents?\\nAs you’ll see, we’ll make use of the cv2.split function.\\nFor the time being, let’s take a look at a sample image in\\nFigure 6.11.\\nWe have an image of a wave crashing down. This image\\nis very “blue” due to the ocean. How do we interpret the\\ndifferent channels of the image?\\nThe Red channel (Top-Left) is very dark. This makes sense,\\nbecause an ocean scene has very few red colors in it. The\\nred colors present are either very dark, and thus not repre-\\nsented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.\\nFinally, the Blue channel (Bottom-Left) is extremely light,\\nand near pure white in some locations.\\nThis is because\\nshades of blue are heavily represented in our image.\\nNow that we have visualized our channels, let’s examine\\nsome code to accomplish this for us:\\n81'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 93}, page_content='6.5 splitting and merging channels\\nFigure 6.11: The three RGB channels of our\\nwave\\nimage\\nare\\nshown\\non\\nthe\\nBottom-Right. The Red channel is on\\nthe Top-Left, the Green channel on\\nthe Top-Right, and the Blue channel\\non the Bottom-Left.\\n82'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 94}, page_content='6.5 splitting and merging channels\\nListing 6.22: splitting_and_merging.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 (B, G, R) = cv2.split(image)\\n12\\n13 cv2.imshow(\"Red\", R)\\n14 cv2.imshow(\"Green\", G)\\n15 cv2.imshow(\"Blue\", B)\\n16 cv2.waitKey(0)\\n17\\n18 merged = cv2.merge([B, G, R])\\n19 cv2.imshow(\"Merged\", merged)\\n20 cv2.waitKey(0)\\n21 cv2.destroyAllWindows()\\nLines 1-10 imports our packages, sets up our argument\\nparser, and then loads our image. Splitting the channels is\\ndone using a call to cv2.split on Line 11.\\nNormally, we think of images in the RGB color space –\\nthe red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image\\nin RGB order, it instead stores the image in BGR order; thus\\nwe unpack the tuple in reverse order.\\nLines 13-16 then show each channel individually, as in\\nFigure 6.11.\\nWe can also merge the channels back together again us-\\ning the cv2.merge function. We simply specify our chan-\\n83'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 95}, page_content='6.5 splitting and merging channels\\nFigure 6.12: Representing the Red, Green, and\\nBlue channels of our wave image.\\nnels, again in BGR order, and then cv2.merge takes care of\\nthe rest for us (Line 18).\\nListing 6.23: splitting_and_merging.py\\n22 zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\\n23 cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\\n24 cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\\n25 cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\\n26 cv2.waitKey(0)\\nAn alternative method to visualize the channels of an im-\\nage can be seen in Figure 6.12. In order to show the actual\\n“color” of the channel, we ﬁrst need to take apart the image\\nusing cv2.split. Then, we need to re-construct the image,\\nbut this time setting all pixels but the current channel as zero.\\nOn Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-\\nage, we make a call to cv2.merge, but specifying our zeros\\narray for the Green and Blue channels. We take similar ap-\\nproaches to the other channels in Line 24 and 25.\\n84'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 96}, page_content='6.6 color spaces\\n6.6\\ncolor spaces\\nIn this book, we have only explored the RGB color space;\\nhowever, there are many other color spaces that we can uti-\\nlize.\\nThe Hue-Saturation-Value (HSV) color space is more sim-\\nilar to how humans think and conceive of color. Then there\\nis the L*a*b* color space, which is more tuned to how hu-\\nmans perceive color.\\nOpenCV provides support for many, many different color\\nspaces. And understanding how color is perceived by hu-\\nmans and represented by computers occupies an entire li-\\nbrary of literature itself.\\nIn order to not get bogged down in the details, I’ll just\\nshow you how to convert color spaces. If you think your\\napplication of image processing and computer vision might\\nneed a different color space than RGB, I will leave that as\\nan exercise to the reader to explore the peculiarities of each\\ncolor space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n85'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 97}, page_content='6.6 color spaces\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Gray\", gray)\\n15\\n16 hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\\n17 cv2.imshow(\"HSV\", hsv)\\n18\\n19 lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\\n20 cv2.imshow(\"L*a*b*\", lab)\\n21 cv2.waitKey(0)\\nLines 1-11 imports the packages we need, parses our ar-\\nguments, and loads our image. Then, on Line 13, we con-\\nvert our image from the RGB color space to grayscale by\\nspecifying the cv2.COLOR_BGR2GRAY ﬂag.\\nConverting our image to the HSV color space is performed\\non Line 16 by specifying the cv2.COLOR_BGR2HSV ﬂag. Fi-\\nnally, on Line 19, we convert to the L*a*b* color space by\\nusing the cv2.COLOR_BGR2LAB ﬂag.\\nWe can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.\\nIf you are just getting started in computer vision, it’s likely\\na good idea to stick to the RGB color space for the time\\nbeing. However, I have included this section as a matter\\nof completeness – it’s good to show an example of how to\\nconvert color spaces for when you decide the time is right!\\n86'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 98}, page_content='6.6 color spaces\\nFigure 6.13: Top-Left: An image of beach scenery.\\nTop-Right:\\nThe grayscale represen-\\ntation of the beach image. Bottom-\\nLeft: Converting the beach image to\\nthe HSV color space. Bottom-Right:\\nConverting our image to the L*a*b*\\ncolor space.\\n87'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 99}, page_content='6.6 color spaces\\nFurther Reading\\nChapter 6 is by far the longest chapter in Practical Python\\nand OpenCV – and with good reason. In this chapter,\\nwe covered a lot of important image processing con-\\ncepts that form the foundation on which the rest of\\nyour computer vision education will be built.\\nTo ensure that you have a thorough grasp on these con-\\ncepts, be sure to go through the Chapter 6 supplemen-\\ntary material:\\nhttp://pyimg.co/s3fm7\\n88'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 100}, page_content='7\\nH I S TO G R A M S\\nSo, what exactly is a histogram? A histogram represents\\nthe distribution of pixel intensities (whether color or gray-\\nscale) in an image. It can be visualized as a graph (or plot)\\nthat gives a high-level intuition of the intensity (pixel value)\\ndistribution. We are going to assume an RGB color space in\\nthis example, so these pixel values will be in the range of 0\\nto 255.\\nWhen plotting the histogram, the X-axis serves as our\\n“bins”.\\nIf we construct a histogram with 256 bins, then\\nwe are effectively counting the number of times each pixel\\nvalue occurs. In contrast, if we use only 2 (equally spaced)\\nbins, then we are counting the number of times a pixel is in\\nthe range [0, 128) or [128, 255]. The number of pixels binned\\nto the x-axis value is then plotted on the y-axis.\\nBy simply examining the histogram of an image, you get\\na general understanding regarding the contrast, brightness,\\n89'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 101}, page_content='7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1\\nusing opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms.\\nBefore we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.\\n4. histSize: This is the number of bins we want to use\\nwhen computing a histogram. Again, this is a list, one\\nfor each channel we are computing a histogram for.\\nThe bin sizes do not all have to be the same. Here is\\nan example of 32 bins for each channel: [32,32,32].\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 102}, page_content='7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use the cv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2\\ngrayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet.\\nAll we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Original\", image)\\n91'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 103}, page_content='7.2 grayscale histograms\\n15\\n16 hist = cv2.calcHist([image], [0], None, [256], [0, 256])\\n17\\n18 plt.figure()\\n19 plt.title(\"Grayscale Histogram\")\\n20 plt.xlabel(\"Bins\")\\n21 plt.ylabel(\"# of Pixels\")\\n22 plt.plot(hist)\\n23 plt.xlim([0, 256])\\n24 plt.show()\\n25 cv2.waitKey(0)\\nNow things are getting a little more interesting. On Line\\n13, we convert the image from the RGB colorspace to graysc-\\nale. Line 16 computes the actual histogram. Go ahead and\\nmatch the arguments of the code up with the function docu-\\nmentation above. We can see that our ﬁrst parameter is the\\ngrayscale image. A grayscale image has only one channel,\\nhence we have a value of [0] for channels. We don’t have\\na mask, so we set the mask value to None. We will use 256\\nbins in our histogram, and the possible values range from\\n0 to 256.\\nFinally, a call to plt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the\\nbins (0-255) are plotted on the x-axis. And the y-axis counts\\nthe number of pixels in each bin. The majority of the pixels\\nfall in the range of roughly 60 to 120. Looking at the right\\ntail of the histogram, we see very few pixels in the range\\n200 to 255. This means that there are very few “white” pix-\\nels in the image.\\n92'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 104}, page_content='7.3 color histograms\\nFigure 7.1: Computing a grayscale histogram of\\nour beach image.\\n7.3\\ncolor histograms\\nIn the previous section, we explored grayscale histograms.\\nNow let’s move on to computing a histogram for each chan-\\nnel of the image.\\nListing 7.3: color_histograms.py\\n1 from __future__ import print_function\\n2 from matplotlib import pyplot as plt\\n3 import numpy as np\\n4 import argparse\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9\\nhelp = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 cv2.imshow(\"Original\", image)\\n93'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 105}, page_content='7.3 color histograms\\nAgain, we’ll import the packages that we’ll need, utiliz-\\ning matplotlib once more to plot the histograms.\\nLet’s examine some code:\\nListing 7.4: color_histograms.py\\n14 chans = cv2.split(image)\\n15 colors = (\"b\", \"g\", \"r\")\\n16 plt.figure()\\n17 plt.title(\"’Flattened’ Color Histogram\")\\n18 plt.xlabel(\"Bins\")\\n19 plt.ylabel(\"# of Pixels\")\\n20\\n21 for (chan, color) in zip(chans, colors):\\n22\\nhist = cv2.calcHist([chan], [0], None, [256], [0, 256])\\n23\\nplt.plot(hist, color = color)\\n24\\nplt.xlim([0, 256])\\nThe ﬁrst thing we are going to do is split the image into\\nits three channels: blue, green, and red. Normally, we read\\nthis is red, green, blue (RGB). However, OpenCV stores the\\nimage as a NumPy array in reverse order: BGR. This is\\nimportant to note. We then initialize a tuple of strings rep-\\nresenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into\\neach bin on the y-axis.\\nWe then reach a for loop on Line 21, where we start loop-\\ning over each of the channels in the image.\\nThen, for each channel, we compute a histogram on Line\\n22. The code is identical to that of computing a histogram\\nfor the grayscale image; however, we are doing it for each\\nRed, Green, and Blue channel, allowing us to characterize\\n94'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 106}, page_content='7.3 color histograms\\nFigure 7.2: Color\\nhistograms\\nfor\\neach\\nRed,\\nGreen, and Blue channel of the beach\\nimage.\\nthe distribution of pixel intensities. We add our histogram\\nto the plot on Line 23.\\nWe can examine our color histogram in Figure 7.2. We\\nsee there is a sharp peak in the green histogram around bin\\n100. This indicates a darker green value, from the green\\nvegetation and trees in the beach image.\\nWe also see a lot of blue pixels in the range 170 to 225.\\nConsidering these pixels are much lighter, we know that\\nthey are from the blue sky in our beach image. Similarly,\\nwe see a much smaller range of blue pixels in the range 25\\nto 50 – these pixels are much darker, and are therefore the\\nocean pixels in the bottom-left corner of the image.\\nUp until this point, we have computed a histogram for\\nonly one channel at a time.\\nNow we move on to multi-\\ndimensional histograms and take into consideration two\\n95'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 107}, page_content='7.3 color histograms\\nchannels at a time.\\nI like to explain multi-dimensional histograms by using\\nthe word AND.\\nFor example, we can ask a question such as, “How many\\npixels have a Red value of 10 AND a Blue value of 30?”.\\nHow many pixels have a Green value of 200 AND a Red\\nvalue of 130? By using the conjunctive AND, we are able to\\nconstruct multi-dimensional histograms.\\nIt’s that simple. Let’s check out some code to automate\\nthe process of building a 2D histogram:\\nListing 7.5: color_histograms.py\\n25 fig = plt.figure()\\n26\\n27 ax = fig.add_subplot(131)\\n28 hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None,\\n29\\n[32, 32], [0, 256, 0, 256])\\n30 p = ax.imshow(hist, interpolation = \"nearest\")\\n31 ax.set_title(\"2D Color Histogram for G and B\")\\n32 plt.colorbar(p)\\n33\\n34 ax = fig.add_subplot(132)\\n35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36\\n[32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")\\n39 plt.colorbar(p)\\n40\\n41 ax = fig.add_subplot(133)\\n42 hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None,\\n43\\n[32, 32], [0, 256, 0, 256])\\n44 p = ax.imshow(hist, interpolation = \"nearest\")\\n45 ax.set_title(\"2D Color Histogram for B and R\")\\n46 plt.colorbar(p)\\n47\\n48 print(\"2D histogram shape: {}, with {} values\".format(\\n96'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 108}, page_content='7.3 color histograms\\n49\\nhist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using.\\nIn previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a 256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 109}, page_content='7.3 color histograms\\nFigure 7.3: Computing 2D color histograms for\\neach combination of Red, Green, and\\nBlue channels.\\nof red represent large pixel counts (i.e., peaks in the 2D his-\\ntogram). We tend to see many peaks in the Green and Blue\\nhistogram, where x = 22 and y = 12. This corresponds to\\nthe green pixels of the vegetation and trees and the blue of\\nthe sky and ocean.\\nUsing a 2D histogram takes into account two channels at\\na time. But what if we wanted to account for all three RGB\\nchannels? You guessed it. We’re now going to build a 3D\\nhistogram.\\nListing 7.6: color_histograms.py\\n50 hist = cv2.calcHist([image], [0, 1, 2],\\n51\\nNone, [8, 8, 8], [0, 256, 0, 256, 0, 256])\\n52 print(\"3D histogram shape: {}, with {} values\".format(\\n53\\nhist.shape, hist.flatten().shape[0]))\\n54\\n55 plt.show()\\n98'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 110}, page_content='7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4\\nhistogram equalization\\nHistogram equalization improves the contrast of an image\\nby “stretching” the distribution of pixels. Consider a his-\\ntogram with a large peak at the center of it. Applying his-\\ntogram equalization will stretch the peak out towards the\\ncorner of the image, thus improving the global contrast of\\nthe image. Histogram equalization is applied to grayscale\\nimages.\\nThis method is useful when an image contains foregroun-\\nds and backgrounds that are both dark or both light. It\\ntends to produce unrealistic effects in photographs; how-\\never, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n99'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 111}, page_content='7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12\\n13 eq = cv2.equalizeHist(image)\\n14\\n15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\\n16 cv2.waitKey(0)\\nLines 1-10 handle our standard practice of importing pack-\\nages, parsing arguments, and loading our image. We then\\nconvert our image to grayscale on Line 11.\\nPerforming histogram equalization is done using just a\\nsingle function: cv2.equalizeHist, which accepts a single\\nparameter, the grayscale image we want to perform his-\\ntogram equalization on. The last couple lines of code dis-\\nplay our histogram equalized image.\\n100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 112}, page_content='7.5 histograms and masks\\nThe result of applying histogram equalization can be seen\\nin Figure 7.4. On the left, we have our original beach image.\\nThen, on the right, we have our histogram-equalized beach\\nimage. Notice how the contrast of the image has been radi-\\ncally changed and now spans the entire range of [0, 255].\\n7.5\\nhistograms and masks\\nIn Chapter 6, Section 6.4, I mentioned that masks can be\\nused to focus on speciﬁc regions of an image that interest\\nus. We are now going to construct a mask and compute\\ncolor histograms for the masked region only.\\nFirst, we need to deﬁne a convenience function to save us\\nfrom writing repetitive lines of code:\\nListing 7.8: histogram_with_mask.py\\n1 from matplotlib import pyplot as plt\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 def plot_histogram(image, title, mask = None):\\n7\\nchans = cv2.split(image)\\n8\\ncolors = (\"b\", \"g\", \"r\")\\n9\\nplt.figure()\\n10\\nplt.title(title)\\n11\\nplt.xlabel(\"Bins\")\\n12\\nplt.ylabel(\"# of Pixels\")\\n13\\n14\\nfor (chan, color) in zip(chans, colors):\\n15\\nhist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16\\nplt.plot(hist, color = color)\\n17\\nplt.xlim([0, 256])\\n101'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 113}, page_content='7.5 histograms and masks\\nOn Lines 1-4 we import our packages; then on Line 6 we\\ndeﬁne plot_histogram. This function accepts three param-\\neters: an image, the title of our plot, and a mask. The mask\\ndefaults to None if we do not have a mask for the image.\\nThe body of our plot_histogram function simply com-\\nputes a histogram for each channel in the image and plots\\nit, just as in previous examples in this chapter.\\nNow that we have a function to help us easily plot his-\\ntograms, let’s move into the bulk of our code:\\nListing 7.9: histogram_with_mask.py\\n18 ap = argparse.ArgumentParser()\\n19 ap.add_argument(\"-i\", \"--image\", required = True,\\n20\\nhelp = \"Path to the image\")\\n21 args = vars(ap.parse_args())\\n22\\n23 image = cv2.imread(args[\"image\"])\\n24 cv2.imshow(\"Original\", image)\\n25 plot_histogram(image, \"Histogram for Original Image\")\\nLines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot\\nfor our image can be seen in Figure 7.5. We will refer to\\nthis histogram again once we compute a histogram for the\\nmasked region.\\nListing 7.10: histogram_with_mask.py\\n26 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n27 cv2.rectangle(mask, (15, 15), (130, 100), 255, -1)\\n28 cv2.imshow(\"Mask\", mask)\\n29\\n30 masked = cv2.bitwise_and(image, image, mask = mask)\\n31 cv2.imshow(\"Applying the Mask\", masked)\\n102'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 114}, page_content='7.5 histograms and masks\\nFigure 7.5: Left: The original beach image. Right:\\nColor histograms for the red, green,\\nand blue channels.\\nCompare these\\nhistograms to the histograms of the\\nmasked region of blue sky in Figure\\n7.7.\\n103'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 115}, page_content='7.5 histograms and masks\\nFigure 7.6: Left: Our rectangular mask.\\nRight:\\nApplying our mask to the beach im-\\nage using a bitwise AND. Now we\\nsee only the blue sky – the rest of the\\nimage is ignored.\\nNow we are ready to construct a mask for the image. We\\ndeﬁne our mask as a NumPy array, with the same width\\nand height as our beach image on Line 26. We then draw a\\nwhite rectangle starting from point (15, 15) to point (130, 100)\\non Line 27. This rectangle will serve as our mask – only pix-\\nels in our original image belonging to the masked region\\nwill be considered in the histogram computation.\\nTo visualize our mask, we apply a bitwise AND to the\\nbeach image (Line 30), the results of which can be seen in\\nFigure 7.6. Notice how the image on the left is simply a\\nwhite rectangle, but when we apply our mask to the beach\\nimage, we only see the blue sky (right).\\nListing 7.11: histogram_with_mask.py\\n32 plot_histogram(image, \"Histogram for Masked Image\", mask = mask)\\n104'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 116}, page_content='7.5 histograms and masks\\n33\\n34 plt.show()\\nFinally, we compute a histogram for our masked image\\nusing our plot_histogram function and show our results\\n(Lines 32-34).\\nWe can see our masked histogram in Figure 7.7. Most\\nred pixels fall in the range [0, 80], indicating that red pixels\\ncontribute very little to our image. This makes sense, since\\nour sky is blue. Green pixels are then present, but again,\\nare towards the darker end of the RGB spectrum. Finally,\\nour blue pixels fall in the brighter range and are obviously\\nour blue sky.\\nMost importantly, compare our masked color histograms\\nin Figure 7.5 to the unmasked color histograms in Figure\\n7.7 above. Notice how dramatically different the color his-\\ntograms are. By utilizing masks, we are able to apply our\\ncomputation only to the speciﬁc regions of the image that\\ninterest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.\\nHistograms are simple, but are used extensively in image\\nprocessing and computer vision.\\nMake sure you have a\\ngood grasp of histograms; you’ll certainly be using them in\\nthe future!\\n105'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 117}, page_content='7.5 histograms and masks\\nFigure 7.7: The\\nresulting\\nhistogram\\nof\\nthe\\nmasked image in Figure 7.6.\\nRed\\ncontributes little to our image and is\\ntowards the darker end of the spec-\\ntrum. Some lighter green values are\\npresent, and many light blue colors\\ncorrespond to the sky in the image.\\n106'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 118}, page_content='7.5 histograms and masks\\nFurther Reading\\nThe purpose of Chapter 7 was to learn how to extract\\nand visualize color histograms from an image.\\nBut\\nother than simply visualizing the color distributions of\\nan image, what else can we do? What are the actual\\napplications of utilizing color histograms?\\nTo learn how to compare color histograms for similar-\\nity, and even build an image search engine, take a look\\nat the Chapter 7 supplementary page:\\nhttp://pyimg.co/aa4ax\\n107'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 119}, page_content='8\\nS M O O T H I N G A N D B L U R R I N G\\nI’m pretty sure we all know what blurring is. It’s what\\nhappens when your camera takes a picture out of focus.\\nSharper regions in the image lose their detail, normally as\\na disc/circular shape.\\nPractically, this means that each pixel in the image is\\nmixed in with its surrounding pixel intensities. This “mix-\\nture” of pixels in a neighborhood becomes our blurred pixel.\\nWhile this effect is usually unwanted in our photographs,\\nit’s actually quite helpful when performing image process-\\ning tasks.\\nIn fact, many image processing and computer vision func-\\ntions, such as thresholding and edge detection, perform bet-\\nter if the image is ﬁrst smoothed or blurred.\\nIn order to explore different types of blurring methods,\\nlet’s start with a baseline of our original T-Rex image in Fig-\\nure 8.1.\\nListing 8.1: blurring.py\\n108'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 120}, page_content='smoothing and blurring\\nFigure 8.1: Our original T-Rex image before ap-\\nplying any blurring effects.\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nIn order to perform image blurring, we ﬁrst need to im-\\nport our packages and parse our arguments (Lines 1-8). We\\nthen load our image and show it as a baseline to compare\\nour blurring methods to on Lines 10 and 11.\\n109'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 121}, page_content='8.1 averaging\\nNow that our image is loaded, we can start blurring our\\nimages.\\n8.1\\naveraging\\nThe ﬁrst blurring method we are going to explore is averag-\\ning.\\nAs the name suggests, we are going to deﬁne a k × k slid-\\ning window on top of our image, where k is always an odd\\nnumber. This window is going to slide from left-to-right\\nand from top-to-bottom. The pixel at the center of this ma-\\ntrix (we have to use an odd number, otherwise there would\\nnot be a true “center”) is then set to be the average of all\\nother pixels surrounding it.\\nWe call this sliding window a “convolution kernel” or\\njust a “kernel”. We’ll continue to use this terminology throu-\\nghout this chapter.\\nAs we will see, as the size of the kernel increases, the\\nmore blurred our image will become.\\nLet’s check out some code to perform average blurring:\\nListing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13\\ncv2.blur(image, (3, 3)),\\n14\\ncv2.blur(image, (5, 5)),\\n15\\ncv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)\\n17 cv2.waitKey(0)\\n110'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 122}, page_content='8.1 averaging\\nFigure 8.2: Performing averaging blurring with\\na 3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right).\\nIn order to average blur an image, we use the cv2.blur\\nfunction. This function requires two arguments: the image\\nwe want to blur and the size of the kernel. As Lines 13-15\\nshow, we blur our image with increasing-sized kernels. The\\nlarger our kernel becomes, the more blurred our image will\\nappear.\\nWe make use of the np.hstack function to stack our out-\\nput images together. This method “horizontally stacks” our\\nthree images into a row. This is useful since we don’t want\\nto create three separate windows using the cv2.imshow func-\\ntion.\\nThe output of our averaged blur can be seen in Figure 8.2.\\nThe image on the left is barely blurred, but by the time we\\nreach a kernel of size 7 × 7, we see that our T-Rex is very\\nblurry indeed. Perhaps he was running at a high speed and\\nchasing a jeep?\\n111'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 123}, page_content='8.2 gaussian\\nFigure 8.3: Performing Gaussian blurring with a\\n3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right). Again,\\nour image becomes more blurred as\\nthe kernel size increases, but is less\\nblurred than the average method in\\nFigure 8.2.\\n8.2\\ngaussian\\nNext up, we are going to review Gaussian blurring. Gaus-\\nsian blurring is similar to average blurring, but instead of\\nusing a simple mean, we are now using a weighted mean,\\nwhere neighborhood pixels that are closer to the central\\npixel contribute more “weight” to the average.\\nThe end result is that our image is less blurred, but more\\nnaturally blurred, than using the average method discussed\\nin the previous section.\\nLet’s look at some code to perform Gaussian blurring:\\nListing 8.3: blurring.py\\n18 blurred = np.hstack([\\n19\\ncv2.GaussianBlur(image, (3, 3), 0),\\n112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 124}, page_content='8.3 median\\n20\\ncv2.GaussianBlur(image, (5, 5), 0),\\n21\\ncv2.GaussianBlur(image, (7, 7), 0)])\\n22 cv2.imshow(\"Gaussian\", blurred)\\n23 cv2.waitKey(0)\\nHere you can see that we are making use of the cv2.\\nGaussianBlur function on Lines 19-21. The ﬁrst argument\\nto the function is the image we want to blur. Then, simi-\\nlar to cv2.blur, we provide a tuple representing our kernel\\nsize. Again, we start with a small kernel size of 3 × 3 and\\nstart to increase it.\\nThe last parameter is our σ, the standard deviation in the\\nx-axis direction. By setting this value to 0, we are instruct-\\ning OpenCV to automatically compute them based on our\\nkernel size.\\nWe can see the output of our Gaussian blur in Figure 8.3.\\nOur images have less of a blur effect than when using the\\naveraging method in Figure 8.2; however, the blur itself is\\nmore natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3\\nmedian\\nTraditionally, the median blur method has been most ef-\\nfective when removing salt-and-pepper noise. This type of\\nnoise is exactly what it sounds like: imagine taking a photo-\\ngraph, putting it on your dining room table, and sprinkling\\nsalt and pepper on top of it. Using the median blur method,\\nyou could remove the salt and pepper from your image.\\n113'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 125}, page_content='8.3 median\\nWhen applying a median blur, we ﬁrst deﬁne our kernel\\nsize k. Then, as in the averaging blurring method, we con-\\nsider all pixels in the neighborhood of size k × k. But, unlike\\nthe averaging method, instead of replacing the central pixel\\nwith the average of the neighborhood, we instead replace\\nthe central pixel with the median of the neighborhood.\\nMedian blurring is more effective at removing salt-and-\\npepper style noise from an image because each central pixel\\nis always replaced with a pixel intensity that exists in the\\nimage.\\nAveraging and Gaussian methods can compute means or\\nweighted means for the neighborhood – this average pixel\\nintensity may or may not be present in the neighborhood.\\nBut by deﬁnition, the median pixel must exist in our neigh-\\nborhood.\\nBy replacing our central pixel with a median\\nrather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([\\n25\\ncv2.medianBlur(image, 3),\\n26\\ncv2.medianBlur(image, 5),\\n27\\ncv2.medianBlur(image, 7)])\\n28 cv2.imshow(\"Median\", blurred)\\n29 cv2.waitKey(0)\\nApplying a median blur is accomplished by making a call\\nto the cv2.medianBlur function. This method takes two pa-\\nrameters: the image we want to blur and the size of our\\nkernel. On Lines 25-27, we start off with a kernel size of\\n3, then increase it to 5 and 7. The resulting blurred images\\n114'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 126}, page_content='8.3 median\\nFigure 8.4: Applying the median blur method to\\nour T-Rex image with increasing ker-\\nnel sizes of 3 (left), 5 (middle), and\\n7 (right), respectively.\\nNotice that\\nwe are no longer creating a “motion\\nblur”.\\nare then stacked and displayed to us.\\nOur median blurred images can be seen in Figure 8.4.\\nNotice that we are no longer creating a “motion blur” ef-\\nfect like in averaging and Gaussian blurring – instead, we\\nare removing detail and noise.\\nFor example, take a look at the color of the scales of the\\nT-Rex. As our kernel size increases, the scales become less\\npronounced. The black and brown stripes on the legs and\\ntail of the T-Rex especially lose their detail, all without cre-\\nating a motion blur.\\n115'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 127}, page_content='8.4 bilateral\\n8.4\\nbilateral\\nThe last method we are going to explore is bilateral blur-\\nring.\\nThus far, the intention of our blurring methods has been\\nto reduce noise and detail in an image; however, we tend to\\nlose edges in the image.\\nIn order to reduce noise while still maintaining edges, we\\ncan use bilateral blurring. Bilateral blurring accomplishes\\nthis by introducing two Gaussian distributions.\\nThe ﬁrst Gaussian function only considers spatial neigh-\\nbors, that is, pixels that appear close together in the (x, y)\\ncoordinate space of the image. The second Gaussian then\\nmodels the pixel intensity of the neighborhood, ensuring\\nthat only pixels with similar intensity are included in the\\nactual computation of the blur.\\nOverall, this method is able to preserve edges of an im-\\nage, while still reducing noise. The largest downside to this\\nmethod is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py\\n30 blurred = np.hstack([\\n31\\ncv2.bilateralFilter(image, 5, 21, 21),\\n32\\ncv2.bilateralFilter(image, 7, 31, 31),\\n33\\ncv2.bilateralFilter(image, 9, 41, 41)])\\n34 cv2.imshow(\"Bilateral\", blurred)\\n35 cv2.waitKey(0)\\n116'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 128}, page_content='8.4 bilateral\\nFigure 8.5: Applying Bilateral blurring to our\\nbeach image. As the diameter of the\\nneighborhood, color σ, and space σ\\nincreases (from left to right), our im-\\nage has noise removed, yet still re-\\ntains edges and does not appear to\\nbe “motion blurred”.\\nWe apply bilateral blurring by calling the cv2.bilateralFil\\nter function on Lines 31-33. The ﬁrst parameter we supply\\nis the image we want to blur. Then, we need to deﬁne the\\ndiameter of our pixel neighborhood. The third argument\\nis our color σ. A larger value for color σ means that more\\ncolors in the neighborhood will be considered when com-\\nputing the blur. Finally, we need to supply the space σ. A\\nlarger value of space σ means that pixels farther out from\\nthe central pixel will inﬂuence the blurring calculation, pro-\\nvided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be\\nseen in Figure 8.5. As the size of our parameters increases,\\nour image has noise removed, yet the edges still remain.\\n117'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 129}, page_content='8.4 bilateral\\nNow that we know how to blur our images, we can move\\non to thresholding in the next chapter. You can be sure that\\nwe’ll make use of blurring throughout the rest of this book!\\nFurther Reading\\nOne topic that I didn’t get a chance to cover in detail in-\\nside Practical Python and OpenCV is the convolution op-\\neration. Whether you are smoothing an image, sharp-\\nening details, or detecting edges, convolutions are being\\napplied.\\nTo learn more convolutions, and the role they play in\\ncomputer vision, image processing, and deep learning,\\nbe sure to refer to the Chapter 8 supplementary mate-\\nrial:\\nhttp://pyimg.co/y454z\\n118'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 130}, page_content='9\\nT H R E S H O L D I N G\\nThresholding is the binarization of an image. In general,\\nwe seek to convert a grayscale image to a binary image,\\nwhere the pixels are either 0 or 255.\\nA simple thresholding example would be selecting a pixel\\nvalue p, and then setting all pixel intensities less than p to\\nzero, and all pixel values greater than p to 255. In this way,\\nwe are able to create a binary representation of the image.\\nNormally, we use thresholding to focus on objects or ar-\\neas of particular interest in an image. In the examples in the\\nsections below, we will empty our pockets and look at our\\nspare change. Using thresholding methods, we’ll be able to\\nﬁnd the coins in an image.\\n9.1\\nsimple thresholding\\nApplying simple thresholding methods requires human in-\\ntervention. We must specify a threshold value T. All pixel\\nintensities below T are set to 0. And all pixel intensities\\ngreater than T are set to 255.\\n119'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 131}, page_content='9.1 simple thresholding\\nWe can also apply the inverse of this binarization by set-\\nting all pixels below T to 255 and all pixel intensities greater\\nthan T to 0.\\nLet’s explore some code to apply simple thresholding\\nmethods:\\nListing 9.1: simple_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\nOn Lines 1-10 we import our packages, parse our argu-\\nments, and load our image.\\nFrom there, we convert the\\nimage from the RGB color space to grayscale on Line 11.\\nAt this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.\\nListing 9.2: simple_thresholding.py\\n14 (T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\\n15 cv2.imshow(\"Threshold Binary\", thresh)\\n16\\n17 (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.\\nTHRESH_BINARY_INV)\\n120'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 132}, page_content='9.1 simple thresholding\\nFigure 9.1: Top-Left: The original coins image in\\ngrayscale. Top-Right: Applying sim-\\nple binary thresholding.\\nThe coins\\nare shown in black and the back-\\nground in white. Bottom-Left: Apply-\\ning inverse binary thresholding. The\\ncoins are now white and the back-\\nground is black.\\nBottom-Right: Ap-\\nplying the inverse binary threshold\\nas a mask to the grayscale image. We\\nare now focused on only the coins in\\nthe image.\\n121'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 133}, page_content='9.1 simple thresholding\\n18 cv2.imshow(\"Threshold Binary Inverse\", threshInv)\\n19\\n20 cv2.imshow(\"Coins\", cv2.bitwise_and(image, image, mask =\\nthreshInv))\\n21 cv2.waitKey(0)\\nAfter the image is blurred, we compute the thresholded\\nimage on Line 14 using the cv2.threshold function. This\\nmethod requires four arguments. The ﬁrst is the grayscale\\nimage that we wish to threshold. We supply our blurred\\nimage here.\\nThen, we manually supply our T threshold value. We\\nuse a value of T = 155.\\nOur third argument is our maximum value applied dur-\\ning thresholding. Any pixel intensity p that is greater than\\nT, is set to this value. In our example, any pixel value that\\nis greater than 155 is set to 255. Any value that is less than\\n155 is set to zero.\\nFinally, we must provide a thresholding method. We use\\nthe cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst\\nis T, the value we manually speciﬁed for thresholding. The\\nsecond is our actual thresholded image.\\nWe then show our thresholded image in Figure 9.1, Top-\\nRight. We can see that our coins are now black pixels and\\nthe white pixels are the background.\\n122'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 134}, page_content='9.2 adaptive thresholding\\nOn Line 17 we apply inverse thresholding rather than\\nnormal thresholding by using cv2.THRESH_BINARY_INV as\\nour thresholding method.\\nAs we can see in Figure 9.1,\\nBottom-Left, our coins are now white and the background\\nis black. This is convenient as we will see in a second.\\nThe last task we are going to perform is to reveal the\\ncoins in the image and hide everything else.\\nRemember when we discussed masking? That will come\\nin handy here.\\nOn Line 20 we perform masking by using the cv2.bitwise_\\nand function. We supply our original coin image as the ﬁrst\\ntwo arguments, and then our inverted thresholded image as\\nour mask. Remember, a mask only considers pixels in the\\noriginal image where the mask is greater than zero. Since\\nour inverted thresholded image on Line 17 does a good job\\nat approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our\\nmask – the coins are clearly revealed while the rest of the\\nimage is hidden.\\n9.2\\nadaptive thresholding\\nOne of the downsides of using simple thresholding meth-\\nods is that we need to manually supply our threshold value\\nT. Not only does ﬁnding a good value of T require a lot of\\nmanual experiments and parameter tunings, it’s not very\\n123'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 135}, page_content='9.2 adaptive thresholding\\nFigure 9.2: Left: The grayscale coins image. Mid-\\ndle: Applying adaptive thresholding\\nusing mean neighborhood values.\\nRight: Applying adaptive threshold-\\ning using Gaussian neighborhood\\nvalues.\\nhelpful if the image exhibits a lot of range in pixel intensi-\\nties.\\nSimply put, having just one value of T might not sufﬁce.\\nIn order to overcome this problem, we can use adap-\\ntive thresholding, which considers small neighbors of pixels\\nand then ﬁnds an optimal threshold value T for each neigh-\\nbor. This method allows us to handle cases where there\\nmay be dramatic ranges of pixel intensities and the optimal\\nvalue of T may change for different parts of the image.\\nLet’s go ahead and jump into some code that applies\\nadaptive thresholding:\\n124'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 136}, page_content='9.2 adaptive thresholding\\nListing 9.3: adaptive_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\n14\\n15 thresh = cv2.adaptiveThreshold(blurred, 255,\\n16\\ncv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\\n17 cv2.imshow(\"Mean Thresh\", thresh)\\n18\\n19 thresh = cv2.adaptiveThreshold(blurred, 255,\\n20\\ncv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\\n21 cv2.imshow(\"Gaussian Thresh\", thresh)\\n22 cv2.waitKey(0)\\nLines 1-10 once again handle setting up our example. We\\nimport our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it\\nslightly on Lines 11 and 12.\\nWe then apply adaptive thresholding to our blurred im-\\nage using the cv2.adaptiveThreshold function on Line 15.\\nThe ﬁrst parameter we supply is the image we want to\\nthreshold.\\nThen, we supply our maximum value of 255,\\nsimilar to simple thresholding mentioned above.\\nThe third argument is our method to compute the thresh-\\nold for the current neighborhood of pixels. By supplying\\ncv2.ADAPTIVE_THRESH_MEAN_C, we indicate that we want to\\ncompute the mean of the neighborhood of pixels and treat\\n125'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 137}, page_content='9.2 adaptive thresholding\\nit as our T value.\\nNext, we need our thresholding method. Again, the de-\\nscription of this parameter is identical to the simple thresh-\\nolding method mentioned above. We use cv2.THRESH_BINAR\\nY_INV to indicate that any pixel intensity greater than T in\\nthe neighborhood should be set to 255, otherwise it should\\nbe set to 0.\\nThe next parameter is our neighborhood size. This inte-\\nger value must be odd and indicates how large our neigh-\\nborhood of pixels is going to be. We supply a value of 11,\\nindicating that we are going to examine 11 × 11 pixel re-\\ngions of the image, instead of trying to threshold the image\\nglobally, as in simple thresholding methods.\\nFinally, we supply a parameter simply called C.\\nThis\\nvalue is an integer that is subtracted from the mean, allow-\\ning us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.\\nBesides applying standard mean thresholding, we can\\nalso apply Gaussian (weighted mean) thresholding, as we\\ndo on Line 19. The order of the parameters are identical to\\nLine 15, but now we are tuning a few of the values.\\nInstead of supplying a value of cv2.ADAPTIVE_THRESH_\\nMEAN_C, we instead use cv2.ADAPTIVE_THRESH_GAUSSIAN_C\\nto indicate we want to use the weighted mean.\\nWe are\\nalso using a 15 × 15 pixel neighborhood size rather than\\n126'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 138}, page_content='9.3 otsu and riddler-calvard\\nan 11 × 11 neighborhood size as in the previous example.\\nWe also alter our C value (the value we subtract from the\\nmean) slightly and use 3 rather than 4.\\nThe results of applying Gaussian adaptive thresholding\\ncan be seen in the right image of Figure 9.2. There is little\\ndifference between the two images.\\nIn general, choosing between mean adaptive threshold-\\ning and Gaussian adaptive thresholding requires a few ex-\\nperiments on your end.\\nThe most important parameters\\nto vary are the neighborhood size and C, the value you\\nsubtract from the mean. By experimenting with this value,\\nyou will be able to dramatically change the results of your\\nthresholding.\\n9.3\\notsu and riddler-calvard\\nAnother way we can automatically compute the threshold\\nvalue of T is to use Otsu’s method.\\nOtsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image.\\nIt then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.\\nWhile OpenCV provides support for Otsu’s method, I\\nprefer the implementation by Luis Pedro Coelho in the mahotas\\npackage since it is more Pythonic.\\nLet’s jump into some sample code:\\n127'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 139}, page_content='9.3 otsu and riddler-calvard\\nListing 9.4: otsu_and_riddler.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import mahotas\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9\\nhelp = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n15 cv2.imshow(\"Image\", image)\\n16\\n17 T = mahotas.thresholding.otsu(blurred)\\n18 print(\"Otsu’s threshold: {}\".format(T))\\nOn Lines 1-5 we import the packages we will utilize. We\\nhave seen numpy, argparse, and cv2 before. We are now\\nintroducing mahotas, another image processing package.\\nLines 7-12 then handle our standard practice of parsing\\narguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-\\ntion in the mahotas.thresholding package. As our output\\nwill later show us, Otsu’s method ﬁnds a value of T = 137\\nthat we will use for thresholding.\\nListing 9.5: otsu_and_riddler.py\\n19 thresh = image.copy()\\n20 thresh[thresh > T] = 255\\n128'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 140}, page_content='9.3 otsu and riddler-calvard\\n21 thresh[thresh < 255] = 0\\n22 thresh = cv2.bitwise_not(thresh)\\n23 cv2.imshow(\"Otsu\", thresh)\\n24\\n25 T = mahotas.thresholding.rc(blurred)\\n26 print(\"Riddler-Calvard: {}\".format(T))\\n27 thresh = image.copy()\\n28 thresh[thresh > T] = 255\\n29 thresh[thresh < 255] = 0\\n30 thresh = cv2.bitwise_not(thresh)\\n31 cv2.imshow(\"Riddler-Calvard\", thresh)\\n32 cv2.waitKey(0)\\nApplying the thresholding is accomplished on Lines 19-\\n22. First, we make a copy of our grayscale image so that we\\nhave an image to threshold. Line 20 then makes any values\\ngreater than T white, whereas Line 21 makes all remaining\\npixels that are not white into black pixels. We then invert\\nour threshold by using cv2.bitwise_not. This is equivalent\\nto applying a cv2.THRESH_BINARY_INV thresholding type as\\nin previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.\\nAnother method to keep in mind when ﬁnding optimal\\nvalues for T is the Riddler-Calvard method.\\nJust as in\\nOtsu’s method, the Riddler-Calvard method also computes\\nan optimal value of 137 for T. We apply this method on\\nLine 25 using the rc function in mahotas.thresholding. Fi-\\nnally, the actual thresholding of the image takes place on\\nLines 27-30, as in the previous example.\\nGiven that the\\nvalues of T are identical for Otsu and Riddler-Calvard, the\\nthresholded image in Figure 9.3 (right) is identical to the\\nthresholded image in the center.\\n129'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 141}, page_content='9.3 otsu and riddler-calvard\\nFigure 9.3: Left:\\nThe original grayscale coins\\nimage.\\nMiddle:\\nApplying Otsu’s\\nmethod to ﬁnd an optimal value of T.\\nRight: Applying the Riddler-Calvard\\nmethod to ﬁnd an optimal value of\\nT.\\nListing 9.6: otsu_and_riddler.py\\nOtsu’s threshold: 137\\nRiddler-Calvard: 137\\nNow that we have explored thresholding, we will move\\non to another powerful image processing technique – edge\\ndetection.\\n130'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 142}, page_content='9.3 otsu and riddler-calvard\\nFurther Reading\\nThresholding is often used as a method to segment the\\nforeground of an image from the background.\\nThis\\nworks ﬁne for foreground objects that can be cleanly\\nsegmented. But what if your foreground objects “touch”,\\nthereby making segmentation more difﬁcult. What do\\nyou do then?\\nThe answer is to apply the watershed algorithm, which I\\ncover inside the Chapter 9 supplementary material:\\nhttp://pyimg.co/z1ef6\\n131'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 143}, page_content='10\\nG R A D I E N T S A N D E D G E D E T E C T I O N\\nThis chapter is primarily concerned with gradients and\\nedge detection. Formally, edge detection embodies math-\\nematical methods to ﬁnd points in an image where the\\nbrightness of pixel intensities changes distinctly.\\nThe ﬁrst thing we are going to do is ﬁnd the “gradient” of\\nthe grayscale image, allowing us to ﬁnd edge-like regions\\nin the x and y direction.\\nWe’ll then apply Canny edge detection, a multi-stage pro-\\ncess of noise reduction (blurring), ﬁnding the gradient of\\nthe image (utilizing the Sobel kernel in both the horizon-\\ntal and vertical direction), non-maximum suppression, and\\nhysteresis thresholding.\\nIf that sounds like a mouthful, it’s because it is. Again,\\nwe won’t jump too far into the details since this book is con-\\ncerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the\\nalgorithms. Overall, they are not complicated and can be\\n132'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 144}, page_content='10.1 laplacian and sobel\\nFigure 10.1: Left:\\nThe\\noriginal\\ncoins\\nimage.\\nRight:\\nApplying\\nthe\\nLaplacian\\nmethod to obtain the gradient of the\\nimage.\\ninsightful to the behind-the-scenes action of OpenCV.\\n10.1\\nlaplacian and sobel\\nLet’s go ahead and explore some code:\\nListing 10.1: sobel_and_laplacian.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 cv2.imshow(\"Original\", image)\\n133'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 145}, page_content='10.1 laplacian and sobel\\n13\\n14 lap = cv2.Laplacian(image, cv2.CV_64F)\\n15 lap = np.uint8(np.absolute(lap))\\n16 cv2.imshow(\"Laplacian\", lap)\\n17 cv2.waitKey(0)\\nLines 1-8 import our packages and set up our argument\\nparser. From there, we load our image and convert it to\\ngrayscale on Lines 10 and 11. When computing gradients\\nand edges, we (normally) compute them on a single chan-\\nnel – in this case, we are using the grayscale image; how-\\never, we can also compute gradients for each channel of\\nthe RGB image. For the sake of simplicity, let’s stick with\\nthe grayscale image since that is what you will use in most\\ncases.\\nOn Line 14, we use the Laplacian method to compute the\\ngradient magnitude image by calling the cv2.Laplacian\\nfunction. The ﬁrst argument is our grayscale image – the\\nimage we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-\\nsigned integers. Why are we using a 64-bit ﬂoat now?\\nThe reason involves the transition of black-to-white and\\nwhite-to-black in the image.\\nTransitioning from black-to-white is considered a posi-\\ntive slope, whereas a transition from white-to-black is a\\nnegative slope. If you remember our discussion of image\\narithmetic in Chapter 6, you’ll know that an 8-bit unsigned\\ninteger does not represent negative values. Either it will be\\nclipped to zero if you are using OpenCV or a modulus op-\\n134'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 146}, page_content='10.1 laplacian and sobel\\neration will be performed using NumPy.\\nThe short answer here is that if you don’t use a ﬂoating\\npoint data type when computing the gradient magnitude\\nimage, you will miss edges, speciﬁcally the white-to-black\\ntransitions.\\nIn order to ensure you catch all edges, use a ﬂoating point\\ndata type, then take the absolute value of the gradient im-\\nage and convert it back to an 8-bit unsigned integer, as in\\nLine 15. This is deﬁnitely an important technique to take\\nnote of – otherwise you’ll be missing edges in your image!\\nTo see the results of our gradient processing, take a look\\nat Figure 10.1.\\nLet’s move on to computing the Sobel gradient represen-\\ntation:\\nListing 10.2: sobel_and_laplacian.py\\n18 sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\\n19 sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\\n20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)\\n27 cv2.imshow(\"Sobel Y\", sobelY)\\n28 cv2.imshow(\"Sobel Combined\", sobelCombined)\\n29 cv2.waitKey(0)\\nUsing the Sobel operator, we can compute gradient mag-\\nnitude representations along the x and y axis, allowing us\\n135'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 147}, page_content='10.1 laplacian and sobel\\nFigure 10.2: Top-Left: The original coins image.\\nTop-Right: Computing the Sobel gra-\\ndient magnitude along the x-axis\\n(ﬁnding vertical edges).\\nBottom-\\nLeft: Computing the Sobel gradient\\nalong the y-axis (ﬁnding horizontal\\nedges).\\nBottom-Right: Applying a\\nbitwise OR to combine the two So-\\nbel representations.\\n136'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 148}, page_content='10.1 laplacian and sobel\\nto ﬁnd both horizontal and vertical edge-like regions.\\nIn fact, that’s exactly what Lines 18 and 19 do by us-\\ning the cv2.Sobel method. The ﬁrst argument to the Sobel\\noperator is the image we want to compute the gradient rep-\\nresentation for. Then, just like in the Laplacian example\\nabove, we use a ﬂoating point data type. The last two argu-\\nments are the order of the derivatives in the x and y direc-\\ntion, respectively. Specify a value of 1 and 0 to ﬁnd vertical\\nedge-like regions and 0 and 1 to ﬁnd horizontal edge-like\\nregions\\nOn Lines 21 and 22 we then ensure we ﬁnd all edges by\\ntaking the absolute value of the ﬂoating point image and\\nthen converting it to an 8-bit unsigned integer.\\nIn order to combine the gradient images in both the x\\nand y direction, we can apply a bitwise OR. Remember, an\\nOR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.\\nFinally, we show our gradient images on Lines 26-29.\\nYou can see the result of our work in Figure 10.2. We\\nstart with our original image, Top-Left, and then ﬁnd vertical\\nedges, Top-Right, and horizontal edges, Bottom-Left. Finally,\\nwe compute a bitwise OR to combine the two directions\\ninto a single image, Bottom-Right.\\nOne thing you’ll notice is that the edges are very “noisy”.\\nThey are not clean and crisp. We’ll remedy that by using\\n137'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 149}, page_content='10.2 canny edge detector\\nFigure 10.3: Left: Our coins image in grayscale\\nand blurred slightly. Right: Apply-\\ning the Canny edge detector to the\\nblurred image to ﬁnd edges.\\nNo-\\ntice how our edges are more “crisp”\\nand the outlines of the coins are\\nfound.\\nthe Canny edge detector in the next section.\\n10.2\\ncanny edge detector\\nThe Canny edge detector is a multi-step process. It involves\\nblurring the image to remove noise, computing Sobel gradi-\\nent images in the x and y direction, suppressing edges, and\\nﬁnally a hysteresis thresholding stage that determines if a\\npixel is “edge-like” or not.\\n138'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 150}, page_content='10.2 canny edge detector\\nWe won’t get into all these steps in detail. Instead, we’ll\\njust look at some code and show how it’s done:\\nListing 10.3: canny.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7\\nhelp = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 image = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Blurred\", image)\\n14\\n15 canny = cv2.Canny(image, 30, 150)\\n16 cv2.imshow(\"Canny\", canny)\\n17 cv2.waitKey(0)\\nThe ﬁrst thing we do is import our packages and parse\\nour arguments. We then load our image, convert it to graysc-\\nale, and blur it using the Gaussian blurring method. By ap-\\nplying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.\\nApplying the Canny edge detector is performed on Line\\n15 using the cv2.Canny function.\\nThe ﬁrst argument we\\nsupply is our blurred, grayscale image. Then, we need to\\nprovide two values: threshold1 and threshold2.\\nAny gradient value larger than threshold2 is considered\\nto be an edge.\\nAny value below threshold1 is consid-\\nered not to be an edge.\\nValues in between threshold1\\nand threshold2 are either classiﬁed as edges or non-edges\\n139'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 151}, page_content='10.2 canny edge detector\\nbased on how their intensities are “connected”. In this case,\\nany gradient values below 30 are considered non-edges wh-\\nereas any values above 150 are considered edges.\\nWe then show the results of our edge detection on Line\\n16.\\nFigure 10.3 shows the results of the Canny edge detector.\\nThe image on the left is the grayscale, blurred image that\\nwe pass into the Canny operator. The image on the right is\\nthe result of applying the Canny operator.\\nNotice how the edges are more “crisp”. We have substan-\\ntially less noise than when we used the Laplacian or Sobel\\ngradient images. Furthermore, the outline of our coins are\\nclearly revealed.\\nIn the next chapter, we’ll continue to make use of the\\nCanny edge detector and use it to count the number of\\ncoins in our image.\\n140'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 152}, page_content='10.2 canny edge detector\\nFurther Reading\\nJust like thresholding is a common method for seg-\\nmenting foreground objects from background objects,\\nthe same can be said for edge detection – only instead\\nof obtaining a large blob representing the foreground,\\nthe Canny detector gives us the outline.\\nHowever, a common challenge of using the Canny edge\\ndetector is getting the lower and upper edge thresh-\\nolds just right.\\nIn order to help you (automatically)\\ndetermine these lower and upper boundaries, be sure\\nto read about the automatic Canny edge detector in this\\nsupplementary material:\\nhttp://pyimg.co/91daw\\n141'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 153}, page_content='11\\nC O N TO U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in the curve. Contours are extremely useful for such\\nthings as shape approximation and analysis.\\nIn order to ﬁnd contours in an image, you need to ﬁrst ob-\\ntain a binarization of the image, using either edge detection\\nmethods or thresholding. In the examples below, we’ll use\\nthe Canny edge detector to ﬁnd the outlines of the coins,\\nand then ﬁnd the actual contours of the coins.\\nReady?\\nHere we go:\\n11.1\\ncounting coins\\n142'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 154}, page_content='11.1 counting coins\\nListing 11.1: counting_coins.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8\\nhelp = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n13 blurred = cv2.GaussianBlur(gray, (11, 11), 0)\\n14 cv2.imshow(\"Image\", image)\\n15\\n16 edged = cv2.Canny(blurred, 30, 150)\\n17 cv2.imshow(\"Edges\", edged)\\nThe ﬁrst 11 lines of code simply set up our environment\\nby importing packages, parsing arguments, and loading the\\nimage.\\nJust as in the edge detection methods discussed in the\\nprevious chapter, we are going to convert our image to\\ngrayscale and then apply a Gaussian blur, making it eas-\\nier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.\\nWe then obtain the edged image by applying the Canny\\nedge detector on Line 16. Again, just as in previous edge\\ndetection examples, any gradient values below 30 are con-\\nsidered non-edges whereas any values above 150 are con-\\nsidered sure edges.\\nListing 11.2: counting_coins.py\\n143'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 155}, page_content='11.1 counting coins\\n18 (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2\\n.CHAIN_APPROX_SIMPLE)\\n19\\n20 print(\"I count {} coins in this image\".format(len(cnts)))\\n21\\n22 coins = image.copy()\\n23 cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\\n24 cv2.imshow(\"Coins\", coins)\\n25 cv2.waitKey(0)\\nNow that we have the outlines of the coins, we can ﬁnd\\nthe contours of the outlines.\\nWe do this using the cv2.\\nfindContours function on Line 18. This method returns\\na 3-tuple of: (1) our image after applying contour detec-\\ntion (which is modiﬁed and essentially destroyed), (2) the\\ncontours themselves, cnts, and (3) the hierarchy of the con-\\ntours (see below).\\nThe ﬁrst argument to cv2.findContours is our edged im-\\nage. It’s important to note that this function is destructive\\nto the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.\\nWe use cv2.RETR_EXTERNAL to retrieve only the outermost\\ncontours (i.e., the contours that follow the outline of the\\ncoin). We can also pass in cv2.RETR_LIST to grab all con-\\ntours. Other methods include hierarchical contours using\\ncv2.RETR_COMP and cv2.RETR_TREE, but hierarchical con-\\ntours are outside the scope of this book.\\nOur last argument is how we want to approximate the\\ncontour.\\nWe use cv2.CHAIN_APPROX_SIMPLE to compress\\nhorizontal, vertical, and diagonal segments into their end-\\npoints only. This saves both computation and memory. If\\n144'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 156}, page_content='11.1 counting coins\\nwe wanted all the points along the contour, without com-\\npression, we can pass in cv2.CHAIN_APPROX_NONE; however,\\nbe very sparing when using this function. Retrieving all\\npoints along a contour is often unnecessary and is wasteful\\nof resources.\\nOur contours cnts is simply a Python list. We can use\\nthe len function on it to count the number of contours that\\nwere returned. We do this on Line 20 to show how many\\ncontours we have found.\\nWhen we execute our script, we will have the output “I\\ncount 9 coins in this image” printed out to our console.\\nNow, we are able to draw our contours. In order not to\\ndraw on our original image, we make a copy of the original\\nimage, called coins on Line 22.\\nA call to cv2.drawContours draws the actual contours on\\nour image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative\\nvalue of −1, we are indicating that we want to draw all of\\nthe contours. However, we would also supply an index i,\\nwhich would be the i’th contour in cnts. This would allow\\nus to draw only a single contour rather than all of them.\\nFor example, here is some code to draw the ﬁrst, second,\\nand third contours, respectively:\\nListing 11.3: Drawing Contours via an Index\\n1 cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)\\n145'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 157}, page_content='11.1 counting coins\\n2 cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)\\n3 cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)\\nThe fourth argument to the cv2.drawContours function\\nis the color of the line we are going to draw. Here, we use\\na green color.\\nFinally, our last argument is the thickness of the line we\\nare drawing. We’ll draw the contour with a thickness of\\ntwo pixels.\\nNow that our contours are drawn on the image, we can\\nvisualize them on Line 24.\\nTake a look at Figure 11.1 to see the results of our work.\\nOn the left is our original image. Then, we apply Canny\\nedge detection to ﬁnd the outlines of the coins (middle). Fi-\\nnally, we ﬁnd the contours of the coin outlines and draw\\nthem. You can see that each contour has been drawn with\\na two-pixel thick green line.\\nBut we’re not done yet!\\nLet’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27\\n(x, y, w, h) = cv2.boundingRect(c)\\n28\\n29\\nprint(\"Coin #{}\".format(i + 1))\\n30\\ncoin = image[y:y + h, x:x + w]\\n31\\ncv2.imshow(\"Coin\", coin)\\n32\\n33\\nmask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n34\\n((centerX, centerY), radius) = cv2.minEnclosingCircle(c)\\n146'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 158}, page_content='11.1 counting coins\\nFigure 11.1: Left: The original coin image. Mid-\\ndle: Applying the Canny edge detec-\\ntor to ﬁnd the outlines of the coins.\\nRight: Finding the contours of the\\ncoin outlines and then drawing the\\ncontours.\\nWe have now success-\\nfully found the coins and are able\\nto count them.\\n147'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 159}, page_content='11.1 counting coins\\n35\\ncv2.circle(mask, (int(centerX), int(centerY)), int(radius),\\n255, -1)\\n36\\nmask = mask[y:y + h, x:x + w]\\n37\\ncv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask =\\nmask))\\n38\\ncv2.waitKey(0)\\nWe start off on Line 26 by looping over our contours.\\nWe then use the cv2.boundingRect function on the cur-\\nrent contour. This method ﬁnds the “enclosing box” that\\nour contour will ﬁt into, allowing us to crop it from the\\nimage. The function takes a single parameter, a contour,\\nand then returns a tuple of the x and y position that the\\nrectangle starts at, followed by the width and height of the\\nrectangle.\\nWe then crop the coin from the image using our bound-\\ning box coordinates and NumPy array slicing on Line 30.\\nThe coin itself is shown to us on Line 31.\\nIf we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array\\nof zeros, with the same width and height of our original\\nimage.\\nA call to cv2.minEnclosingCircle on Line 34 ﬁts a circle\\nto our contour. We pass in a circle variable, the current\\ncontour, and are given the x and y coordinates of the circle,\\nalong with its radius.\\nUsing the (x, y) coordinates and the radius, we can draw\\na circle on our mask, representing the coin. Drawing circles\\n148'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 160}, page_content='11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work.\\nThe\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2\\ncontours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 161}, page_content='11.2 contours and opencv version caveats\\nFigure 11.2: Top:\\nCropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing.\\nBottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 162}, page_content='11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, the grab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6\\nif len(cnts) == 2:\\n7\\ncnts = cnts[0]\\n8\\n9\\nelif len(cnts) == 3:\\n10\\ncnts = cnts[1]\\n11\\n12\\nelse:\\n13\\nraise Exception((\"Contours tuple must have length 2 or \"\\n14\\n\"3, otherwise OpenCV changed their cv2.findContours \"\\n15\\n\"return signature yet again. Refer to OpenCV’s\\n16\\ndocumentation in that case.\"))\\n17\\n18\\nreturn cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)\\nOn Line 1 we call the cv2.findContours function to de-\\ntect contours in an image.\\nFrom there, Line 2 utilizes the grab_contours function\\nto inspect the tuple returned by cv2.findContours and ex-\\n151'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 163}, page_content='11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally, Line 3 takes the parsed contours from grab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplementary material for this chap-\\nter – be sure to take a look:\\nhttp://pyimg.co/saz76\\n152'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 164}, page_content='12\\nW H E R E TO N O W ?\\nIn this book, we’ve explored many image processing and\\ncomputer vision techniques, including basic image process-\\ning, such as translation, rotating, and resizing. We learned\\nall about image arithmetic and how to apply bitwise op-\\nerations. Then, we explored how a simple technique like\\nmasking can be used to focus our attention and computa-\\ntion to only a single part of an image.\\nTo better understand the pixel intensity distribution of an\\nimage, we then explored histograms. We started by com-\\nputing grayscale histograms, then worked our way up to\\ncolor, including 2D and 3D color histograms. We adjusted\\nthe contrast of images using histogram equalization, then\\nmoved on to blurring our images, using different methods,\\nsuch as averaging, Gaussian, and median ﬁltering.\\nWe thresholded our images to ﬁnd objects of interest,\\nthen applied edge detection.\\nFinally we learned how to use contours to count the num-\\nber of coins in the image.\\n153'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '', 'modDate': \"D:20251009201354+06'30'\", 'creationDate': \"D:20190106063150-05'00'\", 'page': 165}, page_content='where to now?\\nSo, where do you go from here?\\nYou continue learning, exploring, and experimenting!\\nUse the source code and images provided in this book to\\ncreate projects of your own. That’s the best way to learn!\\nIf you need project ideas, be sure to contact me. I love\\ntalking with readers and helping out when I can. You can\\nreach me at adrian@pyimagesearch.com.\\nFinally, I constantly post on my blog, www.PyImageSear\\nch.com, sharing new and interesting techniques related to\\ncomputer vision and image search engines. Be sure to fol-\\nlow the blog for new posts, as well as new books and courses\\nas I write them.\\n154'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 0}, page_content='SQL-QUERIES\\nTables\\nYou need to create and populate the following tables to start working on the\\nqueries.\\n1.1.           Emp table data'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 1}, page_content='Emp Table Data'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 2}, page_content='Dept table Data'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 3}, page_content='2.    Exercises with Answers\\n2.1.           Display all the information of the EMP table?\\nA) select * from emp;\\n2.2.           Display unique Jobs from EMP table?\\nA)    select  distinct job from emp;\\nB)    select unique job from emp;\\n2.3.           List the emps in the asc order of their Salaries?\\nA) select  * from emp  order by sal asc;\\n2.4.           List the details of the emps in asc order of the Dptnos and desc of\\nJobs?\\nA)select * from emp order by deptno asc,job desc;\\n2.5.           Display all the unique job groups in the descending order?\\nA)select distinct job from emp order by job desc;\\n2.6.           Display all the details of all ‘Mgrs’\\nA)Select * from emp where empno in ( select  mgr  from emp) ;\\n2.7.           List the emps who joined before 1981.\\nA) select * from emp where hiredate < (’01-jan-81’);\\n2.8.           List the Empno, Ename, Sal, Daily sal of all emps in the asc order of\\nAnnsal.\\nA) select empno ,ename ,sal,sal/30,12*sal annsal from emp order by annsal asc;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 4}, page_content='2.9.           Display the Empno, Ename, job, Hiredate, Exp of all Mgrs \\nA) select  empno,ename ,job,hiredate, months_between(sysdate,hiredate)  exp\\nfrom emp where empno in (select mgr from emp);\\n2.10.     List the Empno, Ename, Sal, Exp of all emps working for Mgr 7369.\\nA) select empno,ename,sal,exp from emp where mgr = 7369;\\n2.11.     Display all the details of the emps whose Comm. Is more than their Sal.\\nA) select * from emp where comm. > sal;\\n2.12.     List the emps in the asc order of Designations of those joined after the\\nsecond half of 1981.\\nA) select * from emp where hiredate > (’30-jun-81’) and\\nto_char(hiredate,’YYYY’) = 1981 order by job asc;\\n2.13.     List the emps along with their Exp and Daily Sal is more than Rs.100.\\nA) select * from emp where (sal/30) >100;\\n2.14.     List the emps who are either ‘CLERK’ or ‘ANALYST’ in the Desc\\norder.\\nA) select * from emp where job = ‘CLERK’ or job = ‘ANALYST’ order by job\\ndesc;\\n2.15.     List the emps who joined on 1-MAY-81,3-DEC-81,17-DEC-81,19-JAN-\\n80 in asc order of seniority.\\nA) select  * from emp where hiredate  in (’01-may-81’,’03-dec-81’,’17-dec-\\n81’,’19-jan-80’)  order by hiredate asc;\\n2.16.     List the emp who are working for the Deptno 10 or20.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 5}, page_content='A) select * from emp where deptno = 10  or deptno = 20 ;\\n2.17.     List the emps who are joined in the year 81.\\nA) select * from emp where  hiredate between ’01-jan-81’ and ’31-dec-81’;\\n2.18.     List the emps who are joined in the month of Aug 1980.\\nC)    select * from emp where hiredate between ’01-aug-80’ and ’31-aug-80’;  \\n(OR)\\nselect * from emp where to_char(hiredate,’mon-yyyy’) =’aug-1980;\\n2.19.     List the emps Who Annual sal ranging from 22000 and 45000.\\nA) select * from emp where 12*sal between 22000 and 45000;\\n2.20.     List the Enames those are having five characters in their Names.\\nA) select  ename from emp where  length (ename) = 5;\\n2.21.     List the Enames those are starting with ‘S’ and with five characters.\\nA) select ename from emp where  ename like ‘S%’ and length (ename) = 5;\\n2.22.     List the emps those are having four chars and third character must be ‘r’.\\nA) select  * from emp where length(ename) = 4 and ename like ‘__R%’;\\n2.23.     List the Five character names starting with ‘S’ and ending with ‘H’.\\nA) select * from emp where length(ename) = 5 and ename like  ‘S%H’;\\n2.24.     List the emps who joined in January.\\nA) select * from emp where to_char (hiredate,’mon’) = ‘jan’;\\n2.25.     List the emps who joined in the month of which second character is ‘a’.\\nD)    select * from emp where to_char(hiredate,’mon’)  like ‘_a_’; (OR)'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 6}, page_content='B) select * from emp where to_char(hiredate,’mon’) like ‘_a%’;\\n2.26.     List the emps whose Sal is four digit number ending with Zero.\\nA) select  *  from  emp where  length (sal) = 4 and sal like ‘%0’;\\n2.27.     List the emps whose names having a character set ‘ll’ together.\\nA) select  * from emp where  ename like ‘%LL%’;\\n2.28.     List the emps those who joined in 80’s.\\nA) select * from emp where  to_char(hiredate,’yy’)  like ‘8%’;\\n2.29.     List the emps who does not belong to Deptno 20.\\nA) select * from emp where  deptno not in (20); (OR)\\nB) select * from emp where  deptno != 20; (OR)\\nC) select * from emp where deptno <>20; (OR)\\nD) select  * from emp where deptno not like ‘20’;\\n2.30.     List all the emps except ‘PRESIDENT’ & ‘MGR” in asc order of\\nSalaries.\\nSelect * from emp where  job not in (‘PRESIDENT’,’MANAGER’)  order by\\nsal  asc;\\nselect * from emp where job not like ‘PRESIDENT’ and job not like\\n‘MANAGER’  order by sal  asc;\\nC) Select * from emp where job != ‘PRESIDENT’ and job <> ‘MANAGER’ \\norder  by  sal  asc;\\n2.31.     List all the emps who joined before or after 1981.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 7}, page_content='A)    select * from emp where to_char (hiredate,’YYYY’)  not in (‘1981’);  (OR)\\nB)    select *  from emp where to_char ( hiredate,’YYYY’)  !=  ‘1981’;   (OR)\\nC)    select * from emp where to_char(hiredate,’YYYY’)  <>  ‘1981’ ; (OR)\\nD) select * from emp where to_char (hiredate ,’YYYY’)  not like ‘1981’;\\n2.32.     List the emps whose Empno not starting with digit78.\\nA)  select * from emp where empno not like ‘78%’;\\n2.33.     List the emps who are working under ‘MGR’.\\nA) select e.ename || ‘ works for ‘ || m.ename  from emp e ,emp m where e.mgr =\\nm.empno ;        (OR)\\nB) select  e.ename || ‘ has an employee ‘|| m.ename from emp e , emp m where\\ne.empno = m.mgr;\\n2.34.     List the emps who joined in any year but not belongs to the month of\\nMarch.\\nE)     select * from emp  where  to_char (hiredate,’MON’) not in (‘MAR’);  (OR)\\nF)     select * from emp where to_char (hiredate,’MON’)  !=  ‘MAR’; (OR)\\nG)    select * from emp  where to_char(hiredate,’MONTH’) not like ‘MAR%’ ; \\n(OR)\\nH)    select * from emp where to_char(hiredate,’MON’)  <> ‘MAR’;\\n2.35.     List all the Clerks of Deptno 20.\\nA)select * from emp where job =‘CLERK’ and deptno = 20;\\n2.36.     List the emps of Deptno 30 or 10 joined in the year 1981.\\nA) select * from emp where to_char(hiredate,’YYYY’) = ‘1981’ and (deptno'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 8}, page_content='=30 or deptno =10) ;  (OR)  select *  from emp where to_char\\n(hiredate,’YYYY’)  in (‘1981’)  and  (deptno = 30 or deptno =10 ) ;\\n2.37.     Display the details of SMITH.\\nA) select * from emp where ename = ‘SMITH’ ;\\n2.38.     Display the location of  SMITH.\\nA) select loc from emp  e , dept d where  e.ename = ‘SMITH’ and  e.deptno =\\nd.deptno ;\\n2.39.     List the total information of EMP table along with DNAME and Loc of\\nall the emps Working Under ‘ACCOUNTING’ & ‘RESEARCH’ in the asc\\nDeptno.\\nA)    select * from emp e ,dept d where (dname = ‘ACCOUNTING’ or dname\\n=’RESEARCH’ ) and e.deptno = d.deptno order by e.deptno asc;  (OR)\\nB)    select * from emp e ,dept d where d.dname in\\n(‘ACCOUNTING’,’RESEARCH’) and e.deptno = d.deptno order by e.deptno\\nasc;\\n2.40.     List the Empno, Ename, Sal, Dname of all the ‘MGRS’ and ‘ANALYST’\\nworking in New York, Dallas with an exp more than 7 years without receiving\\nthe Comm asc order of Loc.\\nA)    select e.empno,e.ename,e.sal,d.dname  from emp e ,dept d where  d.loc in\\n(‘NEW YORK’,’DALLAS’) and e.deptno = d.deptno and e.empno in (select\\ne.empno from emp e where e.job in (‘MANAGER’,’ANALYST’) and \\n(months_between(sysdate,e.hiredate)/12)> 7  and  e.comm. is null)\\norder by d.loc  asc;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 9}, page_content=\"2.41.     Display the Empno, Ename, Sal, Dname, Loc, Deptno, Job of all emps\\nworking at CJICAGO or working for ACCOUNTING dept with Ann\\nSal>28000, but the Sal should not be=3000 or 2800 who doesn’t belongs to the\\nMgr and whose no is having a digit ‘7’ or ‘8’ in 3rd position in the asc order of\\nDeptno and desc order of job.\\nA) select E.empno,E.ename,E.sal,D.dname,D.loc,E.deptno,E.job\\nfrom emp E,dept D\\nwhere (D.loc = 'CHICAGO' or D.dname = 'ACCOUNTING') and\\nE.deptno=D.deptno and E.empno in\\n(select E.empno from emp E where (12*E.sal) > 28000 and  E.sal not in\\n(3000,2800)  and E.job !='MANAGER'\\nand ( E.empno like '__7%' or E.empno like '__8%'))\\norder by E.deptno asc , E.job desc;\\n2.42.     Display the total information of the emps along with Grades in the asc\\norder.\\nA) select * from emp e ,salgrade s where e.sal between s.losal and s.hisal  order\\nby grade asc; (OR)\\nB) select * from emp e ,salgrade s where e.sal >= s.losal and e.sal <= s.hisal \\norder by s.grade  asc;        (using between and is a bit simple)\\n2.43.     List all the Grade2 and Grade 3 emps.\\nB)    select * from emp e where e.empno in (select e.empno from emp e ,salgrade\\ns where e.sal  between s.losal and s.hisal and s.grade in(2,3)); (OR) \\nB) select * from emp e ,salgrade s where e.sal between s.losal and s.hisal  and\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 10}, page_content='s.grade in (2,3) ;\\n2.44.     Display all Grade 4,5 Analyst and Mgr.\\nA) select * from emp e, salgrade s where e.sal between s.losal and s.hisal  and\\ns.grade in (4,5) and e.empno in (select e.empno from emp e where e.job in\\n(‘MANAGER’,’ANALYST’) );\\n2.45.     List the Empno, Ename, Sal, Dname, Grade, Exp, and Ann Sal of emps\\nworking for Dept10 or20.\\nA)\\nselectE.empno,E.ename,E.sal,S.grade,D.dname,\\n(months_between(sysdate,E.hiredate)/12) \"EXP\" ,12*E.sal  “ANN SAL”\\nfrom emp E,dept D ,salgrade S\\nwhere E.deptno in (10,20) and E.deptno = D.deptno  and E.sal between S.losal\\nand S.hisal ;\\n2.46.     List all the information of emp with Loc and the Grade of all the emps\\nbelong to the Grade range from 2 to 4 working at the Dept those are not starting\\nwith char set ‘OP’ and not ending with ‘S’ with the designation having a char ‘a’\\nany where joined in the year 1981 but not in the month of Mar or Sep and Sal\\nnot end with ‘00’ in the asc order of Grades\\nA)  select e.empno,e.ename,d.loc,s.grade,e.sal from emp e ,dept d,salgrade s\\nwhere e.deptno = d.deptno\\nand (d.dname not like \\'OP%\\' and d.dname not like \\'%S\\') and e.sal between\\ns.losal and s.hisal and s.grade in (2,3,4)\\nand empno in (select empno from emp where job like \\'%A%\\'and sal not like\\n\\'%00\\' and (to_char (hiredate,\\'YYYY\\') = \\'1981\\'\\nand to_char(hiredate,\\'MON\\') not in (\\'MAR\\',\\'SEP\\')));'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 11}, page_content='2.47.     List the details of the Depts along with Empno, Ename or without the\\nemps\\nA) select * from emp e,dept d where e.deptno(+)= d.deptno;\\n2.48.     List the details of the emps whose Salaries more than the employee\\nBLAKE.\\nA) select * from emp where sal > (select  sal from emp where ename =\\n‘BLAKE’);\\n2.49.     List the emps whose Jobs are same as ALLEN.\\nA) select * from emp where job = (select job from emp where ename =\\n‘ALLEN’);\\n2.50.     List the emps who are senior to King.\\nC)    select * from emp where hiredate < ( select hiredate from emp where ename\\n= ‘KING’);\\n2.51.     List the Emps who are senior to their own MGRS.\\nD)    select * from emp w,emp m where w.mgr = m.empno  and w.hiredate < \\nm.hiredate ; (OR)\\nE)     select * from emp w,emp m where w.empno= m.mgr and\\nw.hiredate> m.hiredate;\\n2.52.     List the Emps of Deptno 20 whose Jobs are same as Deptno10.\\nA) select * from emp e ,dept d where d.deptno = 20 and e.deptno = d.deptno and\\ne.job in ( select e.job from emp e,dept d where e.deptno = d.deptno and d.deptno\\n=10);\\n2.53.     List the Emps whose Sal is same as FORD or SMITH in desc order of'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 12}, page_content='Sal.\\nA)\\nSelect *  from  emp where sal in (select sal from emp where ( ename = ‘SMITH’\\nor  ename = ‘FORD’ ))  order by sal desc;\\n2.54.     List the emps Whose Jobs are same as MILLER or Sal is more than\\nALLEN.\\nA) select *  from emp  where job = (select  job from emp where ename =\\n‘MILLER’ ) or  sal>(select sal from emp where ename = ‘ALLEN’);\\n2.55.     List the Emps whose Sal is > the total remuneration of the SALESMAN.\\nA) select * from emp where sal >(select sum(nvl2(comm,sal+comm,sal)) from\\nemp  where job = ‘SALESMAN’);\\n2.56.     List the emps who are senior to BLAKE working at CHICAGO &\\nBOSTON.\\nF)     select * from emp e ,dept d where  d.loc in (‘CHICAGO’,’BOSTON’) and\\ne.deptno = d.deptno and e.hiredate <(select e.hiredate from emp e where e.ename\\n= ‘BLAKE’) ;\\n2.57.     List the Emps of Grade 3,4 belongs to the dept ACCOUNTING and\\nRESEARCH whose Sal is more than ALLEN and exp more than SMITH in the\\nasc order of EXP.\\nG)    select * from emp e where e.deptno in (select d.deptno  from dept d where\\nd.dname  in (‘ACCOUNTING’,’RESEARCH’) ) and \\ne.sal >(select sal from emp where ename = ‘ALLEN’)  and \\ne.hiredate <( select hiredate from emp where ename = ‘SMITH’) and\\ne.empno in (select e.empno from emp e ,salgrade s where e.sal between s.losal\\nand s.hisal  and s.grade in (3,4) )'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 13}, page_content='order by e.hiredate desc;\\n2.58.     List the emps whose jobs same as SMITH or ALLEN.\\nH)    select * from emp where  job in (select job from emp where ename =\\n‘SMITH’ or ename = ‘ALLEN’);  (OR)\\nB) select * from emp where job in (select job from emp where ename in\\n(‘SMITH’,’ALLEN’);\\n2.59.     Write a Query to display the details of emps whose Sal is same as of\\nb)     Employee Sal of EMP1 table.\\nc)      ¾ Sal of any Mgr of EMP2 table.\\nd)     The sal of any person with exp of 5 years belongs to the sales dept of emp3\\ntable.\\ne)      Any grade 2 employee of emp4 table.\\nf)       Any grade 2 and 3 employee working fro sales dept or operations dept\\njoined in 89.\\n2.60.     Any jobs of deptno 10 those that are not found in deptno 20.\\nA) select  e.job from emp e where e.deptno = 10 and e.job not in (select job from\\nemp where deptno =20);\\n2.61.     List of emps of emp1 who are not found in emp2.\\n2.62.     Find the highest sal of EMP table.\\nA) select max(sal) from emp;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 14}, page_content=\"2.63.     Find details of highest paid employee.\\nA)    select * from emp where sal in (select  max(sal) from emp);\\n2.64.     Find the highest paid employee of sales department.\\nA) select * from emp where sal in (select max(sal) from emp where deptno in\\n(select d.deptno from\\ndept d where d.dname = 'SALES'));\\n2.65.     List the most recently hired emp of grade3 belongs to  location\\nCHICAGO.\\nA) select * from emp e where  e.deptno in ( select  d.deptno from dept d where\\nd.loc = 'CHICAGO') and\\ne.hiredate in  (select max(hiredate) from emp where empno in (select empno\\nfrom emp e,salgrade s\\nwhere e.sal between s.losal and s.hisal and s.grade = 3)) ; (or)\\nselect * from emp e,dept d where d.loc='chicago'\\nand hiredate in(select max(hiredate) from emp e,salgrade s\\nwhere sal between losal and hisal and grade=3);\\n2.66.     List the employees who are senior to most recently hired employee\\nworking under king.\\nA) select * from emp where hiredate < (select max(hiredate) from emp where\\nmgr in\\n(select empno from emp where ename = 'KING')) ;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 15}, page_content=\"2.67.     List the details of the employee belongs to newyork with grade 3 to 5\\nexcept ‘PRESIDENT’ whose sal> the highest paid employee of Chicago in a\\ngroup where there is manager and salesman not working under king\\nA) select * from emp where deptno in (select deptno from dept where dept.loc\\n='NEW YORK')\\nand empno in (select empno from emp e,salgrade s where e.sal between s.losal\\nand s.hisal and\\ns.grade in (3,4,5) ) and job != 'PRESIDENT' and sal >(select max(sal) from emp\\nwhere deptno in\\n(select deptno from dept where dept.loc = 'CHICAGO') and job in\\n('MANAGER','SALESMAN') and\\nmgr not in (select empno from emp where ename = 'KING'));\\n2.68.     List the details of the senior employee belongs to 1981.\\nB)    select  *  from emp where hiredate in (select min(hiredate) from emp  \\nwhere  to_char( hiredate,’YYYY’) = ‘1981’);  (OR)\\nC)    select * from emp where hiredate  = (select min(hiredate) from emp  where\\nto_char(hiredate,’YYYY’) = ‘1981’);\\n2.69.     List the employees who joined in 1981 with the job same as the most\\nsenior person of the year 1981.\\nA)select * from emp where job in (select  job from emp where hiredate in\\n(select min(hiredate) from emp where to_char(hiredate,’YYYY’) =’1981’));\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 16}, page_content=\"2.70.     List the most senior empl working under the king and grade is more \\nthan 3.\\nA) select * from emp where hiredate in (select min(hiredate) from emp where\\nempno in\\n(select empno from emp e ,salgrade s where e.sal between s.losal and s.hisal and\\ns.grade in (4,5)))\\nand mgr in (select empno from emp where ename = 'KING');\\n2.71.     Find the total sal given to the MGR.\\nD)    select sum (sal) from emp where job = ‘MANAGER’; (OR)\\nB) select sum(sal) from emp where empno in(select mgr from emp);\\n2.72.     Find the total annual sal to distribute job wise in the year 81.\\nA) select job,sum(12*sal) from emp where to_char(hiredate,'YYYY') = '1981'\\ngroup by job ;\\n2.73.     Display total sal employee belonging to grade 3.\\nE)     select sum(sal) from emp where empno\\nin  (select empno from emp e ,salgrade s\\nwhere e.sal between s.losal and s.hisal and s.grade = 3)\\n2.74.     Display the average salaries of all the clerks.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 17}, page_content='A) select avg(sal) from emp where job = ‘CLERK’;\\n2.75.     List the employeein dept 20 whose sal is >the average sal 0f dept 10\\nemps.\\nA) select * from emp where deptno =20 and sal >(select avg (sal) from emp\\nwhere  deptno = 10);\\n2.76.     Display the number of employee  for each job group deptno wise.\\nF)     select  deptno ,job ,count(*)  from emp group by  deptno,job; (or)\\nB) select d.deptno,e.job,count(e.job) from emp e,dept d where\\ne.deptno(+)=d.deptno group by e.job,d.deptno;\\n2.77.     List the manage rno and the number of employees working for those\\nmgrs in the ascending Mgrno.\\nG)    select w.mgr ,count(*) from emp w,emp m\\nwhere w.mgr = m.empno\\ngroup by w.mgr\\norder by w.mgr asc;\\n2.78.     List the department,details where at least two emps are working\\nH)    select deptno ,count(*) from emp group by deptno\\nhaving count(*) >= 2;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 18}, page_content=\"2.79.     Display the Grade, Number of emps, and max sal of each grade.\\nA) select s.grade ,count(*),max(sal) from emp e,salgrade s where e.sal between\\ns.losal and s.hisal\\ngroup by s.grade;\\n2.80.     Display dname, grade, No. of emps where at least two emps are clerks.\\nA) select d.dname,s.grade,count(*) from emp e,dept d,salgrade s where e.deptno\\n= d.deptno and\\ne.job = 'CLERK' and e.sal between s.losal and s.hisal  group by d.dname,s.grade\\nhaving count(*) >= 2;\\n2.81.     List the details of the department where maximum number of emps are\\nworking.\\nI)       select * from dept where deptno in\\n(select deptno from emp group by deptno        \\nhaving count(*) in\\n(select max(count(*)) from emp group by deptno) ); (OR)\\nJ)      select d.deptno,d.dname,d.loc,count(*) from emp e ,dept d\\nwhere e.deptno = d.deptno group by d.deptno,d.dname,d..loc\\nhaving count(*) = (select max(count(*) ) from emp group by deptno);\\n2.82.     Display the emps whose manager name is jones.\\nK)    select * from emp where mgr in\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 19}, page_content=\"(select empno from emp where ename = ‘JONES’); (OR)\\nL)     select * from emp where mgr =\\n(select empno from emp where ename = ‘JONES’);\\n2.83.     List the employees whose salary is more than 3000 after giving 20%\\nincrement.\\nM)  SELECT * FROM EMP WHERE (1.2*SAL) > 3000 ;\\n2.84.     List the emps with dept names.\\nA) select\\ne.empno,e.ename,e.job,e.mgr,e.hiredate,e.sal,e.comm,e.deptno,d.dname\\nfrom emp e ,dept d where e.deptno = d.deptno;\\n2.85.     List the emps who are not working in sales dept.\\nN)    select * from emp where deptno not in\\n(select deptno from emp where dname = ‘SALES’);\\n2.86.     List the emps name ,dept, sal and comm. For those whose salary is\\nbetween 2000 and 5000 while loc is Chicago.\\nA) select e.ename,e.deptno,e.sal,e.comm from emp e ,dept d where e.deptno =\\nd.deptno and\\nd.loc = 'CHICAGO' and e.sal between 2000 and 5000;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 20}, page_content=\"2.87.     List the emps whose sal is greater than his managers salary\\nA) select * from emp w,emp m where w.mgr = m.empno and w.sal > m.sal;\\n2.88.     List the grade, EMP name for the deptno 10 or deptno 30 but sal grade is\\nnot 4 while they joined the company before ’31-dec-82’.\\nA) select s.grade ,e.ename from emp e,salgrade s where e.deptno in (10,20) and\\nhiredate < ('31-DEC-82') and (e.sal between s.losal and s.hisal and s.grade not in\\n(4));\\n2.      List the name ,job, dname, location for those who are working as MGRS.\\nA)    select e.ename,e.job,d.dname,d.loc from emp e ,dept d\\nwhere e.deptno = d.deptno and\\ne.empno in (select mgr from emp ) ;\\n3.      List the emps whose mgr name is jones and also list their manager name.\\nA) select w.empno,w.ename,w.job,w.mgr,w.hiredate,w.sal,w.deptno,m.ename\\nfrom emp w ,emp m\\nwhere w.mgr = m.empno and m.ename = 'JONES';\\n4.      List the name and salary of ford if his salary is equal to hisal of his grade.\\nA) select e.ename,e.sal from emp e ,salgrade s where e.ename = 'FORD' and\\ne.sal between s.losal and s.hisal and e.sal = s.hisal ;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 21}, page_content=\"5.      Lit the name, job, dname ,sal, grade dept wise\\nA)    select e.ename,e.job,d.dname,e.sal,s.grade from emp e,dept d,salgrade s\\nwhere e.deptno = d.deptno and e.sal between s.losal and s.hisal\\norder by e.deptno ;\\n6.      List the emp name, job, sal, grade and dname except clerks and sort on the\\nbasis of highest sal.\\nA)    select e.ename,e.job,e.sal,s.grade,d.dname from emp e ,dept d ,salgrade s\\nwhere e.deptno = d.deptno and e.sal between s.losal and s.hisal and\\ne.job not in('CLERK')\\norder by e.sal desc;\\n7.      List the emps name, job  who are with out manager.\\nA) select e.ename,e.job from emp e where mgr is null;\\n8.      List the names of the emps who are getting the highest sal dept wise.\\nA)    select e.ename,e.deptno from emp e where e.sal in\\n(select max(sal) from emp group by deptno) ;\\n9.      List the emps whose sal is equal to the average of max and minimum\\nA) select * from emp where sal =(select (max(sal)+min(sal))/2 from emp);\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 22}, page_content='10.  List the no. of emps in each department where the no. is more than 3.\\nA) select deptno,count(*) from emp group by deptno  having count(*) < 3;\\n11.        List the names of depts. Where atleast 3 are working in that department.\\nA)    select d.dname,count(*) from emp e ,dept d where e.deptno = d.deptno\\ngroup by d.dname\\nhaving count(*) >= 3  ;\\n12.        List the managers whose sal is more than his employess avg salary.\\nA)    select * from emp m  where m.empno in (select mgr from emp)\\nand m.sal > (select avg(e.sal) from emp e where e.mgr = m.empno\\n)                                  \\nThe subquery does the same as   (select (avg(e.sal)),m.ename from emp e,emp m\\nwhere e.mgr=m.empno group by e.mgr,m.ename);\\n13.        List the name,salary,comm. For those employees whose net pay is\\ngreater than or equal to any other employee salary of the company.\\nA)    select e.ename,e.sal,e.comm from emp e  where\\nnvl2(e.comm.,e.sal+e.comm.,e.sal) >= any (select sal from emp);   (OR)\\nB)    select ename,sal,comm. from emp where sal+nvl(comm.,0) >= any (select\\nsal from emp);/\\n14.        List the emp whose sal<his manager but more than any other manager.\\na)select  distinct W.empno,W.ename,W.sal'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 23}, page_content='from (select w.empno,w.ename,w.sal from emp w,emp m where \\nw.mgr = m.empno and w.sal<m.sal) W,\\n(select * from emp where empno in (select mgr from emp)) A\\nwhere W.sal > A.sal; (OR)\\nB) select * from emp w,emp m where w.mgr = m.empno and w.sal < m.sal\\nand w.sal > any (select sal from emp where empno in (select mgr from emp));\\n15.        List the employee names and his average salary department wise.\\nA)\\nselect d.deptno, round(avg(nvl2(e1.comm, e1.sal+e1.comm, e1.sal))) avg,\\ne2.ename from emp e1, emp e2, dept d where d.deptno =e1.deptno and d.deptno\\n= e2.deptno group by d.deptno, e2.ename; (or)\\nB) select d.maxsal,e.ename,e.deptno as \"current sal\" from emp e,\\n(select avg(Sal) maxsal,deptno from emp group by deptno) d\\nwhere e.deptno=d.deptno;\\n16.        Find out least 5 earners of the company.\\nA)    select * from emp e where 5> (select count(*) from emp where e.sal >sal);\\n(or)\\nB)    select rownum rank,empno,ename,job,sal from (select * from emp order by\\nsal asc) where rownum < 6 ; (or)'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 24}, page_content=\"C)    select * from emp e  where 5 >(select count(distinct sal) from emp where\\ne.sal > sal);\\n17.        Find out emps whose salaries greater than salaries of their managers.\\nA)    select * from emp w,emp m where w.mgr = m.empno and w.sal> m.sal;\\n(OR)\\nB)    select * from emp e ,(select * from emp where empno in (select mgr from\\nemp)) a\\nwhere e.sal >a.sal and e.mgr = a.empno\\n18.        List the managers who are not working under the president.\\nA) select * from emp where empno in(select mgr from emp) and mgr not in\\n(select empno from emp where job = 'PRESIDENT')\\n19.        List the records from emp whose deptno isnot in dept.\\n20.        List the Name , Salary, Comm and Net Pay is more than any other\\nemployee.\\nA)    Select e.ename,e.sal,e.comm,nvl2(comm,sal+comm,sal) NETPAY\\nfrom emp e \\nwhere nvl2(comm,sal+comm,sal) > any (select sal from emp where empno\\n=e.empno) ;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 25}, page_content=\"21.        List the Enames who are retiring after 31-Dec-89 the max Job period is\\n20Y.\\nA) select ename from emp where add_months(hiredate,240) > '31-DEC-89';\\nB) select ename from emp\\nwhere add_months(hiredate,240) > to_date(’31-DEC-89’,’DD-MON-RR’); \\n22.        List those Emps whose Salary is odd value.\\nA) select * from emp where mod(sal,2) = 1;\\n23.        List the emp’s whose Salary contain 3 digits.\\nA) select  * from emp  where length (sal) = 3;\\n24.        List the emps who joined in the month of DEC.\\nA)    select * from emp where to_char(hiredate,’MON’) =’DEC’; (OR)\\nB)    select * from emp where to_char(hiredate,’MON’)  in (‘DEC’); (OR)\\nC)    select * from emp where to_char(hiredate,’MONTH’) like ‘DEC%’;\\n25.        List the emps whose names contains ‘A’.\\nA) select * from emp where ename like ‘%A%’;\\n26.        List the emps whose Deptno is available in his Salary.\\nA) select * from emp where instr(sal,deptno) > 0;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 26}, page_content=\"27.        List the emps whose first 2 chars from Hiredate=last 2 characters of\\nSalary.\\nA)    select * from emp\\nwhere substr(hiredate,1,2) = substr(sal,length(sal)-1,length(sal));\\n28.        List the emps Whose 10% of Salary is equal to year of joining.\\nA) select * from emp where to_char(hiredate,'YY') in (select .1*sal from emp);\\n29.        List first 50% of chars of Ename in Lower Case and remaining are upper\\nCase.\\nA)        \\nselect lower(substr(ename,1,round(length(ename)/2)))\\n||substr(ename,round(length(ename)/2)+1,length(ename)) from emp ;  (OR)\\nB) select lower(substr(ename,1,ciel(length(ename)/2)))\\n|| substr(ename,ciel(length(ename)/2)+1,length(ename)) from emp ;\\n30.        List the Dname whose No. of Emps is =to number of chars in the\\nDname.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 27}, page_content='A)    select * from dept d where length(dname) in (select count(*) from emp e\\nwhere e.deptno = d.deptno ); (or)\\nB)    select d.dname,count(*) from emp e ,dept d where e.deptno = d.deptno \\ngroup by d.dname having count(*) = length (d.dname);\\n31.        List the emps those who joined in company before 15th of the month.\\nA)    select * from emp where to_char(hiredate,\\'DD\\') < \\'15\\';\\n32.        List the Dname, no of chars of which is = no. of emp’s in any other\\nDept.\\nA)    select * from dept d where length(dname) in (select count(*) from emp \\nwhere d.deptno <> deptno group by deptno ); (or)\\nB)    select * from dept where length(dname) = any (select count(*) from emp\\nwhere d.deptno <> deptno group by deptno);\\nC)    select * from dept d , (select count(*) s,e.deptno  \"M\"from emp e group by\\ne.deptno) d1\\nwhere length(dname)=d1.s and d1.M <>d.deptno;\\n33.        List the emps who are working as Managers.\\nA)    select * from where job = ‘MANAGER’; (or)\\nB)    select * from emp where empno in (select mgr from emp );\\n34.        List THE Name of dept where highest no.of emps are working.\\nA) select dname from dept where deptno in'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 28}, page_content=\"(select deptno  from emp group by deptno        \\nhaving count(*) in\\n(select max(count(*)) from emp group by deptno) );\\n35.        Count the No.of emps who are working as ‘Managers’(using set option).\\nA)select count(*)\\nfrom(select * from emp minus select * from emp where job != 'MANAGER')\\n36.        List the emps who joined in the company on the same date.\\nA)    select * from emp e where hiredate in\\n(select hiredate from emp where e.empno <> empno);\\n37.        List the details of the emps whose Grade is equal to one tenth of Sales\\nDept.\\nA) select * from emp e,salgrade s\\nwhere e.sal between s.losal and s.hisal and\\ns.grade = 0.1* (select deptno from dept where dname = 'SALES');\\n38.        List the name of the dept where more than average no. of emps are\\nworking.\\nA) select d.dname from dept d, emp e where e.deptno = d.deptno\\ngroup by d.dname\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 29}, page_content='having count(*) > (select avg(count(*)) from emp  group by deptno);\\n39.        List the Managers name who is having max no.of emps working under\\nhim.\\nA)select m.ename,count(*) from emp w,emp m\\nwhere w.mgr = m.empno \\ngroup by m.ename\\nhaving count(*) = (select max(count(*)) from emp group by mgr);     \\n(OR)\\nB) select * from emp where empno = (select mgr from emp group by mgr having\\ncount(*) = (select max(count(*)) from emp group by mgr)) ;\\n40.        List the Ename and Sal is increased by 15% and expressed as no.of\\nDollars.\\nA) select ename,to_char(1.15*sal,\\'$99,999\\') as \"SAL\"  from emp; (only for $ it\\nworks)\\nB) select ename,\\'$\\'||1.15*sal  “SAL” from emp;\\n41.        Produce the output of EMP table ‘EMP_AND_JOB’ for Ename and Job.\\nA) select ename|| job as \"EMP_AND_JOB\" from emp ;\\n42.        Produce the following output from EMP.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 30}, page_content='I.                   EMPLOYEE\\nSMITH (clerk)\\nALLEN (Salesman)\\nA)  select ename || ‘(‘|| lower(job)||’)’ as “EMPLOYEE” from emp;\\n130)   List the emps with Hire date in format June 4, 1988.\\nA)    select empno,ename,sal, to_char(hiredate,\\'MONTH DD,YYYY\\') from emp;\\n131)   Print a list of emp’s Listing ‘just salary’ if Salary is more than 1500, on\\ntarget if Salary is 1500 and ‘Below 1500’ if Salary is less than 1500.\\nA)    select empno,ename,sal|| ‘JUST SALARY’ \"SAL\" from emp where sal >\\n1500 union\\nselect empno,ename, sal|| ‘ON TARGET’ \"SAL\" from emp where sal = 1500       \\nunion\\nselect empno,ename, sal|| ‘BELOW 1500’ \"SAL\" from emp where sal < 1500; \\n(OR)\\nB)select empno,ename,sal,job,\\ncase\\nwhen sal = 1500 then \\'ON TARGET\\'\\nwhen sal < 1500 then \\'BELOW 1500\\'\\nwhen sal > 1500 then \\'JUST SALARY\\'\\nelse \\'nothing\\'\\nend  \"REVISED SALARY\"\\nfrom emp;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 31}, page_content=\"132)   Write a query which return the day of the week for any date entered in\\nformat ‘DD-MM-YY’.\\nA) select to_char(to_date('& s','dd-mm-yy'),'day') from dual ;\\n133)   Write a query to calculate the length of service of any employee with the\\ncompany, use DEFINE to avoid repetitive typing of functions.\\nA)    DEFINE  service = ((months_between(sysdate,hiredate))/12)\\nB)    Select  empno,ename,&service from emp where ename = ‘& name’;\\n134)   Give a string of format ‘NN/NN’, verify that the first and last two\\ncharacters are numbers and that the middle character is’/’. Print the expression\\n‘YES’ if valid, ‘NO’ if not valid. Use the following values to test your solution.\\n‘12/34’,’01/1a’, ‘99/98’.\\nA)\\n135)   Emps hired on or before 15th of any month are paid on the last Friday of\\nthat month those hired after 15th are paid on the first Friday of the following\\nmonth. Print a list of emps their hire date and the first pay date. Sort on hire date.\\nA) select ename,hiredate,next_day(last_day(hiredate),'FRIDAY')-7 from emp\\nwhere to_char(hiredate,'DD') <=15\\nunion\\nselect ename,hiredate,next_day(last_day(hiredate),'FRIDAY') from emp where\\nto_char(hiredate,'DD') > 15;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 32}, page_content=\"136)   Count the no. of characters with out considering spaces for each name.\\nA)    select length(replace(ename,’ ‘,null)) from emp;\\n137)   Find out the emps who are getting decimal value in their Sal without using\\nlike operator.\\nA) select  * from emp where instr(sal,’.’,1,1) > 0;\\n138)   List those emps whose Salary contains first four digit of their Deptno.\\nA)    select * from emp where instr(to_char(sal,,9999),deptno,1,1)>0 and\\ninstr(to_char(sal,9999),deptno,1,2)> 0 ;\\n139)   List those Managers who are getting less than his emps Salary.\\nA)    select distinct m.ename,m.sal from emp w,emp m where w.mgr = m.empno\\nand w.sal>m.sal;\\nB)    select * from emp w where sal  < any ( select sal from emp where\\nw.empno=mgr);\\nC)    select * from emp w where empno in  ( select mgr from emp where   \\nw.sal<sal);\\n140)   Print the details of all the emps who are sub-ordinates to Blake.\\nA)    select *  from emp where mgr in (select empno from emp where ename =\\n'BLAKE');\\n141)   List the emps who are working as Managers using co-related sub-query.\\nA)    select * from emp where empno in (select mgr from emp);\\n142)   List the emps whose Mgr name is ‘Jones’ and also with his Manager\\nname.\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 33}, page_content='A)    select w.ename,m.ename,(select ename from emp where m.mgr = empno)\\n\"his MANAGER\"\\nfrom emp w,emp m where w.mgr = m.empno and m.ename = \\'JONES\\'; (or)\\nB) select e.ename,w.ename,m.ename from emp e,emp w,emp m where e.mgr =\\nw.empno and w.ename = ‘JONES’ and w.mgr = m.empno;\\n143)   Define a variable representing the expression used to calculate on emps\\ntotal annual remuneration use the variable in a statement, which finds all emps\\nwho can earn 30000 a year or more.\\nA)    Set define on\\nB)    Define  annual = 12*nvl2(comm.,sal+comm.,sal)  (here define variable is a\\nsession variable)\\nC)    Select * from emp where &annual > 30000;\\n144)   Find out how may Managers are their in the company.\\nA)    select count(*) from emp where job = ‘MANAGER’; (or)\\nB)    select count(*) from emp where empno in (select mgr from emp); (or)\\nC)    select count(distinct m.empno) from emp w,emp m where w.mgr =\\nm.empno ;\\n145)   Find Average salary and Average total remuneration for each Job type.\\nRemember Salesman earn commission.secommm\\nA) select avg(sal),avg(sal+nvl(comm,0)) from emp;\\n146)   Check whether all the emps numbers are indeed unique.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 34}, page_content='A) select   empno,count(*)  from emp group by empno;\\n147)   List the emps who are drawing less than 1000 Sort the output by Salary.\\nA)select * from emp where sal < 1000 order by sal;\\n148)   List the employee Name, Job, Annual Salary, deptno, Dept name and\\ngrade who earn 36000 a year or who are not CLERKS.\\nA)selecte.ename,e.job,(12*e.sal)\"ANNUALSALARY\",\\ne.deptno,d.dname,s.grade\\nfrom emp e,dept d ,salgrade s where e.deptno = d.deptno and e.sal between\\ns.losal and s.hisal\\nand (((12*e.sal)>= 36000) or (e.job != \\'CLERK\\'))\\n149)   Find out the Job that was filled in the first half of 1983 and same job that\\nwas filled during the same period of 1984.\\nA) select *  from emp where (to_char(hiredate,\\'MM \\') <= 06  and\\nto_char(hiredate,\\'YYYY\\') = 1984) and job in (select job from emp where\\nto_char(hiredate,\\'MM\\' ) <= 06 and to_char(hiredate,\\'YYYY\\') <= 1983) ; \\n150)   Find out the emps who joined in the company before their Managers.\\nA)    select * from emp w,emp m where w.mgr = m.empno and\\nw.hiredate< m.hiredate;(or)\\nB) select * from emp e where hiredate < (select  hiredate from emp where\\nempno = e.mgr)\\n151)   List all the emps by name and number along with their Manager’s name\\nand number. Also List KING who has no ‘Manager’.\\nA) select w.empno,w.ename,m.empno,m.ename from emp w,emp m where'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 35}, page_content='w.mgr= m.empno(+);\\n152)   Find all the emps who earn the minimum Salary for each job wise in\\nascending order.\\nA)    select * from emp where sal in\\n(select min(sal) from emp group by job)\\norder by sal asc;\\n153)   Find out all the emps who earn highest salary in each job type. Sort in\\ndescending salary order.\\nA)    select * from emp where sal in\\n(select max(sal) from emp group by job)\\norder by sal desc;\\n154)   Find out the most recently hired emps in each Dept order by Hiredate.\\nA)    select * from emp  e where hiredate in\\n(select max(hiredate) from emp where e.deptno =  deptno )\\norder by hiredate;\\n155)   List the employee name,Salary and Deptno for each employee who earns\\na salary greater than the average for their department order by Deptno.\\nA)    select * from emp e\\nwhere sal >  (select avg(sal) from emp where e.deptno = deptno );\\nB)    select e.ename,e.sal,e.deptno from emp e,(select avg(sal) A,deptno D from  \\nemp group by deptno) D1 where D1.D = e.deptno and e.sal > D1.A;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 36}, page_content=\"156)   List the Deptno where there are no emps.\\nA)    select  deptno ,count(*) from emp\\ngroup by deptno \\nhaving count(*) = 0;\\n157)   List the No.of emp’s and Avg salary within each department for each job.\\nA)    select count(*),avg(sal),deptno,job from emp\\ngroup by deptno,job;\\n158)   Find the maximum average salary drawn for each job except for\\n‘President’.\\nA) select max(avg(sal)) from emp  where job != 'PRESIDENT' group by job;\\n159)   Find the name and Job of the emps who earn Max salary and Commission.\\nA)    select * from emp where sal = (select max(sal) from emp) and comm. is not\\nnull;\\n160)   List the Name, Job and Salary of the emps who are not belonging to the\\ndepartment 10 but who have the same job and Salary as the emps of dept 10.\\nA) select ename,job,sal from emp where deptno != 10 and job in (select job from\\nemp where deptno = 10)\\nand sal in (select sal from emp where deptno = 10);\\n161)   List the Deptno, Name, Job, Salary and Sal+Comm of the SALESMAN\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 37}, page_content='who are earning maximum salary and commission in descending order.\\nA)select  deptno,name,job,sal,sal+nvl(comm.,0) from emp where job =\\n‘SALESMAN’ and sal in (select max(sal+nvl(comm.,0)) from emp where\\ncomm. is not null)\\nOrder by (sal +nvl(comm.,0)) desc;\\n162)   List the Deptno, Name, Job, Salary and Sal+Comm of the emps who earn\\nthe second highest earnings (sal + comm.).\\nA) select deptno,ename,sal,job,sal+nvl(comm,0) from emp e where  2 = (select\\ncount(distinct sal+nvl(comm,0)) from emp where (e.sal+nvl(comm.,0))\\n<(sal+nvl(comm.,0));\\n163)   List the Deptno and their average salaries for dept with the average salary\\nless than the averages for all department\\nA)    select deptno,avg(sal) from emp group by deptno\\nhaving avg(sal) <(select avg(Sal) from emp);\\n164)   List out the Names and Salaries of the emps along with their manager\\nnames and salaries for those emps who earn more salary than their Manager.\\nA)    select w.ename,w.sal,m.ename,m.sal from emp w,emp m\\nwhere w.mgr = m.empno and w.sal > m.sal;\\n165)   List out the Name, Job, Salary of the emps in the department with the\\nhighest average salary.\\nA)    select * from emp where deptno in'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 38}, page_content='(select deptno from emp e \\nhaving avg(sal) =(select max(avg(sal)) from emp group by deptno)  \\ngroup by deptno);\\n166)   List the empno,sal,comm. Of emps.\\nA) select empno,sal,comm. from emp;\\n167)   List the details of the emps in the ascending order of the sal.\\nA) select * from emp order by sal asc;\\n168)   List the dept in the ascending order of the job and the desc order of the\\nemps print empno, ename.\\nA) select * from emp e  order by e.job asc,e.empno desc ;\\n169)   Display the unique dept of the emps.\\nA)select * from dept where deptno in (select unique deptno from emp);\\n170)   Display the unique dept with jobs.\\nA) select unique deptno ,job from emp ;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 39}, page_content='171)   Display the details of the blake.\\nA) select * from emp where ename = ‘BLAKE’;\\n172)   List all the clerks.\\nA) select * from emp where job = ‘CLERK’;\\n173)   list all the employees joined on 1st may 81.\\nA) select * from emp where hiredate = ’01-MAY-81’;\\n174)   List the empno,ename,sal,deptno of the dept 10 emps in the ascending\\norder of salary.\\nA)    select e.empno,e.ename,e.sal,e.deptno from emp where e.deptno = 10\\norder by e.sal asc;\\n175)   List the emps whose salaries are less than 3500.\\nA) select * from emp where sal <3500;\\n176)   List the empno,ename,sal of all the emp joined before 1 apr 81.\\nA) select e.empno ,e.ename .e.sal from emp where hiredate <’01-APR-81’;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 40}, page_content='177)   List the emp whose annual sal is <25000 in the asc order of the salaries.\\nA) select * from emp where (12*sal) < 25000 order by sal asc;\\n178)   List the empno,ename,annsal,dailysal  of all the salesmen in the asc ann\\nsal\\nA) select e.empno,e.ename ,12*sal \"ANN SAL\" , (12*sal)/365 \"DAILY SAL\"\\nfrom emp e\\nwhere e.job = \\'SALESMAN\\'\\norder by \"ANN SAL\" asc ;\\n179)   List the empno,ename,hiredate,current date & exp in the ascending order\\nof the exp.\\nA)    select empno,ename,hiredate,(select sysdate from dual),\\n((months_between(sysdate,hiredate))/12) EXP\\nfrom emp\\norder by EXP asc;\\n180)   List the emps whose exp is more than 10 years.\\nA) select * from emp where ((months_between(sysdate,hiredate))/12) > 10;\\n181)   List the empno,ename,sal,TA30%,DA 40%,HRA\\n50%,GROSS,LIC,PF,net,deduction,net allow and net sal in the ascending order\\nof the net salary.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 41}, page_content='182)   List the emps who are working as managers.\\nA) select * from emp where job = ‘MANAGER’;\\n183)   List the emps who are either clerks or managers.\\nA) select * from emp where job in (‘CLERK’,’MANAGER’);\\n184)   List the emps who have joined on the following dates 1 may 81,17 nov\\n81,30 dec 81\\nA)    select * from emp where to_char(hiredate,’DD-MON-YY’)  in\\n(’01-MAY-81’,’17-NOV-81’,’30-DEC-81’);\\n185)   List the emps who have joined in the year 1981.\\nA) select * from emp where to_char(hiredate,’YYYY’) = ‘1981’;\\n186)   List the emps whose annual sal ranging from 23000 to 40000.\\nA) select * from emp where (12* sal) between 23000 and 40000;\\n187)   List the emps working under the mgrs 7369,7890,7654,7900.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 42}, page_content='A) select * from emp where mgr in ( 7369,7890,7654,7900);\\n188)   List the emps who joined in the second half of 82.\\nA)select * from emp where hiredate between ’01-JUL-82’ and ’31-DEC-82’;\\n189)   List all the 4char emps.\\nA) select * from emp where length (ename) = 4;\\n190)   List the emp names starting with ‘M’ with 5 chars.\\nA) select * from emp where ename like ‘M%’ and length (ename) = 5;\\n191)   List the emps end with ‘H’ all together 5 chars.\\nA)    select * from emp where ename like ‘%H’ and length (ename) = 5;\\n192)   List names start with ‘M’.\\nA) select * from emp where ename like ‘M%’;\\n193)   List the emps who joined in the year 81.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 43}, page_content='A) select * from emp where to_char(hiredate,’YY’) = ‘81’;\\n194)   List the emps whose sal is ending with 00.\\nA)  select * from where  sal  like  ‘%00’;\\n195)   List the emp who joined in the month of JAN.\\nA)    select * from emp where  to_char(hiredate,’MON’) = ‘JAN’; (OR)\\nB)    select * from emp where to_char (hiredate,’MM’) = 1;\\n196)   Who joined in the month having char ‘a’.\\nA)    select * from emp where to_char (hiredate,’MONTH’) like’%A%’; (OR)\\nB)    select * from emp where instr(to_char(hiredate,’MONTH’),’A’) >0;\\n197)   Who joined in the month having second char ‘a’\\nA)    select * from emp where to_char(hiredate,’MON’) like ‘_A%’; (OR)\\nB)    select * from emp where instr(to_char(hiredate,’MON’),’A’) = 2;\\n198)   List the emps whose salary is 4 digit number.\\nA)    select * from emp where length (sal) = 4;(OR)\\nB)    select * from emp  where sal between 999 and 9999;'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 44}, page_content='199)   List the emp who joined in 80’s.\\nA)    select *  from emp where to_char(hiredate,’YY’)  between ‘80’ and ’89’;\\n(OR)\\nB)    select * from emp where to_char(hiredate,’YY’) >= ‘80’ and\\nto_char(hiredate,’YY’) < ‘90’;\\n200)   List the emp who are clerks who have exp more than 8ys.\\nA) select * from emp where job = ‘CLERK’ and\\n(months_between(sysdate,hiredate) /12) > 8;\\n201)   List the mgrs of dept 10 or 20.\\nA) select * from emp where job = ‘MANAGER’ and (deptno = 10 or deptno\\n=20);\\n202)   List the emps joined in jan with salary ranging from 1500 to 4000.\\nA)    select * from emp where to_char(hiredate,’MON’) = ‘JAN’ and sal\\nbetween 1500 and 4000;\\n203)   List the unique jobs of dept 20 and 30 in desc order.\\nA) select  distinct job from emp where deptno in (20,30) order by job desc;\\n204)   List the emps along with exp of those working under the mgr whose\\nnumber is starting with 7 but should not have a 9 joined before 1983.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 45}, page_content=\"A)    select * from emp where (mgr like '7%' and mgr not like '%9%')\\nand to_char(hiredate,'YY') < '83';\\n205)   List the emps who are working as either mgr or analyst with the salary\\nranging from 2000 to 5000 and with out comm.\\nA)    select * from emp where  (job  in (‘MANAGER’ ,’ANALYST’) ) and sal\\nbetween  2000 and 5000 and comm is null;\\n206)   List the empno,ename,sal,job of the emps with /ann sal <34000 but\\nreceiving some comm. Which should not be>sal and desg should be sales man\\nworking for dept 30.\\nA) select empno,ename,sal,job from emp where\\n12*(sal+nvl(comm,0)) < 34000 and comm is not null and comm<sal and job =\\n'SALESMAN' and deptno = 30;  \\n207)   List the emps who are working for dept 10 or 20 with desgs as clerk or\\nanalyst with a sal is either 3 or 4 digits with an exp>8ys but does not belong to\\nmons of mar,apr,sep and working for mgrs &no is not ending with 88 and 56.\\nA) select * from emp where\\ndeptno in (10,20) and\\njob in ('CLERK','ANALYST') and\\n(length(sal) in (3,4)) and\\n((months_between(sysdate,hiredate))/12)> 8 and\\nto_char(hiredate,'MON') not in ('MAR','SEP','APR') and\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 46}, page_content=\"(mgr not like '%88' and mgr not like '%56');\\n208)   List the empno,ename,sal,job,deptno&exp of all the emps belongs to dept\\n10 or 20 with an exp 6 to 10 y working under the same mgr with out comm.\\nWith a job not ending irrespective of the position with comm.>200 with\\nexp>=7y and sal<2500 but not belongs to the month sep or nov working under\\nthe mgr whose no is not having digits either 9 or 0 in the asc dept& desc dept\\nA)\\n209)   List the details of the emps working at Chicago.\\nA) select * from emp where deptno in (select deptno from dept where dept.loc =\\n‘CHICAGO’);\\n210)   List the empno,ename,deptno,loc of all the emps.\\nA)    select e.empno,e.ename,e.deptno,d.loc from emp e ,dept d\\nwhere e.deptno = d.deptno ;\\n211)   List the empno,ename,loc,dname of all the depts.,10 and 20.\\nA)    select e.empno,e.ename,e.deptno,d.loc,d.dname from emp e ,dept d\\nwhere e.deptno = d.deptno    and  e.deptno in (10,20);\\n212)   List the empno, ename, sal, loc of the emps working at Chicago dallas\\nwith an exp>6ys.\\nA)    select e.empno,e.ename,e.deptno,e.sal,d.loc from emp e ,dept d\\nwhere e.deptno = d.deptno  and d.loc in ('CHICAGO','DALLAS')\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 47}, page_content=\"and (months_between(sysdate,hiredate)/12)> 6 ;\\n213)   List the emps along with loc of those who belongs to dallas ,newyork with\\nsal ranging from 2000 to 5000 joined in 81.\\nA)    select e.empno,e.ename,e.deptno,e.sal,d.loc from emp e ,dept d\\nwhere e.deptno = d.deptno and d.loc in ('NEW YORK','DALLAS')\\nand to_char(e.hiredate,'YY') = '81'  and  e.sal between 2000 and 5000;\\n214)   List the empno,ename,sal,grade of all emps.\\nA)    select e.empno,e.ename,e.sal,s.grade from emp e ,salgrade s \\nwhere e.sal  between s.losal and s.hisal ;\\n215)   List the grade 2 and 3 emp of Chicago.\\nA)    select * from emp where empno in\\n(select empno from emp e,salgrade s where e.sal between s.losal and              \\ns.hisal  and s.grade in (2,3));\\n216)   List the emps with loc and grade of accounting dept or the locs dallas or\\nChicago with the grades 3 to 5 &exp >6y\\nA)    select e.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade from emp\\ne,salgrade s,dept d\\nwheree.deptno = d.deptno and e.sal between s.losal and s.hisal\\nand s.grade in (3,5)\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 48}, page_content=\"and ((months_between(sysdate,hiredate))/12) > 6\\nand ( d.dname = 'ACCOUNTING' or D.loc in ('DALLAS','CHICAGO'))\\n217)   List the grades 3 emps of research and operations depts.. joined after 1987\\nand whose names should not be either miller or allen.\\nA)    select e.ename from emp e ,dept d,salgrade s\\nwhere e.deptno = d.deptno and d.dname in ('OPERATIONS','RESEARCH') and\\ne.sal between s.losal and s.hisal\\nand e.ename not in ('MILLER','ALLEN')\\nand to_char(hiredate,'YYYY') >1987;\\n218)   List the emps whose job is same as smith.\\nA) select * from emp where job = (select job from emp where ename =\\n'SMITH');\\n219)   List the emps who are senior to miller.\\nA)    select  *  from emp  where  hiredate <(select hiredate from emp where\\nename = ‘MILLER’);\\n220)   List the emps whose job is same as either allen or sal>allen.\\nA)    select * from emp\\nwhere job = (select job from emp where ename = 'ALLEN')\\nor sal > (select sal from emp where ename = 'ALLEN');\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 49}, page_content=\"221)   List the emps who are senior to their own manager.\\nA)    select * from emp w,emp m where w.mgr = m.empno and\\nw.hiredate < m.hiredate;\\n222)   List the emps whose sal greater than blakes sal.\\nA)    select * from emp\\nwhere sal>(select sal from emp where ename = ‘BLAKE’);\\n223)   List the dept 10 emps whose sal>allen sal.\\nA)    select * from emp where deptno = 10 and\\nsal > (select sal from emp where ename = 'ALLEN');\\n224)   List the mgrs who are senior to king and who are junior to smith.\\nA)select * from emp where empno in\\n(select mgr from emp\\nwhere hiredate<(select hiredate from emp where ename = 'KING' )\\nand hiredate > (select hiredate from emp where ename =  'SMITH')) and mgr\\nis       \\nnot null;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 50}, page_content=\"225)   List the empno,ename,loc,sal,dname,loc of the all the emps belonging to\\nking dept.\\nA)    select e.empno,e.ename,d.loc,e.sal,d.dname from emp e,dept d\\nwhere e.deptno=d.deptno and e.deptno in\\n(select deptno from  emp where ename = 'KING'and emp.empno <> e.empno);\\n226)   List the emps whose salgrade are greater than the grade of miller.\\nA)    select * from emp e,salgrade s\\nwhere e.sal between s.losal and s.hisal and s.grade >\\n(select s.grade from emp e,salgrade s where e.sal between s.losal and s.hisal and\\ne.ename = 'MILLER') ;\\n227)   List the emps who are belonging dallas or Chicago with the grade same as\\nadamsor exp more than smith.\\nA)    select * from emp e ,dept d,salgrade s\\nwhere e.deptno= d.deptno and d.loc in ('DALLAS','CHICAGO') and e.sal\\nbetween s.losal and s.hisal and\\n(s.grade in (select s.grade from emp e,salgrade s where e.sal between s.losal and\\ns.hisal and e.ename = 'ADAMS')\\nor months_between (sysdate,hiredate) > (select\\nmonths_between(sysdate,hiredate) from emp where ename = 'SMITH')) ;\\n228)   List the emps whose sal is same as ford or blake.\\nA)    select * from emp where sal in (select sal from emp e where e.ename in\\n('FORD','BLAKE')and emp.empno <> e.empno);\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 51}, page_content=\"229)   List the emps whose sal is same as any one of the following.\\nA)    select * from emp where sal  in \\n(select sal from emp e where emp.empno <> e.empno);\\n230)   Sal of any clerk of emp1 table.\\nA) select * from emp where job = ‘CLERK’;\\n231)   Any emp of emp2 joined before 82.\\nA) select * from emp where to_char(hiredate,'YYYY') < 1982;\\n232)   The total remuneration (sal+comm.) of all sales person of Sales dept\\nbelonging to emp3 table.\\nA)    select * from emp e\\nwhere (sal+nvl(comm,0)) in\\n(select sal+nvl(comm,0)  from emp e,dept d where e.deptno=d.deptno \\nand d.dname = 'SALES'and e.job = 'SALESMAN');\\n233)   Any Grade 4 emps Sal of emp 4 table.\\nA)    select * from emp4 e,salgrade s where e.sal between s.losal and s.hisal and\\ns.grade = 4;\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 52}, page_content='234)   Any emp Sal of emp5 table.\\nA) select * from emp5;\\n235)   List the highest paid emp.\\nA)    select * from emp where sal in (select max(sal) from emp);\\n236)   List the details of most recently hired emp of dept 30.\\nA)    select * from emp where hiredate in\\n(select max(hiredate) from emp where deptno = 30);\\n237)   List the highest paid emp of Chicago joined before the most  recently\\nhired emp of grade 2.\\nA)    select * from emp\\nwhere sal = ( select max(sal) from emp e,dept d where e.deptno = \\nd.deptno and d.loc = ‘CHICAGO’ and\\nhiredate <(select max(hiredate) from emp e ,salgrade s        \\nwhere e.sal between s.losal and s.hisal and s.grade = 2))\\n238)   List the highest paid emp working under king.\\nA)select * from emp where sal in\\n(select max(sal) from emp where mgr in'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'file_path': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:30+06:30', 'trapped': '', 'modDate': \"D:20251009201330+06'30'\", 'creationDate': '', 'page': 53}, page_content=\"(select empno from emp where ename = 'KING'));\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\", ## Pattern to match files  \n",
    "    loader_cls= PyMuPDFLoader, ##loader class to use\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad63a003",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[43mpdf_documents\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'pdf_documents' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "type(pdf_documents[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
