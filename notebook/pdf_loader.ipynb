{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4794e2",
   "metadata": {},
   "source": [
    "## RAG Pipelines = Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6edcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dubey\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679fcb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: Practical Python and OpenCV.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 2328 0 (offset 0)\n",
      "Ignoring wrong pointing object 359 0 (offset 0)\n",
      "Ignoring wrong pointing object 360 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Loaded 166 pages\n",
      "\n",
      "Processing: SQL Queries .pdf\n",
      "  ✓ Loaded 54 pages\n",
      "\n",
      "Total documents loaded: 220\n"
     ]
    }
   ],
   "source": [
    "## read all the pdf inside the directory\n",
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f09a5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 0, 'page_label': '1', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 1, 'page_label': 'i', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 2, 'page_label': 'ii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 3, 'page_label': 'iii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N T E N T S\\n1 introduction 1\\n2 python and required packages 5\\n2.1 A note on Python & OpenCV Versions . . . . 6\\n2.2 NumPy and SciPy . . . . . . . . . . . . . . . . 7\\n2.2.1 Windows . . . . . . . . . . . . . . . . . 7\\n2.2.2 OSX . . . . . . . . . . . . . . . . . . . 7\\n2.2.3 Linux . . . . . . . . . . . . . . . . . . . 8\\n2.3 Matplotlib . . . . . . . . . . . . . . . . . . . . 8\\n2.3.1 All Platforms . . . . . . . . . . . . . . 8\\n2.4 OpenCV . . . . . . . . . . . . . . . . . . . . . . 9\\n2.4.1 Linux and OSX . . . . . . . . . . . . . 9\\n2.4.2 Windows . . . . . . . . . . . . . . . . . 10\\n2.5 Mahotas . . . . . . . . . . . . . . . . . . . . . . 10\\n2.5.1 All Platforms . . . . . . . . . . . . . . 10\\n2.6 scikit-learn . . . . . . . . . . . . . . . . . . . . 11\\n2.6.1 All Platforms . . . . . . . . . . . . . . 11\\n2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19\\n4.1 So, What’s a Pixel? . . . . . . . . . . . . . . . 19\\n4.2 Overview of the Coordinate System . . . . . 22\\n4.3 Accessing and Manipulating Pixels . . . . . . 22\\n5 drawing 31\\n5.1 Lines and Rectangles . . . . . . . . . . . . . . 31\\n5.2 Circles . . . . . . . . . . . . . . . . . . . . . . 36\\n6 image processing 42\\n6.1 Image Transformations . . . . . . . . . . . . . 42\\niii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 4, 'page_label': 'iv', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\n6.1.1 Translation . . . . . . . . . . . . . . . . 43\\n6.1.2 Rotation . . . . . . . . . . . . . . . . . 48\\n6.1.3 Resizing . . . . . . . . . . . . . . . . . 53\\n6.1.4 Flipping . . . . . . . . . . . . . . . . . 59\\n6.1.5 Cropping . . . . . . . . . . . . . . . . 62\\n6.2 Image Arithmetic . . . . . . . . . . . . . . . . 64\\n6.3 Bitwise Operations . . . . . . . . . . . . . . . 71\\n6.4 Masking . . . . . . . . . . . . . . . . . . . . . 74\\n6.5 Splitting and Merging Channels . . . . . . . . 81\\n6.6 Color Spaces . . . . . . . . . . . . . . . . . . . 85\\n7 histograms 89\\n7.1 Using OpenCV to Compute Histograms . . . 90\\n7.2 Grayscale Histograms . . . . . . . . . . . . . . 91\\n7.3 Color Histograms . . . . . . . . . . . . . . . . 93\\n7.4 Histogram Equalization . . . . . . . . . . . . . 99\\n7.5 Histograms and Masks . . . . . . . . . . . . . 101\\n8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112\\n8.3 Median . . . . . . . . . . . . . . . . . . . . . . 113\\n8.4 Bilateral . . . . . . . . . . . . . . . . . . . . . . 116\\n9 thresholding 119\\n9.1 Simple Thresholding . . . . . . . . . . . . . . 119\\n9.2 Adaptive Thresholding . . . . . . . . . . . . . 123\\n9.3 Otsu and Riddler-Calvard . . . . . . . . . . . 127\\n10 gradients and edge detection 132\\n10.1 Laplacian and Sobel . . . . . . . . . . . . . . . 133\\n10.2 Canny Edge Detector . . . . . . . . . . . . . . 138\\n11 contours 142\\n11.1 Counting Coins . . . . . . . . . . . . . . . . . 142\\n11.2 Contours and OpenCV Version Caveats . . . 149\\n12 where to now ? 153\\niv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 5, 'page_label': 'v', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O M PA N I O N W E B S I T E & S U P P L E M E N TA R Y\\nM AT E R I A L\\nThank you for picking up a copy of the 4th edition of\\nPractical Python and OpenCV!\\nIn this latest edition, I’m excited to announce the creation\\nof a companion website which includes supplementary mate-\\nrial that I could not ﬁt inside the book.\\nAt the end of nearly every chapter inside Practical Python\\nand OpenCV + Case Studies, you’ll ﬁnd a link to a supplemen-\\ntary webpage that includes additional information, such as\\nmy commentary on methods to extend your knowledge,\\ndiscussions of common error messages, recommendations\\non various algorithms to try, and optional quizzes to test\\nyour knowledge.\\nRegistration to the companion website is free with your\\npurchase of Practical Python and OpenCV.\\nTo create your companion website account, just use this\\nlink:\\nhttp://pyimg.co/o1y7e\\nTake a second to create your account now so you’ll have\\naccess to the supplementary materials as you work through\\nthe book.\\nv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 6, 'page_label': 'vi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E FA C E\\nWhen I ﬁrst set out to write this book, I wanted it to be\\nas hands-on as possible. I wanted lots of visual examples\\nwith lots of code. I wanted to write something that you\\ncould easily learn from, without all the rigor and detail of\\nmathematics associated with college level computer vision\\nand image processing courses.\\nI know from all my years spent in the classroom that the\\nway I learned best was from simply opening up an editor\\nand writing some code. Sure, the theory and examples in\\nmy textbooks gave me a solid starting point. But I never\\nreally “learned” something until I did it myself. I was very\\nhands-on. And that’s exactly how I wanted this book to be.\\nVery hands-on, with all the code easily modiﬁable and well\\ndocumented so you could play with it on your own. That’s\\nwhy I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst\\nstarted learning computer vision – it was a daunting task.\\nBut I learned a lot. And I had a lot of fun.\\nI hope this book helps you in your journey into computer\\nvision. I had a blast writing it. If you have any questions,\\nsuggestions, or comments, or if you simply want to say\\nhello, shoot me an email at adrian@pyimagesearch.com, or\\nvi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 7, 'page_label': 'vii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\nyou can visit my website at www.PyImageSearch.com and\\nleave a comment. I look forward to hearing from you soon!\\n-Adrian Rosebrock\\nvii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 8, 'page_label': 'viii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E R E Q U I S I T E S\\nIn order to make the most of this, you will need to have\\na little bit of programming experience. All examples in this\\nbook are in the Python programming language. Familiarity\\nwith Python or other scripting languages is suggested, but\\nnot required.\\nYou’ll also need to know some basic mathematics. This\\nbook is hands-on and example driven: lots of examples and\\nlots of code, so even if your math skills are not up to par,\\ndo not worry! The examples are very detailed and heavily\\ndocumented to help you follow along.\\nviii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 9, 'page_label': 'ix', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N V E N T I O N S U S E D I N T H I S B O O K\\nThis book includes many code listings and terms to aid\\nyou in your journey to learn computer vision and image\\nprocessing. Below are the typographical conventions used\\nin this book:\\nItalic\\nIndicates key terms and important information that\\nyou should take note of. May also denote mathemati-\\ncal equations or formulas based on connotation.\\nBold\\nImportant information that you should take note of.\\nConstant width\\nUsed for source code listings, as well as paragraphs\\nthat make reference to the source code, such as func-\\ntion and method names.\\nix'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 10, 'page_label': 'x', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='U S I N G T H E C O D E E X A M P L E S\\nThis book is meant to be a hands-on approach to com-\\nputer vision and machine learning. The code included in\\nthis book, along with the source code distributed with this\\nbook, are free for you to modify, explore, and share as you\\nwish.\\nIn general, you do not need to contact me for permis-\\nsion if you are using the source code in this book. Writing\\na script that uses chunks of code from this book is totally\\nand completely okay with me.\\nHowever, selling or distributing the code listings in this\\nbook, whether as information product or in your product’s\\ndocumentation, does require my permission.\\nIf you have any questions regarding the fair use of the\\ncode examples in this book, please feel free to shoot me an\\nemail. You can reach me at adrian@pyimagesearch.com.\\nx'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 11, 'page_label': 'xi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='H O W T O C O N TA C T M E\\nWant to ﬁnd me online? Look no further:\\nWebsite: www.PyImageSearch.com\\nEmail: adrian@pyimagesearch.com\\nTwitter: @PyImageSearch\\nGoogle+: +AdrianRosebrock\\nLinkedIn: Adrian Rosebrock\\nxi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 12, 'page_label': '1', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='1\\nI N T R O D U C T I O N\\nThe goal of computer vision is to understand the story\\nunfolding in a picture. As humans, this is quite simple. But\\nfor computers, the task is extremely difﬁcult.\\nSo why bother learning computer vision?\\nWell, images are everywhere!\\nWhether it be personal photo albums on your smartphone,\\npublic photos on Facebook, or videos on YouTube, we now\\nhave more images than ever – and we need methods to an-\\nalyze, categorize, and quantify the contents of these images.\\nFor example, have you recently tagged a photo of your-\\nself or a friend on Facebook lately? How does Facebook\\nseem to “know” where the faces are in an image?\\nFacebook has implemented facial recognition algorithms\\ninto their website, meaning that they cannot only ﬁnd faces\\nin an image, they can also identify whose face it is as well!\\nFacial recognition is an application of computer vision in\\nthe real world.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 13, 'page_label': '2', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nWhat other types of useful applications of computer vi-\\nsion are there?\\nWell, we could build representations of our 3D world us-\\ning public image repositories like Flickr. We could down-\\nload thousands and thousands of pictures of Manhattan,\\ntaken by citizens with their smartphones and cameras, and\\nthen analyze them and organize them to construct a 3D rep-\\nresentation of the city. We would then virtually navigate\\nthis city through our computers. Sound cool?\\nAnother popular application of computer vision is surveil-\\nlance.\\nWhile surveillance tends to have a negative connotation\\nof sorts, there are many different types. One type of surveil-\\nlance is related to analyzing security videos, looking for\\npossible suspects after a robbery.\\nBut a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.\\nOn your last visit to your favorite clothing retailer, did\\nyou stop to examine the spring’s latest jeans trends? How\\nlong did you look at the jeans? What was your facial expres-\\nsion as you looked at the jeans? Did you then pick up a pair\\nand head to the dressing room? These are all types of ques-\\ntions that computer vision surveillance systems can answer.\\nComputer vision can also be applied to the medical ﬁeld.\\nA year ago, I consulted with the National Cancer Institute\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 14, 'page_label': '3', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nto develop methods to automatically analyze breast histol-\\nogy images for cancer risk factors. Normally, a task like\\nthis would require a trained pathologist with years of expe-\\nrience – and it would be extremely time consuming!\\nOur research demonstrated that computer vision algo-\\nrithms could be applied to these images and could auto-\\nmatically analyze and quantify cellular structures – without\\nhuman intervention! Now, we can analyze breast histology\\nimages for cancer risk factors much faster.\\nOf course, computer vision can also be applied to other\\nareas of the medical ﬁeld. Analyzing X-rays, MRI scans,\\nand cellular structures all can be performed using computer\\nvision algorithms.\\nPerhaps the biggest success computer vision success story\\nyou may have heard of is the X-Box 360 Kinect. The Kinect\\ncan use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.\\nThe list doesn’t stop there.\\nComputer vision is now prevalent in many areas of your\\nlife, whether you realize it or not. We apply computer vi-\\nsion algorithms to analyze movies, football games, hand\\ngesture recognition (for sign language), license plates (just\\nin case you were driving too fast), medicine, surgery, mili-\\ntary, and retail.\\nWe even use computer visions in space! NASA’s Mars\\nRover includes capabilities to model the terrain of the planet,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 15, 'page_label': '4', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\ndetect obstacles in its path, and stitch together panoramic\\nimages.\\nThis list will continue to grow in the coming years.\\nCertainly, computer vision is an exciting ﬁeld with end-\\nless possibilities.\\nWith this in mind, ask yourself: what does your imagina-\\ntion want to build? Let it run wild. And let the computer\\nvision techniques introduced in this book help you build it.\\nFurther Reading\\nWelcome to the supplementary material portion of the\\nchapter! If you haven’t already registered and created\\nyour account for the companion website, please do so\\nusing the following link:\\nhttp://pyimg.co/o1y7e\\nFrom there, you can ﬁnd the Chapter 1 supplemen-\\ntary material page here:\\nhttp://pyimg.co/rhsgi\\nThis page serves as an introduction to the companion\\nwebsite and details how to use it and what to expect\\nas you work through the rest of Practical Python and\\nOpenCV.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 16, 'page_label': '5', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2\\nP Y T H O N A N D R E Q U I R E D PA C K A G E S\\nIn order to explore the world of computer vision, we’ll\\nﬁrst need to install some packages and libraries. As a ﬁrst-\\ntimer in computer vision, installing some of these packages\\n(especially OpenCV) can be quite tedious, depending on\\nwhat operating system you are using. I’ve tried to consoli-\\ndate the installation instructions into a short how-to guide,\\nbut as you know, projects change, websites change, and in-\\nstallation instructions change! If you run into problems, be\\nsure to consult the package’s website for the most up-to-\\ndate installation instructions.\\nI highly recommend that you use either easy_install or\\npip to manage the installation of your packages. It will\\nmake your life much easier! You can read more about pip\\nhere: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image\\nprocessing packages you need to run the examples in this\\nbook pre-installed! Using this virtual machine allows you\\nto jump right in to the examples in this book, without hav-\\ning to worry about package managers, installation instruc-\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 17, 'page_label': '6', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1 a note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the\\nPython 2.7 and the Python 3+ environments!\\nIf you are looking for the OpenCV 2.4.X and Python 2.7\\nversion of this book, please look in the download directory\\nassociated with your purchase – inside you will ﬁnd the\\nOpenCV 2.4.X + Python 2.7 edition.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 18, 'page_label': '7', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.2 numpy and scipy\\n2.2 numpy and scipy\\nNumPy is a library for the Python programming language\\nthat (among other things) provides support for large, multi-\\ndimensional arrays. Why is that important? Using NumPy,\\nwe can express images as multi-dimensional arrays. Repre-\\nsenting images as NumPy arrays is not only computation-\\nally and resource efﬁcient, many other image processing\\nand machine learning libraries use NumPy array represen-\\ntations as well. Furthermore, by using NumPy’s built-in\\nhigh-level mathematical functions, we can quickly and eas-\\nily perform numerical analysis on an image.\\nGoing hand-in-hand with NumPy, we also have SciPy.\\nSciPy adds further support for scientiﬁc and technical com-\\nputing.\\n2.2.1 Windows\\nBy far, the easiest way to install NumPy and SciPy on your\\nWindows system is to download and install the binary dis-\\ntribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.\\nYou can also install NumPy and SciPy using pip:\\nListing 2.1: Install NumPy and SciPy on OSX\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 19, 'page_label': '8', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.3 matplotlib\\n$ pip install numpy\\n$ pip install scipy\\n2.2.3 Linux\\nOn many Linux distributions, such as Ubuntu, NumPy comes\\npre-installed and conﬁgured.\\nIf you want the latest versions of NumPy and SciPy, you\\ncan build the libraries from source, but the easiest method\\nis to use a pip:\\nListing 2.2: Install NumPy and SciPy on Linux\\n$ pip install numpy\\n$ pip install scipy\\n2.3 matplotlib\\nSimply put, matplotlib is a plotting library. If you’ve ever\\nused MATLAB before, you’ll probably feel very comfort-\\nable in the matplotlib environment. When analyzing im-\\nages, we’ll make use of matplotlib. Whether plotting image\\nhistograms or simply viewing the image itself, matplotlib\\nis a great tool to have in your toolbox.\\n2.3.1 All Platforms\\nMatplotlib is available from http://matplotlib.org/. The\\nmatplotlib package is also pip-installable:\\nListing 2.3: Install matplotlib\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 20, 'page_label': '9', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4 opencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in\\nprevious years, but has luckily gotten much easier. I have\\naccumulated OpenCV installation instructions on the PyIm-\\nageSearch blog for Debian-based Linux distributions (such\\nas Ubuntu) and OSX here:\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 21, 'page_label': '10', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.5 mahotas\\nhttp://pyimg.co/vvlpy\\nJust scroll down the “Install OpenCV 3 and Python” and\\n“Install OpenCV 4 and Python” sections, select the oper-\\nating system and Python version that you want to install\\nOpenCV for, and you’ll be on your way!\\n2.4.2 Windows\\nThe OpenCV Docs provide fantastic tutorials on how to in-\\nstall OpenCV in Windows using binary distributions. You\\ncan check out the installation instructions here:\\nhttp://pyimg.co/l2q6s\\n2.5 mahotas\\nMahotas, just like OpenCV , relies on NumPy arrays. Much\\nof the functionality implemented in Mahotas can be found\\nin OpenCV , but in some cases, the Mahotas interface is just\\neasier to use. We’ll use Mahotas to complement OpenCV .\\n2.5.1 All Platforms\\nInstalling Mahotas is extremely easy on all platforms. As-\\nsuming you already have NumPy and SciPy installed, all\\nyou need is a single call to the pip command:\\nListing 2.4: Install Mahotas\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 22, 'page_label': '11', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.6 scikit -learn\\n$ pip install mahotas\\n2.6 scikit -learn\\nAlright, you got me, scikit-learn isn’t an image processing\\nor computer vision library – it’s a machine learning library.\\nThat said, you can’t have advanced computer vision tech-\\nniques without some sort of machine learning, whether it\\nbe clustering, vector quantization, classiﬁcation models, etc.\\nScikit-learn also includes a handful of image feature extrac-\\ntion functions as well. We don’t use the scikit-learn library\\nin Practical Python and OpenCV, but it’s heavily used inCase\\nStudies.\\n2.6.1 All Platforms\\nInstalling scikit-learn on all platforms is dead-simple using\\npip:\\nListing 2.5: Install scikit-learn\\n$ pip install scikit-learn\\n2.7 scikit -image\\nThe algorithms included in scikit-image (I would argue) fol-\\nlow closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-\\nrithms, you need to have developed some rigor and under-\\nstanding in the computer vision ﬁeld. If you already have\\nsome experience in computer vision and image processing,\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 23, 'page_label': '12', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\ndeﬁnitely check out scikit-image; otherwise, I would con-\\ntinue working with OpenCV to start. Again, scikit-image\\nwon’t be used in of Practical Python and OpenCV, but it will\\nbe used in Case Studies, especially when we perform hand-\\nwritten digit recognition.\\nAssuming you already have NumPy and SciPy installed,\\nyou can install scikit-image using pip:\\nListing 2.6: Install scikit-image\\n$ pip install -U scikit-image\\nNow that we have all our packages installed, let’s start\\nexploring the world of computer vision!\\n2.8 skip the installation\\nAs I’ve mentioned above, installing all these packages can\\nbe time consuming and tedious. If you want to skip the\\ninstallation process and jump right into the world of im-\\nage processing and computer vision, I have set up a pre-\\nconﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 24, 'page_label': '13', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\nFurther Reading\\nTo learn more about installing OpenCV , Python virtual\\nenvironments, and choosing a code editor, please see\\nthe Chapter 2 supplementary material webpage:\\nhttp://pyimg.co/f0sxq\\nIn particular, I think you’ll be interested in learning\\nhow the PyCharm IDE can be utilized with Python vir-\\ntual environments to create the perfect computer vision\\ndevelopment environment.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 25, 'page_label': '14', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='3\\nL O A D I N G , D I S P L AY I N G , A N D S AV I N G\\nThis book is meant to be a hands-on, how-to guide to get-\\nting started with computer vision using Python and OpenCV .\\nWith that said, let’s not waste any time. We’ll get our feet\\nwet by writing some simple code to load an image off disk,\\ndisplay it on our screen, and write it to ﬁle in a different\\nformat. When executed, our Python script should show\\nour image on screen, like in Figure 3.1.\\nFirst, let’s create a ﬁle named load_display_save.py to\\ncontain our code. Now we can start writing some code:\\nListing 3.1: load_display_save.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\nThe ﬁrst thing we are going to do is import the packages\\nwe will need for this example.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 26, 'page_label': '15', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nFigure 3.1: Example of loading and displaying\\na Tyrannosaurus Rex image on our\\nscreen.\\nThroughout this book you’ll see us importing the print_\\nfunction from the __future__ package. We’ll be using the\\nactual print() function rather than the print statement so\\nthat our code will work with both Python 2.7 and Python\\n3 – just something to keep in mind as we work through the\\nexamples!\\nWe’ll useargparse to handle parsing our command line\\narguments. Then, cv2 is imported – cv2 is our OpenCV li-\\nbrary and contains our image processing functions.\\nFrom there, Lines 5-8 handle parsing the command line\\narguments. The only argument we need is --image: the\\npath to our image on disk. Finally, we parse the arguments\\nand store them in a dictionary.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 27, 'page_label': '16', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nListing 3.2: load_display_save.py\\n9 image = cv2.imread(args[\"image\"])\\n10 print(\"width: {} pixels\".format(image.shape[1]))\\n11 print(\"height: {} pixels\".format(image.shape[0]))\\n12 print(\"channels: {}\".format(image.shape[2]))\\n13\\n14 cv2.imshow(\"Image\", image)\\n15 cv2.waitKey(0)\\nNow that we have the path to the image, we can load it\\noff the disk using the cv2.imread function on Line 9. The\\ncv2.imread function returns a NumPy array representing\\nthe image.\\nLines 10-12 examine the dimensions of the image. Again,\\nsince images are represented as NumPy arrays, we can sim-\\nply use the shape attribute to examine the width, height,\\nand the number of channels.\\nFinally, Lines 14 and 15 handle displaying the actual\\nimage on our screen. The ﬁrst parameter is a string, the\\n“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until\\nwe press a key on our keyboard. Using a parameter of 0\\nindicates that any keypress will un-pause the execution.\\nThe last thing we are going to do is write our image to\\nﬁle in JPG format:\\nListing 3.3: load_display_save.py\\n16 cv2.imwrite(\"newimage.jpg\", image)\\nAll we are doing here is providing the path to the ﬁle\\n(the ﬁrst argument) and then the image we want to save\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 28, 'page_label': '17', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\n(the second argument). It’s that simple.\\nTo run our script and display our image, we simply open\\nup a terminal window and execute the following command:\\nListing 3.4: load_display_save.py\\n$ python load_display_save.py --image ../images/trex.png\\nIf everything has worked correctly, you should see the T-\\nRex on your screen as in Figure 3.1. To stop the script from\\nexecuting, simply click on the image window and press any\\nkey.\\nExamining the output of the script, you should also see\\nsome basic information on our image. You’ll note that the\\nimage has a width of 350 pixels, a height of 228 pixels, and 3\\nchannels (the RGB components of the image). Represented\\nas a NumPy array, our image has a shape of (228,350,3).\\nThe NumPy shape may seem reversed to you (specifying\\nthe height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).\\nHere, our image has a height of 228 pixels (the number of\\nrows) and a width of 350 pixels (the number of columns) –\\nthus, the NumPy shape makes sense (although it may seen\\na bit confusing at ﬁrst).\\nFinally, note the contents of your directory. You’ll see a\\nnew ﬁle there: newimage.jpg. OpenCV has automatically\\nconverted our PNG image to JPG for us! No further effort\\nis needed on our part to convert between image formats.\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 29, 'page_label': '18', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nNext up, we’ll explore how to access and manipulate the\\npixel values in an image.\\nFurther Reading\\nYou can ﬁnd the Chapter 3 supplementary material, re-\\nsources, and quizzes here:\\nhttp://pyimg.co/xh73h\\nSpeciﬁcally, I discuss some common “gotchas” that may\\ntrip you up when utilizing OpenCV for the ﬁrst time –\\nthese tips and tricks are especially useful if this is your\\nﬁrst exposure to OpenCV .\\nBe sure to take the quiz to test your knowledge after\\nreading this chapter!\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 30, 'page_label': '19', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4\\nI M A G E B A S I C S\\nIn this chapter we are going to review the building blocks\\nof an image – the pixel. We’ll discuss exactly what a pixel\\nis, how pixels are used to form an image, and then how to\\naccess and manipulate pixels in OpenCV .\\n4.1 so , what ’s a pixel?\\nEvery image consists of a set of pixels. Pixels are the raw\\nbuilding blocks of an image. There is no ﬁner granularity\\nthan the pixel.\\nNormally, we think of a pixel as the “color” or the “inten-\\nsity” of light that appears in a given place in our image.\\nIf we think of an image as a grid, each square in the grid\\ncontains a single pixel.\\nFor example, let’s pretend we have an image with a res-\\nolution of 500 × 300. This means that our image is repre-\\nsented as a grid of pixels, with 500 rows and 300 columns.\\nOverall, there are 500 × 300 = 150, 000 pixels in our image.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 31, 'page_label': '20', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nMost pixels are represented in two ways: grayscale and\\ncolor. In a grayscale image, each pixel has a value between\\n0 and 255, where zero corresponds to “black” and 255 cor-\\nresponds to “white”. The values in between 0 and 255 are\\nvarying shades of gray, where values closer to 0 are darker\\nand values closer to 255 are lighter.\\nColor pixels are normally represented in the RGB color\\nspace – one value for the Red component, one for Green,\\nand one for Blue. Other color spaces exist, but let’s start\\nwith the basics and move our way up from there.\\nEach of the three colors is represented by an integer in\\nthe range 0 to 255, which indicates how “much” of the color\\nthere is. Given that the pixel value only needs to be in the\\nrange [0, 255], we normally use an 8-bit unsigned integer to\\nrepresent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.\\nTo construct a white color, we would ﬁll up each of the\\nred, green, and blue buckets completely, like this: (255,\\n255,255).\\nThen, to create a black color, we would empty each of the\\nbuckets out: (0,0,0).\\nTo create a pure red color, we would ﬁll up the red bucket\\n(and only the red bucket) up completely: (255,0,0).\\nAre you starting to see a pattern?\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 32, 'page_label': '21', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nFor your reference, here are some common colors repre-\\nsented as RGB tuples:\\n• Black: (0,0,0)\\n• White: (255,255,255)\\n• Red: (255,0,0)\\n• Green: (0,255,0)\\n• Blue: (0,0,255)\\n• Aqua: (0,255,255)\\n• Fuchsia: (255,0,255)\\n• Maroon: (128,0,0)\\n• Navy: (0,0,128)\\n• Olive: (128,128,0)\\n• Purple: (128,0,128)\\n• Teal: (0,128,128)\\n• Yellow: (255,255,0)\\nNow that we have a good understanding of pixels, let’s\\nhave a quick review of the coordinate system.\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 33, 'page_label': '22', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.2 overview of the coordinate system\\n4.2 overview of the coordinate system\\nAs I mentioned above, an image is represented as a grid of\\npixels. Imagine our grid as a piece of graph paper. Using\\nthis graph paper, the point (0, 0) corresponds to the upper\\nleft corner of the image. As we move down and to the right,\\nboth the x and y values increase.\\nLet’s take a look at the image in Figure 4.1 to make this\\npoint clearer.\\nHere we have the letter “I” on a piece of graph paper. We\\nsee that we have an 8 × 8 grid with a total of 64 pixels.\\nThe point (0, 0) corresponds to the top left pixel in our\\nimage, whereas the point (7, 7) corresponds to the bottom\\nright corner.\\nFinally, the point (3, 4) is the pixel three columns to the\\nright and four rows down, once again keeping in mind that\\nwe start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.\\n4.3 accessing and manipulating pixels\\nAdmittedly, the example from Chapter 3 wasn’t very excit-\\ning. All we did was load an image off disk, display it, and\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 34, 'page_label': '23', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.1: The letter “I” placed on a piece of\\ngraph paper. Pixels are accessed by\\ntheir (x, y) coordinates, where we go\\nx columns to the right and y rows\\ndown, keeping in mind that Python\\nis zero-indexed: we start counting\\nfrom zero rather than one.\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 35, 'page_label': '24', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nthen write it back to disk in a different image ﬁle format.\\nLet’s do something a little more exciting and see how we\\ncan access and manipulate the pixels in an image:\\nListing 4.1: getting_and_setting.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nSimilar to our example in the previous chapter, Lines 1-8\\nhandle importing the packages we need, along with setting\\nup our argument parser. There is only one command line\\nargument needed: the path to the image we are going to\\nwork with.\\nLines 10 and 11 handle loading the actual image off disk\\nand displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.\\nConceptually, we can think of this representation as a ma-\\ntrix, as discussed in Section 4.1 above. In order to access a\\npixel value, we just need to supply the x and y coordinates\\nof the pixel we are interested in. From there, we are given\\na tuple representing the Red, Green, and Blue components\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 36, 'page_label': '25', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nof the image.\\nHowever, it’s important to note that OpenCV stores RGB\\nchannels in reverse order. While we normally think in terms\\nof Red, Green, and Blue, OpenCV actually stores them in\\nthe order of Blue, Green, and Red. This is important to\\nnote since it could cause some confusion later.\\nAlright, let’s explore some code that can be used to ac-\\ncess and manipulate pixels:\\nListing 4.2: getting_and_setting.py\\n12 (b, g, r) = image[0, 0]\\n13 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\n14\\n15 image[0, 0] = (0, 0, 255)\\n16 (b, g, r) = image[0, 0]\\n17 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\nOn Line 12, we grab the pixel located at (0, 0) – the top-\\nleft corner of the image. This pixel is represented as a tuple.\\nAgain, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out\\nthe values of each channel to our console.\\nAs you can see, accessing pixel values is quite easy! Num-\\nPy takes care of all the hard work for us. All we are doing\\nis providing indexes into the array.\\nJust as NumPy makes it easy to access pixel values, it also\\nmakes it easy to manipulate pixel values.\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 37, 'page_label': '26', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nOn Line 15 we manipulate the top-left pixel in the im-\\nage, which is located at coordinate (0, 0) and set it to have\\na value of (0, 0, 255). If we were reading this pixel value\\nin RGB format, we would have a value of 0 for red, 0 for\\ngreen, and 255 for blue, thus making it a pure blue color.\\nHowever, as I mentioned above, we need to take special\\ncare when working with OpenCV . Our pixels are actually\\nstored in BGR format, not RGB format.\\nWe actually read this pixel as255 for red, 0 for green, and\\n0 for blue, making it a red color, not a blue color.\\nAfter setting the top-left pixel to have a red color on Line\\n15, we then grab the pixel value and print it back to con-\\nsole on Lines 16 and 17, just to demonstrate that we have\\nindeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-\\nbilities to access larger rectangular portions of the image?\\nThe code below demonstrates how we can do this:\\nListing 4.3: getting_and_setting.py\\n18 corner = image[0:100, 0:100]\\n19 cv2.imshow(\"Corner\", corner)\\n20\\n21 image[0:100, 0:100] = (0, 255, 0)\\n22\\n23 cv2.imshow(\"Updated\", image)\\n24 cv2.waitKey(0)\\nOn Line 18 we grab a 100 × 100 pixel region of the image.\\nIn fact, this is the top-left corner of the image! In order to\\ngrab chunks of an image, NumPy expects we provide four\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 38, 'page_label': '27', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nindexes:\\n1. Start y: The ﬁrst value is the starting y coordinate.\\nThis is where our array slice will start along the y-axis.\\nIn our example above, our slice starts at y = 0.\\n2. End y:Just as we supplied a starting y value, we must\\nprovide an ending y value. Our slice stops along the\\ny-axis when y = 100.\\n3. Start x:The third value we must supply is the starting\\nx coordinate for the slice. In order to grab the top-left\\nregion of the image, we start at x = 0.\\n4. End x:Finally, we need to provide an x-axis value for\\nour slice to stop. We stop when x = 100.\\nOnce we have extracted the top-left corner of the image,\\nLine 19 shows us the result of the cropping. Notice how\\nour image is just the 100 × 100 pixel region from the top-\\nleft corner of our original image.\\nThe last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the\\nimage; however, this time we are setting this region to have\\na value of (0, 255, 0) (green).\\nLines 23 and 24 then show us the results of our work.\\nSo how do we run our Python script?\\nAssuming you have downloaded the source code listings\\nfor this book, simply navigate to the chapter-04 directory\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 39, 'page_label': '28', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nand execute the command below:\\nListing 4.4: getting_and_setting.py\\n$ python getting_and_setting.py --image ../images/trex.png\\nOnce our script starts running, you should see some out-\\nput printed to your console ( Line 13). The ﬁrst line of out-\\nput tells us that the pixel located at (0, 0) has a value of\\n254 for all three red, green, and blue channels. This pixel\\nappears to be almost pure white.\\nThe second line of output shows us that we have success-\\nfully changed the pixel located at (0, 0) to be red rather than\\nwhite (Lines 15-17).\\nListing 4.5: getting_and_setting.py\\nPixel at (0, 0) - Red: 254, Green: 254, Blue: 254\\nPixel at (0, 0) - Red: 255, Green: 0, Blue: 0\\nWe can see the results of our work in Figure 4.2. The Top-\\nLeft image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if\\nyou look closely, you can see that the top-left pixel located\\nat (0, 0) is red!\\nFinally, the bottom image shows that we have successfully\\ndrawn a green square on our image.\\nIn this chapter, we have explored how to access and ma-\\nnipulate the pixels in an image using NumPy’s built-in ar-\\nray slicing functionality. We were even able to draw a green\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 40, 'page_label': '29', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.2: Top-Left: Our original image. Top-\\nRight: Cropping our image using\\nNumPy array slicing. Bottom: Draw-\\ning a 100 ×100 pixel green square on\\nour image by using basic NumPy in-\\ndexing.\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 41, 'page_label': '30', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nsquare using nothing but NumPy array manipulation!\\nHowever, we won’t get very far using only NumPy func-\\ntions. The next chapter will show you how to draw lines,\\nrectangles, and circles using OpenCV methods.\\nFurther Reading\\nOne of the most common errors I see with developers\\njust starting to learn OpenCV is the (x, y) -coordinate\\nordering passed into images. I also tend to see a lot of\\nconfusion regarding the BGR versus RGB channel or-\\ndering.\\nTo learn more about these common errors (and how\\nyou can avoid) then, be sure to refer to the Chapter 4\\nsupplementary material:\\nhttp://pyimg.co/mtemn\\nI’ve also included a quiz that you can use to test your\\nknowledge on image basics.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 42, 'page_label': '31', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5\\nD R AW I N G\\nUsing NumPy array slices in Chapter 4, we were able to\\ndraw a green square on our image. But what if we wanted\\nto draw a single line? Or a circle? NumPy does not provide\\nthat type of functionality – it’s only a numerical processing\\nlibrary after all!\\nLuckily, OpenCV provides convenient, easy-to-use meth-\\nods to draw shapes on an image. In this chapter, we’ll re-\\nview the three most basic methods to draw shapes: cv2.\\nline, cv2.rectangle, and cv2.circle.\\nWhile this chapter is by no means a complete, exhaus-\\ntive overview of the drawing capabilities of OpenCV , it will\\nnonetheless provide a quick, hands-on approach to get you\\nstarted drawing immediately.\\n5.1 lines and rectangles\\nBefore we start exploring the the drawing capabilities of\\nOpenCV , let’s ﬁrst deﬁne our canvas in which we will draw\\nour masterpieces.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 43, 'page_label': '32', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nUp until this point, we have only loaded images off disk.\\nHowever, we can also deﬁne our images manually using\\nNumPy arrays. Given that OpenCV interprets an image as\\na NumPy array, there is no reason why we can’t manually\\ndeﬁne the image ourselves!\\nIn order to initialize our image, let’s examine the code\\nbelow:\\nListing 5.1: drawing.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\nLines 1 and 2 imports the packages we will be using.\\nAs a shortcut, we’ll create an alias for numpy as np. We’ll\\ncontinue this convention throughout the rest of the book.\\nIn fact, you’ll commonly see this convention in the Python\\ncommunity as well! We’ll also import cv2, so we can have\\naccess to the OpenCV library.\\nInitializing our image is handled on Line 4. We construct\\na NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,\\nrespectively. As the name suggests, the zeros method ﬁlls\\nevery element in the array with an initial value of zero.\\nIt’s important to draw your attention to the second argu-\\nment of the np.zeros method: the data type, dtype. Since\\nwe are representing our image as an RGB image with pixels\\nin the range [0, 255], it’s important that we use an 8-bit un-\\nsigned integer, or uint8. There are many other data types\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 44, 'page_label': '33', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nthat we can use (common ones include 32-bit integers, and\\n32-bit or 64-bit ﬂoats), but we’ll mainly be using uint8 for\\nthe majority of the examples in this book.\\nNow that we have our canvas initialized, we can do some\\ndrawing:\\nListing 5.2: drawing.py\\n5 green = (0, 255, 0)\\n6 cv2.line(canvas, (0, 0), (300, 300), green)\\n7 cv2.imshow(\"Canvas\", canvas)\\n8 cv2.waitKey(0)\\n9\\n10 red = (0, 0, 255)\\n11 cv2.line(canvas, (300, 0), (0, 300), red, 3)\\n12 cv2.imshow(\"Canvas\", canvas)\\n13 cv2.waitKey(0)\\nThe ﬁrst thing we do on Line 5 is deﬁne a tuple used to\\nrepresent the color “green”. Then, we draw a green line\\nfrom point (0, 0) (the top-left corner of the image) to point\\n(300, 300), the bottom-right corner of the image on Line 6.\\nIn order to draw the line, we make use of the cv2.line\\nmethod. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose\\nto start our line from the top-left corner of the image, at\\npoint (0, 0). We also need to supply an ending point for the\\nline (the third argument). We deﬁne our ending point to be\\n(300, 300), the bottom-right corner of the image. The last ar-\\ngument is the color of our line, which, in this case, is green.\\nLines 7 and 8 show our image and then wait for a keypress.\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 45, 'page_label': '34', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nFigure 5.1: Examples of drawing lines and rect-\\nangles using OpenCV .\\nAs you can see, drawing a line is quite simple! But\\nthere is one other important argument to consider in the\\ncv2.line method: the thickness.\\nOn Lines 10-13 we deﬁne a red color as a tuple (again,\\nin BGR rather than RGB format). We then draw a red line\\nfrom the top-right corner of the image to the bottom left.\\nThe last parameter to the method controls the thickness of\\nthe line – we decide to make the thickness 3 pixels. Again,\\nwe show our image and wait for a keypress.\\nDrawing a line was simple enough. Now we can move on\\nto drawing rectangles. Check out the code below for more\\ndetails:\\nListing 5.3: drawing.py\\n14 cv2.rectangle(canvas, (10, 10), (60, 60), green)\\n15 cv2.imshow(\"Canvas\", canvas)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 46, 'page_label': '35', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\n16 cv2.waitKey(0)\\n17\\n18 cv2.rectangle(canvas, (50, 200), (200, 225), red, 5)\\n19 cv2.imshow(\"Canvas\", canvas)\\n20 cv2.waitKey(0)\\n21\\n22 blue = (255, 0, 0)\\n23 cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)\\n24 cv2.imshow(\"Canvas\", canvas)\\n25 cv2.waitKey(0)\\nOn Line 14 we make use of the cv2.rectangle method.\\nThe signature of this method is identical to the cv2.line\\nmethod above, but let’s explore each argument anyway.\\nThe ﬁrst argument is the image we want to draw our rect-\\nangle on. We want to draw on ourcanvas, so we pass it into\\nthe method. The second argument is the starting (x, y) po-\\nsition of our rectangle – here, we are starting our rectangle\\nat point (10, 10). Then, we must provide an ending (x, y)\\npoint for the rectangle. We decide to end our rectangle at\\n(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also\\ncontrol the thickness of a rectangle. Line 18 provides one\\nadded argument: the thickness. Here, we draw a red rect-\\nangle that is 5 pixels thick, starting from point (50, 200) and\\nending at (200, 225).\\nAt this point, we have only drawn the outline of a rect-\\nangle. How do we draw a rectangle that is “ﬁlled in”, like\\nwhen using NumPy array slices in Chapter 4?\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 47, 'page_label': '36', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.2: Drawing a simple bullseye with the\\ncv2.circle function.\\nSimple. We just pass in a negative value for the thickness\\nargument.\\nLine 23 demonstrates how to draw a rectangle of a solid\\ncolor. We draw a blue rectangle, starting from (200, 50) and\\nending at (225, 125). By specifying -1 as the thickness, our\\nrectangle is drawn as a solid blue.\\nCongratulations! You now have a solid grasp of drawing\\nrectangles. In the next section, we’ll move on to drawing\\ncircles.\\n5.2 circles\\nDrawing circles is just as simple as drawing rectangles, but\\nthe function arguments are a little different. Let’s go ahead\\nand get started:\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 48, 'page_label': '37', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nListing 5.4: drawing.py\\n26 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\n27 (centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\\n28 white = (255, 255, 255)\\n29\\n30 for r in range(0, 175, 25):\\n31 cv2.circle(canvas, (centerX, centerY), r, white)\\n32\\n33 cv2.imshow(\"Canvas\", canvas)\\n34 cv2.waitKey(0)\\nOn Line 26 we re-initialize our canvas to be blank. The\\nrectangles are gone! We need a fresh canvas to draw our\\ncircles.\\nLine 27 calculates two variables: centerX and centerY.\\nThese two variables represent the (x, y) coordinates of the\\ncenter of the image. We calculate the center by examining\\nthe shape of our NumPy array, and then dividing by two.\\nThe height of the image can be found in canvas.shape[0]\\nand the width in canvas.shape[1]. Finally, Line 28 deﬁnes\\na white pixel.\\nNow, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.\\nLine 31 handles the actual drawing of the circle. The ﬁrst\\nparameter is our canvas, the image we want to draw the\\ncircle on. We then need to supply the point in which our\\ncircle will be drawn around. We pass in a tuple of(centerX,\\ncenterY) so that our circles will be centered at the middle\\nof the image. The third argument is the radius of the circle\\nwe wish to draw. Finally, we pass in the color of our circle,\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 49, 'page_label': '38', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nin this case, white.\\nLines 33 and 34 then show our image and wait for a key-\\npress.\\nSo what does our image look like?\\nCheck out Figure 5.2 and you will see that we have drawn\\na simple bullseye! The “dot” in the very center of the image\\nis drawn with a radius of 0. The larger circles are drawn\\nwith every increasing radii sizes from our for loop.\\nNot too bad. But what else can we do?\\nLet’s do some abstract drawing:\\nListing 5.5: drawing.py\\n35 for i in range(0, 25):\\n36 radius = np.random.randint(5, high = 200)\\n37 color = np.random.randint(0, high = 256, size = (3,)).tolist\\n()\\n38 pt = np.random.randint(0, high = 300, size = (2,))\\n39\\n40 cv2.circle(canvas, tuple(pt), radius, color, -1)\\n41\\n42 cv2.imshow(\"Canvas\", canvas)\\n43 cv2.waitKey(0)\\nOur code starts off on Line 35 with more looping. This\\ntime we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.\\nIn order to draw a random circle, we need to generate\\nthree values: the radius of the circle, the color of the circle,\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 50, 'page_label': '39', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.3: The results of our masterpiece. No-\\ntice that each circle is randomly\\nplaced on the canvas with a random\\ncolor.\\nand the pt – the (x, y) coordinate of where the circle will be\\ndrawn.\\nWe generate a radius value in the range [5, 200) on Line\\n36. This value controls how large our circle will be.\\nNext, we randomly generate a color on Line 37. As we\\nknow, the color of an RGB pixel consists of three values in\\nthe range [0, 255]. In order to get three random integers\\nrather than only one integer, we pass the keyword argu-\\nment size=(3,), instructing NumPy to return a list of three\\nnumbers.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 51, 'page_label': '40', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFinally, we need an (x, y) point to draw our circle. We’ll\\ngenerate a point in the range [0, 300), again using NumPy’s\\nnp.random.randint function.\\nThe drawing of our circle then takes place on Line 40,\\nusing the radius, color, and pt that we randomly gener-\\nated. Notice how we use a thickness of -1, so our circles\\nare drawn as a solid color and not just an outline.\\nOur masterpiece is then shown to us on Lines 42 and 43.\\nYou can check out our work in Figure 5.3. Notice how\\neach circle has a different size, color, and placement on our\\ncanvas.\\nIn this chapter, you were introduced to basic drawing\\nfunctions using OpenCV . We explored how to draw shapes\\nusing the cv2.line, cv2.rectangle, and cv2.circle meth-\\nods.\\nWhile these functions seem extremely basic and simple,\\nmake sure you understand them! They are essential build-\\ning blocks that will come in handy later in this book.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 52, 'page_label': '41', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFurther Reading\\nWhy are we bothering learning how to draw rectangles,\\ncircles, and lines in a book on computer vision and im-\\nage processing?\\nIsn’t the point of computer vision to write software that\\nunderstands the contents of an image? And if so, why\\nin the world do we need to know how to draw various\\nshapes on images?\\nThese are excellent questions – and I address each of\\nthem (and provide examples of how drawing methods\\nare used in object detection and extraction) in side the\\nChapter 5 supplementary material:\\nhttp://pyimg.co/rlpak\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 53, 'page_label': '42', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6\\nI M A G E P R O C E S S I N G\\nNow that you have a solid foundation to build upon, we\\ncan start to exploring simple image processing techniques.\\nFirst, we’ll start off with basic image transformations,\\nsuch as translation, rotation, resizing, ﬂipping, and crop-\\nping. Then, we’ll explore other types of image processing\\ntechniques, including image arithmetic, bitwise operations,\\nand masking.\\nFinally, we’ll explore how to split an image into its re-\\nspective channels and then merge them back together again.\\nWe’ll conclude this chapter with a discussion of different\\ncolor spaces that OpenCV supports and the beneﬁts and\\nlimitations of each of them.\\n6.1 image transformations\\nIn this section, we’ll cover basic image transformations. These\\nare common techniques that you’ll likely apply to images,\\nincluding translation, rotation, resizing, ﬂipping, and crop-\\nping. We’ll explore each of these techniques in detail.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 54, 'page_label': '43', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nMake sure you have a good grasp of these methods! They\\nare important in nearly all areas of computer vision.\\n6.1.1 Translation\\nThe ﬁrst method we are going to explore is translation.\\nTranslation is the shifting of an image along the x and y\\naxis. Using translation, we can shift an image up, down,\\nleft, or right, along with any combination of the above!\\nThis concept is better explained through some code:\\nListing 6.1: translation.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 M = np.float32([[1, 0, 25], [0, 1, 50]])\\n15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])\\n19 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n20 cv2.imshow(\"Shifted Up and Left\", shifted)\\nOn Lines 1-4, we simply import the packages we will\\nmake use of. At this point, using numpy, argparse, and\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 55, 'page_label': '44', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\ncv2 should feel commonplace already. However, I am intro-\\nducing a new package here: imutils. This isn’t a package\\nincluded in NumPy or OpenCV . Rather, it’s a library that\\nwe are going to write ourselves and create “convenience”\\nmethods to do common tasks like translation, rotation, and\\nresizing.\\nAfter we have the necessary packages imported, we con-\\nstruct our argument parser and load our image on Lines\\n6-12.\\nThe actual translation takes place on Lines 14-16. We ﬁrst\\ndeﬁne our translation matrix M. This matrix tells us how\\nmany pixels to the left or right, and up or down, the image\\nwill be shifted.\\nOur translation matrix M is deﬁned as a ﬂoating point\\narray – this is important because OpenCV expects this ma-\\ntrix to be of ﬂoating point type. The ﬁrst row of the matrix\\nis [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to\\nthe right.\\nThen, we deﬁne the second row of the matrix as [0, 1,ty],\\nwhere ty is the number of pixels we will shift the image up\\nor down. Negative value of ty will shift the image up and\\npositive values will shift the image down.\\nUsing this notation, we can see on Line 14 that tx = 25\\nand ty = 50, implying that we are shifting the image 25 pix-\\nels to the right and 50 pixels down.\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 56, 'page_label': '45', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nNow that we have our translation matrix deﬁned, the\\nactual translation takes place on Line 15 using the cv2.\\nwarpAffine function. The ﬁrst argument is the image we\\nwish to shift and the second argument is our translation ma-\\ntrix M. Finally, we manually supply the dimensions (width\\nand height) of our image as the third argument. Line 16\\nshows the results of the translation.\\nMoving on to Lines 18-20, we perform another transla-\\ntion. Here, we set tx = −50 and ty = −90, implying that\\nwe are shifting the image 50 pixels to the left and 90 pixels\\nup. The image is shifted left and up rather than right and\\ndown, because we are providing a negative values for both\\ntx and ty.\\nHowever, manually constructing this translation matrix\\nand calling the cv2.warpAffine method takes a fair amount\\nof code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently\\ncall them without writing a lot of code.\\nThe ﬁrst method we are going to deﬁne is a translate\\nfunction:\\nListing 6.2: imutils.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 def translate(image, x, y):\\n5 M = np.float32([[1, 0, x], [0, 1, y]])\\n6 shifted = cv2.warpAffine(image, M, (image.shape[1], image.\\nshape[0]))\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 57, 'page_label': '46', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n7\\n8 return shifted\\nOur translate method takes three parameters: the image\\nwe are going to translate, the number of pixels that we are\\ngoing to shift along the x-axis, and the number of pixels we\\nare going to shift along the y-axis.\\nThis method then deﬁnes our translation matrix M on\\nLine 5 and then applies the actual shift on Line 6. Finally,\\nwe return the shifted image on Line 8.\\nLet’s apply our translate method and compare to the\\nmethods discussed above:\\nListing 6.3: translation.py\\n21 shifted = imutils.translate(image, 0, 100)\\n22 cv2.imshow(\"Shifted Down\", shifted)\\n23 cv2.waitKey(0)\\nUsing our convenience translate method, we are able\\nto shift the image 100 pixels down using a single line of\\ncode. Furthermore, this translate method is much easier\\nto use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.\\nOur original image is on the top-left. On the top-right, we\\nshift our image 25 pixels to the right and 50 pixels down.\\nNext, we translate our image 50 pixels to the left and 90\\npixels up by using negative values for tx and ty. Finally, on\\nthe bottom-right, we shift our T-Rex 100 pixels down using\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 58, 'page_label': '47', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.1: Top-Left: Our original T-Rex image.\\nTop-Right: Translating our image 25\\npixels to the right and 50 pixels\\ndown. Bottom-Left: Shifting T-Rex\\n50 pixels to the left and 90 pix-\\nels up. Bottom-Right: Shifting the\\nT-Rex down using our convenience\\nmethod.\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 59, 'page_label': '48', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nour convenient translate method deﬁned above.\\nIn this section we explored how to shift an image up,\\ndown, left, and right. Next up, we’ll explore how to rotate\\nan image.\\n6.1.2 Rotation\\nRotation is exactly what it sounds like: rotating an image\\nby some angle θ. In this section, we’ll explore how to rotate\\nan image. We’ll use θ to represent by how many degrees\\nwe are rotating the image. Later, I’ll provide another con-\\nvenience method, rotate, to make performing rotations on\\nimages easier.\\nListing 6.4: rotate.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))\\n19 cv2.imshow(\"Rotated by 45 Degrees\", rotated)\\n20\\n21 M = cv2.getRotationMatrix2D(center, -90, 1.0)\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 60, 'page_label': '49', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n22 rotated = cv2.warpAffine(image, M, (w, h))\\n23 cv2.imshow(\"Rotated by -90 Degrees\", rotated)\\nLines 1-4 again import the packages we need. You should\\ntake note of imutils. Once again, we will be deﬁning a con-\\nvenience method to make our lives easier.\\nLines 6-12 construct our argument parser. We only need\\none argument: the path to the image we are going to use.\\nWe then load our image off disk and display it.\\nWhen we rotate an image, we need to specify around\\nwhich point we want to rotate. In most cases, you will want\\nto rotate around the center of an image; however, OpenCV\\nallows you to specify any arbitrary point you want to rotate\\naround. Let’s just go ahead and rotate around the center of\\nthe image. Lines 14 and 15 grabs the width and height of\\nthe image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.\\nJust as we deﬁned a matrix to translate an image, we\\nalso deﬁne a matrix to rotate the image. Instead of manu-\\nally constructing the matrix using NumPy, we’ll just make\\na call to the cv2.getRotationMatrix2D method on Line 17.\\nThe cv2.getRotationMatrix2D function takes three argu-\\nments: the point at which we want to rotate the image\\naround (in this case, the center of the image). We then\\nspecify θ, the number of degrees we are going to rotate the\\nimage by. In this case, we are going to rotate the image 45\\ndegrees. The last argument is the scale of the image. We\\nhaven’t discussed resizing an image yet, but here you can\\nspecify a ﬂoating point value, where 1.0 means the same di-\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 61, 'page_label': '50', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nmensions of the image are used. However, if you speciﬁed\\na value of 2.0 the image would be doubled in size. Similarly,\\na value of 0.5 halves the size of the image.\\nOnce we have our rotation matrixM from the cv2.getRot\\nationMatrix2D function, we can apply the rotation to our\\nimage using the cv2.warpAffine method on Line 18. The\\nﬁrst argument to this function is the image we want to ro-\\ntate. We then specify our rotation matrix M along with the\\noutput dimensions (width and height) of our image. Line\\n19 then shows our image rotated by 45 degrees. Check out\\nFigure 6.2 Top-Right to see our rotated image.\\nLet’s not waste any time. We’ll go ahead and jump into\\nsome code to perform rotations:\\nOn Lines 21-23, we perform another rotation. The code\\nis identical to that in Lines 17-19, only this time we are ro-\\ntating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-\\nage isn’t the most pretty and Pythonic. Let’s change that\\nand deﬁne our own custom rotate method:\\nListing 6.5: imutils.py\\n27 def rotate(image, angle, center = None, scale = 1.0):\\n28 (h, w) = image.shape[:2]\\n29\\n30 if center is None:\\n31 center = (w // 2, h // 2)\\n32\\n33 M = cv2.getRotationMatrix2D(center, angle, scale)\\n34 rotated = cv2.warpAffine(image, M, (w, h))\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 62, 'page_label': '51', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.2: Top-Left: Our original T-Rex image.\\nTop-Right: Rotating the image by 45\\ndegrees. Bottom-Left: Rotating the\\nimage by −90 degrees. Bottom-Right:\\nFlipping T-Rex upside down by rotat-\\ning the image by 180 degrees.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 63, 'page_label': '52', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n35\\n36 return rotated\\nOur rotate method takes four arguments. The ﬁrst is\\nour image. The second is the angle θ in which we want\\nto rotate the image. We provide two optional keyword ar-\\nguments, center and scale. The center parameter is the\\npoint which we wish to rotate our image around. If a value\\nof None is provided, the method automatically determines\\nthe center of the image on Lines 30-31. Finally, the scale\\nparameter is used to handle if the size of the image should\\nbe changed during the rotation. The scale parameter has\\na default value of 1.0, implying that no resizing should be\\ndone.\\nThe actual rotation of the image takes place on Lines 33\\nand 34, where we construct our rotation matrix M and ap-\\nply it to the image. Finally, our image is returned on Line\\n36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)\\nHere, we are rotating our image by 180 degrees. Fig-\\nure 6.2 Bottom-Right shows that our T-Rex has indeed been\\nﬂipped upside down. The code for our rotate method is\\nmuch easier to read and maintain than making calls to\\ncv2.getRotationMatrix2D and cv2.warpAffine each time\\nwe want to rotate an image.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 64, 'page_label': '53', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6.1.3 Resizing\\nSo far we’ve covered two image transformations: transla-\\ntion and rotation. Now, we are going to explore how to\\nresize an image. We’ll also deﬁne one last method for our\\nimutils.py ﬁle, a convenience method to help us resize im-\\nages with ease.\\nPerhaps, not surprisingly, we will be using thecv2.resize\\nfunction to resize our images. But we need to keep in mind\\nthe aspect ratio of the image when we are using this func-\\ntion. Before we get too deep into the details, let’s jump right\\ninto an example:\\nListing 6.7: resize.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n18 cv2.imshow(\"Resized (Width)\", resized)\\nLines 1-12 should start to feel quite redundant at this\\npoint. We are importing our packages, setting up our argu-\\nment parser, and ﬁnally loading our image and displaying\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 65, 'page_label': '54', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nit.\\nThe actual interesting code doesn’t start until Lines 14\\nand 15. When resizing an image, we need to keep in mind\\nthe aspect ratio of the image. The aspect ratio is the propor-\\ntional relationship of the width and the height of the image.\\nIf we aren’t mindful of the aspect ratio, our resizing will\\nreturn results that don’t look correct.\\nComputing the aspect ratio is handled on Line 14. In\\nthis line of code, we deﬁne our new image width to be 150\\npixels. In order to compute the ratio of the new height to\\nthe old height, we simply deﬁne our ratio r to be the new\\nwidth (150 pixels) divided by the old width, which we ac-\\ncess using image.shape[1].\\nNow that we have our ratio, we can compute the new di-\\nmensions of the image on Line 15. Again, the width of the\\nnew image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.\\nThe ﬁrst argument is the image we wish to resize and the\\nsecond is our computed dimensions for the new image.The\\nlast parameter is our interpolation method, which is the\\nalgorithm working behind the scenes to handle how the\\nactual image is resized. In general, I ﬁnd that using cv2.\\nINTER_AREA obtains the best results when resizing; how-\\never, other appropriate choices include cv2.INTER_LINEAR,\\ncv2.INTER_CUBIC, and cv2.INTER_NEAREST.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 66, 'page_label': '55', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFinally, we show our resized image on Line 18.\\nIn the example we just explored, we only resized the im-\\nage by specifying the width. But what if we wanted to\\nresize the image by specifying the height? All that requires\\nis a change to computing the aspect ratio:\\nListing 6.8: resize.py\\n19 r = 50.0 / image.shape[0]\\n20 dim = (int(image.shape[1] * r), 50)\\n21\\n22 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n23 cv2.imshow(\"Resized (Height)\", resized)\\n24 cv2.waitKey(0)\\nOn Line 19 we deﬁne our ratio r. Our new image will\\nhave a height of 50 pixels. To determine the ratio of the new\\nheight to the old height, we divide 50 by the old height.\\nThen, we deﬁne the dimensions of our new image. We\\nalready know that the new image will have a height of 50\\npixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.\\nResizing an image is simple enough, but having to com-\\npute the aspect ratio, deﬁne the dimensions of the new im-\\nage, and then perform the resizing takes three lines of code.\\nThis looks like the perfect time to deﬁne a resize method\\nin our imutils.py ﬁle:\\nListing 6.9: resize.py\\n25 resized = imutils.resize(image, width = 100)\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 67, 'page_label': '56', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 cv2.imshow(\"Resized via Function\", resized)\\n27 cv2.waitKey(0)\\nIn this example, you can see that the resizing of the im-\\nage is handled by a single function: imutils.resize. The\\nﬁrst argument we pass in is the image we want to resize.\\nThen, we specify the keyword argument width, which is\\nthe width of our new image. The function then handles the\\nresizing for us.\\nOf course, we can also resize via the height of the image\\nby changing the function call to:\\nListing 6.10: resize.py\\n1 resized = imutils.resize(image, height = 50)\\nLet’s take this function apart and see what’s going on un-\\nder the hood:\\nListing 6.11: imutils.py\\n9 def resize(image, width = None, height = None, inter = cv2.\\nINTER_AREA):\\n10 dim = None\\n11 (h, w) = image.shape[:2]\\n12\\n13 if width is None and height is None:\\n14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23\\n24 resized = cv2.resize(image, dim, interpolation = inter)\\n25\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 68, 'page_label': '57', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 return resized\\nAs you can see, we have deﬁned our resize function.\\nThe ﬁrst argument is the image we want to resize. Then, we\\ndeﬁne two keyword arguments, width and height. Both of\\nthese arguments cannot be None, otherwise we won’t know\\nhow to resize the image. We also provide inter, which is\\nour interpolation method and defaults to cv2.INTER_AREA.\\nOn Lines 10 and 11, we deﬁne the dimensions of our new,\\nresized image and grab the dimensions of the original im-\\nage.\\nWe perform a quick check on Lines 13-14 to ensure that\\na numerical value has been provided for either the width\\nor the height.\\nThe computation of the ratio and new, resized image di-\\nmensions are handled on Lines 16-22, depending on whether\\nwe are resizing via width or via height.\\nLine 24 handles the actual resizing of the image, then\\nLine 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.\\nThen, on the Top-Right we have our T-Rex resized to have a\\nwidth of 150 pixels. The Middle-Right image then shows our\\nimage resized to have a height of 50 pixels. Finally, Bottom-\\nRight shows the output of our resize function – the T-Rex\\nis now resized to have a width of 100 pixels using only a\\nsingle line of code.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 69, 'page_label': '58', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.3: Top-Left: Our original T-Rex image.\\nTop-Right: The T-Rex resized to have\\na width of 150 pixels. Middle-Right:\\nOur image resized to have a height\\nof 50 pixels. Bottom-Right: Resizing\\nour image to have a width of 100 pix-\\nels using our helper function. In all\\ncases, the aspect ratio of the image is\\nmaintained.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 70, 'page_label': '59', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nTranslation, rotation, and resizing are certainly the more\\nchallenging and involved image transformation tasks. The\\nnext two we will explore, ﬂipping and cropping, are sub-\\nstantially easier.\\n6.1.4 Flipping\\nNext up on our image transformations to explore is ﬂip-\\nping an image. We can ﬂip an image around either the x or\\ny axis, or even both.\\nIn fact, I think explaining how to ﬂip an image is better\\nexplained by viewing the output of an image ﬂip, before\\nwe get into the code. Check out Figure 6.4 to see our T-Rex\\nimage ﬂipped horizontally, vertically, and both horizontally\\nand vertically at the same time.\\nNow that you see what an image ﬂip looks like, we can\\nexplore the code:\\nListing 6.12: ﬂipping.py\\n1 import argparse\\n2 import cv2\\n3\\n4 ap = argparse.ArgumentParser()\\n5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11\\n12 flipped = cv2.flip(image, 1)\\n13 cv2.imshow(\"Flipped Horizontally\", flipped)\\n14\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 71, 'page_label': '60', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.4: Top-Left: Our original T-Rex image.\\nTop-Right: Flipping the T-Rex image\\nhorizontally. Bottom-Left: Flipping\\nthe T-Rex vertically. Bottom-Right:\\nFlipping the image both horizontally\\nand vertically.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 72, 'page_label': '61', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n15 flipped = cv2.flip(image, 0)\\n16 cv2.imshow(\"Flipped Vertically\", flipped)\\n17\\n18 flipped = cv2.flip(image, -1)\\n19 cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\\n20 cv2.waitKey(0)\\nLines 1-10 handle our standard procedure of importing\\nour packages, parsing arguments, and loading our image\\nfrom disk.\\nFlipping an image is accomplished by making a call to\\nthe cv2.flip function on Line 12. The cv2.flip method\\nrequires two arguments: the image we want to ﬂip and a\\nﬂip code that is used to determine how we are going to ﬂip\\nthe image.\\nUsing a ﬂip code value of 1 indicates that we are going\\nto ﬂip the image horizontally, around the y-axis ( Line 12).\\nSpecifying a ﬂip code of 0 indicates that we want to ﬂip the\\nimage vertically, around the x-axis (Line 15). Finally, using\\na negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-\\nzontally, vertically, and around both axes.\\nFlipping an image is very simple, perhaps one of the sim-\\nplest examples in this book! Next up, we’ll go over crop-\\nping an image and how to extract regions of an image using\\nNumPy array slices.\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 73, 'page_label': '62', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.5: Top: Our original T-Rex image. Bot-\\ntom: Cropping the face of the T-Rex\\nusing NumPy array slices.\\n6.1.5 Cropping\\nWhen we crop an image, we want to remove the outer parts\\nof the image that we are not interested in. We can accom-\\nplish image cropping by using NumPy array slicing. In fact,\\nwe already performed image cropping in Chapter 4!\\nHowever, let’s review it again and make sure we under-\\nstand what is going on:\\nListing 6.13: crop.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 74, 'page_label': '63', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 cropped = image[30:120 , 240:335]\\n14 cv2.imshow(\"T-Rex Face\", cropped)\\n15 cv2.waitKey(0)\\nLines 1-11 handle importing our packages, parsing our\\narguments, and loading our images. For our cropping ex-\\nample, we will use our T-Rex image.\\nThe actual cropping takes place on a single line of code:\\nLine 13. We are supplying NumPy array slices to extract\\na rectangular region of the image, starting at (240, 30) and\\nending at (335, 120). The order in which we supply the\\nindexes to the crop may seem counterintuitive; however, re-\\nmember that OpenCV represents images as NumPy arrays\\nwith the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:\\n1. Start y: The starting y coordinate. In this case, we\\nstart at y = 30.\\n2. End y:The ending y coordinate. We will end our crop\\nat y = 120.\\n3. Start x:The starting x coordinate of the slice. We start\\nthe crop at x = 240.\\n63'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 75, 'page_label': '64', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\n4. End x: The ending x-axis coordinate of the slice. Our\\nslice ends at x = 335.\\nExecuting our code detailed above, we will see from Fig-\\nure 6.5 that we have cropped out the face of our T-Rex!\\nWhile the T-Rex might seem a little scary, cropping sure\\nisn’t! In fact, it’s quite simple when you consider all we are\\ndoing is performing array slices on NumPy arrays.\\n6.2 image arithmetic\\nWe all know basic arithmetic operations like addition and\\nsubtraction. But when working with images, we need to\\nkeep in mind the limits of our color space and data type.\\nFor example, RGB images have pixels that fall within the\\nrange [0, 255]. So what happens if we are examining a pixel\\nwith intensity 250 and we try to add 10 to it?\\nUnder normal arithmetic rules, we would end up with a\\nvalue of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check\\nof some sort to ensure no pixel falls outside the range of\\n[0, 255], thus clipping all pixels to have a minimum value of\\n0 and a maximum value of 255?\\nOr do we apply a modulus operation, and “wrap around”?\\nUnder modulus rules, adding 10 to 250 would simply wrap\\naround to a value of 4.\\n64'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 76, 'page_label': '65', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWhich way is the “correct” way to handle image addi-\\ntions and subtractions that fall outside the range of [0, 255]?\\nThe answer is there is no correct way – it simply depends\\non how you are manipulate your pixels and what you want\\nthe desired results to be.\\nHowever, be sure to keep in mind that there is a differ-\\nence between OpenCV and NumPy addition. NumPy will\\nperform modulo arithmetic and “wrap around”. OpenCV ,\\non the other hand, will perform clipping and ensure pixel\\nvalues never fall outside the range [0, 255].\\nBut don’t worry! These nuances will become clearer as\\nwe explore some code below.\\nListing 6.14: arithmetic.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 print(\"max of 255: {}\".format(cv2.add(np.uint8([200]), np.uint8\\n([100]))))\\n15 print(\"min of 0: {}\".format(cv2.subtract(np.uint8([50]), np.uint8\\n([100]))))\\n16\\n17 print(\"wrap around: {}\".format(np.uint8([200]) + np.uint8([100]))\\n)\\n18 print(\"wrap around: {}\".format(np.uint8([50]) - np.uint8([100])))\\n65'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 77, 'page_label': '66', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWe are going to perform our standard procedure onLines\\n1-12 by importing our packages, setting up our argument\\nparser, and loading our image.\\nRemember how I mentioned the difference between OpenCV\\nand NumPy addition above? Well, now we are going to ex-\\nplore it further and provide a concrete example to ensure\\nwe fully understand it.\\nOn Line 14, we deﬁne two NumPy arrays that are 8-\\nbit unsigned integers. The ﬁrst array has one element: a\\nvalue of 200. The second array also has only one element,\\nbut with a value of 100. We then use OpenCV’s cv2.add\\nmethod to add the values together.\\nWhat do you think the output is going to be?\\nWell, according to standard arithmetic rules, we would\\nthink the result should be 300, but, remember that we are\\nworking with 8-bit unsigned integers that only have a range\\nbetween [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-\\necute this code, we can see the result on the ﬁrst line of\\nListing 6.15. Sure enough, the addition returned a value of\\n255.\\nLine 15 then performs subtraction using cv2.subtract.\\nAgain, we deﬁne two NumPy arrays, each with a single ele-\\nment, and of the 8-bit unsigned integer data type. The ﬁrst\\narray has a value of 50 and the second a value of 100.\\n66'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 78, 'page_label': '67', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nAccording to our arithmetic rules, the subtraction should\\nreturn a value of −50; however, OpenCV once again per-\\nforms clipping for us. We ﬁnd that the value is clipped to a\\nvalue of 0. The second line of Listing 6.15 veriﬁes this: sub-\\ntracting 100 from 50 using cv2.subtract returns a value of\\n0.\\nListing 6.15: arithmetic.py\\nmax of 255: [[255]]\\nmin of 0: [[0]]\\nBut what happens if we use NumPy to perform the arith-\\nmetic instead of OpenCV?\\nLine 17 and 18 explore this question.\\nFirst, we deﬁne two NumPy arrays, each with a single\\nelement, and of the 8-bit unsigned integer data type. The\\nﬁrst array has a value of 200, and the second has a value\\nof 100. Using the cv2.add function, our addition would be\\nclipped and a value of 255 returned.\\nHowever, NumPy does not perform clipping – it instead\\nperforms modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been\\nreached. You can see this is true via the ﬁrst line of output\\non Listing 6.16.\\nThen, we deﬁne two more NumPy arrays: one has a value\\nof 50 and the other 100. Using the cv2.subtract method,\\nthis subtraction would be clipped to return a value of 0.\\nHowever, we know that NumPy performs modulo arith-\\n67'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 79, 'page_label': '68', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nmetic rather than clipping. Instead, once 0 is reached dur-\\ning the subtraction, the modulos operations wraps around\\nand starts counting backwards from 255 – thus the result\\non the second line of output on Listing 6.16.\\nListing 6.16: arithmetic.py\\nwrap around: [44]\\nwrap around: [206]\\nWhen performing integer arithmetic, it is important to\\nkeep in mind your desired output.\\nDo you want all values to be clipped if they fall outside\\nthe range [0, 255]? Then use OpenCV’s built-in methods for\\nimage arithmetic.\\nDo you want modulus arithmetic operations and have\\nvalues wrap around if they fall outside the range of [0, 255]?\\nThen simply add and subtract the NumPy arrays as you\\nnormally would.\\nNow that we have explored the caveats of image arith-\\nmetic in OpenCV and NumPy, let’s perform the arithmetic\\non actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)\\n22\\n23 M = np.ones(image.shape, dtype = \"uint8\") * 50\\n24 subtracted = cv2.subtract(image, M)\\n25 cv2.imshow(\"Subtracted\", subtracted)\\n26 cv2.waitKey(0)\\n68'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 80, 'page_label': '69', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nFigure 6.6: Top-Left: Our original T-Rex image.\\nTop-Right: Adding 100 to every pixel\\nin the image. Notice how the image\\nlooks more “washed out” and is sub-\\nstantially brighter than the original.\\nBottom: Subtracting 50 from every\\npixel in the image. Notice that the\\nimage is now darker than the origi-\\nnal.\\n69'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 81, 'page_label': '70', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nLine 19 deﬁnes a NumPy array of ones, with the same\\nsize as our image. Again, we are sure to use 8-bit unsigned\\nintegers as our data type. In order to ﬁll our matrix with\\nvalues of 100’s rather than 1’s, we simply multiply our ma-\\ntrix of 1’s by 100. Finally, we use the cv2.add function to\\nadd our matrix of 100’s to the original image – thus increas-\\ning every pixel intensity in the image by 100, but ensuring\\nall values are clipped to the range [0, 255] if they attempt to\\nexceed 255.\\nThe result of our operation can be found in Figure 6.6\\nTop-Right. Notice how the image looks more “washed out”\\nand is substantially brighter than the original. This is be-\\ncause we are increasing the pixel intensities by adding 100\\nto them and pushing them towards brighter colors.\\nWe then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image\\nin Figure 6.6 shows the results of this subtraction. Our im-\\nage now looks considerably darker than the original T-Rex.\\nPixels that were once white now look gray. This is because\\nwe are subtracting 50 from the pixels and pushing them to-\\nwards the darker regions of the RGB color space.\\nIn this section, we explored the peculiarities of image\\narithmetic using OpenCV and NumPy. These caveats are\\nimportant to keep in mind, otherwise you may get unwanted\\nresults when performing arithmetic operations on your im-\\nages.\\n70'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 82, 'page_label': '71', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\n6.3 bitwise operations\\nNow we will review four bitwise operations: AND, OR,\\nXOR, and NOT. These four operations, while very basic\\nand low level, are paramount to image processing, espe-\\ncially when we start working with masks in Section 6.4.\\nBitwise operations operate in a binary manner and are\\nrepresented as grayscale images. A given pixel is turned\\n“off” if it has a value of zero, and it is turned “on” if the\\npixel has a value greater than zero.\\nLet’s go ahead and jump into some code:\\nListing 6.18: bitwise.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 rectangle = np.zeros((300, 300), dtype = \"uint8\")\\n5 cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\\n6 cv2.imshow(\"Rectangle\", rectangle)\\n7\\n8 circle = np.zeros((300, 300), dtype = \"uint8\")\\n9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image\\nas a 300 × 300 NumPy array on Line 4. We then draw a\\n250 × 250 white rectangle at the center of the image.\\nSimilarly, on Line 8, we initialize another image to con-\\ntain our circle, which we draw on Line 9, again centered at\\nthe center of the image, with a radius of 150 pixels.\\n71'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 83, 'page_label': '72', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nFigure 6.7: Left: Our rectangle image. Right: Our\\ncircle image. We will explore how\\nthese two images can be combined\\nusing bitwise operations.\\nFigure 6.7 shows our two shapes. We will make use of\\nthese shapes to demonstrate our bitwise operations:\\nListing 6.19: bitwise.py\\n11 bitwiseAnd = cv2.bitwise_and(rectangle, circle)\\n12 cv2.imshow(\"AND\", bitwiseAnd)\\n13 cv2.waitKey(0)\\n14\\n15 bitwiseOr = cv2.bitwise_or(rectangle, circle)\\n16 cv2.imshow(\"OR\", bitwiseOr)\\n17 cv2.waitKey(0)\\n18\\n19 bitwiseXor = cv2.bitwise_xor(rectangle, circle)\\n20 cv2.imshow(\"XOR\", bitwiseXor)\\n21 cv2.waitKey(0)\\n22\\n23 bitwiseNot = cv2.bitwise_not(circle)\\n24 cv2.imshow(\"NOT\", bitwiseNot)\\n25 cv2.waitKey(0)\\n72'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 84, 'page_label': '73', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nAs I mentioned above, a given pixel is turned “on” if it\\nhas a value greater than zero, and it is turned “off” if it has\\na value of zero. Bitwise functions operate on these binary\\nconditions.\\nIn order to utilize bitwise functions, we assume (in most\\ncases) that we are comparing two pixels (the only exception\\nis the NOT function). We’ll compare each of the pixels and\\nthen construct our bitwise representation.\\nLet’s quickly review our binary operations:\\n1. AND: A bitwise AND is true if and only if both pixels\\nare greater than zero.\\n2. OR: A bitwise OR is true if either of the two pixels\\nare greater than zero.\\n3. XOR: A bitwise XOR is true if and only if either of the\\ntwo pixels are greater than zero, but not both.\\n4. NOT: A bitwise NOT inverts the “on” and “off” pixels\\nin an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if\\nboth pixels are greater than zero. The output of our bitwise\\nAND can be seen in Figure 6.8 Top-Left. We can see that\\nedges of our square are lost – this makes sense because our\\nrectangle does not cover as large of an area as the circle,\\nand thus both pixels are not “on”.\\n73'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 85, 'page_label': '74', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nWe then apply a bitwise OR on Line 15 using the cv2.\\nbitwise_or function. A bitwise OR is true if either of the\\ntwo pixels are greater than zero. Figure 6.8 Top-Right shows\\nthe output of our bitwise OR. In this case, our square and\\nrectangle have been combined together.\\nNext up is the bitwise XOR function, applied on Line 19\\nusing the cv2.bitwise_xor function. An XOR operation\\nis true if both pixels are greater than zero, but both pixels\\ncannot be greater than zero. The output of the XOR oper-\\nation is displayed on Figure 6.8 Bottom-Right. Here we see\\nthat the center of the square has been removed. Again, this\\nmakes sense because an XOR operation cannot have both\\npixels greater than zero.\\nFinally, we apply the NOT function on Line 23 using the\\ncv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are\\nset to 255. Figure 6.8 Bottom-Right ﬂips our white circle to a\\nblack circle.\\nOverall, bitwise functions are extremely simple, yet very\\npowerful. And they are absolutely essential when we start\\nto discuss masking in Section 6.4.\\n6.4 masking\\nIn the previous section, we explored bitwise functions. Now\\nwe are ready to explore masking, an extremely powerful\\nand useful technique in computer vision and image pro-\\n74'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 86, 'page_label': '75', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.8: Top-Left: Applying a bitwise AND to\\nour rectangle and circle image. Top-\\nRight: A bitwise OR applied to our\\nsquare and circle. Bottom-Left: An\\nXOR applied to our shapes. Bottom-\\nRight: Flipping pixel values of our\\ncircle using a bitwise NOT.\\n75'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 87, 'page_label': '76', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ncessing.\\nUsing a mask allows us to focus only on the portions of\\nthe image that interests us.\\nFor example, let’s say that we were building a computer\\nvision system to recognize faces. The only part of the image\\nwe are interested in ﬁnding and describing are the parts of\\nthe image that contain faces – we simply don’t care about\\nthe rest of the content of the image. Provided that we could\\nﬁnd the faces in the image, we might construct a mask to\\nshow only the faces in the image.\\nLet’s make this example a little more concrete.\\nIn Figure 6.9, we have an image of a beach on the Top-Left.\\nBut I’m not interested in the beach in the image. I’m only\\ninterested in the sky and the palm tree. We could apply a\\ncropping to extract that region of the image. Or, we could\\napply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-\\ning our rectangle mask, we have focused only on the sky\\nand palm tree in the image.\\nLet’s examine the code to accomplish the masking in Fig-\\nure 6.9:\\nListing 6.20: masking.py\\n1 import numpy as np\\n76'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 88, 'page_label': '77', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.9: Top-Left: Our image of a peaceful\\nbeach scene. Top-Right: Our mask im-\\nage – a white rectangle at the center\\nof the image. Bottom: Applying the\\nrectangular mask to the beach image.\\nOnly the parts of the image where\\nthe mask pixels are greater than zero\\nare shown.\\n77'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 89, 'page_label': '78', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n14 (cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\\n15 cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255,\\n-1)\\n16 cv2.imshow(\"Mask\", mask)\\n17\\n18 masked = cv2.bitwise_and(image, image, mask = mask)\\n19 cv2.imshow(\"Mask Applied to Image\", masked)\\n20 cv2.waitKey(0)\\nOn Lines 1-11 we import the packages we need, parse\\nour arguments, and load our image.\\nWe then construct a NumPy array, ﬁlled with zeros, with\\nthe same width and height as our beach image on Line 13.\\nIn order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-\\nsion. Finally, we draw our white rectangle on Line 15.\\nRemember reviewing the cv2.bitwise_and function in\\nthe previous section? It’s a function that is used extensively\\nwhen applying masks to images.\\nWe apply our mask on Line 18 using the cv2.bitwise_\\nand function. The ﬁrst two parameters are the image it-\\nself. Obviously, the AND function will be True for all pix-\\nels in the image; however, the important part of this func-\\n78'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 90, 'page_label': '79', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ntion is the mask keyword argument. By supplying a mask,\\nthe cv2.bitwise_and function only examines pixels that are\\n“on” in the mask. In this case, only pixels that are part of\\nthe white rectangle.\\nLet’s look at another example:\\nListing 6.21: masking.py\\n21 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n22 cv2.circle(mask, (cX, cY), 100, 255, -1)\\n23 masked = cv2.bitwise_and(image, image, mask = mask)\\n24 cv2.imshow(\"Mask\", mask)\\n25 cv2.imshow(\"Mask Applied to Image\", masked)\\n26 cv2.waitKey(0)\\nOn Line 21 we re-initialize our mask to be ﬁlled with ze-\\nros and the same dimensions as our beach image. Then, we\\ndraw a white circle on our mask image, starting at the cen-\\nter of the image and a radius of 100 pixels. Applying the\\ncircular mask is then performed on Line 23, again using the\\ncv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on\\nthe Bottom. Instead of a rectangular region of the beach be-\\ning shown, we now have a circular region.\\nRight now masking may not seem very interesting. But\\nwe’ll return to it once we start computing histograms in\\nChapter 7. Again, the key point of masks is that they allow\\nus to focus our computation only on regions of the image\\nthat interests us.\\n79'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 91, 'page_label': '80', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.10: Applying the circular mask to the\\nbeach image. Only pixels within\\nthe circular white region are shown.\\n80'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 92, 'page_label': '81', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\n6.5 splitting and merging channels\\nA color image consists of multiple channels: a Red, a Green,\\nand a Blue component. We have seen that we can access\\nthese components via indexing into NumPy arrays. But\\nwhat if we wanted to split an image into its respective com-\\nponents?\\nAs you’ll see, we’ll make use of thecv2.split function.\\nFor the time being, let’s take a look at a sample image in\\nFigure 6.11.\\nWe have an image of a wave crashing down. This image\\nis very “blue” due to the ocean. How do we interpret the\\ndifferent channels of the image?\\nThe Red channel (Top-Left) is very dark. This makes sense,\\nbecause an ocean scene has very few red colors in it. The\\nred colors present are either very dark, and thus not repre-\\nsented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.\\nFinally, the Blue channel ( Bottom-Left) is extremely light,\\nand near pure white in some locations. This is because\\nshades of blue are heavily represented in our image.\\nNow that we have visualized our channels, let’s examine\\nsome code to accomplish this for us:\\n81'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 93, 'page_label': '82', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.11: The three RGB channels of our\\nwave image are shown on the\\nBottom-Right. The Red channel is on\\nthe Top-Left, the Green channel on\\nthe Top-Right, and the Blue channel\\non the Bottom-Left.\\n82'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 94, 'page_label': '83', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nListing 6.22: splitting_and_merging.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 (B, G, R) = cv2.split(image)\\n12\\n13 cv2.imshow(\"Red\", R)\\n14 cv2.imshow(\"Green\", G)\\n15 cv2.imshow(\"Blue\", B)\\n16 cv2.waitKey(0)\\n17\\n18 merged = cv2.merge([B, G, R])\\n19 cv2.imshow(\"Merged\", merged)\\n20 cv2.waitKey(0)\\n21 cv2.destroyAllWindows()\\nLines 1-10 imports our packages, sets up our argument\\nparser, and then loads our image. Splitting the channels is\\ndone using a call to cv2.split on Line 11.\\nNormally, we think of images in the RGB color space –\\nthe red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image\\nin RGB order, it instead stores the image in BGR order; thus\\nwe unpack the tuple in reverse order.\\nLines 13-16 then show each channel individually, as in\\nFigure 6.11.\\nWe can also merge the channels back together again us-\\ning the cv2.merge function. We simply specify our chan-\\n83'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 95, 'page_label': '84', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.12: Representing the Red, Green, and\\nBlue channels of our wave image.\\nnels, again in BGR order, and then cv2.merge takes care of\\nthe rest for us ( Line 18).\\nListing 6.23: splitting_and_merging.py\\n22 zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\\n23 cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\\n24 cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\\n25 cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\\n26 cv2.waitKey(0)\\nAn alternative method to visualize the channels of an im-\\nage can be seen in Figure 6.12. In order to show the actual\\n“color” of the channel, we ﬁrst need to take apart the image\\nusing cv2.split. Then, we need to re-construct the image,\\nbut this time setting all pixels but the current channel as zero.\\nOn Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-\\nage, we make a call to cv2.merge, but specifying our zeros\\narray for the Green and Blue channels. We take similar ap-\\nproaches to the other channels in Line 24 and 25.\\n84'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 96, 'page_label': '85', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n6.6 color spaces\\nIn this book, we have only explored the RGB color space;\\nhowever, there are many other color spaces that we can uti-\\nlize.\\nThe Hue-Saturation-Value (HSV) color space is more sim-\\nilar to how humans think and conceive of color. Then there\\nis the L*a*b* color space, which is more tuned to how hu-\\nmans perceive color.\\nOpenCV provides support for many, many different color\\nspaces. And understanding how color is perceived by hu-\\nmans and represented by computers occupies an entire li-\\nbrary of literature itself.\\nIn order to not get bogged down in the details, I’ll just\\nshow you how to convert color spaces. If you think your\\napplication of image processing and computer vision might\\nneed a different color space than RGB, I will leave that as\\nan exercise to the reader to explore the peculiarities of each\\ncolor space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n85'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 97, 'page_label': '86', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Gray\", gray)\\n15\\n16 hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\\n17 cv2.imshow(\"HSV\", hsv)\\n18\\n19 lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\\n20 cv2.imshow(\"L*a*b*\", lab)\\n21 cv2.waitKey(0)\\nLines 1-11 imports the packages we need, parses our ar-\\nguments, and loads our image. Then, on Line 13, we con-\\nvert our image from the RGB color space to grayscale by\\nspecifying the cv2.COLOR_BGR2GRAY ﬂag.\\nConverting our image to the HSV color space is performed\\non Line 16 by specifying the cv2.COLOR_BGR2HSV ﬂag. Fi-\\nnally, on Line 19, we convert to the L*a*b* color space by\\nusing the cv2.COLOR_BGR2LAB ﬂag.\\nWe can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.\\nIf you are just getting started in computer vision, it’s likely\\na good idea to stick to the RGB color space for the time\\nbeing. However, I have included this section as a matter\\nof completeness – it’s good to show an example of how to\\nconvert color spaces for when you decide the time is right!\\n86'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 98, 'page_label': '87', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFigure 6.13: Top-Left: An image of beach scenery.\\nTop-Right: The grayscale represen-\\ntation of the beach image. Bottom-\\nLeft: Converting the beach image to\\nthe HSV color space. Bottom-Right:\\nConverting our image to the L*a*b*\\ncolor space.\\n87'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 99, 'page_label': '88', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFurther Reading\\nChapter 6 is by far the longest chapter inPractical Python\\nand OpenCV – and with good reason. In this chapter,\\nwe covered a lot of important image processing con-\\ncepts that form the foundation on which the rest of\\nyour computer vision education will be built.\\nTo ensure that you have a thorough grasp on these con-\\ncepts, be sure to go through the Chapter 6 supplemen-\\ntary material:\\nhttp://pyimg.co/s3fm7\\n88'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 100, 'page_label': '89', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7\\nH I S T O G R A M S\\nSo, what exactly is a histogram? A histogram represents\\nthe distribution of pixel intensities (whether color or gray-\\nscale) in an image. It can be visualized as a graph (or plot)\\nthat gives a high-level intuition of the intensity (pixel value)\\ndistribution. We are going to assume an RGB color space in\\nthis example, so these pixel values will be in the range of 0\\nto 255.\\nWhen plotting the histogram, the X-axis serves as our\\n“bins”. If we construct a histogram with 256 bins, then\\nwe are effectively counting the number of times each pixel\\nvalue occurs. In contrast, if we use only 2 (equally spaced)\\nbins, then we are counting the number of times a pixel is in\\nthe range [0, 128) or [128, 255]. The number of pixels binned\\nto the x-axis value is then plotted on the y-axis.\\nBy simply examining the histogram of an image, you get\\na general understanding regarding the contrast, brightness,\\n89'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 101, 'page_label': '90', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1 using opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms. Before we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.\\n4. histSize: This is the number of bins we want to use\\nwhen computing a histogram. Again, this is a list, one\\nfor each channel we are computing a histogram for.\\nThe bin sizes do not all have to be the same. Here is\\nan example of 32 bins for each channel: [32,32,32].\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 102, 'page_label': '91', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use thecv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2 grayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet. All we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Original\", image)\\n91'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 103, 'page_label': '92', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n15\\n16 hist = cv2.calcHist([image], [0], None, [256], [0, 256])\\n17\\n18 plt.figure()\\n19 plt.title(\"Grayscale Histogram\")\\n20 plt.xlabel(\"Bins\")\\n21 plt.ylabel(\"# of Pixels\")\\n22 plt.plot(hist)\\n23 plt.xlim([0, 256])\\n24 plt.show()\\n25 cv2.waitKey(0)\\nNow things are getting a little more interesting. On Line\\n13, we convert the image from the RGB colorspace to graysc-\\nale. Line 16 computes the actual histogram. Go ahead and\\nmatch the arguments of the code up with the function docu-\\nmentation above. We can see that our ﬁrst parameter is the\\ngrayscale image. A grayscale image has only one channel,\\nhence we have a value of [0] for channels. We don’t have\\na mask, so we set the mask value to None. We will use 256\\nbins in our histogram, and the possible values range from\\n0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the\\nbins (0-255) are plotted on the x-axis. And the y-axis counts\\nthe number of pixels in each bin. The majority of the pixels\\nfall in the range of roughly 60 to 120. Looking at the right\\ntail of the histogram, we see very few pixels in the range\\n200 to 255. This means that there are very few “white” pix-\\nels in the image.\\n92'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 104, 'page_label': '93', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.1: Computing a grayscale histogram of\\nour beach image.\\n7.3 color histograms\\nIn the previous section, we explored grayscale histograms.\\nNow let’s move on to computing a histogram for each chan-\\nnel of the image.\\nListing 7.3: color_histograms.py\\n1 from __future__ import print_function\\n2 from matplotlib import pyplot as plt\\n3 import numpy as np\\n4 import argparse\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 cv2.imshow(\"Original\", image)\\n93'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 105, 'page_label': '94', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nAgain, we’ll import the packages that we’ll need, utiliz-\\ning matplotlib once more to plot the histograms.\\nLet’s examine some code:\\nListing 7.4: color_histograms.py\\n14 chans = cv2.split(image)\\n15 colors = (\"b\", \"g\", \"r\")\\n16 plt.figure()\\n17 plt.title(\"’Flattened’ Color Histogram\")\\n18 plt.xlabel(\"Bins\")\\n19 plt.ylabel(\"# of Pixels\")\\n20\\n21 for (chan, color) in zip(chans, colors):\\n22 hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\\n23 plt.plot(hist, color = color)\\n24 plt.xlim([0, 256])\\nThe ﬁrst thing we are going to do is split the image into\\nits three channels: blue, green, and red. Normally, we read\\nthis is red, green, blue (RGB). However, OpenCV stores the\\nimage as a NumPy array in reverse order: BGR. This is\\nimportant to note. We then initialize a tuple of strings rep-\\nresenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into\\neach bin on the y-axis.\\nWe then reach a for loop on Line 21, where we start loop-\\ning over each of the channels in the image.\\nThen, for each channel, we compute a histogram on Line\\n22. The code is identical to that of computing a histogram\\nfor the grayscale image; however, we are doing it for each\\nRed, Green, and Blue channel, allowing us to characterize\\n94'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 106, 'page_label': '95', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.2: Color histograms for each Red,\\nGreen, and Blue channel of the beach\\nimage.\\nthe distribution of pixel intensities. We add our histogram\\nto the plot on Line 23.\\nWe can examine our color histogram in Figure 7.2. We\\nsee there is a sharp peak in the green histogram around bin\\n100. This indicates a darker green value, from the green\\nvegetation and trees in the beach image.\\nWe also see a lot of blue pixels in the range 170 to 225.\\nConsidering these pixels are much lighter, we know that\\nthey are from the blue sky in our beach image. Similarly,\\nwe see a much smaller range of blue pixels in the range 25\\nto 50 – these pixels are much darker, and are therefore the\\nocean pixels in the bottom-left corner of the image.\\nUp until this point, we have computed a histogram for\\nonly one channel at a time. Now we move on to multi-\\ndimensional histograms and take into consideration two\\n95'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 107, 'page_label': '96', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nchannels at a time.\\nI like to explain multi-dimensional histograms by using\\nthe word AND.\\nFor example, we can ask a question such as, “How many\\npixels have a Red value of 10 AND a Blue value of 30?”.\\nHow many pixels have a Green value of 200 AND a Red\\nvalue of 130? By using the conjunctive AND, we are able to\\nconstruct multi-dimensional histograms.\\nIt’s that simple. Let’s check out some code to automate\\nthe process of building a 2D histogram:\\nListing 7.5: color_histograms.py\\n25 fig = plt.figure()\\n26\\n27 ax = fig.add_subplot(131)\\n28 hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None,\\n29 [32, 32], [0, 256, 0, 256])\\n30 p = ax.imshow(hist, interpolation = \"nearest\")\\n31 ax.set_title(\"2D Color Histogram for G and B\")\\n32 plt.colorbar(p)\\n33\\n34 ax = fig.add_subplot(132)\\n35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")\\n39 plt.colorbar(p)\\n40\\n41 ax = fig.add_subplot(133)\\n42 hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None,\\n43 [32, 32], [0, 256, 0, 256])\\n44 p = ax.imshow(hist, interpolation = \"nearest\")\\n45 ax.set_title(\"2D Color Histogram for B and R\")\\n46 plt.colorbar(p)\\n47\\n48 print(\"2D histogram shape: {}, with {} values\".format(\\n96'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 108, 'page_label': '97', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\n49 hist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using. In previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 109, 'page_label': '98', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.3: Computing 2D color histograms for\\neach combination of Red, Green, and\\nBlue channels.\\nof red represent large pixel counts (i.e., peaks in the 2D his-\\ntogram). We tend to see many peaks in the Green and Blue\\nhistogram, where x = 22 and y = 12. This corresponds to\\nthe green pixels of the vegetation and trees and the blue of\\nthe sky and ocean.\\nUsing a 2D histogram takes into account two channels at\\na time. But what if we wanted to account for all three RGB\\nchannels? You guessed it. We’re now going to build a 3D\\nhistogram.\\nListing 7.6: color_histograms.py\\n50 hist = cv2.calcHist([image], [0, 1, 2],\\n51 None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\\n52 print(\"3D histogram shape: {}, with {} values\".format(\\n53 hist.shape, hist.flatten().shape[0]))\\n54\\n55 plt.show()\\n98'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 110, 'page_label': '99', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4 histogram equalization\\nHistogram equalization improves the contrast of an image\\nby “stretching” the distribution of pixels. Consider a his-\\ntogram with a large peak at the center of it. Applying his-\\ntogram equalization will stretch the peak out towards the\\ncorner of the image, thus improving the global contrast of\\nthe image. Histogram equalization is applied to grayscale\\nimages.\\nThis method is useful when an image contains foregroun-\\nds and backgrounds that are both dark or both light. It\\ntends to produce unrealistic effects in photographs; how-\\never, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n99'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 111, 'page_label': '100', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12\\n13 eq = cv2.equalizeHist(image)\\n14\\n15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\\n16 cv2.waitKey(0)\\nLines 1-10 handle our standard practice of importing pack-\\nages, parsing arguments, and loading our image. We then\\nconvert our image to grayscale on Line 11.\\nPerforming histogram equalization is done using just a\\nsingle function: cv2.equalizeHist, which accepts a single\\nparameter, the grayscale image we want to perform his-\\ntogram equalization on. The last couple lines of code dis-\\nplay our histogram equalized image.\\n100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 112, 'page_label': '101', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nThe result of applying histogram equalization can be seen\\nin Figure 7.4. On the left, we have our original beach image.\\nThen, on the right, we have our histogram-equalized beach\\nimage. Notice how the contrast of the image has been radi-\\ncally changed and now spans the entire range of [0, 255].\\n7.5 histograms and masks\\nIn Chapter 6, Section 6.4, I mentioned that masks can be\\nused to focus on speciﬁc regions of an image that interest\\nus. We are now going to construct a mask and compute\\ncolor histograms for the masked region only.\\nFirst, we need to deﬁne a convenience function to save us\\nfrom writing repetitive lines of code:\\nListing 7.8: histogram_with_mask.py\\n1 from matplotlib import pyplot as plt\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13\\n14 for (chan, color) in zip(chans, colors):\\n15 hist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16 plt.plot(hist, color = color)\\n17 plt.xlim([0, 256])\\n101'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 113, 'page_label': '102', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nOn Lines 1-4 we import our packages; then on Line 6 we\\ndeﬁne plot_histogram. This function accepts three param-\\neters: an image, the title of our plot, and a mask. The mask\\ndefaults to None if we do not have a mask for the image.\\nThe body of our plot_histogram function simply com-\\nputes a histogram for each channel in the image and plots\\nit, just as in previous examples in this chapter.\\nNow that we have a function to help us easily plot his-\\ntograms, let’s move into the bulk of our code:\\nListing 7.9: histogram_with_mask.py\\n18 ap = argparse.ArgumentParser()\\n19 ap.add_argument(\"-i\", \"--image\", required = True,\\n20 help = \"Path to the image\")\\n21 args = vars(ap.parse_args())\\n22\\n23 image = cv2.imread(args[\"image\"])\\n24 cv2.imshow(\"Original\", image)\\n25 plot_histogram(image, \"Histogram for Original Image\")\\nLines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot\\nfor our image can be seen in Figure 7.5. We will refer to\\nthis histogram again once we compute a histogram for the\\nmasked region.\\nListing 7.10: histogram_with_mask.py\\n26 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n27 cv2.rectangle(mask, (15, 15), (130, 100), 255, -1)\\n28 cv2.imshow(\"Mask\", mask)\\n29\\n30 masked = cv2.bitwise_and(image, image, mask = mask)\\n31 cv2.imshow(\"Applying the Mask\", masked)\\n102'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 114, 'page_label': '103', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.5: Left: The original beach image. Right:\\nColor histograms for the red, green,\\nand blue channels. Compare these\\nhistograms to the histograms of the\\nmasked region of blue sky in Figure\\n7.7.\\n103'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 115, 'page_label': '104', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.6: Left: Our rectangular mask. Right:\\nApplying our mask to the beach im-\\nage using a bitwise AND. Now we\\nsee only the blue sky – the rest of the\\nimage is ignored.\\nNow we are ready to construct a mask for the image. We\\ndeﬁne our mask as a NumPy array, with the same width\\nand height as our beach image on Line 26. We then draw a\\nwhite rectangle starting from point(15, 15) to point (130, 100)\\non Line 27. This rectangle will serve as our mask – only pix-\\nels in our original image belonging to the masked region\\nwill be considered in the histogram computation.\\nTo visualize our mask, we apply a bitwise AND to the\\nbeach image ( Line 30), the results of which can be seen in\\nFigure 7.6. Notice how the image on the left is simply a\\nwhite rectangle, but when we apply our mask to the beach\\nimage, we only see the blue sky ( right).\\nListing 7.11: histogram_with_mask.py\\n32 plot_histogram(image, \"Histogram for Masked Image\", mask = mask)\\n104'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 116, 'page_label': '105', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\n33\\n34 plt.show()\\nFinally, we compute a histogram for our masked image\\nusing our plot_histogram function and show our results\\n(Lines 32-34).\\nWe can see our masked histogram in Figure 7.7. Most\\nred pixels fall in the range [0, 80], indicating that red pixels\\ncontribute very little to our image. This makes sense, since\\nour sky is blue. Green pixels are then present, but again,\\nare towards the darker end of the RGB spectrum. Finally,\\nour blue pixels fall in the brighter range and are obviously\\nour blue sky.\\nMost importantly, compare our masked color histograms\\nin Figure 7.5 to the unmasked color histograms in Figure\\n7.7 above. Notice how dramatically different the color his-\\ntograms are. By utilizing masks, we are able to apply our\\ncomputation only to the speciﬁc regions of the image that\\ninterest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.\\nHistograms are simple, but are used extensively in image\\nprocessing and computer vision. Make sure you have a\\ngood grasp of histograms; you’ll certainly be using them in\\nthe future!\\n105'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 117, 'page_label': '106', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.7: The resulting histogram of the\\nmasked image in Figure 7.6. Red\\ncontributes little to our image and is\\ntowards the darker end of the spec-\\ntrum. Some lighter green values are\\npresent, and many light blue colors\\ncorrespond to the sky in the image.\\n106'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 118, 'page_label': '107', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFurther Reading\\nThe purpose of Chapter 7 was to learn how to extract\\nand visualize color histograms from an image. But\\nother than simply visualizing the color distributions of\\nan image, what else can we do? What are the actual\\napplications of utilizing color histograms?\\nTo learn how to compare color histograms for similar-\\nity, and even build an image search engine, take a look\\nat the Chapter 7 supplementary page:\\nhttp://pyimg.co/aa4ax\\n107'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 119, 'page_label': '108', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8\\nS M O O T H I N G A N D B L U R R I N G\\nI’m pretty sure we all know what blurring is. It’s what\\nhappens when your camera takes a picture out of focus.\\nSharper regions in the image lose their detail, normally as\\na disc/circular shape.\\nPractically, this means that each pixel in the image is\\nmixed in with its surrounding pixel intensities. This “mix-\\nture” of pixels in a neighborhood becomes our blurred pixel.\\nWhile this effect is usually unwanted in our photographs,\\nit’s actually quite helpful when performing image process-\\ning tasks.\\nIn fact, many image processing and computer vision func-\\ntions, such as thresholding and edge detection, perform bet-\\nter if the image is ﬁrst smoothed or blurred.\\nIn order to explore different types of blurring methods,\\nlet’s start with a baseline of our original T-Rex image in Fig-\\nure 8.1.\\nListing 8.1: blurring.py\\n108'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 120, 'page_label': '109', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='smoothing and blurring\\nFigure 8.1: Our original T-Rex image before ap-\\nplying any blurring effects.\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nIn order to perform image blurring, we ﬁrst need to im-\\nport our packages and parse our arguments (Lines 1-8). We\\nthen load our image and show it as a baseline to compare\\nour blurring methods to on Lines 10 and 11.\\n109'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 121, 'page_label': '110', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nNow that our image is loaded, we can start blurring our\\nimages.\\n8.1 averaging\\nThe ﬁrst blurring method we are going to explore is averag-\\ning.\\nAs the name suggests, we are going to deﬁne a k × k slid-\\ning window on top of our image, where k is always an odd\\nnumber. This window is going to slide from left-to-right\\nand from top-to-bottom. The pixel at the center of this ma-\\ntrix (we have to use an odd number, otherwise there would\\nnot be a true “center”) is then set to be the average of all\\nother pixels surrounding it.\\nWe call this sliding window a “convolution kernel” or\\njust a “kernel”. We’ll continue to use this terminology throu-\\nghout this chapter.\\nAs we will see, as the size of the kernel increases, the\\nmore blurred our image will become.\\nLet’s check out some code to perform average blurring:\\nListing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)\\n17 cv2.waitKey(0)\\n110'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 122, 'page_label': '111', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nFigure 8.2: Performing averaging blurring with\\na 3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right).\\nIn order to average blur an image, we use the cv2.blur\\nfunction. This function requires two arguments: the image\\nwe want to blur and the size of the kernel. As Lines 13-15\\nshow, we blur our image with increasing-sized kernels. The\\nlarger our kernel becomes, the more blurred our image will\\nappear.\\nWe make use of the np.hstack function to stack our out-\\nput images together. This method “horizontally stacks” our\\nthree images into a row. This is useful since we don’t want\\nto create three separate windows using thecv2.imshow func-\\ntion.\\nThe output of our averaged blur can be seen in Figure 8.2.\\nThe image on the left is barely blurred, but by the time we\\nreach a kernel of size 7 × 7, we see that our T-Rex is very\\nblurry indeed. Perhaps he was running at a high speed and\\nchasing a jeep?\\n111'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 123, 'page_label': '112', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.2 gaussian\\nFigure 8.3: Performing Gaussian blurring with a\\n3 × 3 kernel ( left), 5 × 5 kernel ( mid-\\ndle), and 7 × 7 kernel ( right). Again,\\nour image becomes more blurred as\\nthe kernel size increases, but is less\\nblurred than the average method in\\nFigure 8.2.\\n8.2 gaussian\\nNext up, we are going to review Gaussian blurring. Gaus-\\nsian blurring is similar to average blurring, but instead of\\nusing a simple mean, we are now using a weighted mean,\\nwhere neighborhood pixels that are closer to the central\\npixel contribute more “weight” to the average.\\nThe end result is that our image is less blurred, but more\\nnaturally blurred, than using the average method discussed\\nin the previous section.\\nLet’s look at some code to perform Gaussian blurring:\\nListing 8.3: blurring.py\\n18 blurred = np.hstack([\\n19 cv2.GaussianBlur(image, (3, 3), 0),\\n112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 124, 'page_label': '113', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\n20 cv2.GaussianBlur(image, (5, 5), 0),\\n21 cv2.GaussianBlur(image, (7, 7), 0)])\\n22 cv2.imshow(\"Gaussian\", blurred)\\n23 cv2.waitKey(0)\\nHere you can see that we are making use of the cv2.\\nGaussianBlur function on Lines 19-21. The ﬁrst argument\\nto the function is the image we want to blur. Then, simi-\\nlar to cv2.blur, we provide a tuple representing our kernel\\nsize. Again, we start with a small kernel size of 3 × 3 and\\nstart to increase it.\\nThe last parameter is our σ, the standard deviation in the\\nx-axis direction. By setting this value to 0, we are instruct-\\ning OpenCV to automatically compute them based on our\\nkernel size.\\nWe can see the output of our Gaussian blur in Figure 8.3.\\nOur images have less of a blur effect than when using the\\naveraging method in Figure 8.2; however, the blur itself is\\nmore natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median\\nTraditionally, the median blur method has been most ef-\\nfective when removing salt-and-pepper noise. This type of\\nnoise is exactly what it sounds like: imagine taking a photo-\\ngraph, putting it on your dining room table, and sprinkling\\nsalt and pepper on top of it. Using the median blur method,\\nyou could remove the salt and pepper from your image.\\n113'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 125, 'page_label': '114', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nWhen applying a median blur, we ﬁrst deﬁne our kernel\\nsize k. Then, as in the averaging blurring method, we con-\\nsider all pixels in the neighborhood of sizek ×k. But, unlike\\nthe averaging method, instead of replacing the central pixel\\nwith the average of the neighborhood, we instead replace\\nthe central pixel with the median of the neighborhood.\\nMedian blurring is more effective at removing salt-and-\\npepper style noise from an image because each central pixel\\nis always replaced with a pixel intensity that exists in the\\nimage.\\nAveraging and Gaussian methods can compute means or\\nweighted means for the neighborhood – this average pixel\\nintensity may or may not be present in the neighborhood.\\nBut by deﬁnition, the median pixel must exist in our neigh-\\nborhood. By replacing our central pixel with a median\\nrather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([\\n25 cv2.medianBlur(image, 3),\\n26 cv2.medianBlur(image, 5),\\n27 cv2.medianBlur(image, 7)])\\n28 cv2.imshow(\"Median\", blurred)\\n29 cv2.waitKey(0)\\nApplying a median blur is accomplished by making a call\\nto the cv2.medianBlur function. This method takes two pa-\\nrameters: the image we want to blur and the size of our\\nkernel. On Lines 25-27, we start off with a kernel size of\\n3, then increase it to 5 and 7. The resulting blurred images\\n114'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 126, 'page_label': '115', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nFigure 8.4: Applying the median blur method to\\nour T-Rex image with increasing ker-\\nnel sizes of 3 ( left), 5 ( middle), and\\n7 ( right), respectively. Notice that\\nwe are no longer creating a “motion\\nblur”.\\nare then stacked and displayed to us.\\nOur median blurred images can be seen in Figure 8.4.\\nNotice that we are no longer creating a “motion blur” ef-\\nfect like in averaging and Gaussian blurring – instead, we\\nare removing detail and noise.\\nFor example, take a look at the color of the scales of the\\nT-Rex. As our kernel size increases, the scales become less\\npronounced. The black and brown stripes on the legs and\\ntail of the T-Rex especially lose their detail, all without cre-\\nating a motion blur.\\n115'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 127, 'page_label': '116', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\n8.4 bilateral\\nThe last method we are going to explore is bilateral blur-\\nring.\\nThus far, the intention of our blurring methods has been\\nto reduce noise and detail in an image; however, we tend to\\nlose edges in the image.\\nIn order to reduce noise while still maintaining edges, we\\ncan use bilateral blurring. Bilateral blurring accomplishes\\nthis by introducing two Gaussian distributions.\\nThe ﬁrst Gaussian function only considers spatial neigh-\\nbors, that is, pixels that appear close together in the (x, y)\\ncoordinate space of the image. The second Gaussian then\\nmodels the pixel intensity of the neighborhood, ensuring\\nthat only pixels with similar intensity are included in the\\nactual computation of the blur.\\nOverall, this method is able to preserve edges of an im-\\nage, while still reducing noise. The largest downside to this\\nmethod is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py\\n30 blurred = np.hstack([\\n31 cv2.bilateralFilter(image, 5, 21, 21),\\n32 cv2.bilateralFilter(image, 7, 31, 31),\\n33 cv2.bilateralFilter(image, 9, 41, 41)])\\n34 cv2.imshow(\"Bilateral\", blurred)\\n35 cv2.waitKey(0)\\n116'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 128, 'page_label': '117', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nFigure 8.5: Applying Bilateral blurring to our\\nbeach image. As the diameter of the\\nneighborhood, color σ, and space σ\\nincreases (from left to right), our im-\\nage has noise removed, yet still re-\\ntains edges and does not appear to\\nbe “motion blurred”.\\nWe apply bilateral blurring by calling thecv2.bilateralFil\\nter function on Lines 31-33. The ﬁrst parameter we supply\\nis the image we want to blur. Then, we need to deﬁne the\\ndiameter of our pixel neighborhood. The third argument\\nis our color σ. A larger value for color σ means that more\\ncolors in the neighborhood will be considered when com-\\nputing the blur. Finally, we need to supply the space σ. A\\nlarger value of space σ means that pixels farther out from\\nthe central pixel will inﬂuence the blurring calculation, pro-\\nvided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be\\nseen in Figure 8.5. As the size of our parameters increases,\\nour image has noise removed, yet the edges still remain.\\n117'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 129, 'page_label': '118', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nNow that we know how to blur our images, we can move\\non to thresholding in the next chapter. You can be sure that\\nwe’ll make use of blurring throughout the rest of this book!\\nFurther Reading\\nOne topic that I didn’t get a chance to cover in detail in-\\nside Practical Python and OpenCV is the convolution op-\\neration. Whether you are smoothing an image, sharp-\\nening details, or detecting edges, convolutions are being\\napplied.\\nTo learn more convolutions, and the role they play in\\ncomputer vision, image processing, and deep learning,\\nbe sure to refer to the Chapter 8 supplementary mate-\\nrial:\\nhttp://pyimg.co/y454z\\n118'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 130, 'page_label': '119', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9\\nT H R E S H O L D I N G\\nThresholding is the binarization of an image. In general,\\nwe seek to convert a grayscale image to a binary image,\\nwhere the pixels are either 0 or 255.\\nA simple thresholding example would be selecting a pixel\\nvalue p, and then setting all pixel intensities less than p to\\nzero, and all pixel values greater than p to 255. In this way,\\nwe are able to create a binary representation of the image.\\nNormally, we use thresholding to focus on objects or ar-\\neas of particular interest in an image. In the examples in the\\nsections below, we will empty our pockets and look at our\\nspare change. Using thresholding methods, we’ll be able to\\nﬁnd the coins in an image.\\n9.1 simple thresholding\\nApplying simple thresholding methods requires human in-\\ntervention. We must specify a threshold value T. All pixel\\nintensities below T are set to 0. And all pixel intensities\\ngreater than T are set to 255.\\n119'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 131, 'page_label': '120', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nWe can also apply the inverse of this binarization by set-\\nting all pixels below T to 255 and all pixel intensities greater\\nthan T to 0.\\nLet’s explore some code to apply simple thresholding\\nmethods:\\nListing 9.1: simple_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\nOn Lines 1-10 we import our packages, parse our argu-\\nments, and load our image. From there, we convert the\\nimage from the RGB color space to grayscale on Line 11.\\nAt this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.\\nListing 9.2: simple_thresholding.py\\n14 (T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\\n15 cv2.imshow(\"Threshold Binary\", thresh)\\n16\\n17 (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.\\nTHRESH_BINARY_INV)\\n120'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 132, 'page_label': '121', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nFigure 9.1: Top-Left: The original coins image in\\ngrayscale. Top-Right: Applying sim-\\nple binary thresholding. The coins\\nare shown in black and the back-\\nground in white. Bottom-Left: Apply-\\ning inverse binary thresholding. The\\ncoins are now white and the back-\\nground is black. Bottom-Right: Ap-\\nplying the inverse binary threshold\\nas a mask to the grayscale image. We\\nare now focused on only the coins in\\nthe image.\\n121'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 133, 'page_label': '122', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\n18 cv2.imshow(\"Threshold Binary Inverse\", threshInv)\\n19\\n20 cv2.imshow(\"Coins\", cv2.bitwise_and(image, image, mask =\\nthreshInv))\\n21 cv2.waitKey(0)\\nAfter the image is blurred, we compute the thresholded\\nimage on Line 14 using the cv2.threshold function. This\\nmethod requires four arguments. The ﬁrst is the grayscale\\nimage that we wish to threshold. We supply our blurred\\nimage here.\\nThen, we manually supply our T threshold value. We\\nuse a value of T = 155.\\nOur third argument is our maximum value applied dur-\\ning thresholding. Any pixel intensity p that is greater than\\nT, is set to this value. In our example, any pixel value that\\nis greater than 155 is set to 255. Any value that is less than\\n155 is set to zero.\\nFinally, we must provide a thresholding method. We use\\nthe cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst\\nis T, the value we manually speciﬁed for thresholding. The\\nsecond is our actual thresholded image.\\nWe then show our thresholded image in Figure 9.1, Top-\\nRight. We can see that our coins are now black pixels and\\nthe white pixels are the background.\\n122'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 134, 'page_label': '123', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nOn Line 17 we apply inverse thresholding rather than\\nnormal thresholding by using cv2.THRESH_BINARY_INV as\\nour thresholding method. As we can see in Figure 9.1,\\nBottom-Left, our coins are now white and the background\\nis black. This is convenient as we will see in a second.\\nThe last task we are going to perform is to reveal the\\ncoins in the image and hide everything else.\\nRemember when we discussed masking? That will come\\nin handy here.\\nOn Line 20 we perform masking by using thecv2.bitwise_\\nand function. We supply our original coin image as the ﬁrst\\ntwo arguments, and then our inverted thresholded image as\\nour mask. Remember, a mask only considers pixels in the\\noriginal image where the mask is greater than zero. Since\\nour inverted thresholded image on Line 17 does a good job\\nat approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our\\nmask – the coins are clearly revealed while the rest of the\\nimage is hidden.\\n9.2 adaptive thresholding\\nOne of the downsides of using simple thresholding meth-\\nods is that we need to manually supply our threshold value\\nT. Not only does ﬁnding a good value of T require a lot of\\nmanual experiments and parameter tunings, it’s not very\\n123'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 135, 'page_label': '124', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nFigure 9.2: Left: The grayscale coins image. Mid-\\ndle: Applying adaptive thresholding\\nusing mean neighborhood values.\\nRight: Applying adaptive threshold-\\ning using Gaussian neighborhood\\nvalues.\\nhelpful if the image exhibits a lot of range in pixel intensi-\\nties.\\nSimply put, having just one value of T might not sufﬁce.\\nIn order to overcome this problem, we can use adap-\\ntive thresholding, which considers small neighbors of pixels\\nand then ﬁnds an optimal threshold value T for each neigh-\\nbor. This method allows us to handle cases where there\\nmay be dramatic ranges of pixel intensities and the optimal\\nvalue of T may change for different parts of the image.\\nLet’s go ahead and jump into some code that applies\\nadaptive thresholding:\\n124'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 136, 'page_label': '125', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nListing 9.3: adaptive_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\n14\\n15 thresh = cv2.adaptiveThreshold(blurred, 255,\\n16 cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\\n17 cv2.imshow(\"Mean Thresh\", thresh)\\n18\\n19 thresh = cv2.adaptiveThreshold(blurred, 255,\\n20 cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\\n21 cv2.imshow(\"Gaussian Thresh\", thresh)\\n22 cv2.waitKey(0)\\nLines 1-10 once again handle setting up our example. We\\nimport our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it\\nslightly on Lines 11 and 12.\\nWe then apply adaptive thresholding to our blurred im-\\nage using the cv2.adaptiveThreshold function on Line 15.\\nThe ﬁrst parameter we supply is the image we want to\\nthreshold. Then, we supply our maximum value of 255,\\nsimilar to simple thresholding mentioned above.\\nThe third argument is our method to compute the thresh-\\nold for the current neighborhood of pixels. By supplying\\ncv2.ADAPTIVE_THRESH_MEAN_C, we indicate that we want to\\ncompute the mean of the neighborhood of pixels and treat\\n125'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 137, 'page_label': '126', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nit as our T value.\\nNext, we need our thresholding method. Again, the de-\\nscription of this parameter is identical to the simple thresh-\\nolding method mentioned above. We usecv2.THRESH_BINAR\\nY_INV to indicate that any pixel intensity greater than T in\\nthe neighborhood should be set to 255, otherwise it should\\nbe set to 0.\\nThe next parameter is our neighborhood size. This inte-\\nger value must be odd and indicates how large our neigh-\\nborhood of pixels is going to be. We supply a value of 11,\\nindicating that we are going to examine 11 × 11 pixel re-\\ngions of the image, instead of trying to threshold the image\\nglobally, as in simple thresholding methods.\\nFinally, we supply a parameter simply called C. This\\nvalue is an integer that is subtracted from the mean, allow-\\ning us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.\\nBesides applying standard mean thresholding, we can\\nalso apply Gaussian (weighted mean) thresholding, as we\\ndo on Line 19. The order of the parameters are identical to\\nLine 15, but now we are tuning a few of the values.\\nInstead of supplying a value of cv2.ADAPTIVE_THRESH_\\nMEAN_C, we instead use cv2.ADAPTIVE_THRESH_GAUSSIAN_C\\nto indicate we want to use the weighted mean. We are\\nalso using a 15 × 15 pixel neighborhood size rather than\\n126'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 138, 'page_label': '127', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nan 11 × 11 neighborhood size as in the previous example.\\nWe also alter our C value (the value we subtract from the\\nmean) slightly and use 3 rather than 4.\\nThe results of applying Gaussian adaptive thresholding\\ncan be seen in the right image of Figure 9.2. There is little\\ndifference between the two images.\\nIn general, choosing between mean adaptive threshold-\\ning and Gaussian adaptive thresholding requires a few ex-\\nperiments on your end. The most important parameters\\nto vary are the neighborhood size and C, the value you\\nsubtract from the mean. By experimenting with this value,\\nyou will be able to dramatically change the results of your\\nthresholding.\\n9.3 otsu and riddler -calvard\\nAnother way we can automatically compute the threshold\\nvalue of T is to use Otsu’s method.\\nOtsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.\\nWhile OpenCV provides support for Otsu’s method, I\\nprefer the implementation by Luis Pedro Coelho in themahotas\\npackage since it is more Pythonic.\\nLet’s jump into some sample code:\\n127'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 139, 'page_label': '128', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nListing 9.4: otsu_and_riddler.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import mahotas\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n15 cv2.imshow(\"Image\", image)\\n16\\n17 T = mahotas.thresholding.otsu(blurred)\\n18 print(\"Otsu’s threshold: {}\".format(T))\\nOn Lines 1-5 we import the packages we will utilize. We\\nhave seen numpy, argparse, and cv2 before. We are now\\nintroducing mahotas, another image processing package.\\nLines 7-12 then handle our standard practice of parsing\\narguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-\\ntion in the mahotas.thresholding package. As our output\\nwill later show us, Otsu’s method ﬁnds a value of T = 137\\nthat we will use for thresholding.\\nListing 9.5: otsu_and_riddler.py\\n19 thresh = image.copy()\\n20 thresh[thresh > T] = 255\\n128'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 140, 'page_label': '129', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\n21 thresh[thresh < 255] = 0\\n22 thresh = cv2.bitwise_not(thresh)\\n23 cv2.imshow(\"Otsu\", thresh)\\n24\\n25 T = mahotas.thresholding.rc(blurred)\\n26 print(\"Riddler-Calvard: {}\".format(T))\\n27 thresh = image.copy()\\n28 thresh[thresh > T] = 255\\n29 thresh[thresh < 255] = 0\\n30 thresh = cv2.bitwise_not(thresh)\\n31 cv2.imshow(\"Riddler-Calvard\", thresh)\\n32 cv2.waitKey(0)\\nApplying the thresholding is accomplished on Lines 19-\\n22. First, we make a copy of our grayscale image so that we\\nhave an image to threshold. Line 20 then makes any values\\ngreater than T white, whereas Line 21 makes all remaining\\npixels that are not white into black pixels. We then invert\\nour threshold by using cv2.bitwise_not. This is equivalent\\nto applying a cv2.THRESH_BINARY_INV thresholding type as\\nin previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.\\nAnother method to keep in mind when ﬁnding optimal\\nvalues for T is the Riddler-Calvard method. Just as in\\nOtsu’s method, the Riddler-Calvard method also computes\\nan optimal value of 137 for T. We apply this method on\\nLine 25 using the rc function in mahotas.thresholding. Fi-\\nnally, the actual thresholding of the image takes place on\\nLines 27-30, as in the previous example. Given that the\\nvalues of T are identical for Otsu and Riddler-Calvard, the\\nthresholded image in Figure 9.3 (right) is identical to the\\nthresholded image in the center.\\n129'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 141, 'page_label': '130', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFigure 9.3: Left: The original grayscale coins\\nimage. Middle: Applying Otsu’s\\nmethod to ﬁnd an optimal value of T.\\nRight: Applying the Riddler-Calvard\\nmethod to ﬁnd an optimal value of\\nT.\\nListing 9.6: otsu_and_riddler.py\\nOtsu’s threshold: 137\\nRiddler-Calvard: 137\\nNow that we have explored thresholding, we will move\\non to another powerful image processing technique – edge\\ndetection.\\n130'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 142, 'page_label': '131', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFurther Reading\\nThresholding is often used as a method to segment the\\nforeground of an image from the background. This\\nworks ﬁne for foreground objects that can be cleanly\\nsegmented. But what if your foreground objects “touch”,\\nthereby making segmentation more difﬁcult. What do\\nyou do then?\\nThe answer is to apply the watershed algorithm, which I\\ncover inside the Chapter 9 supplementary material:\\nhttp://pyimg.co/z1ef6\\n131'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 143, 'page_label': '132', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10\\nG R A D I E N T S A N D E D G E D E T E C T I O N\\nThis chapter is primarily concerned with gradients and\\nedge detection. Formally, edge detection embodies math-\\nematical methods to ﬁnd points in an image where the\\nbrightness of pixel intensities changes distinctly.\\nThe ﬁrst thing we are going to do is ﬁnd the “gradient” of\\nthe grayscale image, allowing us to ﬁnd edge-like regions\\nin the x and y direction.\\nWe’ll then apply Canny edge detection, a multi-stage pro-\\ncess of noise reduction (blurring), ﬁnding the gradient of\\nthe image (utilizing the Sobel kernel in both the horizon-\\ntal and vertical direction), non-maximum suppression, and\\nhysteresis thresholding.\\nIf that sounds like a mouthful, it’s because it is. Again,\\nwe won’t jump too far into the details since this book is con-\\ncerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the\\nalgorithms. Overall, they are not complicated and can be\\n132'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 144, 'page_label': '133', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.1: Left: The original coins image.\\nRight: Applying the Laplacian\\nmethod to obtain the gradient of the\\nimage.\\ninsightful to the behind-the-scenes action of OpenCV .\\n10.1 laplacian and sobel\\nLet’s go ahead and explore some code:\\nListing 10.1: sobel_and_laplacian.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 cv2.imshow(\"Original\", image)\\n133'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 145, 'page_label': '134', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\n13\\n14 lap = cv2.Laplacian(image, cv2.CV_64F)\\n15 lap = np.uint8(np.absolute(lap))\\n16 cv2.imshow(\"Laplacian\", lap)\\n17 cv2.waitKey(0)\\nLines 1-8 import our packages and set up our argument\\nparser. From there, we load our image and convert it to\\ngrayscale on Lines 10 and 11. When computing gradients\\nand edges, we (normally) compute them on a single chan-\\nnel – in this case, we are using the grayscale image; how-\\never, we can also compute gradients for each channel of\\nthe RGB image. For the sake of simplicity, let’s stick with\\nthe grayscale image since that is what you will use in most\\ncases.\\nOn Line 14, we use the Laplacian method to compute the\\ngradient magnitude image by calling the cv2.Laplacian\\nfunction. The ﬁrst argument is our grayscale image – the\\nimage we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-\\nsigned integers. Why are we using a 64-bit ﬂoat now?\\nThe reason involves the transition of black-to-white and\\nwhite-to-black in the image.\\nTransitioning from black-to-white is considered a posi-\\ntive slope, whereas a transition from white-to-black is a\\nnegative slope. If you remember our discussion of image\\narithmetic in Chapter 6, you’ll know that an 8-bit unsigned\\ninteger does not represent negative values. Either it will be\\nclipped to zero if you are using OpenCV or a modulus op-\\n134'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 146, 'page_label': '135', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\neration will be performed using NumPy.\\nThe short answer here is that if you don’t use a ﬂoating\\npoint data type when computing the gradient magnitude\\nimage, you will miss edges, speciﬁcally the white-to-black\\ntransitions.\\nIn order to ensure you catch all edges, use a ﬂoating point\\ndata type, then take the absolute value of the gradient im-\\nage and convert it back to an 8-bit unsigned integer, as in\\nLine 15. This is deﬁnitely an important technique to take\\nnote of – otherwise you’ll be missing edges in your image!\\nTo see the results of our gradient processing, take a look\\nat Figure 10.1.\\nLet’s move on to computing the Sobel gradient represen-\\ntation:\\nListing 10.2: sobel_and_laplacian.py\\n18 sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\\n19 sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\\n20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)\\n27 cv2.imshow(\"Sobel Y\", sobelY)\\n28 cv2.imshow(\"Sobel Combined\", sobelCombined)\\n29 cv2.waitKey(0)\\nUsing the Sobel operator, we can compute gradient mag-\\nnitude representations along the x and y axis, allowing us\\n135'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 147, 'page_label': '136', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.2: Top-Left: The original coins image.\\nTop-Right: Computing the Sobel gra-\\ndient magnitude along the x-axis\\n(ﬁnding vertical edges). Bottom-\\nLeft: Computing the Sobel gradient\\nalong the y-axis (ﬁnding horizontal\\nedges). Bottom-Right: Applying a\\nbitwise OR to combine the two So-\\nbel representations.\\n136'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 148, 'page_label': '137', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nto ﬁnd both horizontal and vertical edge-like regions.\\nIn fact, that’s exactly what Lines 18 and 19 do by us-\\ning the cv2.Sobel method. The ﬁrst argument to the Sobel\\noperator is the image we want to compute the gradient rep-\\nresentation for. Then, just like in the Laplacian example\\nabove, we use a ﬂoating point data type. The last two argu-\\nments are the order of the derivatives in the x and y direc-\\ntion, respectively. Specify a value of 1 and 0 to ﬁnd vertical\\nedge-like regions and 0 and 1 to ﬁnd horizontal edge-like\\nregions\\nOn Lines 21 and 22 we then ensure we ﬁnd all edges by\\ntaking the absolute value of the ﬂoating point image and\\nthen converting it to an 8-bit unsigned integer.\\nIn order to combine the gradient images in both the x\\nand y direction, we can apply a bitwise OR. Remember, an\\nOR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.\\nFinally, we show our gradient images on Lines 26-29.\\nYou can see the result of our work in Figure 10.2. We\\nstart with our original image, Top-Left, and then ﬁnd vertical\\nedges, Top-Right, and horizontal edges, Bottom-Left. Finally,\\nwe compute a bitwise OR to combine the two directions\\ninto a single image, Bottom-Right.\\nOne thing you’ll notice is that the edges are very “noisy”.\\nThey are not clean and crisp. We’ll remedy that by using\\n137'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 149, 'page_label': '138', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFigure 10.3: Left: Our coins image in grayscale\\nand blurred slightly. Right: Apply-\\ning the Canny edge detector to the\\nblurred image to ﬁnd edges. No-\\ntice how our edges are more “crisp”\\nand the outlines of the coins are\\nfound.\\nthe Canny edge detector in the next section.\\n10.2 canny edge detector\\nThe Canny edge detector is a multi-step process. It involves\\nblurring the image to remove noise, computing Sobel gradi-\\nent images in the x and y direction, suppressing edges, and\\nﬁnally a hysteresis thresholding stage that determines if a\\npixel is “edge-like” or not.\\n138'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 150, 'page_label': '139', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nWe won’t get into all these steps in detail. Instead, we’ll\\njust look at some code and show how it’s done:\\nListing 10.3: canny.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 image = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Blurred\", image)\\n14\\n15 canny = cv2.Canny(image, 30, 150)\\n16 cv2.imshow(\"Canny\", canny)\\n17 cv2.waitKey(0)\\nThe ﬁrst thing we do is import our packages and parse\\nour arguments. We then load our image, convert it to graysc-\\nale, and blur it using the Gaussian blurring method. By ap-\\nplying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.\\nApplying the Canny edge detector is performed on Line\\n15 using the cv2.Canny function. The ﬁrst argument we\\nsupply is our blurred, grayscale image. Then, we need to\\nprovide two values: threshold1 and threshold2.\\nAny gradient value larger than threshold2 is considered\\nto be an edge. Any value below threshold1 is consid-\\nered not to be an edge. Values in between threshold1\\nand threshold2 are either classiﬁed as edges or non-edges\\n139'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 151, 'page_label': '140', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nbased on how their intensities are “connected”. In this case,\\nany gradient values below 30 are considered non-edges wh-\\nereas any values above 150 are considered edges.\\nWe then show the results of our edge detection on Line\\n16.\\nFigure 10.3 shows the results of the Canny edge detector.\\nThe image on the left is the grayscale, blurred image that\\nwe pass into the Canny operator. The image on the right is\\nthe result of applying the Canny operator.\\nNotice how the edges are more “crisp”. We have substan-\\ntially less noise than when we used the Laplacian or Sobel\\ngradient images. Furthermore, the outline of our coins are\\nclearly revealed.\\nIn the next chapter, we’ll continue to make use of the\\nCanny edge detector and use it to count the number of\\ncoins in our image.\\n140'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 152, 'page_label': '141', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFurther Reading\\nJust like thresholding is a common method for seg-\\nmenting foreground objects from background objects,\\nthe same can be said for edge detection – only instead\\nof obtaining a large blob representing the foreground,\\nthe Canny detector gives us the outline.\\nHowever, a common challenge of using the Canny edge\\ndetector is getting the lower and upper edge thresh-\\nolds just right. In order to help you (automatically)\\ndetermine these lower and upper boundaries, be sure\\nto read about the automatic Canny edge detector in this\\nsupplementary material:\\nhttp://pyimg.co/91daw\\n141'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 153, 'page_label': '142', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11\\nC O N T O U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in the curve. Contours are extremely useful for such\\nthings as shape approximation and analysis.\\nIn order to ﬁnd contours in an image, you need to ﬁrst ob-\\ntain a binarization of the image, using either edge detection\\nmethods or thresholding. In the examples below, we’ll use\\nthe Canny edge detector to ﬁnd the outlines of the coins,\\nand then ﬁnd the actual contours of the coins.\\nReady?\\nHere we go:\\n11.1 counting coins\\n142'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 154, 'page_label': '143', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nListing 11.1: counting_coins.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n13 blurred = cv2.GaussianBlur(gray, (11, 11), 0)\\n14 cv2.imshow(\"Image\", image)\\n15\\n16 edged = cv2.Canny(blurred, 30, 150)\\n17 cv2.imshow(\"Edges\", edged)\\nThe ﬁrst 11 lines of code simply set up our environment\\nby importing packages, parsing arguments, and loading the\\nimage.\\nJust as in the edge detection methods discussed in the\\nprevious chapter, we are going to convert our image to\\ngrayscale and then apply a Gaussian blur, making it eas-\\nier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.\\nWe then obtain the edged image by applying the Canny\\nedge detector on Line 16. Again, just as in previous edge\\ndetection examples, any gradient values below 30 are con-\\nsidered non-edges whereas any values above 150 are con-\\nsidered sure edges.\\nListing 11.2: counting_coins.py\\n143'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 155, 'page_label': '144', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n18 (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2\\n.CHAIN_APPROX_SIMPLE)\\n19\\n20 print(\"I count {} coins in this image\".format(len(cnts)))\\n21\\n22 coins = image.copy()\\n23 cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\\n24 cv2.imshow(\"Coins\", coins)\\n25 cv2.waitKey(0)\\nNow that we have the outlines of the coins, we can ﬁnd\\nthe contours of the outlines. We do this using the cv2.\\nfindContours function on Line 18. This method returns\\na 3-tuple of: ( 1) our image after applying contour detec-\\ntion (which is modiﬁed and essentially destroyed), ( 2) the\\ncontours themselves, cnts, and (3) the hierarchy of the con-\\ntours (see below).\\nThe ﬁrst argument to cv2.findContours is our edged im-\\nage. It’s important to note that this function is destructive\\nto the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.\\nWe use cv2.RETR_EXTERNAL to retrieve only the outermost\\ncontours (i.e., the contours that follow the outline of the\\ncoin). We can also pass in cv2.RETR_LIST to grab all con-\\ntours. Other methods include hierarchical contours using\\ncv2.RETR_COMP and cv2.RETR_TREE, but hierarchical con-\\ntours are outside the scope of this book.\\nOur last argument is how we want to approximate the\\ncontour. We use cv2.CHAIN_APPROX_SIMPLE to compress\\nhorizontal, vertical, and diagonal segments into their end-\\npoints only. This saves both computation and memory. If\\n144'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 156, 'page_label': '145', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nwe wanted all the points along the contour, without com-\\npression, we can pass in cv2.CHAIN_APPROX_NONE; however,\\nbe very sparing when using this function. Retrieving all\\npoints along a contour is often unnecessary and is wasteful\\nof resources.\\nOur contours cnts is simply a Python list. We can use\\nthe len function on it to count the number of contours that\\nwere returned. We do this on Line 20 to show how many\\ncontours we have found.\\nWhen we execute our script, we will have the output “I\\ncount 9 coins in this image” printed out to our console.\\nNow, we are able to draw our contours. In order not to\\ndraw on our original image, we make a copy of the original\\nimage, called coins on Line 22.\\nA call to cv2.drawContours draws the actual contours on\\nour image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative\\nvalue of −1, we are indicating that we want to draw all of\\nthe contours. However, we would also supply an index i,\\nwhich would be the i’th contour in cnts. This would allow\\nus to draw only a single contour rather than all of them.\\nFor example, here is some code to draw the ﬁrst, second,\\nand third contours, respectively:\\nListing 11.3: Drawing Contours via an Index\\n1 cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)\\n145'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 157, 'page_label': '146', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n2 cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)\\n3 cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)\\nThe fourth argument to the cv2.drawContours function\\nis the color of the line we are going to draw. Here, we use\\na green color.\\nFinally, our last argument is the thickness of the line we\\nare drawing. We’ll draw the contour with a thickness of\\ntwo pixels.\\nNow that our contours are drawn on the image, we can\\nvisualize them on Line 24.\\nTake a look at Figure 11.1 to see the results of our work.\\nOn the left is our original image. Then, we apply Canny\\nedge detection to ﬁnd the outlines of the coins ( middle). Fi-\\nnally, we ﬁnd the contours of the coin outlines and draw\\nthem. You can see that each contour has been drawn with\\na two-pixel thick green line.\\nBut we’re not done yet!\\nLet’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))\\n30 coin = image[y:y + h, x:x + w]\\n31 cv2.imshow(\"Coin\", coin)\\n32\\n33 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n34 ((centerX, centerY), radius) = cv2.minEnclosingCircle(c)\\n146'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 158, 'page_label': '147', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nFigure 11.1: Left: The original coin image. Mid-\\ndle: Applying the Canny edge detec-\\ntor to ﬁnd the outlines of the coins.\\nRight: Finding the contours of the\\ncoin outlines and then drawing the\\ncontours. We have now success-\\nfully found the coins and are able\\nto count them.\\n147'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 159, 'page_label': '148', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n35 cv2.circle(mask, (int(centerX), int(centerY)), int(radius),\\n255, -1)\\n36 mask = mask[y:y + h, x:x + w]\\n37 cv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask =\\nmask))\\n38 cv2.waitKey(0)\\nWe start off on Line 26 by looping over our contours.\\nWe then use the cv2.boundingRect function on the cur-\\nrent contour. This method ﬁnds the “enclosing box” that\\nour contour will ﬁt into, allowing us to crop it from the\\nimage. The function takes a single parameter, a contour,\\nand then returns a tuple of the x and y position that the\\nrectangle starts at, followed by the width and height of the\\nrectangle.\\nWe then crop the coin from the image using our bound-\\ning box coordinates and NumPy array slicing on Line 30.\\nThe coin itself is shown to us on Line 31.\\nIf we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array\\nof zeros, with the same width and height of our original\\nimage.\\nA call to cv2.minEnclosingCircle on Line 34 ﬁts a circle\\nto our contour. We pass in a circle variable, the current\\ncontour, and are given the x and y coordinates of the circle,\\nalong with its radius.\\nUsing the (x, y) coordinates and the radius, we can draw\\na circle on our mask, representing the coin. Drawing circles\\n148'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 160, 'page_label': '149', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work. The\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2 contours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 161, 'page_label': '150', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nFigure 11.2: Top: Cropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing. Bottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 162, 'page_label': '151', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, thegrab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6 if len(cnts) == 2:\\n7 cnts = cnts[0]\\n8\\n9 elif len(cnts) == 3:\\n10 cnts = cnts[1]\\n11\\n12 else:\\n13 raise Exception((\"Contours tuple must have length 2 or \"\\n14 \"3, otherwise OpenCV changed their cv2.findContours \"\\n15 \"return signature yet again. Refer to OpenCV’s\\n16 documentation in that case.\"))\\n17\\n18 return cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)\\nOn Line 1 we call the cv2.findContours function to de-\\ntect contours in an image.\\nFrom there, Line 2 utilizes the grab_contours function\\nto inspect the tuple returned by cv2.findContours and ex-\\n151'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 163, 'page_label': '152', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplementary material for this chap-\\nter – be sure to take a look:\\nhttp://pyimg.co/saz76\\n152'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 164, 'page_label': '153', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12\\nW H E R E T O N O W ?\\nIn this book, we’ve explored many image processing and\\ncomputer vision techniques, including basic image process-\\ning, such as translation, rotating, and resizing. We learned\\nall about image arithmetic and how to apply bitwise op-\\nerations. Then, we explored how a simple technique like\\nmasking can be used to focus our attention and computa-\\ntion to only a single part of an image.\\nTo better understand the pixel intensity distribution of an\\nimage, we then explored histograms. We started by com-\\nputing grayscale histograms, then worked our way up to\\ncolor, including 2D and 3D color histograms. We adjusted\\nthe contrast of images using histogram equalization, then\\nmoved on to blurring our images, using different methods,\\nsuch as averaging, Gaussian, and median ﬁltering.\\nWe thresholded our images to ﬁnd objects of interest,\\nthen applied edge detection.\\nFinally we learned how to use contours to count the num-\\nber of coins in the image.\\n153'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 165, 'page_label': '154', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='where to now ?\\nSo, where do you go from here?\\nYou continue learning, exploring, and experimenting!\\nUse the source code and images provided in this book to\\ncreate projects of your own. That’s the best way to learn!\\nIf you need project ideas, be sure to contact me. I love\\ntalking with readers and helping out when I can. You can\\nreach me at adrian@pyimagesearch.com.\\nFinally, I constantly post on my blog, www.PyImageSear\\nch.com, sharing new and interesting techniques related to\\ncomputer vision and image search engines. Be sure to fol-\\nlow the blog for new posts, as well as new books and courses\\nas I write them.\\n154'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 0, 'page_label': '1', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='SQL-QUERIES\\nTables\\nYou\\tneed\\tto\\tcreate\\tand\\tpopulate\\tthe\\tfollowing\\ttables\\tto\\tstart\\tworking\\ton\\tthe\\nqueries.\\n1.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEmp\\ttable\\tdata'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 1, 'page_label': '2', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 2, 'page_label': '3', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=''),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 3, 'page_label': '4', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.\\t\\t\\t\\tExercises\\twith\\tAnswers\\n2.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tinformation\\tof\\tthe\\tEMP\\ttable?\\nA)\\tselect\\t*\\tfrom\\temp;\\n2.2.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tunique\\tJobs\\tfrom\\tEMP\\ttable?\\nA)\\t\\t\\t\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp;\\nB)\\t\\t\\t\\tselect\\tunique\\tjob\\tfrom\\temp;\\n2.3.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\ttheir\\tSalaries?\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\torder\\tby\\tsal\\tasc;\\n2.4.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tasc\\torder\\tof\\tthe\\tDptnos\\tand\\tdesc\\tof\\nJobs?\\nA)select\\t*\\tfrom\\temp\\torder\\tby\\tdeptno\\tasc,job\\tdesc;\\n2.5.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tunique\\tjob\\tgroups\\tin\\tthe\\tdescending\\torder?\\nA)select\\tdistinct\\tjob\\tfrom\\temp\\torder\\tby\\tjob\\tdesc;\\n2.6.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tall\\t‘Mgrs’\\nA)Select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(\\tselect\\t\\tmgr\\t\\tfrom\\temp)\\t;\\n2.7.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tbefore\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(’01-jan-81’);\\n2.8.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDaily\\tsal\\tof\\tall\\temps\\tin\\tthe\\tasc\\torder\\tof\\nAnnsal.\\nA)\\tselect\\tempno\\t,ename\\t,sal,sal/30,12*sal\\tannsal\\tfrom\\temp\\torder\\tby\\tannsal\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 4, 'page_label': '5', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.9.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tjob,\\tHiredate,\\tExp\\tof\\tall\\tMgrs\\t\\nA)\\tselect\\t\\tempno,ename\\t,job,hiredate,\\tmonths_between(sysdate,hiredate)\\t\\texp\\nfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n2.10.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tExp\\tof\\tall\\temps\\tworking\\tfor\\tMgr\\t7369.\\nA)\\tselect\\tempno,ename,sal,exp\\tfrom\\temp\\twhere\\tmgr\\t=\\t7369;\\n2.11.\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tComm.\\tIs\\tmore\\tthan\\ttheir\\tSal.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tcomm.\\t>\\tsal;\\n2.12.\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\tDesignations\\tof\\tthose\\tjoined\\tafter\\tthe\\nsecond\\thalf\\tof\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t>\\t(’30-jun-81’)\\tand\\nto_char(hiredate,’YYYY’)\\t=\\t1981\\torder\\tby\\tjob\\tasc;\\n2.13.\\t\\t\\t\\t\\tList\\tthe\\temps\\talong\\twith\\ttheir\\tExp\\tand\\tDaily\\tSal\\tis\\tmore\\tthan\\tRs.100.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;\\n2.15.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\ton\\t1-MAY-81,3-DEC-81,17-DEC-81,19-JAN-\\n80\\tin\\tasc\\torder\\tof\\tseniority.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\tin\\t(’01-may-81’,’03-dec-81’,’17-dec-\\n81’,’19-jan-80’)\\t\\torder\\tby\\thiredate\\tasc;\\n2.16.\\t\\t\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tworking\\tfor\\tthe\\tDeptno\\t10\\tor20.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 5, 'page_label': '6', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\t\\tor\\tdeptno\\t=\\t20\\t;\\n2.17.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\thiredate\\tbetween\\t’01-jan-81’\\tand\\t’31-dec-81’;\\n2.18.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tmonth\\tof\\tAug\\t1980.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-aug-80’\\tand\\t’31-aug-80’;\\t\\t\\n(OR)\\nselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon-yyyy’)\\t=’aug-1980;\\n2.19.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWho\\tAnnual\\tsal\\tranging\\tfrom\\t22000\\tand\\t45000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t12*sal\\tbetween\\t22000\\tand\\t45000;\\n2.20.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\thaving\\tfive\\tcharacters\\tin\\ttheir\\tNames.\\nA)\\tselect\\t\\tename\\tfrom\\temp\\twhere\\t\\tlength\\t(ename)\\t=\\t5;\\n2.21.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\tstarting\\twith\\t‘S’\\tand\\twith\\tfive\\tcharacters.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘S%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;\\n2.23.\\t\\t\\t\\t\\tList\\tthe\\tFive\\tcharacter\\tnames\\tstarting\\twith\\t‘S’\\tand\\tending\\twith\\t‘H’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t5\\tand\\tename\\tlike\\t\\t‘S%H’;\\n2.24.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tJanuary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’mon’)\\t=\\t‘jan’;\\n2.25.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\twhich\\tsecond\\tcharacter\\tis\\t‘a’.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\t\\tlike\\t‘_a_’;\\t(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 6, 'page_label': '7', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='B)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\tlike\\t‘_a%’;\\n2.26.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tSal\\tis\\tfour\\tdigit\\tnumber\\tending\\twith\\tZero.\\nA)\\tselect\\t\\t*\\t\\tfrom\\t\\temp\\twhere\\t\\tlength\\t(sal)\\t=\\t4\\tand\\tsal\\tlike\\t‘%0’;\\n2.27.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\thaving\\ta\\tcharacter\\tset\\t‘ll’\\ttogether.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘%LL%’;\\n2.28.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\t80’s.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’yy’)\\t\\tlike\\t‘8%’;\\n2.29.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tdoes\\tnot\\tbelong\\tto\\tDeptno\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\tnot\\tin\\t(20);\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\t!=\\t20;\\t(OR)\\nC)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t<>20;\\t(OR)\\nD)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tlike\\t‘20’;\\n2.30.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\texcept\\t‘PRESIDENT’\\t&\\t‘MGR”\\tin\\tasc\\torder\\tof\\nSalaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;\\nC)\\tSelect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t‘PRESIDENT’\\tand\\tjob\\t<>\\t‘MANAGER’\\t\\norder\\t\\tby\\t\\tsal\\t\\tasc;\\n2.31.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\twho\\tjoined\\tbefore\\tor\\tafter\\t1981.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 7, 'page_label': '8', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’YYYY’)\\t\\tnot\\tin\\t(‘1981’);\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\t(\\thiredate,’YYYY’)\\t\\t!=\\t\\t‘1981’;\\t\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t\\t<>\\t\\t‘1981’\\t;\\t(OR)\\nD)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate\\t,’YYYY’)\\t\\tnot\\tlike\\t‘1981’;\\n2.32.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tEmpno\\tnot\\tstarting\\twith\\tdigit78.\\nA)\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tnot\\tlike\\t‘78%’;\\n2.33.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tunder\\t‘MGR’.\\nA)\\tselect\\te.ename\\t||\\t‘\\tworks\\tfor\\t‘\\t||\\tm.ename\\t\\tfrom\\temp\\te\\t,emp\\tm\\twhere\\te.mgr\\t=\\nm.empno\\t;\\t\\t\\t\\t\\t\\t\\t\\t(OR)\\nB)\\tselect\\t\\te.ename\\t||\\t‘\\thas\\tan\\temployee\\t‘||\\tm.ename\\tfrom\\temp\\te\\t,\\temp\\tm\\twhere\\ne.empno\\t=\\tm.mgr;\\n2.34.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tany\\tyear\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tof\\nMarch.\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\t\\tto_char\\t(hiredate,’MON’)\\tnot\\tin\\t(‘MAR’);\\t\\t(OR)\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\t<>\\t‘MAR’;\\n2.35.\\t\\t\\t\\t\\tList\\tall\\tthe\\tClerks\\tof\\tDeptno\\t20.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\t=‘CLERK’\\tand\\tdeptno\\t=\\t20;\\n2.36.\\t\\t\\t\\t\\tList\\tthe\\temps\\tof\\tDeptno\\t30\\tor\\t10\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’\\tand\\t(deptno'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 8, 'page_label': '9', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='=30\\tor\\tdeptno\\t=10)\\t;\\t\\t(OR)\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\n(hiredate,’YYYY’)\\t\\tin\\t(‘1981’)\\t\\tand\\t\\t(deptno\\t=\\t30\\tor\\tdeptno\\t=10\\t)\\t;\\n2.37.\\t\\t\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tSMITH.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’\\t;\\n2.38.\\t\\t\\t\\t\\tDisplay\\tthe\\tlocation\\tof\\t\\tSMITH.\\nA)\\tselect\\tloc\\tfrom\\temp\\t\\te\\t,\\tdept\\td\\twhere\\t\\te.ename\\t=\\t‘SMITH’\\tand\\t\\te.deptno\\t=\\nd.deptno\\t;\\n2.39.\\t\\t\\t\\t\\tList\\tthe\\ttotal\\tinformation\\tof\\tEMP\\ttable\\talong\\twith\\tDNAME\\tand\\tLoc\\tof\\nall\\tthe\\temps\\tWorking\\tUnder\\t‘ACCOUNTING’\\t&\\t‘RESEARCH’\\tin\\tthe\\tasc\\nDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t(dname\\t=\\t‘ACCOUNTING’\\tor\\tdname\\n=’RESEARCH’\\t)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\tasc;\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.dname\\tin\\n(‘ACCOUNTING’,’RESEARCH’)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\nasc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,d.dname\\t\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\n(‘NEW\\tYORK’,’DALLAS’)\\tand\\te.deptno\\t=\\td.deptno\\tand\\te.empno\\tin\\t(select\\ne.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\t(‘MANAGER’,’ANALYST’)\\tand\\t\\n(months_between(sysdate,e.hiredate)/12)>\\t7\\t\\tand\\t\\te.comm.\\tis\\tnull)\\norder\\tby\\td.loc\\t\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 9, 'page_label': '10', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.41.\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tLoc,\\tDeptno,\\tJob\\tof\\tall\\temps\\nworking\\tat\\tCJICAGO\\tor\\tworking\\tfor\\tACCOUNTING\\tdept\\twith\\tAnn\\nSal>28000,\\tbut\\tthe\\tSal\\tshould\\tnot\\tbe=3000\\tor\\t2800\\twho\\tdoesn’t\\tbelongs\\tto\\tthe\\nMgr\\tand\\twhose\\tno\\tis\\thaving\\ta\\tdigit\\t‘7’\\tor\\t‘8’\\tin\\t3rd\\tposition\\tin\\tthe\\tasc\\torder\\tof\\nDeptno\\tand\\tdesc\\torder\\tof\\tjob.\\nA)\\tselect\\tE.empno,E.ename,E.sal,D.dname,D.loc,E.deptno,E.job\\nfrom\\temp\\tE,dept\\tD\\nwhere\\t(D.loc\\t=\\t'CHICAGO'\\tor\\tD.dname\\t=\\t'ACCOUNTING')\\tand\\nE.deptno=D.deptno\\tand\\tE.empno\\tin\\n(select\\tE.empno\\tfrom\\temp\\tE\\twhere\\t(12*E.sal)\\t>\\t28000\\tand\\t\\tE.sal\\tnot\\tin\\n(3000,2800)\\t\\tand\\tE.job\\t!='MANAGER'\\nand\\t(\\tE.empno\\tlike\\t'__7%'\\tor\\tE.empno\\tlike\\t'__8%'))\\norder\\tby\\tE.deptno\\tasc\\t,\\tE.job\\tdesc;\\n2.42.\\t\\t\\t\\t\\tDisplay\\tthe\\ttotal\\tinformation\\tof\\tthe\\temps\\talong\\twith\\tGrades\\tin\\tthe\\tasc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\\t\\norder\\tby\\ts.grade\\t\\tasc;\\t\\t\\t\\t\\t\\t\\t\\t(using\\tbetween\\tand\\tis\\ta\\tbit\\tsimple)\\n2.43.\\t\\t\\t\\t\\tList\\tall\\tthe\\tGrade2\\tand\\tGrade\\t3\\temps.\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ns\\twhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin(2,3));\\t(OR)\\t\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 10, 'page_label': '11', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='s.grade\\tin\\t(2,3)\\t;\\n2.44.\\t\\t\\t\\t\\tDisplay\\tall\\tGrade\\t4,5\\tAnalyst\\tand\\tMgr.\\nA)\\tselect\\t*\\tfrom\\temp\\te,\\tsalgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand\\ns.grade\\tin\\t(4,5)\\tand\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\n(‘MANAGER’,’ANALYST’)\\t);\\n2.45.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tGrade,\\tExp,\\tand\\tAnn\\tSal\\tof\\temps\\nworking\\tfor\\tDept10\\tor20.\\nA)\\nselectE.empno,E.ename,E.sal,S.grade,D.dname,\\n(months_between(sysdate,E.hiredate)/12)\\t\"EXP\"\\t,12*E.sal\\t\\t“ANN\\tSAL”\\nfrom\\temp\\tE,dept\\tD\\t,salgrade\\tS\\nwhere\\tE.deptno\\tin\\t(10,20)\\tand\\tE.deptno\\t=\\tD.deptno\\t\\tand\\tE.sal\\tbetween\\tS.losal\\nand\\tS.hisal\\t;\\n2.46.\\t\\t\\t\\t\\tList\\tall\\tthe\\tinformation\\tof\\temp\\twith\\tLoc\\tand\\tthe\\tGrade\\tof\\tall\\tthe\\temps\\nbelong\\tto\\tthe\\tGrade\\trange\\tfrom\\t2\\tto\\t4\\tworking\\tat\\tthe\\tDept\\tthose\\tare\\tnot\\tstarting\\nwith\\tchar\\tset\\t‘OP’\\tand\\tnot\\tending\\twith\\t‘S’\\twith\\tthe\\tdesignation\\thaving\\ta\\tchar\\t‘a’\\nany\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades\\nA)\\t\\tselect\\te.empno,e.ename,d.loc,s.grade,e.sal\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\nand\\t(d.dname\\tnot\\tlike\\t\\'OP%\\'\\tand\\td.dname\\tnot\\tlike\\t\\'%S\\')\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin\\t(2,3,4)\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tjob\\tlike\\t\\'%A%\\'and\\tsal\\tnot\\tlike\\n\\'%00\\'\\tand\\t(to_char\\t(hiredate,\\'YYYY\\')\\t=\\t\\'1981\\'\\nand\\tto_char(hiredate,\\'MON\\')\\tnot\\tin\\t(\\'MAR\\',\\'SEP\\')));'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 11, 'page_label': '12', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.47.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tDepts\\talong\\twith\\tEmpno,\\tEname\\tor\\twithout\\tthe\\nemps\\nA)\\tselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno(+)=\\td.deptno;\\n2.48.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tSalaries\\tmore\\tthan\\tthe\\temployee\\nBLAKE.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>\\t(select\\t\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\n‘BLAKE’);\\n2.49.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tJobs\\tare\\tsame\\tas\\tALLEN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘ALLEN’);\\n2.50.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tKing.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\n=\\t‘KING’);\\n2.51.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tMGRS.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\t\\tand\\tw.hiredate\\t<\\t\\nm.hiredate\\t;\\t(OR)\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.empno=\\tm.mgr\\tand\\nw.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand\\ne.job\\tin\\t(\\tselect\\te.job\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\tand\\td.deptno\\n=10);\\n2.53.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\tsame\\tas\\tFORD\\tor\\tSMITH\\tin\\tdesc\\torder\\tof'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 12, 'page_label': '13', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Sal.\\nA)\\nSelect\\t*\\t\\tfrom\\t\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\t(\\tename\\t=\\t‘SMITH’\\nor\\t\\tename\\t=\\t‘FORD’\\t))\\t\\torder\\tby\\tsal\\tdesc;\\n2.54.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\tJobs\\tare\\tsame\\tas\\tMILLER\\tor\\tSal\\tis\\tmore\\tthan\\nALLEN.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\t\\twhere\\tjob\\t=\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘MILLER’\\t)\\tor\\t\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’);\\n2.55.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\t>\\tthe\\ttotal\\tremuneration\\tof\\tthe\\tSALESMAN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>(select\\tsum(nvl2(comm,sal+comm,sal))\\tfrom\\nemp\\t\\twhere\\tjob\\t=\\t‘SALESMAN’);\\n2.56.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tBLAKE\\tworking\\tat\\tCHICAGO\\t&\\nBOSTON.\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\t(‘CHICAGO’,’BOSTON’)\\tand\\ne.deptno\\t=\\td.deptno\\tand\\te.hiredate\\t<(select\\te.hiredate\\tfrom\\temp\\te\\twhere\\te.ename\\n=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.deptno\\tin\\t(select\\td.deptno\\t\\tfrom\\tdept\\td\\twhere\\nd.dname\\t\\tin\\t(‘ACCOUNTING’,’RESEARCH’)\\t)\\tand\\t\\ne.sal\\t>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’)\\t\\tand\\t\\ne.hiredate\\t<(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’)\\tand\\ne.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\t\\tand\\ts.grade\\tin\\t(3,4)\\t)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 13, 'page_label': '14', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='order\\tby\\te.hiredate\\tdesc;\\n2.58.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tjobs\\tsame\\tas\\tSMITH\\tor\\tALLEN.\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘SMITH’\\tor\\tename\\t=\\t‘ALLEN’);\\t\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\tin\\n(‘SMITH’,’ALLEN’);\\n2.59.\\t\\t\\t\\t\\tWrite\\ta\\tQuery\\tto\\tdisplay\\tthe\\tdetails\\tof\\temps\\twhose\\tSal\\tis\\tsame\\tas\\tof\\nb)\\t\\t\\t\\t\\tEmployee\\tSal\\tof\\tEMP1\\ttable.\\nc)\\t\\t\\t\\t\\t\\t¾\\tSal\\tof\\tany\\tMgr\\tof\\tEMP2\\ttable.\\nd)\\t\\t\\t\\t\\tThe\\tsal\\tof\\tany\\tperson\\twith\\texp\\tof\\t5\\tyears\\tbelongs\\tto\\tthe\\tsales\\tdept\\tof\\temp3\\ntable.\\ne)\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\temployee\\tof\\temp4\\ttable.\\nf)\\t\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\tand\\t3\\temployee\\tworking\\tfro\\tsales\\tdept\\tor\\toperations\\tdept\\njoined\\tin\\t89.\\n2.60.\\t\\t\\t\\t\\tAny\\tjobs\\tof\\tdeptno\\t10\\tthose\\tthat\\tare\\tnot\\tfound\\tin\\tdeptno\\t20.\\nA)\\tselect\\t\\te.job\\tfrom\\temp\\te\\twhere\\te.deptno\\t=\\t10\\tand\\te.job\\tnot\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=20);\\n2.61.\\t\\t\\t\\t\\tList\\tof\\temps\\tof\\temp1\\twho\\tare\\tnot\\tfound\\tin\\temp2.\\n2.62.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tsal\\tof\\tEMP\\ttable.\\nA)\\tselect\\tmax(sal)\\tfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 14, 'page_label': '15', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.63.\\t\\t\\t\\t\\tFind\\tdetails\\tof\\thighest\\tpaid\\temployee.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\t\\tmax(sal)\\tfrom\\temp);\\n2.64.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tpaid\\temployee\\tof\\tsales\\tdepartment.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp\\twhere\\tdeptno\\tin\\n(select\\td.deptno\\tfrom\\ndept\\td\\twhere\\td.dname\\t=\\t'SALES'));\\n2.65.\\t\\t\\t\\t\\tList\\tthe\\tmost\\trecently\\thired\\temp\\tof\\tgrade3\\tbelongs\\tto\\t\\tlocation\\nCHICAGO.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t\\te.deptno\\tin\\t(\\tselect\\t\\td.deptno\\tfrom\\tdept\\td\\twhere\\nd.loc\\t=\\t'CHICAGO')\\tand\\ne.hiredate\\tin\\t\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tempno\\nfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3))\\t;\\t(or)\\nselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\td.loc='chicago'\\nand\\thiredate\\tin(select\\tmax(hiredate)\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\tsal\\tbetween\\tlosal\\tand\\thisal\\tand\\tgrade=3);\\n2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'))\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 15, 'page_label': '16', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.67.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temployee\\tbelongs\\tto\\tnewyork\\twith\\tgrade\\t3\\tto\\t5\\nexcept\\t‘PRESIDENT’\\twhose\\tsal>\\tthe\\thighest\\tpaid\\temployee\\tof\\tChicago\\tin\\ta\\ngroup\\twhere\\tthere\\tis\\tmanager\\tand\\tsalesman\\tnot\\tworking\\tunder\\tking\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\n='NEW\\tYORK')\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\tand\\ns.grade\\tin\\t(3,4,5)\\t)\\tand\\tjob\\t!=\\t'PRESIDENT'\\tand\\tsal\\t>(select\\tmax(sal)\\tfrom\\temp\\nwhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\t'CHICAGO')\\tand\\tjob\\tin\\n('MANAGER','SALESMAN')\\tand\\nmgr\\tnot\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\\n2.68.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tsenior\\temployee\\tbelongs\\tto\\t1981.\\nB)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\t\\nwhere\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\\n2.69.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tjoined\\tin\\t1981\\twith\\tthe\\tjob\\tsame\\tas\\tthe\\tmost\\nsenior\\tperson\\tof\\tthe\\tyear\\t1981.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=’1981’));\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 16, 'page_label': '17', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.70.\\t\\t\\t\\t\\tList\\tthe\\tmost\\tsenior\\templ\\tworking\\tunder\\tthe\\tking\\tand\\tgrade\\tis\\tmore\\t\\nthan\\t3.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\nempno\\tin\\n(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\tin\\t(4,5)))\\nand\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING');\\n2.71.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tsal\\tgiven\\tto\\tthe\\tMGR.\\nD)\\t\\t\\t\\tselect\\tsum\\t(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(OR)\\nB)\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp);\\n2.72.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tannual\\tsal\\tto\\tdistribute\\tjob\\twise\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\tjob,sum(12*sal)\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t=\\t'1981'\\ngroup\\tby\\tjob\\t;\\n2.73.\\t\\t\\t\\t\\tDisplay\\ttotal\\tsal\\temployee\\tbelonging\\tto\\tgrade\\t3.\\nE)\\t\\t\\t\\t\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\nin\\t\\t(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3)\\n2.74.\\t\\t\\t\\t\\tDisplay\\tthe\\taverage\\tsalaries\\tof\\tall\\tthe\\tclerks.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 17, 'page_label': '18', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\tavg(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n2.75.\\t\\t\\t\\t\\tList\\tthe\\temployeein\\tdept\\t20\\twhose\\tsal\\tis\\t>the\\taverage\\tsal\\t0f\\tdept\\t10\\nemps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=20\\tand\\tsal\\t>(select\\tavg\\t(sal)\\tfrom\\temp\\nwhere\\t\\tdeptno\\t=\\t10);\\n2.76.\\t\\t\\t\\t\\tDisplay\\tthe\\tnumber\\tof\\temployee\\t\\tfor\\teach\\tjob\\tgroup\\tdeptno\\twise.\\nF)\\t\\t\\t\\t\\tselect\\t\\tdeptno\\t,job\\t,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\t\\tdeptno,job;\\t(or)\\nB)\\tselect\\td.deptno,e.job,count(e.job)\\tfrom\\temp\\te,dept\\td\\twhere\\ne.deptno(+)=d.deptno\\tgroup\\tby\\te.job,d.deptno;\\n2.77.\\t\\t\\t\\t\\tList\\tthe\\tmanage\\trno\\tand\\tthe\\tnumber\\tof\\temployees\\tworking\\tfor\\tthose\\nmgrs\\tin\\tthe\\tascending\\tMgrno.\\nG)\\t\\t\\t\\tselect\\tw.mgr\\t,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\ngroup\\tby\\tw.mgr\\norder\\tby\\tw.mgr\\tasc;\\n2.78.\\t\\t\\t\\t\\tList\\tthe\\tdepartment,details\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tworking\\nH)\\t\\t\\t\\tselect\\tdeptno\\t,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tcount(*)\\t>=\\t2;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 18, 'page_label': '19', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.79.\\t\\t\\t\\t\\tDisplay\\tthe\\tGrade,\\tNumber\\tof\\temps,\\tand\\tmax\\tsal\\tof\\teach\\tgrade.\\nA)\\tselect\\ts.grade\\t,count(*),max(sal)\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\ngroup\\tby\\ts.grade;\\n2.80.\\t\\t\\t\\t\\tDisplay\\tdname,\\tgrade,\\tNo.\\tof\\temps\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tclerks.\\nA)\\tselect\\td.dname,s.grade,count(*)\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\twhere\\te.deptno\\n=\\td.deptno\\tand\\ne.job\\t=\\t'CLERK'\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tgroup\\tby\\td.dname,s.grade\\nhaving\\tcount(*)\\t>=\\t2;\\n2.81.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tdepartment\\twhere\\tmaximum\\tnumber\\tof\\temps\\tare\\nworking.\\nI)\\t\\t\\t\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\t(OR)\\nJ)\\t\\t\\t\\t\\t\\tselect\\td.deptno,d.dname,d.loc,count(*)\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\\nK)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 19, 'page_label': '20', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\t(OR)\\nL)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\t=\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\n2.83.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twhose\\tsalary\\tis\\tmore\\tthan\\t3000\\tafter\\tgiving\\t20%\\nincrement.\\nM)\\t\\tSELECT\\t*\\tFROM\\tEMP\\tWHERE\\t(1.2*SAL)\\t>\\t3000\\t;\\n2.84.\\t\\t\\t\\t\\tList\\tthe\\temps\\twith\\tdept\\tnames.\\nA)\\tselect\\ne.empno,e.ename,e.job,e.mgr,e.hiredate,e.sal,e.comm,e.deptno,d.dname\\nfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno;\\n2.85.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tnot\\tworking\\tin\\tsales\\tdept.\\nN)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tin\\n(select\\tdeptno\\tfrom\\temp\\twhere\\tdname\\t=\\t‘SALES’);\\n2.86.\\t\\t\\t\\t\\tList\\tthe\\temps\\tname\\t,dept,\\tsal\\tand\\tcomm.\\tFor\\tthose\\twhose\\tsalary\\tis\\nbetween\\t2000\\tand\\t5000\\twhile\\tloc\\tis\\tChicago.\\nA)\\tselect\\te.ename,e.deptno,e.sal,e.comm\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\nd.deptno\\tand\\nd.loc\\t=\\t'CHICAGO'\\tand\\te.sal\\tbetween\\t2000\\tand\\t5000;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 20, 'page_label': '21', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.87.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tgreater\\tthan\\this\\tmanagers\\tsalary\\nA)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n2.88.\\t\\t\\t\\t\\tList\\tthe\\tgrade,\\tEMP\\tname\\tfor\\tthe\\tdeptno\\t10\\tor\\tdeptno\\t30\\tbut\\tsal\\tgrade\\tis\\nnot\\t4\\twhile\\tthey\\tjoined\\tthe\\tcompany\\tbefore\\t’31-dec-82’.\\nA)\\tselect\\ts.grade\\t,e.ename\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.deptno\\tin\\t(10,20)\\tand\\nhiredate\\t<\\t('31-DEC-82')\\tand\\t(e.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tnot\\tin\\n(4));\\n2.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\t,job,\\tdname,\\tlocation\\tfor\\tthose\\twho\\tare\\tworking\\tas\\tMGRS.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\ne.empno\\tin\\t(select\\tmgr\\tfrom\\temp\\t)\\t;\\n3.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tmgr\\tname\\tis\\tjones\\tand\\talso\\tlist\\ttheir\\tmanager\\tname.\\nA)\\tselect\\tw.empno,w.ename,w.job,w.mgr,w.hiredate,w.sal,w.deptno,m.ename\\nfrom\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\\nA)\\tselect\\te.ename,e.sal\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.ename\\t=\\t'FORD'\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\te.sal\\t=\\ts.hisal\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 21, 'page_label': '22', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"5.\\t\\t\\t\\t\\t\\tLit\\tthe\\tname,\\tjob,\\tdname\\t,sal,\\tgrade\\tdept\\twise\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,e.sal,s.grade\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\norder\\tby\\te.deptno\\t;\\n6.\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\tname,\\tjob,\\tsal,\\tgrade\\tand\\tdname\\texcept\\tclerks\\tand\\tsort\\ton\\tthe\\nbasis\\tof\\thighest\\tsal.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,e.sal,s.grade,d.dname\\tfrom\\temp\\te\\t,dept\\td\\t,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.job\\tnot\\tin('CLERK')\\norder\\tby\\te.sal\\tdesc;\\n7.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tname,\\tjob\\t\\twho\\tare\\twith\\tout\\tmanager.\\nA)\\tselect\\te.ename,e.job\\tfrom\\temp\\te\\twhere\\tmgr\\tis\\tnull;\\n8.\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tthe\\temps\\twho\\tare\\tgetting\\tthe\\thighest\\tsal\\tdept\\twise.\\nA)\\t\\t\\t\\tselect\\te.ename,e.deptno\\tfrom\\temp\\te\\twhere\\te.sal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t;\\n9.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tequal\\tto\\tthe\\taverage\\tof\\tmax\\tand\\tminimum\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=(select\\t(max(sal)+min(sal))/2\\tfrom\\temp);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 22, 'page_label': '23', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='10.\\t\\tList\\tthe\\tno.\\tof\\temps\\tin\\teach\\tdepartment\\twhere\\tthe\\tno.\\tis\\tmore\\tthan\\t3.\\nA)\\tselect\\tdeptno,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\thaving\\tcount(*)\\t<\\t3;\\n11.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tdepts.\\tWhere\\tatleast\\t3\\tare\\tworking\\tin\\tthat\\tdepartment.\\nA)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\\nhaving\\tcount(*)\\t>=\\t3\\t\\t;\\n12.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twhose\\tsal\\tis\\tmore\\tthan\\this\\temployess\\tavg\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tm\\t\\twhere\\tm.empno\\tin\\t(select\\tmgr\\tfrom\\temp)\\nand\\tm.sal\\t>\\t(select\\tavg(e.sal)\\tfrom\\temp\\te\\twhere\\te.mgr\\t=\\tm.empno\\n)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\nThe\\tsubquery\\tdoes\\tthe\\tsame\\tas\\t\\t\\t(select\\t(avg(e.sal)),m.ename\\tfrom\\temp\\te,emp\\tm\\nwhere\\te.mgr=m.empno\\tgroup\\tby\\te.mgr,m.ename);\\n13.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname,salary,comm.\\tFor\\tthose\\temployees\\twhose\\tnet\\tpay\\tis\\ngreater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\tename,sal,comm.\\tfrom\\temp\\twhere\\tsal+nvl(comm.,0)\\t>=\\tany\\t(select\\nsal\\tfrom\\temp);/\\n14.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\twhose\\tsal<his\\tmanager\\tbut\\tmore\\tthan\\tany\\tother\\tmanager.\\na)select\\t\\tdistinct\\tW.empno,W.ename,W.sal'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 23, 'page_label': '24', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='from\\t(select\\tw.empno,w.ename,w.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\t\\nw.mgr\\t=\\tm.empno\\tand\\tw.sal<m.sal)\\tW,\\n(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp))\\tA\\nwhere\\tW.sal\\t>\\tA.sal;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t<\\tm.sal\\nand\\tw.sal\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp));\\n15.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temployee\\tnames\\tand\\this\\taverage\\tsalary\\tdepartment\\twise.\\nA)\\nselect\\td.deptno,\\tround(avg(nvl2(e1.comm,\\te1.sal+e1.comm,\\te1.sal)))\\tavg,\\ne2.ename\\tfrom\\temp\\te1,\\temp\\te2,\\tdept\\td\\twhere\\td.deptno\\t=e1.deptno\\tand\\td.deptno\\n=\\te2.deptno\\tgroup\\tby\\td.deptno,\\te2.ename;\\t(or)\\nB)\\tselect\\td.maxsal,e.ename,e.deptno\\tas\\t\"current\\tsal\"\\tfrom\\temp\\te,\\n(select\\tavg(Sal)\\tmaxsal,deptno\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\td\\nwhere\\te.deptno=d.deptno;\\n16.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\tleast\\t5\\tearners\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t5>\\t(select\\tcount(*)\\tfrom\\temp\\twhere\\te.sal\\t>sal);\\n(or)\\nB)\\t\\t\\t\\tselect\\trownum\\trank,empno,ename,job,sal\\tfrom\\t(select\\t*\\tfrom\\temp\\torder\\tby\\nsal\\tasc)\\twhere\\trownum\\t<\\t6\\t;\\t(or)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 24, 'page_label': '25', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"C)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t\\twhere\\t5\\t>(select\\tcount(distinct\\tsal)\\tfrom\\temp\\twhere\\ne.sal\\t>\\tsal);\\n17.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\temps\\twhose\\tsalaries\\tgreater\\tthan\\tsalaries\\tof\\ttheir\\tmanagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal>\\tm.sal;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\nemp))\\ta\\nwhere\\te.sal\\t>a.sal\\tand\\te.mgr\\t=\\ta.empno\\n18.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twho\\tare\\tnot\\tworking\\tunder\\tthe\\tpresident.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp)\\tand\\tmgr\\tnot\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tjob\\t=\\t'PRESIDENT')\\n19.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\trecords\\tfrom\\temp\\twhose\\tdeptno\\tisnot\\tin\\tdept.\\n20.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tName\\t,\\tSalary,\\tComm\\tand\\tNet\\tPay\\tis\\tmore\\tthan\\tany\\tother\\nemployee.\\nA)\\t\\t\\t\\tSelect\\te.ename,e.sal,e.comm,nvl2(comm,sal+comm,sal)\\tNETPAY\\nfrom\\temp\\te\\t\\nwhere\\tnvl2(comm,sal+comm,sal)\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\n=e.empno)\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 25, 'page_label': '26', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"21.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEnames\\twho\\tare\\tretiring\\tafter\\t31-Dec-89\\tthe\\tmax\\tJob\\tperiod\\tis\\n20Y.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\tadd_months(hiredate,240)\\t>\\t'31-DEC-89';\\nB)\\tselect\\tename\\tfrom\\temp\\nwhere\\tadd_months(hiredate,240)\\t>\\tto_date(’31-DEC-89’,’DD-MON-RR’);\\t\\n22.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthose\\tEmps\\twhose\\tSalary\\tis\\todd\\tvalue.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tmod(sal,2)\\t=\\t1;\\n23.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp’s\\twhose\\tSalary\\tcontain\\t3\\tdigits.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\twhere\\tlength\\t(sal)\\t=\\t3;\\n24.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tDEC.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=’DEC’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\tin\\t(‘DEC’);\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MONTH’)\\tlike\\t‘DEC%’;\\n25.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\tcontains\\t‘A’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%A%’;\\n26.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tDeptno\\tis\\tavailable\\tin\\this\\tSalary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(sal,deptno)\\t>\\t0;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 26, 'page_label': '27', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"27.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tfirst\\t2\\tchars\\tfrom\\tHiredate=last\\t2\\tcharacters\\tof\\nSalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsubstr(hiredate,1,2)\\t=\\tsubstr(sal,length(sal)-1,length(sal));\\n28.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\t10%\\tof\\tSalary\\tis\\tequal\\tto\\tyear\\tof\\tjoining.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YY')\\tin\\t(select\\t.1*sal\\tfrom\\temp);\\n29.\\t\\t\\t\\t\\t\\t\\t\\tList\\tfirst\\t50%\\tof\\tchars\\tof\\tEname\\tin\\tLower\\tCase\\tand\\tremaining\\tare\\tupper\\nCase.\\nA)\\t\\t\\t\\t\\t\\t\\t\\t\\nselect\\tlower(substr(ename,1,round(length(ename)/2)))\\n||substr(ename,round(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\t\\t(OR)\\nB)\\tselect\\tlower(substr(ename,1,ciel(length(ename)/2)))\\n||\\tsubstr(ename,ciel(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\n30.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname\\twhose\\tNo.\\tof\\tEmps\\tis\\t=to\\tnumber\\tof\\tchars\\tin\\tthe\\nDname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 27, 'page_label': '28', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\te\\nwhere\\te.deptno\\t=\\td.deptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\t\\ngroup\\tby\\td.dname\\thaving\\tcount(*)\\t=\\tlength\\t(d.dname);\\n31.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\tcompany\\tbefore\\t15th\\tof\\tthe\\tmonth.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,\\'DD\\')\\t<\\t\\'15\\';\\n32.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname,\\tno\\tof\\tchars\\tof\\twhich\\tis\\t=\\tno.\\tof\\temp’s\\tin\\tany\\tother\\nDept.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\t\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tlength(dname)\\t=\\tany\\t(select\\tcount(*)\\tfrom\\temp\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\t,\\t(select\\tcount(*)\\ts,e.deptno\\t\\t\"M\"from\\temp\\te\\tgroup\\tby\\ne.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp\\t);\\n34.\\t\\t\\t\\t\\t\\t\\t\\tList\\tTHE\\tName\\tof\\tdept\\twhere\\thighest\\tno.of\\temps\\tare\\tworking.\\nA)\\tselect\\tdname\\tfrom\\tdept\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 28, 'page_label': '29', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tdeptno\\t\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\n35.\\t\\t\\t\\t\\t\\t\\t\\tCount\\tthe\\tNo.of\\temps\\twho\\tare\\tworking\\tas\\t‘Managers’(using\\tset\\toption).\\nA)select\\tcount(*)\\nfrom(select\\t*\\tfrom\\temp\\tminus\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t'MANAGER')\\n36.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\ton\\tthe\\tsame\\tdate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\tin\\n(select\\thiredate\\tfrom\\temp\\twhere\\te.empno\\t<>\\tempno);\\n37.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tGrade\\tis\\tequal\\tto\\tone\\ttenth\\tof\\tSales\\nDept.\\nA)\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t0.1*\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdname\\t=\\t'SALES');\\n38.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tof\\tthe\\tdept\\twhere\\tmore\\tthan\\taverage\\tno.\\tof\\temps\\tare\\nworking.\\nA)\\tselect\\td.dname\\tfrom\\tdept\\td,\\temp\\te\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 29, 'page_label': '30', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='having\\tcount(*)\\t>\\t(select\\tavg(count(*))\\tfrom\\temp\\t\\tgroup\\tby\\tdeptno);\\n39.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tManagers\\tname\\twho\\tis\\thaving\\tmax\\tno.of\\temps\\tworking\\tunder\\nhim.\\nA)select\\tm.ename,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\t\\ngroup\\tby\\tm.ename\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr);\\t\\t\\t\\t\\t\\n(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\t=\\t(select\\tmgr\\tfrom\\temp\\tgroup\\tby\\tmgr\\thaving\\ncount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr))\\t;\\n40.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEname\\tand\\tSal\\tis\\tincreased\\tby\\t15%\\tand\\texpressed\\tas\\tno.of\\nDollars.\\nA)\\tselect\\tename,to_char(1.15*sal,\\'$99,999\\')\\tas\\t\"SAL\"\\t\\tfrom\\temp;\\t(only\\tfor\\t$\\tit\\nworks)\\nB)\\tselect\\tename,\\'$\\'||1.15*sal\\t\\t“SAL”\\tfrom\\temp;\\n41.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\toutput\\tof\\tEMP\\ttable\\t‘EMP_AND_JOB’\\tfor\\tEname\\tand\\tJob.\\nA)\\tselect\\tename||\\tjob\\tas\\t\"EMP_AND_JOB\"\\tfrom\\temp\\t;\\n42.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\tfollowing\\toutput\\tfrom\\tEMP.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 30, 'page_label': '31', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='I.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEMPLOYEE\\nSMITH\\t(clerk)\\nALLEN\\t(Salesman)\\nA)\\t\\tselect\\tename\\t||\\t‘(‘||\\tlower(job)||’)’\\tas\\t“EMPLOYEE”\\tfrom\\temp;\\n130)\\t\\t\\tList\\tthe\\temps\\twith\\tHire\\tdate\\tin\\tformat\\tJune\\t4,\\t1988.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal,\\tto_char(hiredate,\\'MONTH\\tDD,YYYY\\')\\tfrom\\temp;\\n131)\\t\\t\\tPrint\\ta\\tlist\\tof\\temp’s\\tListing\\t‘just\\tsalary’\\tif\\tSalary\\tis\\tmore\\tthan\\t1500,\\ton\\ntarget\\tif\\tSalary\\tis\\t1500\\tand\\t‘Below\\t1500’\\tif\\tSalary\\tis\\tless\\tthan\\t1500.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal||\\t‘JUST\\tSALARY’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t>\\n1500\\tunion\\nselect\\tempno,ename,\\tsal||\\t‘ON\\tTARGET’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t=\\t1500\\t\\t\\t\\t\\t\\t\\t\\nunion\\nselect\\tempno,ename,\\tsal||\\t‘BELOW\\t1500’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t<\\t1500;\\t\\n(OR)\\nB)select\\tempno,ename,sal,job,\\ncase\\nwhen\\tsal\\t=\\t1500\\tthen\\t\\'ON\\tTARGET\\'\\nwhen\\tsal\\t<\\t1500\\tthen\\t\\'BELOW\\t1500\\'\\nwhen\\tsal\\t>\\t1500\\tthen\\t\\'JUST\\tSALARY\\'\\nelse\\t\\'nothing\\'\\nend\\t\\t\"REVISED\\tSALARY\"\\nfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 31, 'page_label': '32', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"132)\\t\\t\\tWrite\\ta\\tquery\\twhich\\treturn\\tthe\\tday\\tof\\tthe\\tweek\\tfor\\tany\\tdate\\tentered\\tin\\nformat\\t‘DD-MM-YY’.\\nA)\\tselect\\tto_char(to_date('&\\ts','dd-mm-yy'),'day')\\tfrom\\tdual\\t;\\n133)\\t\\t\\tWrite\\ta\\tquery\\tto\\tcalculate\\tthe\\tlength\\tof\\tservice\\tof\\tany\\temployee\\twith\\tthe\\ncompany,\\tuse\\tDEFINE\\tto\\tavoid\\trepetitive\\ttyping\\tof\\tfunctions.\\nA)\\t\\t\\t\\tDEFINE\\t\\tservice\\t=\\t((months_between(sysdate,hiredate))/12)\\nB)\\t\\t\\t\\tSelect\\t\\tempno,ename,&service\\tfrom\\temp\\twhere\\tename\\t=\\t‘&\\tname’;\\n134)\\t\\t\\tGive\\ta\\tstring\\tof\\tformat\\t‘NN/NN’,\\tverify\\tthat\\tthe\\tfirst\\tand\\tlast\\ttwo\\ncharacters\\tare\\tnumbers\\tand\\tthat\\tthe\\tmiddle\\tcharacter\\tis’/’.\\tPrint\\tthe\\texpression\\n‘YES’\\tif\\tvalid,\\t‘NO’\\tif\\tnot\\tvalid.\\tUse\\tthe\\tfollowing\\tvalues\\tto\\ttest\\tyour\\tsolution.\\n‘12/34’,’01/1a’,\\t‘99/98’.\\nA)\\n135)\\t\\t\\tEmps\\thired\\ton\\tor\\tbefore\\t15th\\tof\\tany\\tmonth\\tare\\tpaid\\ton\\tthe\\tlast\\tFriday\\tof\\nthat\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\\nA)\\tselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')-7\\tfrom\\temp\\nwhere\\tto_char(hiredate,'DD')\\t<=15\\nunion\\nselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')\\tfrom\\temp\\twhere\\nto_char(hiredate,'DD')\\t>\\t15;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 32, 'page_label': '33', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"136)\\t\\t\\tCount\\tthe\\tno.\\tof\\tcharacters\\twith\\tout\\tconsidering\\tspaces\\tfor\\teach\\tname.\\nA)\\t\\t\\t\\tselect\\tlength(replace(ename,’\\t‘,null))\\tfrom\\temp;\\n137)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tare\\tgetting\\tdecimal\\tvalue\\tin\\ttheir\\tSal\\twithout\\tusing\\nlike\\toperator.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tinstr(sal,’.’,1,1)\\t>\\t0;\\n138)\\t\\t\\tList\\tthose\\temps\\twhose\\tSalary\\tcontains\\tfirst\\tfour\\tdigit\\tof\\ttheir\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(sal,,9999),deptno,1,1)>0\\tand\\ninstr(to_char(sal,9999),deptno,1,2)>\\t0\\t;\\n139)\\t\\t\\tList\\tthose\\tManagers\\twho\\tare\\tgetting\\tless\\tthan\\this\\temps\\tSalary.\\nA)\\t\\t\\t\\tselect\\tdistinct\\tm.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\nand\\tw.sal>m.sal;\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tsal\\t\\t<\\tany\\t(\\tselect\\tsal\\tfrom\\temp\\twhere\\nw.empno=mgr);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tempno\\tin\\t\\t(\\tselect\\tmgr\\tfrom\\temp\\twhere\\t\\t\\t\\nw.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\\n141)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers\\tusing\\tco-related\\tsub-query.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n142)\\t\\t\\tList\\tthe\\temps\\twhose\\tMgr\\tname\\tis\\t‘Jones’\\tand\\talso\\twith\\this\\tManager\\nname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 33, 'page_label': '34', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\tw.ename,m.ename,(select\\tename\\tfrom\\temp\\twhere\\tm.mgr\\t=\\tempno)\\n\"his\\tMANAGER\"\\nfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t\\'JONES\\';\\t(or)\\nB)\\tselect\\te.ename,w.ename,m.ename\\tfrom\\temp\\te,emp\\tw,emp\\tm\\twhere\\te.mgr\\t=\\nw.empno\\tand\\tw.ename\\t=\\t‘JONES’\\tand\\tw.mgr\\t=\\tm.empno;\\n143)\\t\\t\\tDefine\\ta\\tvariable\\trepresenting\\tthe\\texpression\\tused\\tto\\tcalculate\\ton\\temps\\ntotal\\tannual\\tremuneration\\tuse\\tthe\\tvariable\\tin\\ta\\tstatement,\\twhich\\tfinds\\tall\\temps\\nwho\\tcan\\tearn\\t30000\\ta\\tyear\\tor\\tmore.\\nA)\\t\\t\\t\\tSet\\tdefine\\ton\\nB)\\t\\t\\t\\tDefine\\t\\tannual\\t=\\t12*nvl2(comm.,sal+comm.,sal)\\t\\t(here\\tdefine\\tvariable\\tis\\ta\\nsession\\tvariable)\\nC)\\t\\t\\t\\tSelect\\t*\\tfrom\\temp\\twhere\\t&annual\\t>\\t30000;\\n144)\\t\\t\\tFind\\tout\\thow\\tmay\\tManagers\\tare\\ttheir\\tin\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\t(or)\\nC)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.\\nRemember\\tSalesman\\tearn\\tcommission.secommm\\nA)\\tselect\\tavg(sal),avg(sal+nvl(comm,0))\\tfrom\\temp;\\n146)\\t\\t\\tCheck\\twhether\\tall\\tthe\\temps\\tnumbers\\tare\\tindeed\\tunique.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 34, 'page_label': '35', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t\\t\\tempno,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\tempno;\\n147)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tdrawing\\tless\\tthan\\t1000\\tSort\\tthe\\toutput\\tby\\tSalary.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\t<\\t1000\\torder\\tby\\tsal;\\n148)\\t\\t\\tList\\tthe\\temployee\\tName,\\tJob,\\tAnnual\\tSalary,\\tdeptno,\\tDept\\tname\\tand\\ngrade\\twho\\tearn\\t36000\\ta\\tyear\\tor\\twho\\tare\\tnot\\tCLERKS.\\nA)selecte.ename,e.job,(12*e.sal)\"ANNUALSALARY\",\\ne.deptno,d.dname,s.grade\\nfrom\\temp\\te,dept\\td\\t,salgrade\\ts\\twhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\nand\\t(((12*e.sal)>=\\t36000)\\tor\\t(e.job\\t!=\\t\\'CLERK\\'))\\n149)\\t\\t\\tFind\\tout\\tthe\\tJob\\tthat\\twas\\tfilled\\tin\\tthe\\tfirst\\thalf\\tof\\t1983\\tand\\tsame\\tjob\\tthat\\nwas\\tfilled\\tduring\\tthe\\tsame\\tperiod\\tof\\t1984.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\twhere\\t(to_char(hiredate,\\'MM\\t\\')\\t<=\\t06\\t\\tand\\nto_char(hiredate,\\'YYYY\\')\\t=\\t1984)\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\nto_char(hiredate,\\'MM\\'\\t)\\t<=\\t06\\tand\\tto_char(hiredate,\\'YYYY\\')\\t<=\\t1983)\\t;\\t\\n150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate<\\tm.hiredate;(or)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\t<\\t(select\\t\\thiredate\\tfrom\\temp\\twhere\\nempno\\t=\\te.mgr)\\n151)\\t\\t\\tList\\tall\\tthe\\temps\\tby\\tname\\tand\\tnumber\\talong\\twith\\ttheir\\tManager’s\\tname\\nand\\tnumber.\\tAlso\\tList\\tKING\\twho\\thas\\tno\\t‘Manager’.\\nA)\\tselect\\tw.empno,w.ename,m.empno,m.ename\\tfrom\\temp\\tw,emp\\tm\\twhere'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 35, 'page_label': '36', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='w.mgr=\\tm.empno(+);\\n152)\\t\\t\\tFind\\tall\\tthe\\temps\\twho\\tearn\\tthe\\tminimum\\tSalary\\tfor\\teach\\tjob\\twise\\tin\\nascending\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmin(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tasc;\\n153)\\t\\t\\tFind\\tout\\tall\\tthe\\temps\\twho\\tearn\\thighest\\tsalary\\tin\\teach\\tjob\\ttype.\\tSort\\tin\\ndescending\\tsalary\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tdesc;\\n154)\\t\\t\\tFind\\tout\\tthe\\tmost\\trecently\\thired\\temps\\tin\\teach\\tDept\\torder\\tby\\tHiredate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\te\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\te.deptno\\t=\\t\\tdeptno\\t)\\norder\\tby\\thiredate;\\n155)\\t\\t\\tList\\tthe\\temployee\\tname,Salary\\tand\\tDeptno\\tfor\\teach\\temployee\\twho\\tearns\\na\\tsalary\\tgreater\\tthan\\tthe\\taverage\\tfor\\ttheir\\tdepartment\\torder\\tby\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\tsal\\t>\\t\\t(select\\tavg(sal)\\tfrom\\temp\\twhere\\te.deptno\\t=\\tdeptno\\t);\\nB)\\t\\t\\t\\tselect\\te.ename,e.sal,e.deptno\\tfrom\\temp\\te,(select\\tavg(sal)\\tA,deptno\\tD\\tfrom\\t\\t\\nemp\\tgroup\\tby\\tdeptno)\\tD1\\twhere\\tD1.D\\t=\\te.deptno\\tand\\te.sal\\t>\\tD1.A;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 36, 'page_label': '37', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"156)\\t\\t\\tList\\tthe\\tDeptno\\twhere\\tthere\\tare\\tno\\temps.\\nA)\\t\\t\\t\\tselect\\t\\tdeptno\\t,count(*)\\tfrom\\temp\\ngroup\\tby\\tdeptno\\t\\nhaving\\tcount(*)\\t=\\t0;\\n157)\\t\\t\\tList\\tthe\\tNo.of\\temp’s\\tand\\tAvg\\tsalary\\twithin\\teach\\tdepartment\\tfor\\teach\\tjob.\\nA)\\t\\t\\t\\tselect\\tcount(*),avg(sal),deptno,job\\tfrom\\temp\\ngroup\\tby\\tdeptno,job;\\n158)\\t\\t\\tFind\\tthe\\tmaximum\\taverage\\tsalary\\tdrawn\\tfor\\teach\\tjob\\texcept\\tfor\\n‘President’.\\nA)\\tselect\\tmax(avg(sal))\\tfrom\\temp\\t\\twhere\\tjob\\t!=\\t'PRESIDENT'\\tgroup\\tby\\tjob;\\n159)\\t\\t\\tFind\\tthe\\tname\\tand\\tJob\\tof\\tthe\\temps\\twho\\tearn\\tMax\\tsalary\\tand\\tCommission.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=\\t(select\\tmax(sal)\\tfrom\\temp)\\tand\\tcomm.\\tis\\tnot\\nnull;\\n160)\\t\\t\\tList\\tthe\\tName,\\tJob\\tand\\tSalary\\tof\\tthe\\temps\\twho\\tare\\tnot\\tbelonging\\tto\\tthe\\ndepartment\\t10\\tbut\\twho\\thave\\tthe\\tsame\\tjob\\tand\\tSalary\\tas\\tthe\\temps\\tof\\tdept\\t10.\\nA)\\tselect\\tename,job,sal\\tfrom\\temp\\twhere\\tdeptno\\t!=\\t10\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=\\t10)\\nand\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10);\\n161)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\tSALESMAN\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 37, 'page_label': '38', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='who\\tare\\tearning\\tmaximum\\tsalary\\tand\\tcommission\\tin\\tdescending\\torder.\\nA)select\\t\\tdeptno,name,job,sal,sal+nvl(comm.,0)\\tfrom\\temp\\twhere\\tjob\\t=\\n‘SALESMAN’\\tand\\tsal\\tin\\t(select\\tmax(sal+nvl(comm.,0))\\tfrom\\temp\\twhere\\ncomm.\\tis\\tnot\\tnull)\\nOrder\\tby\\t(sal\\t+nvl(comm.,0))\\tdesc;\\n162)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\temps\\twho\\tearn\\nthe\\tsecond\\thighest\\tearnings\\t(sal\\t+\\tcomm.).\\nA)\\tselect\\tdeptno,ename,sal,job,sal+nvl(comm,0)\\tfrom\\temp\\te\\twhere\\t\\t2\\t=\\t(select\\ncount(distinct\\tsal+nvl(comm,0))\\tfrom\\temp\\twhere\\t(e.sal+nvl(comm.,0))\\n<(sal+nvl(comm.,0));\\n163)\\t\\t\\tList\\tthe\\tDeptno\\tand\\ttheir\\taverage\\tsalaries\\tfor\\tdept\\twith\\tthe\\taverage\\tsalary\\nless\\tthan\\tthe\\taverages\\tfor\\tall\\tdepartment\\nA)\\t\\t\\t\\tselect\\tdeptno,avg(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tavg(sal)\\t<(select\\tavg(Sal)\\tfrom\\temp);\\n164)\\t\\t\\tList\\tout\\tthe\\tNames\\tand\\tSalaries\\tof\\tthe\\temps\\talong\\twith\\ttheir\\tmanager\\nnames\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n165)\\t\\t\\tList\\tout\\tthe\\tName,\\tJob,\\tSalary\\tof\\tthe\\temps\\tin\\tthe\\tdepartment\\twith\\tthe\\nhighest\\taverage\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 38, 'page_label': '39', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='(select\\tdeptno\\tfrom\\temp\\te\\t\\nhaving\\tavg(sal)\\t=(select\\tmax(avg(sal))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t\\t\\ngroup\\tby\\tdeptno);\\n166)\\t\\t\\tList\\tthe\\tempno,sal,comm.\\tOf\\temps.\\nA)\\tselect\\tempno,sal,comm.\\tfrom\\temp;\\n167)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tsal.\\nA)\\tselect\\t*\\tfrom\\temp\\torder\\tby\\tsal\\tasc;\\n168)\\t\\t\\tList\\tthe\\tdept\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tjob\\tand\\tthe\\tdesc\\torder\\tof\\tthe\\nemps\\tprint\\tempno,\\tename.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t\\torder\\tby\\te.job\\tasc,e.empno\\tdesc\\t;\\n169)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\tof\\tthe\\temps.\\nA)select\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\t(select\\tunique\\tdeptno\\tfrom\\temp);\\n170)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\twith\\tjobs.\\nA)\\tselect\\tunique\\tdeptno\\t,job\\tfrom\\temp\\t;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 39, 'page_label': '40', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='171)\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tthe\\tblake.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’;\\n172)\\t\\t\\tList\\tall\\tthe\\tclerks.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n173)\\t\\t\\tlist\\tall\\tthe\\temployees\\tjoined\\ton\\t1st\\tmay\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t=\\t’01-MAY-81’;\\n174)\\t\\t\\tList\\tthe\\tempno,ename,sal,deptno\\tof\\tthe\\tdept\\t10\\temps\\tin\\tthe\\tascending\\norder\\tof\\tsalary.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,e.deptno\\tfrom\\temp\\twhere\\te.deptno\\t=\\t10\\norder\\tby\\te.sal\\tasc;\\n175)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalaries\\tare\\tless\\tthan\\t3500.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t<3500;\\n176)\\t\\t\\tList\\tthe\\tempno,ename,sal\\tof\\tall\\tthe\\temp\\tjoined\\tbefore\\t1\\tapr\\t81.\\nA)\\tselect\\te.empno\\t,e.ename\\t.e.sal\\tfrom\\temp\\twhere\\thiredate\\t<’01-APR-81’;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 40, 'page_label': '41', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='177)\\t\\t\\tList\\tthe\\temp\\twhose\\tannual\\tsal\\tis\\t<25000\\tin\\tthe\\tasc\\torder\\tof\\tthe\\tsalaries.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*sal)\\t<\\t25000\\torder\\tby\\tsal\\tasc;\\n178)\\t\\t\\tList\\tthe\\tempno,ename,annsal,dailysal\\t\\tof\\tall\\tthe\\tsalesmen\\tin\\tthe\\tasc\\tann\\nsal\\nA)\\tselect\\te.empno,e.ename\\t,12*sal\\t\"ANN\\tSAL\"\\t,\\t(12*sal)/365\\t\"DAILY\\tSAL\"\\nfrom\\temp\\te\\nwhere\\te.job\\t=\\t\\'SALESMAN\\'\\norder\\tby\\t\"ANN\\tSAL\"\\tasc\\t;\\n179)\\t\\t\\tList\\tthe\\tempno,ename,hiredate,current\\tdate\\t&\\texp\\tin\\tthe\\tascending\\torder\\nof\\tthe\\texp.\\nA)\\t\\t\\t\\tselect\\tempno,ename,hiredate,(select\\tsysdate\\tfrom\\tdual),\\n((months_between(sysdate,hiredate))/12)\\tEXP\\nfrom\\temp\\norder\\tby\\tEXP\\tasc;\\n180)\\t\\t\\tList\\tthe\\temps\\twhose\\texp\\tis\\tmore\\tthan\\t10\\tyears.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t((months_between(sysdate,hiredate))/12)\\t>\\t10;\\n181)\\t\\t\\tList\\tthe\\tempno,ename,sal,TA30%,DA\\t40%,HRA\\n50%,GROSS,LIC,PF,net,deduction,net\\tallow\\tand\\tnet\\tsal\\tin\\tthe\\tascending\\torder\\nof\\tthe\\tnet\\tsalary.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 41, 'page_label': '42', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='182)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\n183)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\tclerks\\tor\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(‘CLERK’,’MANAGER’);\\n184)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\ton\\tthe\\tfollowing\\tdates\\t1\\tmay\\t81,17\\tnov\\n81,30\\tdec\\t81\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’DD-MON-YY’)\\t\\tin\\n(’01-MAY-81’,’17-NOV-81’,’30-DEC-81’);\\n185)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’;\\n186)\\t\\t\\tList\\tthe\\temps\\twhose\\tannual\\tsal\\tranging\\tfrom\\t23000\\tto\\t40000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*\\tsal)\\tbetween\\t23000\\tand\\t40000;\\n187)\\t\\t\\tList\\tthe\\temps\\tworking\\tunder\\tthe\\tmgrs\\t7369,7890,7654,7900.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 42, 'page_label': '43', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin\\t(\\t7369,7890,7654,7900);\\n188)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tsecond\\thalf\\tof\\t82.\\nA)select\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-JUL-82’\\tand\\t’31-DEC-82’;\\n189)\\t\\t\\tList\\tall\\tthe\\t4char\\temps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(ename)\\t=\\t4;\\n190)\\t\\t\\tList\\tthe\\temp\\tnames\\tstarting\\twith\\t‘M’\\twith\\t5\\tchars.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n191)\\t\\t\\tList\\tthe\\temps\\tend\\twith\\t‘H’\\tall\\ttogether\\t5\\tchars.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%H’\\tand\\tlength\\t(ename)\\t=\\t5;\\n192)\\t\\t\\tList\\tnames\\tstart\\twith\\t‘M’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’;\\n193)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tyear\\t81.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 43, 'page_label': '44', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t=\\t‘81’;\\n194)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tending\\twith\\t00.\\nA)\\t\\tselect\\t*\\tfrom\\twhere\\t\\tsal\\t\\tlike\\t\\t‘%00’;\\n195)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tJAN.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MM’)\\t=\\t1;\\n196)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tchar\\t‘a’.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MONTH’)\\tlike’%A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MONTH’),’A’)\\t>0;\\n197)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tsecond\\tchar\\t‘a’\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\tlike\\t‘_A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MON’),’A’)\\t=\\t2;\\n198)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalary\\tis\\t4\\tdigit\\tnumber.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(sal)\\t=\\t4;(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tsal\\tbetween\\t999\\tand\\t9999;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 44, 'page_label': '45', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='199)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\t80’s.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t\\tbetween\\t‘80’\\tand\\t’89’;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t>=\\t‘80’\\tand\\nto_char(hiredate,’YY’)\\t<\\t‘90’;\\n200)\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tclerks\\twho\\thave\\texp\\tmore\\tthan\\t8ys.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tand\\n(months_between(sysdate,hiredate)\\t/12)\\t>\\t8;\\n201)\\t\\t\\tList\\tthe\\tmgrs\\tof\\tdept\\t10\\tor\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’\\tand\\t(deptno\\t=\\t10\\tor\\tdeptno\\n=20);\\n202)\\t\\t\\tList\\tthe\\temps\\tjoined\\tin\\tjan\\twith\\tsalary\\tranging\\tfrom\\t1500\\tto\\t4000.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’\\tand\\tsal\\nbetween\\t1500\\tand\\t4000;\\n203)\\t\\t\\tList\\tthe\\tunique\\tjobs\\tof\\tdept\\t20\\tand\\t30\\tin\\tdesc\\torder.\\nA)\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(20,30)\\torder\\tby\\tjob\\tdesc;\\n204)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\texp\\tof\\tthose\\tworking\\tunder\\tthe\\tmgr\\twhose\\nnumber\\tis\\tstarting\\twith\\t7\\tbut\\tshould\\tnot\\thave\\ta\\t9\\tjoined\\tbefore\\t1983.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 45, 'page_label': '46', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t(mgr\\tlike\\t'7%'\\tand\\tmgr\\tnot\\tlike\\t'%9%')\\nand\\tto_char(hiredate,'YY')\\t<\\t'83';\\n205)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\teither\\tmgr\\tor\\tanalyst\\twith\\tthe\\tsalary\\nranging\\tfrom\\t2000\\tto\\t5000\\tand\\twith\\tout\\tcomm.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\t(job\\t\\tin\\t(‘MANAGER’\\t,’ANALYST’)\\t)\\tand\\tsal\\nbetween\\t\\t2000\\tand\\t5000\\tand\\tcomm\\tis\\tnull;\\n206)\\t\\t\\tList\\tthe\\tempno,ename,sal,job\\tof\\tthe\\temps\\twith\\t/ann\\tsal\\t<34000\\tbut\\nreceiving\\tsome\\tcomm.\\tWhich\\tshould\\tnot\\tbe>sal\\tand\\tdesg\\tshould\\tbe\\tsales\\tman\\nworking\\tfor\\tdept\\t30.\\nA)\\tselect\\tempno,ename,sal,job\\tfrom\\temp\\twhere\\n12*(sal+nvl(comm,0))\\t<\\t34000\\tand\\tcomm\\tis\\tnot\\tnull\\tand\\tcomm<sal\\tand\\tjob\\t=\\n'SALESMAN'\\tand\\tdeptno\\t=\\t30;\\t\\t\\n207)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tfor\\tdept\\t10\\tor\\t20\\twith\\tdesgs\\tas\\tclerk\\tor\\nanalyst\\twith\\ta\\tsal\\tis\\teither\\t3\\tor\\t4\\tdigits\\twith\\tan\\texp>8ys\\tbut\\tdoes\\tnot\\tbelong\\tto\\nmons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\\n((months_between(sysdate,hiredate))/12)>\\t8\\tand\\nto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP','APR')\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 46, 'page_label': '47', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(mgr\\tnot\\tlike\\t'%88'\\tand\\tmgr\\tnot\\tlike\\t'%56');\\n208)\\t\\t\\tList\\tthe\\tempno,ename,sal,job,deptno&exp\\tof\\tall\\tthe\\temps\\tbelongs\\tto\\tdept\\n10\\tor\\t20\\twith\\tan\\texp\\t6\\tto\\t10\\ty\\tworking\\tunder\\tthe\\tsame\\tmgr\\twith\\tout\\tcomm.\\nWith\\ta\\tjob\\tnot\\tending\\tirrespective\\tof\\tthe\\tposition\\twith\\tcomm.>200\\twith\\nexp>=7y\\tand\\tsal<2500\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tsep\\tor\\tnov\\tworking\\tunder\\nthe\\tmgr\\twhose\\tno\\tis\\tnot\\thaving\\tdigits\\teither\\t9\\tor\\t0\\tin\\tthe\\tasc\\tdept&\\tdesc\\tdept\\nA)\\n209)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tworking\\tat\\tChicago.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\n‘CHICAGO’);\\n210)\\t\\t\\tList\\tthe\\tempno,ename,deptno,loc\\tof\\tall\\tthe\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t;\\n211)\\t\\t\\tList\\tthe\\tempno,ename,loc,dname\\tof\\tall\\tthe\\tdepts.,10\\tand\\t20.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc,d.dname\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\\nwith\\tan\\texp>6ys.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\tand\\td.loc\\tin\\t('CHICAGO','DALLAS')\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 47, 'page_label': '48', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t(months_between(sysdate,hiredate)/12)>\\t6\\t;\\n213)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\tloc\\tof\\tthose\\twho\\tbelongs\\tto\\tdallas\\t,newyork\\twith\\nsal\\tranging\\tfrom\\t2000\\tto\\t5000\\tjoined\\tin\\t81.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.loc\\tin\\t('NEW\\tYORK','DALLAS')\\nand\\tto_char(e.hiredate,'YY')\\t=\\t'81'\\t\\tand\\t\\te.sal\\tbetween\\t2000\\tand\\t5000;\\n214)\\t\\t\\tList\\tthe\\tempno,ename,sal,grade\\tof\\tall\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,s.grade\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\nwhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\t;\\n215)\\t\\t\\tList\\tthe\\tgrade\\t2\\tand\\t3\\temp\\tof\\tChicago.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ns.hisal\\t\\tand\\ts.grade\\tin\\t(2,3));\\n216)\\t\\t\\tList\\tthe\\temps\\twith\\tloc\\tand\\tgrade\\tof\\taccounting\\tdept\\tor\\tthe\\tlocs\\tdallas\\tor\\nChicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\\nwheree.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\ts.grade\\tin\\t(3,5)\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 48, 'page_label': '49', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t((months_between(sysdate,hiredate))/12)\\t>\\t6\\nand\\t(\\td.dname\\t=\\t'ACCOUNTING'\\tor\\tD.loc\\tin\\t('DALLAS','CHICAGO'))\\n217)\\t\\t\\tList\\tthe\\tgrades\\t3\\temps\\tof\\tresearch\\tand\\toperations\\tdepts..\\tjoined\\tafter\\t1987\\nand\\twhose\\tnames\\tshould\\tnot\\tbe\\teither\\tmiller\\tor\\tallen.\\nA)\\t\\t\\t\\tselect\\te.ename\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.dname\\tin\\t('OPERATIONS','RESEARCH')\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\te.ename\\tnot\\tin\\t('MILLER','ALLEN')\\nand\\tto_char(hiredate,'YYYY')\\t>1987;\\n218)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\tsmith.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n'SMITH');\\n219)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tmiller.\\nA)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\t\\twhere\\t\\thiredate\\t<(select\\thiredate\\tfrom\\temp\\twhere\\nename\\t=\\t‘MILLER’);\\n220)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\teither\\tallen\\tor\\tsal>allen.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN')\\nor\\tsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 49, 'page_label': '50', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"221)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tmanager.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate\\t<\\tm.hiredate;\\n222)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tgreater\\tthan\\tblakes\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’);\\n223)\\t\\t\\tList\\tthe\\tdept\\t10\\temps\\twhose\\tsal>allen\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\tand\\nsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\\n224)\\t\\t\\tList\\tthe\\tmgrs\\twho\\tare\\tsenior\\tto\\tking\\tand\\twho\\tare\\tjunior\\tto\\tsmith.\\nA)select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tmgr\\tfrom\\temp\\nwhere\\thiredate<(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'\\t)\\nand\\thiredate\\t>\\t(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t\\t'SMITH'))\\tand\\tmgr\\nis\\t\\t\\t\\t\\t\\t\\t\\nnot\\tnull;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 50, 'page_label': '51', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"225)\\t\\t\\tList\\tthe\\tempno,ename,loc,sal,dname,loc\\tof\\tthe\\tall\\tthe\\temps\\tbelonging\\tto\\nking\\tdept.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,d.loc,e.sal,d.dname\\tfrom\\temp\\te,dept\\td\\nwhere\\te.deptno=d.deptno\\tand\\te.deptno\\tin\\n(select\\tdeptno\\tfrom\\t\\temp\\twhere\\tename\\t=\\t'KING'and\\temp.empno\\t<>\\te.empno);\\n226)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalgrade\\tare\\tgreater\\tthan\\tthe\\tgrade\\tof\\tmiller.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t>\\n(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.ename\\t=\\t'MILLER')\\t;\\n227)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tbelonging\\tdallas\\tor\\tChicago\\twith\\tthe\\tgrade\\tsame\\tas\\nadamsor\\texp\\tmore\\tthan\\tsmith.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno=\\td.deptno\\tand\\td.loc\\tin\\t('DALLAS','CHICAGO')\\tand\\te.sal\\nbetween\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\\nmonths_between(sysdate,hiredate)\\tfrom\\temp\\twhere\\tename\\t=\\t'SMITH'))\\t;\\n228)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tford\\tor\\tblake.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\te\\twhere\\te.ename\\tin\\n('FORD','BLAKE')and\\temp.empno\\t<>\\te.empno);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 51, 'page_label': '52', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"229)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tany\\tone\\tof\\tthe\\tfollowing.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t\\tin\\t\\n(select\\tsal\\tfrom\\temp\\te\\twhere\\temp.empno\\t<>\\te.empno);\\n230)\\t\\t\\tSal\\tof\\tany\\tclerk\\tof\\temp1\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n231)\\t\\t\\tAny\\temp\\tof\\temp2\\tjoined\\tbefore\\t82.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t<\\t1982;\\n232)\\t\\t\\tThe\\ttotal\\tremuneration\\t(sal+comm.)\\tof\\tall\\tsales\\tperson\\tof\\tSales\\tdept\\nbelonging\\tto\\temp3\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\t(sal+nvl(comm,0))\\tin\\n(select\\tsal+nvl(comm,0)\\t\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno=d.deptno\\t\\nand\\td.dname\\t=\\t'SALES'and\\te.job\\t=\\t'SALESMAN');\\n233)\\t\\t\\tAny\\tGrade\\t4\\temps\\tSal\\tof\\temp\\t4\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp4\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t4;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 52, 'page_label': '53', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='234)\\t\\t\\tAny\\temp\\tSal\\tof\\temp5\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp5;\\n235)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp);\\n236)\\t\\t\\tList\\tthe\\tdetails\\tof\\tmost\\trecently\\thired\\temp\\tof\\tdept\\t30.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tdeptno\\t=\\t30);\\n237)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tof\\tChicago\\tjoined\\tbefore\\tthe\\tmost\\t\\trecently\\nhired\\temp\\tof\\tgrade\\t2.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal\\t=\\t(\\tselect\\tmax(sal)\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\t\\nd.deptno\\tand\\td.loc\\t=\\t‘CHICAGO’\\tand\\nhiredate\\t<(select\\tmax(hiredate)\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\t\\t\\t\\t\\t\\t\\t\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t2))\\n238)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tworking\\tunder\\tking.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\twhere\\tmgr\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 53, 'page_label': '54', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\")]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bf0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4f52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 220 documents into 335 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Practical Python and\n",
      "OpenCV: An Introductory,\n",
      "Example Driven Guide to\n",
      "Image Processing and\n",
      "Computer Vision\n",
      "4th Edition\n",
      "Dr. Adrian Rosebrock...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 1, 'page_label': 'i', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 1, 'page_label': 'i', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 2, 'page_label': 'ii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 3, 'page_label': 'iii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N T E N T S\\n1 introduction 1\\n2 python and required packages 5\\n2.1 A note on Python & OpenCV Versions . . . . 6\\n2.2 NumPy and SciPy . . . . . . . . . . . . . . . . 7\\n2.2.1 Windows . . . . . . . . . . . . . . . . . 7\\n2.2.2 OSX . . . . . . . . . . . . . . . . . . . 7\\n2.2.3 Linux . . . . . . . . . . . . . . . . . . . 8\\n2.3 Matplotlib . . . . . . . . . . . . . . . . . . . . 8\\n2.3.1 All Platforms . . . . . . . . . . . . . . 8\\n2.4 OpenCV . . . . . . . . . . . . . . . . . . . . . . 9\\n2.4.1 Linux and OSX . . . . . . . . . . . . . 9\\n2.4.2 Windows . . . . . . . . . . . . . . . . . 10\\n2.5 Mahotas . . . . . . . . . . . . . . . . . . . . . . 10\\n2.5.1 All Platforms . . . . . . . . . . . . . . 10\\n2.6 scikit-learn . . . . . . . . . . . . . . . . . . . . 11\\n2.6.1 All Platforms . . . . . . . . . . . . . . 11\\n2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 3, 'page_label': 'iii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19\\n4.1 So, What’s a Pixel? . . . . . . . . . . . . . . . 19\\n4.2 Overview of the Coordinate System . . . . . 22\\n4.3 Accessing and Manipulating Pixels . . . . . . 22\\n5 drawing 31\\n5.1 Lines and Rectangles . . . . . . . . . . . . . . 31\\n5.2 Circles . . . . . . . . . . . . . . . . . . . . . . 36\\n6 image processing 42\\n6.1 Image Transformations . . . . . . . . . . . . . 42\\niii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 4, 'page_label': 'iv', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\n6.1.1 Translation . . . . . . . . . . . . . . . . 43\\n6.1.2 Rotation . . . . . . . . . . . . . . . . . 48\\n6.1.3 Resizing . . . . . . . . . . . . . . . . . 53\\n6.1.4 Flipping . . . . . . . . . . . . . . . . . 59\\n6.1.5 Cropping . . . . . . . . . . . . . . . . 62\\n6.2 Image Arithmetic . . . . . . . . . . . . . . . . 64\\n6.3 Bitwise Operations . . . . . . . . . . . . . . . 71\\n6.4 Masking . . . . . . . . . . . . . . . . . . . . . 74\\n6.5 Splitting and Merging Channels . . . . . . . . 81\\n6.6 Color Spaces . . . . . . . . . . . . . . . . . . . 85\\n7 histograms 89\\n7.1 Using OpenCV to Compute Histograms . . . 90\\n7.2 Grayscale Histograms . . . . . . . . . . . . . . 91\\n7.3 Color Histograms . . . . . . . . . . . . . . . . 93\\n7.4 Histogram Equalization . . . . . . . . . . . . . 99\\n7.5 Histograms and Masks . . . . . . . . . . . . . 101\\n8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 4, 'page_label': 'iv', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112\\n8.3 Median . . . . . . . . . . . . . . . . . . . . . . 113\\n8.4 Bilateral . . . . . . . . . . . . . . . . . . . . . . 116\\n9 thresholding 119\\n9.1 Simple Thresholding . . . . . . . . . . . . . . 119\\n9.2 Adaptive Thresholding . . . . . . . . . . . . . 123\\n9.3 Otsu and Riddler-Calvard . . . . . . . . . . . 127\\n10 gradients and edge detection 132\\n10.1 Laplacian and Sobel . . . . . . . . . . . . . . . 133\\n10.2 Canny Edge Detector . . . . . . . . . . . . . . 138\\n11 contours 142\\n11.1 Counting Coins . . . . . . . . . . . . . . . . . 142\\n11.2 Contours and OpenCV Version Caveats . . . 149\\n12 where to now ? 153\\niv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 5, 'page_label': 'v', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O M PA N I O N W E B S I T E & S U P P L E M E N TA R Y\\nM AT E R I A L\\nThank you for picking up a copy of the 4th edition of\\nPractical Python and OpenCV!\\nIn this latest edition, I’m excited to announce the creation\\nof a companion website which includes supplementary mate-\\nrial that I could not ﬁt inside the book.\\nAt the end of nearly every chapter inside Practical Python\\nand OpenCV + Case Studies, you’ll ﬁnd a link to a supplemen-\\ntary webpage that includes additional information, such as\\nmy commentary on methods to extend your knowledge,\\ndiscussions of common error messages, recommendations\\non various algorithms to try, and optional quizzes to test\\nyour knowledge.\\nRegistration to the companion website is free with your\\npurchase of Practical Python and OpenCV.\\nTo create your companion website account, just use this\\nlink:\\nhttp://pyimg.co/o1y7e\\nTake a second to create your account now so you’ll have\\naccess to the supplementary materials as you work through\\nthe book.\\nv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 6, 'page_label': 'vi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E FA C E\\nWhen I ﬁrst set out to write this book, I wanted it to be\\nas hands-on as possible. I wanted lots of visual examples\\nwith lots of code. I wanted to write something that you\\ncould easily learn from, without all the rigor and detail of\\nmathematics associated with college level computer vision\\nand image processing courses.\\nI know from all my years spent in the classroom that the\\nway I learned best was from simply opening up an editor\\nand writing some code. Sure, the theory and examples in\\nmy textbooks gave me a solid starting point. But I never\\nreally “learned” something until I did it myself. I was very\\nhands-on. And that’s exactly how I wanted this book to be.\\nVery hands-on, with all the code easily modiﬁable and well\\ndocumented so you could play with it on your own. That’s\\nwhy I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 6, 'page_label': 'vi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='why I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst\\nstarted learning computer vision – it was a daunting task.\\nBut I learned a lot. And I had a lot of fun.\\nI hope this book helps you in your journey into computer\\nvision. I had a blast writing it. If you have any questions,\\nsuggestions, or comments, or if you simply want to say\\nhello, shoot me an email at adrian@pyimagesearch.com, or\\nvi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 7, 'page_label': 'vii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\nyou can visit my website at www.PyImageSearch.com and\\nleave a comment. I look forward to hearing from you soon!\\n-Adrian Rosebrock\\nvii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 8, 'page_label': 'viii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E R E Q U I S I T E S\\nIn order to make the most of this, you will need to have\\na little bit of programming experience. All examples in this\\nbook are in the Python programming language. Familiarity\\nwith Python or other scripting languages is suggested, but\\nnot required.\\nYou’ll also need to know some basic mathematics. This\\nbook is hands-on and example driven: lots of examples and\\nlots of code, so even if your math skills are not up to par,\\ndo not worry! The examples are very detailed and heavily\\ndocumented to help you follow along.\\nviii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 9, 'page_label': 'ix', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N V E N T I O N S U S E D I N T H I S B O O K\\nThis book includes many code listings and terms to aid\\nyou in your journey to learn computer vision and image\\nprocessing. Below are the typographical conventions used\\nin this book:\\nItalic\\nIndicates key terms and important information that\\nyou should take note of. May also denote mathemati-\\ncal equations or formulas based on connotation.\\nBold\\nImportant information that you should take note of.\\nConstant width\\nUsed for source code listings, as well as paragraphs\\nthat make reference to the source code, such as func-\\ntion and method names.\\nix'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 10, 'page_label': 'x', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='U S I N G T H E C O D E E X A M P L E S\\nThis book is meant to be a hands-on approach to com-\\nputer vision and machine learning. The code included in\\nthis book, along with the source code distributed with this\\nbook, are free for you to modify, explore, and share as you\\nwish.\\nIn general, you do not need to contact me for permis-\\nsion if you are using the source code in this book. Writing\\na script that uses chunks of code from this book is totally\\nand completely okay with me.\\nHowever, selling or distributing the code listings in this\\nbook, whether as information product or in your product’s\\ndocumentation, does require my permission.\\nIf you have any questions regarding the fair use of the\\ncode examples in this book, please feel free to shoot me an\\nemail. You can reach me at adrian@pyimagesearch.com.\\nx'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 11, 'page_label': 'xi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='H O W T O C O N TA C T M E\\nWant to ﬁnd me online? Look no further:\\nWebsite: www.PyImageSearch.com\\nEmail: adrian@pyimagesearch.com\\nTwitter: @PyImageSearch\\nGoogle+: +AdrianRosebrock\\nLinkedIn: Adrian Rosebrock\\nxi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 12, 'page_label': '1', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='1\\nI N T R O D U C T I O N\\nThe goal of computer vision is to understand the story\\nunfolding in a picture. As humans, this is quite simple. But\\nfor computers, the task is extremely difﬁcult.\\nSo why bother learning computer vision?\\nWell, images are everywhere!\\nWhether it be personal photo albums on your smartphone,\\npublic photos on Facebook, or videos on YouTube, we now\\nhave more images than ever – and we need methods to an-\\nalyze, categorize, and quantify the contents of these images.\\nFor example, have you recently tagged a photo of your-\\nself or a friend on Facebook lately? How does Facebook\\nseem to “know” where the faces are in an image?\\nFacebook has implemented facial recognition algorithms\\ninto their website, meaning that they cannot only ﬁnd faces\\nin an image, they can also identify whose face it is as well!\\nFacial recognition is an application of computer vision in\\nthe real world.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 13, 'page_label': '2', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nWhat other types of useful applications of computer vi-\\nsion are there?\\nWell, we could build representations of our 3D world us-\\ning public image repositories like Flickr. We could down-\\nload thousands and thousands of pictures of Manhattan,\\ntaken by citizens with their smartphones and cameras, and\\nthen analyze them and organize them to construct a 3D rep-\\nresentation of the city. We would then virtually navigate\\nthis city through our computers. Sound cool?\\nAnother popular application of computer vision is surveil-\\nlance.\\nWhile surveillance tends to have a negative connotation\\nof sorts, there are many different types. One type of surveil-\\nlance is related to analyzing security videos, looking for\\npossible suspects after a robbery.\\nBut a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 13, 'page_label': '2', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='But a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.\\nOn your last visit to your favorite clothing retailer, did\\nyou stop to examine the spring’s latest jeans trends? How\\nlong did you look at the jeans? What was your facial expres-\\nsion as you looked at the jeans? Did you then pick up a pair\\nand head to the dressing room? These are all types of ques-\\ntions that computer vision surveillance systems can answer.\\nComputer vision can also be applied to the medical ﬁeld.\\nA year ago, I consulted with the National Cancer Institute\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 14, 'page_label': '3', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nto develop methods to automatically analyze breast histol-\\nogy images for cancer risk factors. Normally, a task like\\nthis would require a trained pathologist with years of expe-\\nrience – and it would be extremely time consuming!\\nOur research demonstrated that computer vision algo-\\nrithms could be applied to these images and could auto-\\nmatically analyze and quantify cellular structures – without\\nhuman intervention! Now, we can analyze breast histology\\nimages for cancer risk factors much faster.\\nOf course, computer vision can also be applied to other\\nareas of the medical ﬁeld. Analyzing X-rays, MRI scans,\\nand cellular structures all can be performed using computer\\nvision algorithms.\\nPerhaps the biggest success computer vision success story\\nyou may have heard of is the X-Box 360 Kinect. The Kinect\\ncan use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 14, 'page_label': '3', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='can use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.\\nThe list doesn’t stop there.\\nComputer vision is now prevalent in many areas of your\\nlife, whether you realize it or not. We apply computer vi-\\nsion algorithms to analyze movies, football games, hand\\ngesture recognition (for sign language), license plates (just\\nin case you were driving too fast), medicine, surgery, mili-\\ntary, and retail.\\nWe even use computer visions in space! NASA’s Mars\\nRover includes capabilities to model the terrain of the planet,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 15, 'page_label': '4', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\ndetect obstacles in its path, and stitch together panoramic\\nimages.\\nThis list will continue to grow in the coming years.\\nCertainly, computer vision is an exciting ﬁeld with end-\\nless possibilities.\\nWith this in mind, ask yourself: what does your imagina-\\ntion want to build? Let it run wild. And let the computer\\nvision techniques introduced in this book help you build it.\\nFurther Reading\\nWelcome to the supplementary material portion of the\\nchapter! If you haven’t already registered and created\\nyour account for the companion website, please do so\\nusing the following link:\\nhttp://pyimg.co/o1y7e\\nFrom there, you can ﬁnd the Chapter 1 supplemen-\\ntary material page here:\\nhttp://pyimg.co/rhsgi\\nThis page serves as an introduction to the companion\\nwebsite and details how to use it and what to expect\\nas you work through the rest of Practical Python and\\nOpenCV.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 16, 'page_label': '5', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2\\nP Y T H O N A N D R E Q U I R E D PA C K A G E S\\nIn order to explore the world of computer vision, we’ll\\nﬁrst need to install some packages and libraries. As a ﬁrst-\\ntimer in computer vision, installing some of these packages\\n(especially OpenCV) can be quite tedious, depending on\\nwhat operating system you are using. I’ve tried to consoli-\\ndate the installation instructions into a short how-to guide,\\nbut as you know, projects change, websites change, and in-\\nstallation instructions change! If you run into problems, be\\nsure to consult the package’s website for the most up-to-\\ndate installation instructions.\\nI highly recommend that you use either easy_install or\\npip to manage the installation of your packages. It will\\nmake your life much easier! You can read more about pip\\nhere: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 16, 'page_label': '5', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='here: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image\\nprocessing packages you need to run the examples in this\\nbook pre-installed! Using this virtual machine allows you\\nto jump right in to the examples in this book, without hav-\\ning to worry about package managers, installation instruc-\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 17, 'page_label': '6', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1 a note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 17, 'page_label': '6', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Inside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the\\nPython 2.7 and the Python 3+ environments!\\nIf you are looking for the OpenCV 2.4.X and Python 2.7\\nversion of this book, please look in the download directory\\nassociated with your purchase – inside you will ﬁnd the\\nOpenCV 2.4.X + Python 2.7 edition.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 18, 'page_label': '7', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.2 numpy and scipy\\n2.2 numpy and scipy\\nNumPy is a library for the Python programming language\\nthat (among other things) provides support for large, multi-\\ndimensional arrays. Why is that important? Using NumPy,\\nwe can express images as multi-dimensional arrays. Repre-\\nsenting images as NumPy arrays is not only computation-\\nally and resource efﬁcient, many other image processing\\nand machine learning libraries use NumPy array represen-\\ntations as well. Furthermore, by using NumPy’s built-in\\nhigh-level mathematical functions, we can quickly and eas-\\nily perform numerical analysis on an image.\\nGoing hand-in-hand with NumPy, we also have SciPy.\\nSciPy adds further support for scientiﬁc and technical com-\\nputing.\\n2.2.1 Windows\\nBy far, the easiest way to install NumPy and SciPy on your\\nWindows system is to download and install the binary dis-\\ntribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 18, 'page_label': '7', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='tribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.\\nYou can also install NumPy and SciPy using pip:\\nListing 2.1: Install NumPy and SciPy on OSX\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 19, 'page_label': '8', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.3 matplotlib\\n$ pip install numpy\\n$ pip install scipy\\n2.2.3 Linux\\nOn many Linux distributions, such as Ubuntu, NumPy comes\\npre-installed and conﬁgured.\\nIf you want the latest versions of NumPy and SciPy, you\\ncan build the libraries from source, but the easiest method\\nis to use a pip:\\nListing 2.2: Install NumPy and SciPy on Linux\\n$ pip install numpy\\n$ pip install scipy\\n2.3 matplotlib\\nSimply put, matplotlib is a plotting library. If you’ve ever\\nused MATLAB before, you’ll probably feel very comfort-\\nable in the matplotlib environment. When analyzing im-\\nages, we’ll make use of matplotlib. Whether plotting image\\nhistograms or simply viewing the image itself, matplotlib\\nis a great tool to have in your toolbox.\\n2.3.1 All Platforms\\nMatplotlib is available from http://matplotlib.org/. The\\nmatplotlib package is also pip-installable:\\nListing 2.3: Install matplotlib\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 20, 'page_label': '9', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4 opencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 20, 'page_label': '9', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='website at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in\\nprevious years, but has luckily gotten much easier. I have\\naccumulated OpenCV installation instructions on the PyIm-\\nageSearch blog for Debian-based Linux distributions (such\\nas Ubuntu) and OSX here:\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 21, 'page_label': '10', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.5 mahotas\\nhttp://pyimg.co/vvlpy\\nJust scroll down the “Install OpenCV 3 and Python” and\\n“Install OpenCV 4 and Python” sections, select the oper-\\nating system and Python version that you want to install\\nOpenCV for, and you’ll be on your way!\\n2.4.2 Windows\\nThe OpenCV Docs provide fantastic tutorials on how to in-\\nstall OpenCV in Windows using binary distributions. You\\ncan check out the installation instructions here:\\nhttp://pyimg.co/l2q6s\\n2.5 mahotas\\nMahotas, just like OpenCV , relies on NumPy arrays. Much\\nof the functionality implemented in Mahotas can be found\\nin OpenCV , but in some cases, the Mahotas interface is just\\neasier to use. We’ll use Mahotas to complement OpenCV .\\n2.5.1 All Platforms\\nInstalling Mahotas is extremely easy on all platforms. As-\\nsuming you already have NumPy and SciPy installed, all\\nyou need is a single call to the pip command:\\nListing 2.4: Install Mahotas\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 22, 'page_label': '11', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.6 scikit -learn\\n$ pip install mahotas\\n2.6 scikit -learn\\nAlright, you got me, scikit-learn isn’t an image processing\\nor computer vision library – it’s a machine learning library.\\nThat said, you can’t have advanced computer vision tech-\\nniques without some sort of machine learning, whether it\\nbe clustering, vector quantization, classiﬁcation models, etc.\\nScikit-learn also includes a handful of image feature extrac-\\ntion functions as well. We don’t use the scikit-learn library\\nin Practical Python and OpenCV, but it’s heavily used inCase\\nStudies.\\n2.6.1 All Platforms\\nInstalling scikit-learn on all platforms is dead-simple using\\npip:\\nListing 2.5: Install scikit-learn\\n$ pip install scikit-learn\\n2.7 scikit -image\\nThe algorithms included in scikit-image (I would argue) fol-\\nlow closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 22, 'page_label': '11', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='low closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-\\nrithms, you need to have developed some rigor and under-\\nstanding in the computer vision ﬁeld. If you already have\\nsome experience in computer vision and image processing,\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 23, 'page_label': '12', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\ndeﬁnitely check out scikit-image; otherwise, I would con-\\ntinue working with OpenCV to start. Again, scikit-image\\nwon’t be used in of Practical Python and OpenCV, but it will\\nbe used in Case Studies, especially when we perform hand-\\nwritten digit recognition.\\nAssuming you already have NumPy and SciPy installed,\\nyou can install scikit-image using pip:\\nListing 2.6: Install scikit-image\\n$ pip install -U scikit-image\\nNow that we have all our packages installed, let’s start\\nexploring the world of computer vision!\\n2.8 skip the installation\\nAs I’ve mentioned above, installing all these packages can\\nbe time consuming and tedious. If you want to skip the\\ninstallation process and jump right into the world of im-\\nage processing and computer vision, I have set up a pre-\\nconﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 23, 'page_label': '12', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='conﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 24, 'page_label': '13', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\nFurther Reading\\nTo learn more about installing OpenCV , Python virtual\\nenvironments, and choosing a code editor, please see\\nthe Chapter 2 supplementary material webpage:\\nhttp://pyimg.co/f0sxq\\nIn particular, I think you’ll be interested in learning\\nhow the PyCharm IDE can be utilized with Python vir-\\ntual environments to create the perfect computer vision\\ndevelopment environment.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 25, 'page_label': '14', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='3\\nL O A D I N G , D I S P L AY I N G , A N D S AV I N G\\nThis book is meant to be a hands-on, how-to guide to get-\\nting started with computer vision using Python and OpenCV .\\nWith that said, let’s not waste any time. We’ll get our feet\\nwet by writing some simple code to load an image off disk,\\ndisplay it on our screen, and write it to ﬁle in a different\\nformat. When executed, our Python script should show\\nour image on screen, like in Figure 3.1.\\nFirst, let’s create a ﬁle named load_display_save.py to\\ncontain our code. Now we can start writing some code:\\nListing 3.1: load_display_save.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\nThe ﬁrst thing we are going to do is import the packages\\nwe will need for this example.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 26, 'page_label': '15', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nFigure 3.1: Example of loading and displaying\\na Tyrannosaurus Rex image on our\\nscreen.\\nThroughout this book you’ll see us importing the print_\\nfunction from the __future__ package. We’ll be using the\\nactual print() function rather than the print statement so\\nthat our code will work with both Python 2.7 and Python\\n3 – just something to keep in mind as we work through the\\nexamples!\\nWe’ll useargparse to handle parsing our command line\\narguments. Then, cv2 is imported – cv2 is our OpenCV li-\\nbrary and contains our image processing functions.\\nFrom there, Lines 5-8 handle parsing the command line\\narguments. The only argument we need is --image: the\\npath to our image on disk. Finally, we parse the arguments\\nand store them in a dictionary.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 27, 'page_label': '16', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nListing 3.2: load_display_save.py\\n9 image = cv2.imread(args[\"image\"])\\n10 print(\"width: {} pixels\".format(image.shape[1]))\\n11 print(\"height: {} pixels\".format(image.shape[0]))\\n12 print(\"channels: {}\".format(image.shape[2]))\\n13\\n14 cv2.imshow(\"Image\", image)\\n15 cv2.waitKey(0)\\nNow that we have the path to the image, we can load it\\noff the disk using the cv2.imread function on Line 9. The\\ncv2.imread function returns a NumPy array representing\\nthe image.\\nLines 10-12 examine the dimensions of the image. Again,\\nsince images are represented as NumPy arrays, we can sim-\\nply use the shape attribute to examine the width, height,\\nand the number of channels.\\nFinally, Lines 14 and 15 handle displaying the actual\\nimage on our screen. The ﬁrst parameter is a string, the\\n“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 27, 'page_label': '16', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until\\nwe press a key on our keyboard. Using a parameter of 0\\nindicates that any keypress will un-pause the execution.\\nThe last thing we are going to do is write our image to\\nﬁle in JPG format:\\nListing 3.3: load_display_save.py\\n16 cv2.imwrite(\"newimage.jpg\", image)\\nAll we are doing here is providing the path to the ﬁle\\n(the ﬁrst argument) and then the image we want to save\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 28, 'page_label': '17', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\n(the second argument). It’s that simple.\\nTo run our script and display our image, we simply open\\nup a terminal window and execute the following command:\\nListing 3.4: load_display_save.py\\n$ python load_display_save.py --image ../images/trex.png\\nIf everything has worked correctly, you should see the T-\\nRex on your screen as in Figure 3.1. To stop the script from\\nexecuting, simply click on the image window and press any\\nkey.\\nExamining the output of the script, you should also see\\nsome basic information on our image. You’ll note that the\\nimage has a width of 350 pixels, a height of 228 pixels, and 3\\nchannels (the RGB components of the image). Represented\\nas a NumPy array, our image has a shape of (228,350,3).\\nThe NumPy shape may seem reversed to you (specifying\\nthe height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 28, 'page_label': '17', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).\\nHere, our image has a height of 228 pixels (the number of\\nrows) and a width of 350 pixels (the number of columns) –\\nthus, the NumPy shape makes sense (although it may seen\\na bit confusing at ﬁrst).\\nFinally, note the contents of your directory. You’ll see a\\nnew ﬁle there: newimage.jpg. OpenCV has automatically\\nconverted our PNG image to JPG for us! No further effort\\nis needed on our part to convert between image formats.\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 29, 'page_label': '18', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nNext up, we’ll explore how to access and manipulate the\\npixel values in an image.\\nFurther Reading\\nYou can ﬁnd the Chapter 3 supplementary material, re-\\nsources, and quizzes here:\\nhttp://pyimg.co/xh73h\\nSpeciﬁcally, I discuss some common “gotchas” that may\\ntrip you up when utilizing OpenCV for the ﬁrst time –\\nthese tips and tricks are especially useful if this is your\\nﬁrst exposure to OpenCV .\\nBe sure to take the quiz to test your knowledge after\\nreading this chapter!\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 30, 'page_label': '19', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4\\nI M A G E B A S I C S\\nIn this chapter we are going to review the building blocks\\nof an image – the pixel. We’ll discuss exactly what a pixel\\nis, how pixels are used to form an image, and then how to\\naccess and manipulate pixels in OpenCV .\\n4.1 so , what ’s a pixel?\\nEvery image consists of a set of pixels. Pixels are the raw\\nbuilding blocks of an image. There is no ﬁner granularity\\nthan the pixel.\\nNormally, we think of a pixel as the “color” or the “inten-\\nsity” of light that appears in a given place in our image.\\nIf we think of an image as a grid, each square in the grid\\ncontains a single pixel.\\nFor example, let’s pretend we have an image with a res-\\nolution of 500 × 300. This means that our image is repre-\\nsented as a grid of pixels, with 500 rows and 300 columns.\\nOverall, there are 500 × 300 = 150, 000 pixels in our image.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 31, 'page_label': '20', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nMost pixels are represented in two ways: grayscale and\\ncolor. In a grayscale image, each pixel has a value between\\n0 and 255, where zero corresponds to “black” and 255 cor-\\nresponds to “white”. The values in between 0 and 255 are\\nvarying shades of gray, where values closer to 0 are darker\\nand values closer to 255 are lighter.\\nColor pixels are normally represented in the RGB color\\nspace – one value for the Red component, one for Green,\\nand one for Blue. Other color spaces exist, but let’s start\\nwith the basics and move our way up from there.\\nEach of the three colors is represented by an integer in\\nthe range 0 to 255, which indicates how “much” of the color\\nthere is. Given that the pixel value only needs to be in the\\nrange [0, 255], we normally use an 8-bit unsigned integer to\\nrepresent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 31, 'page_label': '20', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='represent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.\\nTo construct a white color, we would ﬁll up each of the\\nred, green, and blue buckets completely, like this: (255,\\n255,255).\\nThen, to create a black color, we would empty each of the\\nbuckets out: (0,0,0).\\nTo create a pure red color, we would ﬁll up the red bucket\\n(and only the red bucket) up completely: (255,0,0).\\nAre you starting to see a pattern?\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 32, 'page_label': '21', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nFor your reference, here are some common colors repre-\\nsented as RGB tuples:\\n• Black: (0,0,0)\\n• White: (255,255,255)\\n• Red: (255,0,0)\\n• Green: (0,255,0)\\n• Blue: (0,0,255)\\n• Aqua: (0,255,255)\\n• Fuchsia: (255,0,255)\\n• Maroon: (128,0,0)\\n• Navy: (0,0,128)\\n• Olive: (128,128,0)\\n• Purple: (128,0,128)\\n• Teal: (0,128,128)\\n• Yellow: (255,255,0)\\nNow that we have a good understanding of pixels, let’s\\nhave a quick review of the coordinate system.\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 33, 'page_label': '22', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.2 overview of the coordinate system\\n4.2 overview of the coordinate system\\nAs I mentioned above, an image is represented as a grid of\\npixels. Imagine our grid as a piece of graph paper. Using\\nthis graph paper, the point (0, 0) corresponds to the upper\\nleft corner of the image. As we move down and to the right,\\nboth the x and y values increase.\\nLet’s take a look at the image in Figure 4.1 to make this\\npoint clearer.\\nHere we have the letter “I” on a piece of graph paper. We\\nsee that we have an 8 × 8 grid with a total of 64 pixels.\\nThe point (0, 0) corresponds to the top left pixel in our\\nimage, whereas the point (7, 7) corresponds to the bottom\\nright corner.\\nFinally, the point (3, 4) is the pixel three columns to the\\nright and four rows down, once again keeping in mind that\\nwe start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 33, 'page_label': '22', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='we start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.\\n4.3 accessing and manipulating pixels\\nAdmittedly, the example from Chapter 3 wasn’t very excit-\\ning. All we did was load an image off disk, display it, and\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 34, 'page_label': '23', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.1: The letter “I” placed on a piece of\\ngraph paper. Pixels are accessed by\\ntheir (x, y) coordinates, where we go\\nx columns to the right and y rows\\ndown, keeping in mind that Python\\nis zero-indexed: we start counting\\nfrom zero rather than one.\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 35, 'page_label': '24', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nthen write it back to disk in a different image ﬁle format.\\nLet’s do something a little more exciting and see how we\\ncan access and manipulate the pixels in an image:\\nListing 4.1: getting_and_setting.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nSimilar to our example in the previous chapter, Lines 1-8\\nhandle importing the packages we need, along with setting\\nup our argument parser. There is only one command line\\nargument needed: the path to the image we are going to\\nwork with.\\nLines 10 and 11 handle loading the actual image off disk\\nand displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 35, 'page_label': '24', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='and displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.\\nConceptually, we can think of this representation as a ma-\\ntrix, as discussed in Section 4.1 above. In order to access a\\npixel value, we just need to supply the x and y coordinates\\nof the pixel we are interested in. From there, we are given\\na tuple representing the Red, Green, and Blue components\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 36, 'page_label': '25', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nof the image.\\nHowever, it’s important to note that OpenCV stores RGB\\nchannels in reverse order. While we normally think in terms\\nof Red, Green, and Blue, OpenCV actually stores them in\\nthe order of Blue, Green, and Red. This is important to\\nnote since it could cause some confusion later.\\nAlright, let’s explore some code that can be used to ac-\\ncess and manipulate pixels:\\nListing 4.2: getting_and_setting.py\\n12 (b, g, r) = image[0, 0]\\n13 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\n14\\n15 image[0, 0] = (0, 0, 255)\\n16 (b, g, r) = image[0, 0]\\n17 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\nOn Line 12, we grab the pixel located at (0, 0) – the top-\\nleft corner of the image. This pixel is represented as a tuple.\\nAgain, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 36, 'page_label': '25', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Again, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out\\nthe values of each channel to our console.\\nAs you can see, accessing pixel values is quite easy! Num-\\nPy takes care of all the hard work for us. All we are doing\\nis providing indexes into the array.\\nJust as NumPy makes it easy to access pixel values, it also\\nmakes it easy to manipulate pixel values.\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 37, 'page_label': '26', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nOn Line 15 we manipulate the top-left pixel in the im-\\nage, which is located at coordinate (0, 0) and set it to have\\na value of (0, 0, 255). If we were reading this pixel value\\nin RGB format, we would have a value of 0 for red, 0 for\\ngreen, and 255 for blue, thus making it a pure blue color.\\nHowever, as I mentioned above, we need to take special\\ncare when working with OpenCV . Our pixels are actually\\nstored in BGR format, not RGB format.\\nWe actually read this pixel as255 for red, 0 for green, and\\n0 for blue, making it a red color, not a blue color.\\nAfter setting the top-left pixel to have a red color on Line\\n15, we then grab the pixel value and print it back to con-\\nsole on Lines 16 and 17, just to demonstrate that we have\\nindeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 37, 'page_label': '26', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='indeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-\\nbilities to access larger rectangular portions of the image?\\nThe code below demonstrates how we can do this:\\nListing 4.3: getting_and_setting.py\\n18 corner = image[0:100, 0:100]\\n19 cv2.imshow(\"Corner\", corner)\\n20\\n21 image[0:100, 0:100] = (0, 255, 0)\\n22\\n23 cv2.imshow(\"Updated\", image)\\n24 cv2.waitKey(0)\\nOn Line 18 we grab a 100 × 100 pixel region of the image.\\nIn fact, this is the top-left corner of the image! In order to\\ngrab chunks of an image, NumPy expects we provide four\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 38, 'page_label': '27', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nindexes:\\n1. Start y: The ﬁrst value is the starting y coordinate.\\nThis is where our array slice will start along the y-axis.\\nIn our example above, our slice starts at y = 0.\\n2. End y:Just as we supplied a starting y value, we must\\nprovide an ending y value. Our slice stops along the\\ny-axis when y = 100.\\n3. Start x:The third value we must supply is the starting\\nx coordinate for the slice. In order to grab the top-left\\nregion of the image, we start at x = 0.\\n4. End x:Finally, we need to provide an x-axis value for\\nour slice to stop. We stop when x = 100.\\nOnce we have extracted the top-left corner of the image,\\nLine 19 shows us the result of the cropping. Notice how\\nour image is just the 100 × 100 pixel region from the top-\\nleft corner of our original image.\\nThe last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 38, 'page_label': '27', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='The last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the\\nimage; however, this time we are setting this region to have\\na value of (0, 255, 0) (green).\\nLines 23 and 24 then show us the results of our work.\\nSo how do we run our Python script?\\nAssuming you have downloaded the source code listings\\nfor this book, simply navigate to the chapter-04 directory\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 39, 'page_label': '28', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nand execute the command below:\\nListing 4.4: getting_and_setting.py\\n$ python getting_and_setting.py --image ../images/trex.png\\nOnce our script starts running, you should see some out-\\nput printed to your console ( Line 13). The ﬁrst line of out-\\nput tells us that the pixel located at (0, 0) has a value of\\n254 for all three red, green, and blue channels. This pixel\\nappears to be almost pure white.\\nThe second line of output shows us that we have success-\\nfully changed the pixel located at (0, 0) to be red rather than\\nwhite (Lines 15-17).\\nListing 4.5: getting_and_setting.py\\nPixel at (0, 0) - Red: 254, Green: 254, Blue: 254\\nPixel at (0, 0) - Red: 255, Green: 0, Blue: 0\\nWe can see the results of our work in Figure 4.2. The Top-\\nLeft image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 39, 'page_label': '28', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Left image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if\\nyou look closely, you can see that the top-left pixel located\\nat (0, 0) is red!\\nFinally, the bottom image shows that we have successfully\\ndrawn a green square on our image.\\nIn this chapter, we have explored how to access and ma-\\nnipulate the pixels in an image using NumPy’s built-in ar-\\nray slicing functionality. We were even able to draw a green\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 40, 'page_label': '29', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.2: Top-Left: Our original image. Top-\\nRight: Cropping our image using\\nNumPy array slicing. Bottom: Draw-\\ning a 100 ×100 pixel green square on\\nour image by using basic NumPy in-\\ndexing.\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 41, 'page_label': '30', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nsquare using nothing but NumPy array manipulation!\\nHowever, we won’t get very far using only NumPy func-\\ntions. The next chapter will show you how to draw lines,\\nrectangles, and circles using OpenCV methods.\\nFurther Reading\\nOne of the most common errors I see with developers\\njust starting to learn OpenCV is the (x, y) -coordinate\\nordering passed into images. I also tend to see a lot of\\nconfusion regarding the BGR versus RGB channel or-\\ndering.\\nTo learn more about these common errors (and how\\nyou can avoid) then, be sure to refer to the Chapter 4\\nsupplementary material:\\nhttp://pyimg.co/mtemn\\nI’ve also included a quiz that you can use to test your\\nknowledge on image basics.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 42, 'page_label': '31', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5\\nD R AW I N G\\nUsing NumPy array slices in Chapter 4, we were able to\\ndraw a green square on our image. But what if we wanted\\nto draw a single line? Or a circle? NumPy does not provide\\nthat type of functionality – it’s only a numerical processing\\nlibrary after all!\\nLuckily, OpenCV provides convenient, easy-to-use meth-\\nods to draw shapes on an image. In this chapter, we’ll re-\\nview the three most basic methods to draw shapes: cv2.\\nline, cv2.rectangle, and cv2.circle.\\nWhile this chapter is by no means a complete, exhaus-\\ntive overview of the drawing capabilities of OpenCV , it will\\nnonetheless provide a quick, hands-on approach to get you\\nstarted drawing immediately.\\n5.1 lines and rectangles\\nBefore we start exploring the the drawing capabilities of\\nOpenCV , let’s ﬁrst deﬁne our canvas in which we will draw\\nour masterpieces.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 43, 'page_label': '32', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nUp until this point, we have only loaded images off disk.\\nHowever, we can also deﬁne our images manually using\\nNumPy arrays. Given that OpenCV interprets an image as\\na NumPy array, there is no reason why we can’t manually\\ndeﬁne the image ourselves!\\nIn order to initialize our image, let’s examine the code\\nbelow:\\nListing 5.1: drawing.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\nLines 1 and 2 imports the packages we will be using.\\nAs a shortcut, we’ll create an alias for numpy as np. We’ll\\ncontinue this convention throughout the rest of the book.\\nIn fact, you’ll commonly see this convention in the Python\\ncommunity as well! We’ll also import cv2, so we can have\\naccess to the OpenCV library.\\nInitializing our image is handled on Line 4. We construct\\na NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 43, 'page_label': '32', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,\\nrespectively. As the name suggests, the zeros method ﬁlls\\nevery element in the array with an initial value of zero.\\nIt’s important to draw your attention to the second argu-\\nment of the np.zeros method: the data type, dtype. Since\\nwe are representing our image as an RGB image with pixels\\nin the range [0, 255], it’s important that we use an 8-bit un-\\nsigned integer, or uint8. There are many other data types\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 44, 'page_label': '33', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nthat we can use (common ones include 32-bit integers, and\\n32-bit or 64-bit ﬂoats), but we’ll mainly be using uint8 for\\nthe majority of the examples in this book.\\nNow that we have our canvas initialized, we can do some\\ndrawing:\\nListing 5.2: drawing.py\\n5 green = (0, 255, 0)\\n6 cv2.line(canvas, (0, 0), (300, 300), green)\\n7 cv2.imshow(\"Canvas\", canvas)\\n8 cv2.waitKey(0)\\n9\\n10 red = (0, 0, 255)\\n11 cv2.line(canvas, (300, 0), (0, 300), red, 3)\\n12 cv2.imshow(\"Canvas\", canvas)\\n13 cv2.waitKey(0)\\nThe ﬁrst thing we do on Line 5 is deﬁne a tuple used to\\nrepresent the color “green”. Then, we draw a green line\\nfrom point (0, 0) (the top-left corner of the image) to point\\n(300, 300), the bottom-right corner of the image on Line 6.\\nIn order to draw the line, we make use of the cv2.line\\nmethod. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 44, 'page_label': '33', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='method. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose\\nto start our line from the top-left corner of the image, at\\npoint (0, 0). We also need to supply an ending point for the\\nline (the third argument). We deﬁne our ending point to be\\n(300, 300), the bottom-right corner of the image. The last ar-\\ngument is the color of our line, which, in this case, is green.\\nLines 7 and 8 show our image and then wait for a keypress.\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 45, 'page_label': '34', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nFigure 5.1: Examples of drawing lines and rect-\\nangles using OpenCV .\\nAs you can see, drawing a line is quite simple! But\\nthere is one other important argument to consider in the\\ncv2.line method: the thickness.\\nOn Lines 10-13 we deﬁne a red color as a tuple (again,\\nin BGR rather than RGB format). We then draw a red line\\nfrom the top-right corner of the image to the bottom left.\\nThe last parameter to the method controls the thickness of\\nthe line – we decide to make the thickness 3 pixels. Again,\\nwe show our image and wait for a keypress.\\nDrawing a line was simple enough. Now we can move on\\nto drawing rectangles. Check out the code below for more\\ndetails:\\nListing 5.3: drawing.py\\n14 cv2.rectangle(canvas, (10, 10), (60, 60), green)\\n15 cv2.imshow(\"Canvas\", canvas)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 46, 'page_label': '35', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\n16 cv2.waitKey(0)\\n17\\n18 cv2.rectangle(canvas, (50, 200), (200, 225), red, 5)\\n19 cv2.imshow(\"Canvas\", canvas)\\n20 cv2.waitKey(0)\\n21\\n22 blue = (255, 0, 0)\\n23 cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)\\n24 cv2.imshow(\"Canvas\", canvas)\\n25 cv2.waitKey(0)\\nOn Line 14 we make use of the cv2.rectangle method.\\nThe signature of this method is identical to the cv2.line\\nmethod above, but let’s explore each argument anyway.\\nThe ﬁrst argument is the image we want to draw our rect-\\nangle on. We want to draw on ourcanvas, so we pass it into\\nthe method. The second argument is the starting (x, y) po-\\nsition of our rectangle – here, we are starting our rectangle\\nat point (10, 10). Then, we must provide an ending (x, y)\\npoint for the rectangle. We decide to end our rectangle at\\n(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 46, 'page_label': '35', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also\\ncontrol the thickness of a rectangle. Line 18 provides one\\nadded argument: the thickness. Here, we draw a red rect-\\nangle that is 5 pixels thick, starting from point (50, 200) and\\nending at (200, 225).\\nAt this point, we have only drawn the outline of a rect-\\nangle. How do we draw a rectangle that is “ﬁlled in”, like\\nwhen using NumPy array slices in Chapter 4?\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 47, 'page_label': '36', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.2: Drawing a simple bullseye with the\\ncv2.circle function.\\nSimple. We just pass in a negative value for the thickness\\nargument.\\nLine 23 demonstrates how to draw a rectangle of a solid\\ncolor. We draw a blue rectangle, starting from (200, 50) and\\nending at (225, 125). By specifying -1 as the thickness, our\\nrectangle is drawn as a solid blue.\\nCongratulations! You now have a solid grasp of drawing\\nrectangles. In the next section, we’ll move on to drawing\\ncircles.\\n5.2 circles\\nDrawing circles is just as simple as drawing rectangles, but\\nthe function arguments are a little different. Let’s go ahead\\nand get started:\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 48, 'page_label': '37', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nListing 5.4: drawing.py\\n26 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\n27 (centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\\n28 white = (255, 255, 255)\\n29\\n30 for r in range(0, 175, 25):\\n31 cv2.circle(canvas, (centerX, centerY), r, white)\\n32\\n33 cv2.imshow(\"Canvas\", canvas)\\n34 cv2.waitKey(0)\\nOn Line 26 we re-initialize our canvas to be blank. The\\nrectangles are gone! We need a fresh canvas to draw our\\ncircles.\\nLine 27 calculates two variables: centerX and centerY.\\nThese two variables represent the (x, y) coordinates of the\\ncenter of the image. We calculate the center by examining\\nthe shape of our NumPy array, and then dividing by two.\\nThe height of the image can be found in canvas.shape[0]\\nand the width in canvas.shape[1]. Finally, Line 28 deﬁnes\\na white pixel.\\nNow, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 48, 'page_label': '37', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Now, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.\\nLine 31 handles the actual drawing of the circle. The ﬁrst\\nparameter is our canvas, the image we want to draw the\\ncircle on. We then need to supply the point in which our\\ncircle will be drawn around. We pass in a tuple of(centerX,\\ncenterY) so that our circles will be centered at the middle\\nof the image. The third argument is the radius of the circle\\nwe wish to draw. Finally, we pass in the color of our circle,\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 49, 'page_label': '38', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nin this case, white.\\nLines 33 and 34 then show our image and wait for a key-\\npress.\\nSo what does our image look like?\\nCheck out Figure 5.2 and you will see that we have drawn\\na simple bullseye! The “dot” in the very center of the image\\nis drawn with a radius of 0. The larger circles are drawn\\nwith every increasing radii sizes from our for loop.\\nNot too bad. But what else can we do?\\nLet’s do some abstract drawing:\\nListing 5.5: drawing.py\\n35 for i in range(0, 25):\\n36 radius = np.random.randint(5, high = 200)\\n37 color = np.random.randint(0, high = 256, size = (3,)).tolist\\n()\\n38 pt = np.random.randint(0, high = 300, size = (2,))\\n39\\n40 cv2.circle(canvas, tuple(pt), radius, color, -1)\\n41\\n42 cv2.imshow(\"Canvas\", canvas)\\n43 cv2.waitKey(0)\\nOur code starts off on Line 35 with more looping. This\\ntime we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 49, 'page_label': '38', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='time we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.\\nIn order to draw a random circle, we need to generate\\nthree values: the radius of the circle, the color of the circle,\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 50, 'page_label': '39', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.3: The results of our masterpiece. No-\\ntice that each circle is randomly\\nplaced on the canvas with a random\\ncolor.\\nand the pt – the (x, y) coordinate of where the circle will be\\ndrawn.\\nWe generate a radius value in the range [5, 200) on Line\\n36. This value controls how large our circle will be.\\nNext, we randomly generate a color on Line 37. As we\\nknow, the color of an RGB pixel consists of three values in\\nthe range [0, 255]. In order to get three random integers\\nrather than only one integer, we pass the keyword argu-\\nment size=(3,), instructing NumPy to return a list of three\\nnumbers.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 51, 'page_label': '40', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFinally, we need an (x, y) point to draw our circle. We’ll\\ngenerate a point in the range [0, 300), again using NumPy’s\\nnp.random.randint function.\\nThe drawing of our circle then takes place on Line 40,\\nusing the radius, color, and pt that we randomly gener-\\nated. Notice how we use a thickness of -1, so our circles\\nare drawn as a solid color and not just an outline.\\nOur masterpiece is then shown to us on Lines 42 and 43.\\nYou can check out our work in Figure 5.3. Notice how\\neach circle has a different size, color, and placement on our\\ncanvas.\\nIn this chapter, you were introduced to basic drawing\\nfunctions using OpenCV . We explored how to draw shapes\\nusing the cv2.line, cv2.rectangle, and cv2.circle meth-\\nods.\\nWhile these functions seem extremely basic and simple,\\nmake sure you understand them! They are essential build-\\ning blocks that will come in handy later in this book.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 52, 'page_label': '41', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFurther Reading\\nWhy are we bothering learning how to draw rectangles,\\ncircles, and lines in a book on computer vision and im-\\nage processing?\\nIsn’t the point of computer vision to write software that\\nunderstands the contents of an image? And if so, why\\nin the world do we need to know how to draw various\\nshapes on images?\\nThese are excellent questions – and I address each of\\nthem (and provide examples of how drawing methods\\nare used in object detection and extraction) in side the\\nChapter 5 supplementary material:\\nhttp://pyimg.co/rlpak\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 53, 'page_label': '42', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6\\nI M A G E P R O C E S S I N G\\nNow that you have a solid foundation to build upon, we\\ncan start to exploring simple image processing techniques.\\nFirst, we’ll start off with basic image transformations,\\nsuch as translation, rotation, resizing, ﬂipping, and crop-\\nping. Then, we’ll explore other types of image processing\\ntechniques, including image arithmetic, bitwise operations,\\nand masking.\\nFinally, we’ll explore how to split an image into its re-\\nspective channels and then merge them back together again.\\nWe’ll conclude this chapter with a discussion of different\\ncolor spaces that OpenCV supports and the beneﬁts and\\nlimitations of each of them.\\n6.1 image transformations\\nIn this section, we’ll cover basic image transformations. These\\nare common techniques that you’ll likely apply to images,\\nincluding translation, rotation, resizing, ﬂipping, and crop-\\nping. We’ll explore each of these techniques in detail.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 54, 'page_label': '43', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nMake sure you have a good grasp of these methods! They\\nare important in nearly all areas of computer vision.\\n6.1.1 Translation\\nThe ﬁrst method we are going to explore is translation.\\nTranslation is the shifting of an image along the x and y\\naxis. Using translation, we can shift an image up, down,\\nleft, or right, along with any combination of the above!\\nThis concept is better explained through some code:\\nListing 6.1: translation.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 M = np.float32([[1, 0, 25], [0, 1, 50]])\\n15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 54, 'page_label': '43', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])\\n19 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n20 cv2.imshow(\"Shifted Up and Left\", shifted)\\nOn Lines 1-4, we simply import the packages we will\\nmake use of. At this point, using numpy, argparse, and\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 55, 'page_label': '44', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\ncv2 should feel commonplace already. However, I am intro-\\nducing a new package here: imutils. This isn’t a package\\nincluded in NumPy or OpenCV . Rather, it’s a library that\\nwe are going to write ourselves and create “convenience”\\nmethods to do common tasks like translation, rotation, and\\nresizing.\\nAfter we have the necessary packages imported, we con-\\nstruct our argument parser and load our image on Lines\\n6-12.\\nThe actual translation takes place on Lines 14-16. We ﬁrst\\ndeﬁne our translation matrix M. This matrix tells us how\\nmany pixels to the left or right, and up or down, the image\\nwill be shifted.\\nOur translation matrix M is deﬁned as a ﬂoating point\\narray – this is important because OpenCV expects this ma-\\ntrix to be of ﬂoating point type. The ﬁrst row of the matrix\\nis [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 55, 'page_label': '44', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='is [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to\\nthe right.\\nThen, we deﬁne the second row of the matrix as [0, 1,ty],\\nwhere ty is the number of pixels we will shift the image up\\nor down. Negative value of ty will shift the image up and\\npositive values will shift the image down.\\nUsing this notation, we can see on Line 14 that tx = 25\\nand ty = 50, implying that we are shifting the image 25 pix-\\nels to the right and 50 pixels down.\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 56, 'page_label': '45', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nNow that we have our translation matrix deﬁned, the\\nactual translation takes place on Line 15 using the cv2.\\nwarpAffine function. The ﬁrst argument is the image we\\nwish to shift and the second argument is our translation ma-\\ntrix M. Finally, we manually supply the dimensions (width\\nand height) of our image as the third argument. Line 16\\nshows the results of the translation.\\nMoving on to Lines 18-20, we perform another transla-\\ntion. Here, we set tx = −50 and ty = −90, implying that\\nwe are shifting the image 50 pixels to the left and 90 pixels\\nup. The image is shifted left and up rather than right and\\ndown, because we are providing a negative values for both\\ntx and ty.\\nHowever, manually constructing this translation matrix\\nand calling the cv2.warpAffine method takes a fair amount\\nof code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 56, 'page_label': '45', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='of code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently\\ncall them without writing a lot of code.\\nThe ﬁrst method we are going to deﬁne is a translate\\nfunction:\\nListing 6.2: imutils.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 def translate(image, x, y):\\n5 M = np.float32([[1, 0, x], [0, 1, y]])\\n6 shifted = cv2.warpAffine(image, M, (image.shape[1], image.\\nshape[0]))\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 57, 'page_label': '46', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n7\\n8 return shifted\\nOur translate method takes three parameters: the image\\nwe are going to translate, the number of pixels that we are\\ngoing to shift along the x-axis, and the number of pixels we\\nare going to shift along the y-axis.\\nThis method then deﬁnes our translation matrix M on\\nLine 5 and then applies the actual shift on Line 6. Finally,\\nwe return the shifted image on Line 8.\\nLet’s apply our translate method and compare to the\\nmethods discussed above:\\nListing 6.3: translation.py\\n21 shifted = imutils.translate(image, 0, 100)\\n22 cv2.imshow(\"Shifted Down\", shifted)\\n23 cv2.waitKey(0)\\nUsing our convenience translate method, we are able\\nto shift the image 100 pixels down using a single line of\\ncode. Furthermore, this translate method is much easier\\nto use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 57, 'page_label': '46', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='to use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.\\nOur original image is on the top-left. On the top-right, we\\nshift our image 25 pixels to the right and 50 pixels down.\\nNext, we translate our image 50 pixels to the left and 90\\npixels up by using negative values for tx and ty. Finally, on\\nthe bottom-right, we shift our T-Rex 100 pixels down using\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 58, 'page_label': '47', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.1: Top-Left: Our original T-Rex image.\\nTop-Right: Translating our image 25\\npixels to the right and 50 pixels\\ndown. Bottom-Left: Shifting T-Rex\\n50 pixels to the left and 90 pix-\\nels up. Bottom-Right: Shifting the\\nT-Rex down using our convenience\\nmethod.\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 59, 'page_label': '48', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nour convenient translate method deﬁned above.\\nIn this section we explored how to shift an image up,\\ndown, left, and right. Next up, we’ll explore how to rotate\\nan image.\\n6.1.2 Rotation\\nRotation is exactly what it sounds like: rotating an image\\nby some angle θ. In this section, we’ll explore how to rotate\\nan image. We’ll use θ to represent by how many degrees\\nwe are rotating the image. Later, I’ll provide another con-\\nvenience method, rotate, to make performing rotations on\\nimages easier.\\nListing 6.4: rotate.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 59, 'page_label': '48', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))\\n19 cv2.imshow(\"Rotated by 45 Degrees\", rotated)\\n20\\n21 M = cv2.getRotationMatrix2D(center, -90, 1.0)\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 60, 'page_label': '49', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n22 rotated = cv2.warpAffine(image, M, (w, h))\\n23 cv2.imshow(\"Rotated by -90 Degrees\", rotated)\\nLines 1-4 again import the packages we need. You should\\ntake note of imutils. Once again, we will be deﬁning a con-\\nvenience method to make our lives easier.\\nLines 6-12 construct our argument parser. We only need\\none argument: the path to the image we are going to use.\\nWe then load our image off disk and display it.\\nWhen we rotate an image, we need to specify around\\nwhich point we want to rotate. In most cases, you will want\\nto rotate around the center of an image; however, OpenCV\\nallows you to specify any arbitrary point you want to rotate\\naround. Let’s just go ahead and rotate around the center of\\nthe image. Lines 14 and 15 grabs the width and height of\\nthe image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 60, 'page_label': '49', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.\\nJust as we deﬁned a matrix to translate an image, we\\nalso deﬁne a matrix to rotate the image. Instead of manu-\\nally constructing the matrix using NumPy, we’ll just make\\na call to the cv2.getRotationMatrix2D method on Line 17.\\nThe cv2.getRotationMatrix2D function takes three argu-\\nments: the point at which we want to rotate the image\\naround (in this case, the center of the image). We then\\nspecify θ, the number of degrees we are going to rotate the\\nimage by. In this case, we are going to rotate the image 45\\ndegrees. The last argument is the scale of the image. We\\nhaven’t discussed resizing an image yet, but here you can\\nspecify a ﬂoating point value, where 1.0 means the same di-\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 61, 'page_label': '50', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nmensions of the image are used. However, if you speciﬁed\\na value of 2.0 the image would be doubled in size. Similarly,\\na value of 0.5 halves the size of the image.\\nOnce we have our rotation matrixM from the cv2.getRot\\nationMatrix2D function, we can apply the rotation to our\\nimage using the cv2.warpAffine method on Line 18. The\\nﬁrst argument to this function is the image we want to ro-\\ntate. We then specify our rotation matrix M along with the\\noutput dimensions (width and height) of our image. Line\\n19 then shows our image rotated by 45 degrees. Check out\\nFigure 6.2 Top-Right to see our rotated image.\\nLet’s not waste any time. We’ll go ahead and jump into\\nsome code to perform rotations:\\nOn Lines 21-23, we perform another rotation. The code\\nis identical to that in Lines 17-19, only this time we are ro-\\ntating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 61, 'page_label': '50', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='tating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-\\nage isn’t the most pretty and Pythonic. Let’s change that\\nand deﬁne our own custom rotate method:\\nListing 6.5: imutils.py\\n27 def rotate(image, angle, center = None, scale = 1.0):\\n28 (h, w) = image.shape[:2]\\n29\\n30 if center is None:\\n31 center = (w // 2, h // 2)\\n32\\n33 M = cv2.getRotationMatrix2D(center, angle, scale)\\n34 rotated = cv2.warpAffine(image, M, (w, h))\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 62, 'page_label': '51', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.2: Top-Left: Our original T-Rex image.\\nTop-Right: Rotating the image by 45\\ndegrees. Bottom-Left: Rotating the\\nimage by −90 degrees. Bottom-Right:\\nFlipping T-Rex upside down by rotat-\\ning the image by 180 degrees.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 63, 'page_label': '52', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n35\\n36 return rotated\\nOur rotate method takes four arguments. The ﬁrst is\\nour image. The second is the angle θ in which we want\\nto rotate the image. We provide two optional keyword ar-\\nguments, center and scale. The center parameter is the\\npoint which we wish to rotate our image around. If a value\\nof None is provided, the method automatically determines\\nthe center of the image on Lines 30-31. Finally, the scale\\nparameter is used to handle if the size of the image should\\nbe changed during the rotation. The scale parameter has\\na default value of 1.0, implying that no resizing should be\\ndone.\\nThe actual rotation of the image takes place on Lines 33\\nand 34, where we construct our rotation matrix M and ap-\\nply it to the image. Finally, our image is returned on Line\\n36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 63, 'page_label': '52', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)\\nHere, we are rotating our image by 180 degrees. Fig-\\nure 6.2 Bottom-Right shows that our T-Rex has indeed been\\nﬂipped upside down. The code for our rotate method is\\nmuch easier to read and maintain than making calls to\\ncv2.getRotationMatrix2D and cv2.warpAffine each time\\nwe want to rotate an image.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 64, 'page_label': '53', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6.1.3 Resizing\\nSo far we’ve covered two image transformations: transla-\\ntion and rotation. Now, we are going to explore how to\\nresize an image. We’ll also deﬁne one last method for our\\nimutils.py ﬁle, a convenience method to help us resize im-\\nages with ease.\\nPerhaps, not surprisingly, we will be using thecv2.resize\\nfunction to resize our images. But we need to keep in mind\\nthe aspect ratio of the image when we are using this func-\\ntion. Before we get too deep into the details, let’s jump right\\ninto an example:\\nListing 6.7: resize.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 64, 'page_label': '53', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n18 cv2.imshow(\"Resized (Width)\", resized)\\nLines 1-12 should start to feel quite redundant at this\\npoint. We are importing our packages, setting up our argu-\\nment parser, and ﬁnally loading our image and displaying\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 65, 'page_label': '54', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nit.\\nThe actual interesting code doesn’t start until Lines 14\\nand 15. When resizing an image, we need to keep in mind\\nthe aspect ratio of the image. The aspect ratio is the propor-\\ntional relationship of the width and the height of the image.\\nIf we aren’t mindful of the aspect ratio, our resizing will\\nreturn results that don’t look correct.\\nComputing the aspect ratio is handled on Line 14. In\\nthis line of code, we deﬁne our new image width to be 150\\npixels. In order to compute the ratio of the new height to\\nthe old height, we simply deﬁne our ratio r to be the new\\nwidth (150 pixels) divided by the old width, which we ac-\\ncess using image.shape[1].\\nNow that we have our ratio, we can compute the new di-\\nmensions of the image on Line 15. Again, the width of the\\nnew image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 65, 'page_label': '54', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='new image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.\\nThe ﬁrst argument is the image we wish to resize and the\\nsecond is our computed dimensions for the new image.The\\nlast parameter is our interpolation method, which is the\\nalgorithm working behind the scenes to handle how the\\nactual image is resized. In general, I ﬁnd that using cv2.\\nINTER_AREA obtains the best results when resizing; how-\\never, other appropriate choices include cv2.INTER_LINEAR,\\ncv2.INTER_CUBIC, and cv2.INTER_NEAREST.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 66, 'page_label': '55', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFinally, we show our resized image on Line 18.\\nIn the example we just explored, we only resized the im-\\nage by specifying the width. But what if we wanted to\\nresize the image by specifying the height? All that requires\\nis a change to computing the aspect ratio:\\nListing 6.8: resize.py\\n19 r = 50.0 / image.shape[0]\\n20 dim = (int(image.shape[1] * r), 50)\\n21\\n22 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n23 cv2.imshow(\"Resized (Height)\", resized)\\n24 cv2.waitKey(0)\\nOn Line 19 we deﬁne our ratio r. Our new image will\\nhave a height of 50 pixels. To determine the ratio of the new\\nheight to the old height, we divide 50 by the old height.\\nThen, we deﬁne the dimensions of our new image. We\\nalready know that the new image will have a height of 50\\npixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 66, 'page_label': '55', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='pixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.\\nResizing an image is simple enough, but having to com-\\npute the aspect ratio, deﬁne the dimensions of the new im-\\nage, and then perform the resizing takes three lines of code.\\nThis looks like the perfect time to deﬁne a resize method\\nin our imutils.py ﬁle:\\nListing 6.9: resize.py\\n25 resized = imutils.resize(image, width = 100)\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 67, 'page_label': '56', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 cv2.imshow(\"Resized via Function\", resized)\\n27 cv2.waitKey(0)\\nIn this example, you can see that the resizing of the im-\\nage is handled by a single function: imutils.resize. The\\nﬁrst argument we pass in is the image we want to resize.\\nThen, we specify the keyword argument width, which is\\nthe width of our new image. The function then handles the\\nresizing for us.\\nOf course, we can also resize via the height of the image\\nby changing the function call to:\\nListing 6.10: resize.py\\n1 resized = imutils.resize(image, height = 50)\\nLet’s take this function apart and see what’s going on un-\\nder the hood:\\nListing 6.11: imutils.py\\n9 def resize(image, width = None, height = None, inter = cv2.\\nINTER_AREA):\\n10 dim = None\\n11 (h, w) = image.shape[:2]\\n12\\n13 if width is None and height is None:\\n14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 67, 'page_label': '56', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23\\n24 resized = cv2.resize(image, dim, interpolation = inter)\\n25\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 68, 'page_label': '57', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 return resized\\nAs you can see, we have deﬁned our resize function.\\nThe ﬁrst argument is the image we want to resize. Then, we\\ndeﬁne two keyword arguments, width and height. Both of\\nthese arguments cannot be None, otherwise we won’t know\\nhow to resize the image. We also provide inter, which is\\nour interpolation method and defaults to cv2.INTER_AREA.\\nOn Lines 10 and 11, we deﬁne the dimensions of our new,\\nresized image and grab the dimensions of the original im-\\nage.\\nWe perform a quick check on Lines 13-14 to ensure that\\na numerical value has been provided for either the width\\nor the height.\\nThe computation of the ratio and new, resized image di-\\nmensions are handled on Lines 16-22, depending on whether\\nwe are resizing via width or via height.\\nLine 24 handles the actual resizing of the image, then\\nLine 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 68, 'page_label': '57', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Line 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.\\nThen, on the Top-Right we have our T-Rex resized to have a\\nwidth of 150 pixels. The Middle-Right image then shows our\\nimage resized to have a height of 50 pixels. Finally, Bottom-\\nRight shows the output of our resize function – the T-Rex\\nis now resized to have a width of 100 pixels using only a\\nsingle line of code.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 69, 'page_label': '58', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.3: Top-Left: Our original T-Rex image.\\nTop-Right: The T-Rex resized to have\\na width of 150 pixels. Middle-Right:\\nOur image resized to have a height\\nof 50 pixels. Bottom-Right: Resizing\\nour image to have a width of 100 pix-\\nels using our helper function. In all\\ncases, the aspect ratio of the image is\\nmaintained.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 70, 'page_label': '59', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nTranslation, rotation, and resizing are certainly the more\\nchallenging and involved image transformation tasks. The\\nnext two we will explore, ﬂipping and cropping, are sub-\\nstantially easier.\\n6.1.4 Flipping\\nNext up on our image transformations to explore is ﬂip-\\nping an image. We can ﬂip an image around either the x or\\ny axis, or even both.\\nIn fact, I think explaining how to ﬂip an image is better\\nexplained by viewing the output of an image ﬂip, before\\nwe get into the code. Check out Figure 6.4 to see our T-Rex\\nimage ﬂipped horizontally, vertically, and both horizontally\\nand vertically at the same time.\\nNow that you see what an image ﬂip looks like, we can\\nexplore the code:\\nListing 6.12: ﬂipping.py\\n1 import argparse\\n2 import cv2\\n3\\n4 ap = argparse.ArgumentParser()\\n5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 70, 'page_label': '59', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11\\n12 flipped = cv2.flip(image, 1)\\n13 cv2.imshow(\"Flipped Horizontally\", flipped)\\n14\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 71, 'page_label': '60', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.4: Top-Left: Our original T-Rex image.\\nTop-Right: Flipping the T-Rex image\\nhorizontally. Bottom-Left: Flipping\\nthe T-Rex vertically. Bottom-Right:\\nFlipping the image both horizontally\\nand vertically.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 72, 'page_label': '61', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n15 flipped = cv2.flip(image, 0)\\n16 cv2.imshow(\"Flipped Vertically\", flipped)\\n17\\n18 flipped = cv2.flip(image, -1)\\n19 cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\\n20 cv2.waitKey(0)\\nLines 1-10 handle our standard procedure of importing\\nour packages, parsing arguments, and loading our image\\nfrom disk.\\nFlipping an image is accomplished by making a call to\\nthe cv2.flip function on Line 12. The cv2.flip method\\nrequires two arguments: the image we want to ﬂip and a\\nﬂip code that is used to determine how we are going to ﬂip\\nthe image.\\nUsing a ﬂip code value of 1 indicates that we are going\\nto ﬂip the image horizontally, around the y-axis ( Line 12).\\nSpecifying a ﬂip code of 0 indicates that we want to ﬂip the\\nimage vertically, around the x-axis (Line 15). Finally, using\\na negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 72, 'page_label': '61', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-\\nzontally, vertically, and around both axes.\\nFlipping an image is very simple, perhaps one of the sim-\\nplest examples in this book! Next up, we’ll go over crop-\\nping an image and how to extract regions of an image using\\nNumPy array slices.\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 73, 'page_label': '62', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.5: Top: Our original T-Rex image. Bot-\\ntom: Cropping the face of the T-Rex\\nusing NumPy array slices.\\n6.1.5 Cropping\\nWhen we crop an image, we want to remove the outer parts\\nof the image that we are not interested in. We can accom-\\nplish image cropping by using NumPy array slicing. In fact,\\nwe already performed image cropping in Chapter 4!\\nHowever, let’s review it again and make sure we under-\\nstand what is going on:\\nListing 6.13: crop.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 74, 'page_label': '63', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 cropped = image[30:120 , 240:335]\\n14 cv2.imshow(\"T-Rex Face\", cropped)\\n15 cv2.waitKey(0)\\nLines 1-11 handle importing our packages, parsing our\\narguments, and loading our images. For our cropping ex-\\nample, we will use our T-Rex image.\\nThe actual cropping takes place on a single line of code:\\nLine 13. We are supplying NumPy array slices to extract\\na rectangular region of the image, starting at (240, 30) and\\nending at (335, 120). The order in which we supply the\\nindexes to the crop may seem counterintuitive; however, re-\\nmember that OpenCV represents images as NumPy arrays\\nwith the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 74, 'page_label': '63', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='with the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:\\n1. Start y: The starting y coordinate. In this case, we\\nstart at y = 30.\\n2. End y:The ending y coordinate. We will end our crop\\nat y = 120.\\n3. Start x:The starting x coordinate of the slice. We start\\nthe crop at x = 240.\\n63'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 75, 'page_label': '64', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\n4. End x: The ending x-axis coordinate of the slice. Our\\nslice ends at x = 335.\\nExecuting our code detailed above, we will see from Fig-\\nure 6.5 that we have cropped out the face of our T-Rex!\\nWhile the T-Rex might seem a little scary, cropping sure\\nisn’t! In fact, it’s quite simple when you consider all we are\\ndoing is performing array slices on NumPy arrays.\\n6.2 image arithmetic\\nWe all know basic arithmetic operations like addition and\\nsubtraction. But when working with images, we need to\\nkeep in mind the limits of our color space and data type.\\nFor example, RGB images have pixels that fall within the\\nrange [0, 255]. So what happens if we are examining a pixel\\nwith intensity 250 and we try to add 10 to it?\\nUnder normal arithmetic rules, we would end up with a\\nvalue of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 75, 'page_label': '64', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='value of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check\\nof some sort to ensure no pixel falls outside the range of\\n[0, 255], thus clipping all pixels to have a minimum value of\\n0 and a maximum value of 255?\\nOr do we apply a modulus operation, and “wrap around”?\\nUnder modulus rules, adding 10 to 250 would simply wrap\\naround to a value of 4.\\n64'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 76, 'page_label': '65', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWhich way is the “correct” way to handle image addi-\\ntions and subtractions that fall outside the range of [0, 255]?\\nThe answer is there is no correct way – it simply depends\\non how you are manipulate your pixels and what you want\\nthe desired results to be.\\nHowever, be sure to keep in mind that there is a differ-\\nence between OpenCV and NumPy addition. NumPy will\\nperform modulo arithmetic and “wrap around”. OpenCV ,\\non the other hand, will perform clipping and ensure pixel\\nvalues never fall outside the range [0, 255].\\nBut don’t worry! These nuances will become clearer as\\nwe explore some code below.\\nListing 6.14: arithmetic.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 76, 'page_label': '65', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 print(\"max of 255: {}\".format(cv2.add(np.uint8([200]), np.uint8\\n([100]))))\\n15 print(\"min of 0: {}\".format(cv2.subtract(np.uint8([50]), np.uint8\\n([100]))))\\n16\\n17 print(\"wrap around: {}\".format(np.uint8([200]) + np.uint8([100]))\\n)\\n18 print(\"wrap around: {}\".format(np.uint8([50]) - np.uint8([100])))\\n65'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 77, 'page_label': '66', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWe are going to perform our standard procedure onLines\\n1-12 by importing our packages, setting up our argument\\nparser, and loading our image.\\nRemember how I mentioned the difference between OpenCV\\nand NumPy addition above? Well, now we are going to ex-\\nplore it further and provide a concrete example to ensure\\nwe fully understand it.\\nOn Line 14, we deﬁne two NumPy arrays that are 8-\\nbit unsigned integers. The ﬁrst array has one element: a\\nvalue of 200. The second array also has only one element,\\nbut with a value of 100. We then use OpenCV’s cv2.add\\nmethod to add the values together.\\nWhat do you think the output is going to be?\\nWell, according to standard arithmetic rules, we would\\nthink the result should be 300, but, remember that we are\\nworking with 8-bit unsigned integers that only have a range\\nbetween [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 77, 'page_label': '66', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='between [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-\\necute this code, we can see the result on the ﬁrst line of\\nListing 6.15. Sure enough, the addition returned a value of\\n255.\\nLine 15 then performs subtraction using cv2.subtract.\\nAgain, we deﬁne two NumPy arrays, each with a single ele-\\nment, and of the 8-bit unsigned integer data type. The ﬁrst\\narray has a value of 50 and the second a value of 100.\\n66'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 78, 'page_label': '67', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nAccording to our arithmetic rules, the subtraction should\\nreturn a value of −50; however, OpenCV once again per-\\nforms clipping for us. We ﬁnd that the value is clipped to a\\nvalue of 0. The second line of Listing 6.15 veriﬁes this: sub-\\ntracting 100 from 50 using cv2.subtract returns a value of\\n0.\\nListing 6.15: arithmetic.py\\nmax of 255: [[255]]\\nmin of 0: [[0]]\\nBut what happens if we use NumPy to perform the arith-\\nmetic instead of OpenCV?\\nLine 17 and 18 explore this question.\\nFirst, we deﬁne two NumPy arrays, each with a single\\nelement, and of the 8-bit unsigned integer data type. The\\nﬁrst array has a value of 200, and the second has a value\\nof 100. Using the cv2.add function, our addition would be\\nclipped and a value of 255 returned.\\nHowever, NumPy does not perform clipping – it instead\\nperforms modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 78, 'page_label': '67', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='performs modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been\\nreached. You can see this is true via the ﬁrst line of output\\non Listing 6.16.\\nThen, we deﬁne two more NumPy arrays: one has a value\\nof 50 and the other 100. Using the cv2.subtract method,\\nthis subtraction would be clipped to return a value of 0.\\nHowever, we know that NumPy performs modulo arith-\\n67'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 79, 'page_label': '68', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nmetic rather than clipping. Instead, once 0 is reached dur-\\ning the subtraction, the modulos operations wraps around\\nand starts counting backwards from 255 – thus the result\\non the second line of output on Listing 6.16.\\nListing 6.16: arithmetic.py\\nwrap around: [44]\\nwrap around: [206]\\nWhen performing integer arithmetic, it is important to\\nkeep in mind your desired output.\\nDo you want all values to be clipped if they fall outside\\nthe range [0, 255]? Then use OpenCV’s built-in methods for\\nimage arithmetic.\\nDo you want modulus arithmetic operations and have\\nvalues wrap around if they fall outside the range of [0, 255]?\\nThen simply add and subtract the NumPy arrays as you\\nnormally would.\\nNow that we have explored the caveats of image arith-\\nmetic in OpenCV and NumPy, let’s perform the arithmetic\\non actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 79, 'page_label': '68', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='on actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)\\n22\\n23 M = np.ones(image.shape, dtype = \"uint8\") * 50\\n24 subtracted = cv2.subtract(image, M)\\n25 cv2.imshow(\"Subtracted\", subtracted)\\n26 cv2.waitKey(0)\\n68'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 80, 'page_label': '69', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nFigure 6.6: Top-Left: Our original T-Rex image.\\nTop-Right: Adding 100 to every pixel\\nin the image. Notice how the image\\nlooks more “washed out” and is sub-\\nstantially brighter than the original.\\nBottom: Subtracting 50 from every\\npixel in the image. Notice that the\\nimage is now darker than the origi-\\nnal.\\n69'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 81, 'page_label': '70', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nLine 19 deﬁnes a NumPy array of ones, with the same\\nsize as our image. Again, we are sure to use 8-bit unsigned\\nintegers as our data type. In order to ﬁll our matrix with\\nvalues of 100’s rather than 1’s, we simply multiply our ma-\\ntrix of 1’s by 100. Finally, we use the cv2.add function to\\nadd our matrix of 100’s to the original image – thus increas-\\ning every pixel intensity in the image by 100, but ensuring\\nall values are clipped to the range [0, 255] if they attempt to\\nexceed 255.\\nThe result of our operation can be found in Figure 6.6\\nTop-Right. Notice how the image looks more “washed out”\\nand is substantially brighter than the original. This is be-\\ncause we are increasing the pixel intensities by adding 100\\nto them and pushing them towards brighter colors.\\nWe then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 81, 'page_label': '70', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='We then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image\\nin Figure 6.6 shows the results of this subtraction. Our im-\\nage now looks considerably darker than the original T-Rex.\\nPixels that were once white now look gray. This is because\\nwe are subtracting 50 from the pixels and pushing them to-\\nwards the darker regions of the RGB color space.\\nIn this section, we explored the peculiarities of image\\narithmetic using OpenCV and NumPy. These caveats are\\nimportant to keep in mind, otherwise you may get unwanted\\nresults when performing arithmetic operations on your im-\\nages.\\n70'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 82, 'page_label': '71', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\n6.3 bitwise operations\\nNow we will review four bitwise operations: AND, OR,\\nXOR, and NOT. These four operations, while very basic\\nand low level, are paramount to image processing, espe-\\ncially when we start working with masks in Section 6.4.\\nBitwise operations operate in a binary manner and are\\nrepresented as grayscale images. A given pixel is turned\\n“off” if it has a value of zero, and it is turned “on” if the\\npixel has a value greater than zero.\\nLet’s go ahead and jump into some code:\\nListing 6.18: bitwise.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 rectangle = np.zeros((300, 300), dtype = \"uint8\")\\n5 cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\\n6 cv2.imshow(\"Rectangle\", rectangle)\\n7\\n8 circle = np.zeros((300, 300), dtype = \"uint8\")\\n9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 82, 'page_label': '71', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image\\nas a 300 × 300 NumPy array on Line 4. We then draw a\\n250 × 250 white rectangle at the center of the image.\\nSimilarly, on Line 8, we initialize another image to con-\\ntain our circle, which we draw on Line 9, again centered at\\nthe center of the image, with a radius of 150 pixels.\\n71'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 83, 'page_label': '72', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nFigure 6.7: Left: Our rectangle image. Right: Our\\ncircle image. We will explore how\\nthese two images can be combined\\nusing bitwise operations.\\nFigure 6.7 shows our two shapes. We will make use of\\nthese shapes to demonstrate our bitwise operations:\\nListing 6.19: bitwise.py\\n11 bitwiseAnd = cv2.bitwise_and(rectangle, circle)\\n12 cv2.imshow(\"AND\", bitwiseAnd)\\n13 cv2.waitKey(0)\\n14\\n15 bitwiseOr = cv2.bitwise_or(rectangle, circle)\\n16 cv2.imshow(\"OR\", bitwiseOr)\\n17 cv2.waitKey(0)\\n18\\n19 bitwiseXor = cv2.bitwise_xor(rectangle, circle)\\n20 cv2.imshow(\"XOR\", bitwiseXor)\\n21 cv2.waitKey(0)\\n22\\n23 bitwiseNot = cv2.bitwise_not(circle)\\n24 cv2.imshow(\"NOT\", bitwiseNot)\\n25 cv2.waitKey(0)\\n72'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 84, 'page_label': '73', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nAs I mentioned above, a given pixel is turned “on” if it\\nhas a value greater than zero, and it is turned “off” if it has\\na value of zero. Bitwise functions operate on these binary\\nconditions.\\nIn order to utilize bitwise functions, we assume (in most\\ncases) that we are comparing two pixels (the only exception\\nis the NOT function). We’ll compare each of the pixels and\\nthen construct our bitwise representation.\\nLet’s quickly review our binary operations:\\n1. AND: A bitwise AND is true if and only if both pixels\\nare greater than zero.\\n2. OR: A bitwise OR is true if either of the two pixels\\nare greater than zero.\\n3. XOR: A bitwise XOR is true if and only if either of the\\ntwo pixels are greater than zero, but not both.\\n4. NOT: A bitwise NOT inverts the “on” and “off” pixels\\nin an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 84, 'page_label': '73', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='in an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if\\nboth pixels are greater than zero. The output of our bitwise\\nAND can be seen in Figure 6.8 Top-Left. We can see that\\nedges of our square are lost – this makes sense because our\\nrectangle does not cover as large of an area as the circle,\\nand thus both pixels are not “on”.\\n73'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 85, 'page_label': '74', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nWe then apply a bitwise OR on Line 15 using the cv2.\\nbitwise_or function. A bitwise OR is true if either of the\\ntwo pixels are greater than zero. Figure 6.8 Top-Right shows\\nthe output of our bitwise OR. In this case, our square and\\nrectangle have been combined together.\\nNext up is the bitwise XOR function, applied on Line 19\\nusing the cv2.bitwise_xor function. An XOR operation\\nis true if both pixels are greater than zero, but both pixels\\ncannot be greater than zero. The output of the XOR oper-\\nation is displayed on Figure 6.8 Bottom-Right. Here we see\\nthat the center of the square has been removed. Again, this\\nmakes sense because an XOR operation cannot have both\\npixels greater than zero.\\nFinally, we apply the NOT function on Line 23 using the\\ncv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 85, 'page_label': '74', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are\\nset to 255. Figure 6.8 Bottom-Right ﬂips our white circle to a\\nblack circle.\\nOverall, bitwise functions are extremely simple, yet very\\npowerful. And they are absolutely essential when we start\\nto discuss masking in Section 6.4.\\n6.4 masking\\nIn the previous section, we explored bitwise functions. Now\\nwe are ready to explore masking, an extremely powerful\\nand useful technique in computer vision and image pro-\\n74'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 86, 'page_label': '75', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.8: Top-Left: Applying a bitwise AND to\\nour rectangle and circle image. Top-\\nRight: A bitwise OR applied to our\\nsquare and circle. Bottom-Left: An\\nXOR applied to our shapes. Bottom-\\nRight: Flipping pixel values of our\\ncircle using a bitwise NOT.\\n75'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 87, 'page_label': '76', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ncessing.\\nUsing a mask allows us to focus only on the portions of\\nthe image that interests us.\\nFor example, let’s say that we were building a computer\\nvision system to recognize faces. The only part of the image\\nwe are interested in ﬁnding and describing are the parts of\\nthe image that contain faces – we simply don’t care about\\nthe rest of the content of the image. Provided that we could\\nﬁnd the faces in the image, we might construct a mask to\\nshow only the faces in the image.\\nLet’s make this example a little more concrete.\\nIn Figure 6.9, we have an image of a beach on the Top-Left.\\nBut I’m not interested in the beach in the image. I’m only\\ninterested in the sky and the palm tree. We could apply a\\ncropping to extract that region of the image. Or, we could\\napply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 87, 'page_label': '76', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='apply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-\\ning our rectangle mask, we have focused only on the sky\\nand palm tree in the image.\\nLet’s examine the code to accomplish the masking in Fig-\\nure 6.9:\\nListing 6.20: masking.py\\n1 import numpy as np\\n76'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 88, 'page_label': '77', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.9: Top-Left: Our image of a peaceful\\nbeach scene. Top-Right: Our mask im-\\nage – a white rectangle at the center\\nof the image. Bottom: Applying the\\nrectangular mask to the beach image.\\nOnly the parts of the image where\\nthe mask pixels are greater than zero\\nare shown.\\n77'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 89, 'page_label': '78', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n14 (cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\\n15 cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255,\\n-1)\\n16 cv2.imshow(\"Mask\", mask)\\n17\\n18 masked = cv2.bitwise_and(image, image, mask = mask)\\n19 cv2.imshow(\"Mask Applied to Image\", masked)\\n20 cv2.waitKey(0)\\nOn Lines 1-11 we import the packages we need, parse\\nour arguments, and load our image.\\nWe then construct a NumPy array, ﬁlled with zeros, with\\nthe same width and height as our beach image on Line 13.\\nIn order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 89, 'page_label': '78', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='In order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-\\nsion. Finally, we draw our white rectangle on Line 15.\\nRemember reviewing the cv2.bitwise_and function in\\nthe previous section? It’s a function that is used extensively\\nwhen applying masks to images.\\nWe apply our mask on Line 18 using the cv2.bitwise_\\nand function. The ﬁrst two parameters are the image it-\\nself. Obviously, the AND function will be True for all pix-\\nels in the image; however, the important part of this func-\\n78'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 90, 'page_label': '79', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ntion is the mask keyword argument. By supplying a mask,\\nthe cv2.bitwise_and function only examines pixels that are\\n“on” in the mask. In this case, only pixels that are part of\\nthe white rectangle.\\nLet’s look at another example:\\nListing 6.21: masking.py\\n21 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n22 cv2.circle(mask, (cX, cY), 100, 255, -1)\\n23 masked = cv2.bitwise_and(image, image, mask = mask)\\n24 cv2.imshow(\"Mask\", mask)\\n25 cv2.imshow(\"Mask Applied to Image\", masked)\\n26 cv2.waitKey(0)\\nOn Line 21 we re-initialize our mask to be ﬁlled with ze-\\nros and the same dimensions as our beach image. Then, we\\ndraw a white circle on our mask image, starting at the cen-\\nter of the image and a radius of 100 pixels. Applying the\\ncircular mask is then performed on Line 23, again using the\\ncv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 90, 'page_label': '79', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on\\nthe Bottom. Instead of a rectangular region of the beach be-\\ning shown, we now have a circular region.\\nRight now masking may not seem very interesting. But\\nwe’ll return to it once we start computing histograms in\\nChapter 7. Again, the key point of masks is that they allow\\nus to focus our computation only on regions of the image\\nthat interests us.\\n79'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 91, 'page_label': '80', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.10: Applying the circular mask to the\\nbeach image. Only pixels within\\nthe circular white region are shown.\\n80'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 92, 'page_label': '81', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\n6.5 splitting and merging channels\\nA color image consists of multiple channels: a Red, a Green,\\nand a Blue component. We have seen that we can access\\nthese components via indexing into NumPy arrays. But\\nwhat if we wanted to split an image into its respective com-\\nponents?\\nAs you’ll see, we’ll make use of thecv2.split function.\\nFor the time being, let’s take a look at a sample image in\\nFigure 6.11.\\nWe have an image of a wave crashing down. This image\\nis very “blue” due to the ocean. How do we interpret the\\ndifferent channels of the image?\\nThe Red channel (Top-Left) is very dark. This makes sense,\\nbecause an ocean scene has very few red colors in it. The\\nred colors present are either very dark, and thus not repre-\\nsented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 92, 'page_label': '81', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='sented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.\\nFinally, the Blue channel ( Bottom-Left) is extremely light,\\nand near pure white in some locations. This is because\\nshades of blue are heavily represented in our image.\\nNow that we have visualized our channels, let’s examine\\nsome code to accomplish this for us:\\n81'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 93, 'page_label': '82', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.11: The three RGB channels of our\\nwave image are shown on the\\nBottom-Right. The Red channel is on\\nthe Top-Left, the Green channel on\\nthe Top-Right, and the Blue channel\\non the Bottom-Left.\\n82'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 94, 'page_label': '83', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nListing 6.22: splitting_and_merging.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 (B, G, R) = cv2.split(image)\\n12\\n13 cv2.imshow(\"Red\", R)\\n14 cv2.imshow(\"Green\", G)\\n15 cv2.imshow(\"Blue\", B)\\n16 cv2.waitKey(0)\\n17\\n18 merged = cv2.merge([B, G, R])\\n19 cv2.imshow(\"Merged\", merged)\\n20 cv2.waitKey(0)\\n21 cv2.destroyAllWindows()\\nLines 1-10 imports our packages, sets up our argument\\nparser, and then loads our image. Splitting the channels is\\ndone using a call to cv2.split on Line 11.\\nNormally, we think of images in the RGB color space –\\nthe red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 94, 'page_label': '83', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image\\nin RGB order, it instead stores the image in BGR order; thus\\nwe unpack the tuple in reverse order.\\nLines 13-16 then show each channel individually, as in\\nFigure 6.11.\\nWe can also merge the channels back together again us-\\ning the cv2.merge function. We simply specify our chan-\\n83'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 95, 'page_label': '84', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.12: Representing the Red, Green, and\\nBlue channels of our wave image.\\nnels, again in BGR order, and then cv2.merge takes care of\\nthe rest for us ( Line 18).\\nListing 6.23: splitting_and_merging.py\\n22 zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\\n23 cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\\n24 cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\\n25 cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\\n26 cv2.waitKey(0)\\nAn alternative method to visualize the channels of an im-\\nage can be seen in Figure 6.12. In order to show the actual\\n“color” of the channel, we ﬁrst need to take apart the image\\nusing cv2.split. Then, we need to re-construct the image,\\nbut this time setting all pixels but the current channel as zero.\\nOn Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 95, 'page_label': '84', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='On Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-\\nage, we make a call to cv2.merge, but specifying our zeros\\narray for the Green and Blue channels. We take similar ap-\\nproaches to the other channels in Line 24 and 25.\\n84'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 96, 'page_label': '85', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n6.6 color spaces\\nIn this book, we have only explored the RGB color space;\\nhowever, there are many other color spaces that we can uti-\\nlize.\\nThe Hue-Saturation-Value (HSV) color space is more sim-\\nilar to how humans think and conceive of color. Then there\\nis the L*a*b* color space, which is more tuned to how hu-\\nmans perceive color.\\nOpenCV provides support for many, many different color\\nspaces. And understanding how color is perceived by hu-\\nmans and represented by computers occupies an entire li-\\nbrary of literature itself.\\nIn order to not get bogged down in the details, I’ll just\\nshow you how to convert color spaces. If you think your\\napplication of image processing and computer vision might\\nneed a different color space than RGB, I will leave that as\\nan exercise to the reader to explore the peculiarities of each\\ncolor space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 96, 'page_label': '85', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='color space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n85'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 97, 'page_label': '86', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Gray\", gray)\\n15\\n16 hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\\n17 cv2.imshow(\"HSV\", hsv)\\n18\\n19 lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\\n20 cv2.imshow(\"L*a*b*\", lab)\\n21 cv2.waitKey(0)\\nLines 1-11 imports the packages we need, parses our ar-\\nguments, and loads our image. Then, on Line 13, we con-\\nvert our image from the RGB color space to grayscale by\\nspecifying the cv2.COLOR_BGR2GRAY ﬂag.\\nConverting our image to the HSV color space is performed\\non Line 16 by specifying the cv2.COLOR_BGR2HSV ﬂag. Fi-\\nnally, on Line 19, we convert to the L*a*b* color space by\\nusing the cv2.COLOR_BGR2LAB ﬂag.\\nWe can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 97, 'page_label': '86', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='We can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.\\nIf you are just getting started in computer vision, it’s likely\\na good idea to stick to the RGB color space for the time\\nbeing. However, I have included this section as a matter\\nof completeness – it’s good to show an example of how to\\nconvert color spaces for when you decide the time is right!\\n86'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 98, 'page_label': '87', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFigure 6.13: Top-Left: An image of beach scenery.\\nTop-Right: The grayscale represen-\\ntation of the beach image. Bottom-\\nLeft: Converting the beach image to\\nthe HSV color space. Bottom-Right:\\nConverting our image to the L*a*b*\\ncolor space.\\n87'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 99, 'page_label': '88', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFurther Reading\\nChapter 6 is by far the longest chapter inPractical Python\\nand OpenCV – and with good reason. In this chapter,\\nwe covered a lot of important image processing con-\\ncepts that form the foundation on which the rest of\\nyour computer vision education will be built.\\nTo ensure that you have a thorough grasp on these con-\\ncepts, be sure to go through the Chapter 6 supplemen-\\ntary material:\\nhttp://pyimg.co/s3fm7\\n88'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 100, 'page_label': '89', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7\\nH I S T O G R A M S\\nSo, what exactly is a histogram? A histogram represents\\nthe distribution of pixel intensities (whether color or gray-\\nscale) in an image. It can be visualized as a graph (or plot)\\nthat gives a high-level intuition of the intensity (pixel value)\\ndistribution. We are going to assume an RGB color space in\\nthis example, so these pixel values will be in the range of 0\\nto 255.\\nWhen plotting the histogram, the X-axis serves as our\\n“bins”. If we construct a histogram with 256 bins, then\\nwe are effectively counting the number of times each pixel\\nvalue occurs. In contrast, if we use only 2 (equally spaced)\\nbins, then we are counting the number of times a pixel is in\\nthe range [0, 128) or [128, 255]. The number of pixels binned\\nto the x-axis value is then plotted on the y-axis.\\nBy simply examining the histogram of an image, you get\\na general understanding regarding the contrast, brightness,\\n89'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 101, 'page_label': '90', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1 using opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms. Before we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 101, 'page_label': '90', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='provided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.\\n4. histSize: This is the number of bins we want to use\\nwhen computing a histogram. Again, this is a list, one\\nfor each channel we are computing a histogram for.\\nThe bin sizes do not all have to be the same. Here is\\nan example of 32 bins for each channel: [32,32,32].\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 102, 'page_label': '91', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use thecv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2 grayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet. All we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 102, 'page_label': '91', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Original\", image)\\n91'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 103, 'page_label': '92', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n15\\n16 hist = cv2.calcHist([image], [0], None, [256], [0, 256])\\n17\\n18 plt.figure()\\n19 plt.title(\"Grayscale Histogram\")\\n20 plt.xlabel(\"Bins\")\\n21 plt.ylabel(\"# of Pixels\")\\n22 plt.plot(hist)\\n23 plt.xlim([0, 256])\\n24 plt.show()\\n25 cv2.waitKey(0)\\nNow things are getting a little more interesting. On Line\\n13, we convert the image from the RGB colorspace to graysc-\\nale. Line 16 computes the actual histogram. Go ahead and\\nmatch the arguments of the code up with the function docu-\\nmentation above. We can see that our ﬁrst parameter is the\\ngrayscale image. A grayscale image has only one channel,\\nhence we have a value of [0] for channels. We don’t have\\na mask, so we set the mask value to None. We will use 256\\nbins in our histogram, and the possible values range from\\n0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 103, 'page_label': '92', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the\\nbins (0-255) are plotted on the x-axis. And the y-axis counts\\nthe number of pixels in each bin. The majority of the pixels\\nfall in the range of roughly 60 to 120. Looking at the right\\ntail of the histogram, we see very few pixels in the range\\n200 to 255. This means that there are very few “white” pix-\\nels in the image.\\n92'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 104, 'page_label': '93', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.1: Computing a grayscale histogram of\\nour beach image.\\n7.3 color histograms\\nIn the previous section, we explored grayscale histograms.\\nNow let’s move on to computing a histogram for each chan-\\nnel of the image.\\nListing 7.3: color_histograms.py\\n1 from __future__ import print_function\\n2 from matplotlib import pyplot as plt\\n3 import numpy as np\\n4 import argparse\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 cv2.imshow(\"Original\", image)\\n93'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 105, 'page_label': '94', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nAgain, we’ll import the packages that we’ll need, utiliz-\\ning matplotlib once more to plot the histograms.\\nLet’s examine some code:\\nListing 7.4: color_histograms.py\\n14 chans = cv2.split(image)\\n15 colors = (\"b\", \"g\", \"r\")\\n16 plt.figure()\\n17 plt.title(\"’Flattened’ Color Histogram\")\\n18 plt.xlabel(\"Bins\")\\n19 plt.ylabel(\"# of Pixels\")\\n20\\n21 for (chan, color) in zip(chans, colors):\\n22 hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\\n23 plt.plot(hist, color = color)\\n24 plt.xlim([0, 256])\\nThe ﬁrst thing we are going to do is split the image into\\nits three channels: blue, green, and red. Normally, we read\\nthis is red, green, blue (RGB). However, OpenCV stores the\\nimage as a NumPy array in reverse order: BGR. This is\\nimportant to note. We then initialize a tuple of strings rep-\\nresenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 105, 'page_label': '94', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='resenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into\\neach bin on the y-axis.\\nWe then reach a for loop on Line 21, where we start loop-\\ning over each of the channels in the image.\\nThen, for each channel, we compute a histogram on Line\\n22. The code is identical to that of computing a histogram\\nfor the grayscale image; however, we are doing it for each\\nRed, Green, and Blue channel, allowing us to characterize\\n94'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 106, 'page_label': '95', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.2: Color histograms for each Red,\\nGreen, and Blue channel of the beach\\nimage.\\nthe distribution of pixel intensities. We add our histogram\\nto the plot on Line 23.\\nWe can examine our color histogram in Figure 7.2. We\\nsee there is a sharp peak in the green histogram around bin\\n100. This indicates a darker green value, from the green\\nvegetation and trees in the beach image.\\nWe also see a lot of blue pixels in the range 170 to 225.\\nConsidering these pixels are much lighter, we know that\\nthey are from the blue sky in our beach image. Similarly,\\nwe see a much smaller range of blue pixels in the range 25\\nto 50 – these pixels are much darker, and are therefore the\\nocean pixels in the bottom-left corner of the image.\\nUp until this point, we have computed a histogram for\\nonly one channel at a time. Now we move on to multi-\\ndimensional histograms and take into consideration two\\n95'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 107, 'page_label': '96', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nchannels at a time.\\nI like to explain multi-dimensional histograms by using\\nthe word AND.\\nFor example, we can ask a question such as, “How many\\npixels have a Red value of 10 AND a Blue value of 30?”.\\nHow many pixels have a Green value of 200 AND a Red\\nvalue of 130? By using the conjunctive AND, we are able to\\nconstruct multi-dimensional histograms.\\nIt’s that simple. Let’s check out some code to automate\\nthe process of building a 2D histogram:\\nListing 7.5: color_histograms.py\\n25 fig = plt.figure()\\n26\\n27 ax = fig.add_subplot(131)\\n28 hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None,\\n29 [32, 32], [0, 256, 0, 256])\\n30 p = ax.imshow(hist, interpolation = \"nearest\")\\n31 ax.set_title(\"2D Color Histogram for G and B\")\\n32 plt.colorbar(p)\\n33\\n34 ax = fig.add_subplot(132)\\n35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 107, 'page_label': '96', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")\\n39 plt.colorbar(p)\\n40\\n41 ax = fig.add_subplot(133)\\n42 hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None,\\n43 [32, 32], [0, 256, 0, 256])\\n44 p = ax.imshow(hist, interpolation = \"nearest\")\\n45 ax.set_title(\"2D Color Histogram for B and R\")\\n46 plt.colorbar(p)\\n47\\n48 print(\"2D histogram shape: {}, with {} values\".format(\\n96'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 108, 'page_label': '97', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\n49 hist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using. In previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 108, 'page_label': '97', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='The most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 109, 'page_label': '98', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.3: Computing 2D color histograms for\\neach combination of Red, Green, and\\nBlue channels.\\nof red represent large pixel counts (i.e., peaks in the 2D his-\\ntogram). We tend to see many peaks in the Green and Blue\\nhistogram, where x = 22 and y = 12. This corresponds to\\nthe green pixels of the vegetation and trees and the blue of\\nthe sky and ocean.\\nUsing a 2D histogram takes into account two channels at\\na time. But what if we wanted to account for all three RGB\\nchannels? You guessed it. We’re now going to build a 3D\\nhistogram.\\nListing 7.6: color_histograms.py\\n50 hist = cv2.calcHist([image], [0, 1, 2],\\n51 None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\\n52 print(\"3D histogram shape: {}, with {} values\".format(\\n53 hist.shape, hist.flatten().shape[0]))\\n54\\n55 plt.show()\\n98'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 110, 'page_label': '99', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4 histogram equalization\\nHistogram equalization improves the contrast of an image\\nby “stretching” the distribution of pixels. Consider a his-\\ntogram with a large peak at the center of it. Applying his-\\ntogram equalization will stretch the peak out towards the\\ncorner of the image, thus improving the global contrast of\\nthe image. Histogram equalization is applied to grayscale\\nimages.\\nThis method is useful when an image contains foregroun-\\nds and backgrounds that are both dark or both light. It\\ntends to produce unrealistic effects in photographs; how-\\never, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 110, 'page_label': '99', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ever, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n99'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 111, 'page_label': '100', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12\\n13 eq = cv2.equalizeHist(image)\\n14\\n15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\\n16 cv2.waitKey(0)\\nLines 1-10 handle our standard practice of importing pack-\\nages, parsing arguments, and loading our image. We then\\nconvert our image to grayscale on Line 11.\\nPerforming histogram equalization is done using just a\\nsingle function: cv2.equalizeHist, which accepts a single\\nparameter, the grayscale image we want to perform his-\\ntogram equalization on. The last couple lines of code dis-\\nplay our histogram equalized image.\\n100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 112, 'page_label': '101', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nThe result of applying histogram equalization can be seen\\nin Figure 7.4. On the left, we have our original beach image.\\nThen, on the right, we have our histogram-equalized beach\\nimage. Notice how the contrast of the image has been radi-\\ncally changed and now spans the entire range of [0, 255].\\n7.5 histograms and masks\\nIn Chapter 6, Section 6.4, I mentioned that masks can be\\nused to focus on speciﬁc regions of an image that interest\\nus. We are now going to construct a mask and compute\\ncolor histograms for the masked region only.\\nFirst, we need to deﬁne a convenience function to save us\\nfrom writing repetitive lines of code:\\nListing 7.8: histogram_with_mask.py\\n1 from matplotlib import pyplot as plt\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 112, 'page_label': '101', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13\\n14 for (chan, color) in zip(chans, colors):\\n15 hist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16 plt.plot(hist, color = color)\\n17 plt.xlim([0, 256])\\n101'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 113, 'page_label': '102', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nOn Lines 1-4 we import our packages; then on Line 6 we\\ndeﬁne plot_histogram. This function accepts three param-\\neters: an image, the title of our plot, and a mask. The mask\\ndefaults to None if we do not have a mask for the image.\\nThe body of our plot_histogram function simply com-\\nputes a histogram for each channel in the image and plots\\nit, just as in previous examples in this chapter.\\nNow that we have a function to help us easily plot his-\\ntograms, let’s move into the bulk of our code:\\nListing 7.9: histogram_with_mask.py\\n18 ap = argparse.ArgumentParser()\\n19 ap.add_argument(\"-i\", \"--image\", required = True,\\n20 help = \"Path to the image\")\\n21 args = vars(ap.parse_args())\\n22\\n23 image = cv2.imread(args[\"image\"])\\n24 cv2.imshow(\"Original\", image)\\n25 plot_histogram(image, \"Histogram for Original Image\")\\nLines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 113, 'page_label': '102', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Lines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot\\nfor our image can be seen in Figure 7.5. We will refer to\\nthis histogram again once we compute a histogram for the\\nmasked region.\\nListing 7.10: histogram_with_mask.py\\n26 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n27 cv2.rectangle(mask, (15, 15), (130, 100), 255, -1)\\n28 cv2.imshow(\"Mask\", mask)\\n29\\n30 masked = cv2.bitwise_and(image, image, mask = mask)\\n31 cv2.imshow(\"Applying the Mask\", masked)\\n102'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 114, 'page_label': '103', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.5: Left: The original beach image. Right:\\nColor histograms for the red, green,\\nand blue channels. Compare these\\nhistograms to the histograms of the\\nmasked region of blue sky in Figure\\n7.7.\\n103'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 115, 'page_label': '104', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.6: Left: Our rectangular mask. Right:\\nApplying our mask to the beach im-\\nage using a bitwise AND. Now we\\nsee only the blue sky – the rest of the\\nimage is ignored.\\nNow we are ready to construct a mask for the image. We\\ndeﬁne our mask as a NumPy array, with the same width\\nand height as our beach image on Line 26. We then draw a\\nwhite rectangle starting from point(15, 15) to point (130, 100)\\non Line 27. This rectangle will serve as our mask – only pix-\\nels in our original image belonging to the masked region\\nwill be considered in the histogram computation.\\nTo visualize our mask, we apply a bitwise AND to the\\nbeach image ( Line 30), the results of which can be seen in\\nFigure 7.6. Notice how the image on the left is simply a\\nwhite rectangle, but when we apply our mask to the beach\\nimage, we only see the blue sky ( right).\\nListing 7.11: histogram_with_mask.py\\n32 plot_histogram(image, \"Histogram for Masked Image\", mask = mask)\\n104'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 116, 'page_label': '105', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\n33\\n34 plt.show()\\nFinally, we compute a histogram for our masked image\\nusing our plot_histogram function and show our results\\n(Lines 32-34).\\nWe can see our masked histogram in Figure 7.7. Most\\nred pixels fall in the range [0, 80], indicating that red pixels\\ncontribute very little to our image. This makes sense, since\\nour sky is blue. Green pixels are then present, but again,\\nare towards the darker end of the RGB spectrum. Finally,\\nour blue pixels fall in the brighter range and are obviously\\nour blue sky.\\nMost importantly, compare our masked color histograms\\nin Figure 7.5 to the unmasked color histograms in Figure\\n7.7 above. Notice how dramatically different the color his-\\ntograms are. By utilizing masks, we are able to apply our\\ncomputation only to the speciﬁc regions of the image that\\ninterest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 116, 'page_label': '105', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='interest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.\\nHistograms are simple, but are used extensively in image\\nprocessing and computer vision. Make sure you have a\\ngood grasp of histograms; you’ll certainly be using them in\\nthe future!\\n105'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 117, 'page_label': '106', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.7: The resulting histogram of the\\nmasked image in Figure 7.6. Red\\ncontributes little to our image and is\\ntowards the darker end of the spec-\\ntrum. Some lighter green values are\\npresent, and many light blue colors\\ncorrespond to the sky in the image.\\n106'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 118, 'page_label': '107', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFurther Reading\\nThe purpose of Chapter 7 was to learn how to extract\\nand visualize color histograms from an image. But\\nother than simply visualizing the color distributions of\\nan image, what else can we do? What are the actual\\napplications of utilizing color histograms?\\nTo learn how to compare color histograms for similar-\\nity, and even build an image search engine, take a look\\nat the Chapter 7 supplementary page:\\nhttp://pyimg.co/aa4ax\\n107'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 119, 'page_label': '108', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8\\nS M O O T H I N G A N D B L U R R I N G\\nI’m pretty sure we all know what blurring is. It’s what\\nhappens when your camera takes a picture out of focus.\\nSharper regions in the image lose their detail, normally as\\na disc/circular shape.\\nPractically, this means that each pixel in the image is\\nmixed in with its surrounding pixel intensities. This “mix-\\nture” of pixels in a neighborhood becomes our blurred pixel.\\nWhile this effect is usually unwanted in our photographs,\\nit’s actually quite helpful when performing image process-\\ning tasks.\\nIn fact, many image processing and computer vision func-\\ntions, such as thresholding and edge detection, perform bet-\\nter if the image is ﬁrst smoothed or blurred.\\nIn order to explore different types of blurring methods,\\nlet’s start with a baseline of our original T-Rex image in Fig-\\nure 8.1.\\nListing 8.1: blurring.py\\n108'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 120, 'page_label': '109', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='smoothing and blurring\\nFigure 8.1: Our original T-Rex image before ap-\\nplying any blurring effects.\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nIn order to perform image blurring, we ﬁrst need to im-\\nport our packages and parse our arguments (Lines 1-8). We\\nthen load our image and show it as a baseline to compare\\nour blurring methods to on Lines 10 and 11.\\n109'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 121, 'page_label': '110', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nNow that our image is loaded, we can start blurring our\\nimages.\\n8.1 averaging\\nThe ﬁrst blurring method we are going to explore is averag-\\ning.\\nAs the name suggests, we are going to deﬁne a k × k slid-\\ning window on top of our image, where k is always an odd\\nnumber. This window is going to slide from left-to-right\\nand from top-to-bottom. The pixel at the center of this ma-\\ntrix (we have to use an odd number, otherwise there would\\nnot be a true “center”) is then set to be the average of all\\nother pixels surrounding it.\\nWe call this sliding window a “convolution kernel” or\\njust a “kernel”. We’ll continue to use this terminology throu-\\nghout this chapter.\\nAs we will see, as the size of the kernel increases, the\\nmore blurred our image will become.\\nLet’s check out some code to perform average blurring:\\nListing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 121, 'page_label': '110', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Listing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)\\n17 cv2.waitKey(0)\\n110'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 122, 'page_label': '111', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nFigure 8.2: Performing averaging blurring with\\na 3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right).\\nIn order to average blur an image, we use the cv2.blur\\nfunction. This function requires two arguments: the image\\nwe want to blur and the size of the kernel. As Lines 13-15\\nshow, we blur our image with increasing-sized kernels. The\\nlarger our kernel becomes, the more blurred our image will\\nappear.\\nWe make use of the np.hstack function to stack our out-\\nput images together. This method “horizontally stacks” our\\nthree images into a row. This is useful since we don’t want\\nto create three separate windows using thecv2.imshow func-\\ntion.\\nThe output of our averaged blur can be seen in Figure 8.2.\\nThe image on the left is barely blurred, but by the time we\\nreach a kernel of size 7 × 7, we see that our T-Rex is very\\nblurry indeed. Perhaps he was running at a high speed and\\nchasing a jeep?\\n111'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 123, 'page_label': '112', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.2 gaussian\\nFigure 8.3: Performing Gaussian blurring with a\\n3 × 3 kernel ( left), 5 × 5 kernel ( mid-\\ndle), and 7 × 7 kernel ( right). Again,\\nour image becomes more blurred as\\nthe kernel size increases, but is less\\nblurred than the average method in\\nFigure 8.2.\\n8.2 gaussian\\nNext up, we are going to review Gaussian blurring. Gaus-\\nsian blurring is similar to average blurring, but instead of\\nusing a simple mean, we are now using a weighted mean,\\nwhere neighborhood pixels that are closer to the central\\npixel contribute more “weight” to the average.\\nThe end result is that our image is less blurred, but more\\nnaturally blurred, than using the average method discussed\\nin the previous section.\\nLet’s look at some code to perform Gaussian blurring:\\nListing 8.3: blurring.py\\n18 blurred = np.hstack([\\n19 cv2.GaussianBlur(image, (3, 3), 0),\\n112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 124, 'page_label': '113', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\n20 cv2.GaussianBlur(image, (5, 5), 0),\\n21 cv2.GaussianBlur(image, (7, 7), 0)])\\n22 cv2.imshow(\"Gaussian\", blurred)\\n23 cv2.waitKey(0)\\nHere you can see that we are making use of the cv2.\\nGaussianBlur function on Lines 19-21. The ﬁrst argument\\nto the function is the image we want to blur. Then, simi-\\nlar to cv2.blur, we provide a tuple representing our kernel\\nsize. Again, we start with a small kernel size of 3 × 3 and\\nstart to increase it.\\nThe last parameter is our σ, the standard deviation in the\\nx-axis direction. By setting this value to 0, we are instruct-\\ning OpenCV to automatically compute them based on our\\nkernel size.\\nWe can see the output of our Gaussian blur in Figure 8.3.\\nOur images have less of a blur effect than when using the\\naveraging method in Figure 8.2; however, the blur itself is\\nmore natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 124, 'page_label': '113', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='more natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median\\nTraditionally, the median blur method has been most ef-\\nfective when removing salt-and-pepper noise. This type of\\nnoise is exactly what it sounds like: imagine taking a photo-\\ngraph, putting it on your dining room table, and sprinkling\\nsalt and pepper on top of it. Using the median blur method,\\nyou could remove the salt and pepper from your image.\\n113'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 125, 'page_label': '114', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nWhen applying a median blur, we ﬁrst deﬁne our kernel\\nsize k. Then, as in the averaging blurring method, we con-\\nsider all pixels in the neighborhood of sizek ×k. But, unlike\\nthe averaging method, instead of replacing the central pixel\\nwith the average of the neighborhood, we instead replace\\nthe central pixel with the median of the neighborhood.\\nMedian blurring is more effective at removing salt-and-\\npepper style noise from an image because each central pixel\\nis always replaced with a pixel intensity that exists in the\\nimage.\\nAveraging and Gaussian methods can compute means or\\nweighted means for the neighborhood – this average pixel\\nintensity may or may not be present in the neighborhood.\\nBut by deﬁnition, the median pixel must exist in our neigh-\\nborhood. By replacing our central pixel with a median\\nrather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack(['),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 125, 'page_label': '114', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='rather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([\\n25 cv2.medianBlur(image, 3),\\n26 cv2.medianBlur(image, 5),\\n27 cv2.medianBlur(image, 7)])\\n28 cv2.imshow(\"Median\", blurred)\\n29 cv2.waitKey(0)\\nApplying a median blur is accomplished by making a call\\nto the cv2.medianBlur function. This method takes two pa-\\nrameters: the image we want to blur and the size of our\\nkernel. On Lines 25-27, we start off with a kernel size of\\n3, then increase it to 5 and 7. The resulting blurred images\\n114'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 126, 'page_label': '115', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nFigure 8.4: Applying the median blur method to\\nour T-Rex image with increasing ker-\\nnel sizes of 3 ( left), 5 ( middle), and\\n7 ( right), respectively. Notice that\\nwe are no longer creating a “motion\\nblur”.\\nare then stacked and displayed to us.\\nOur median blurred images can be seen in Figure 8.4.\\nNotice that we are no longer creating a “motion blur” ef-\\nfect like in averaging and Gaussian blurring – instead, we\\nare removing detail and noise.\\nFor example, take a look at the color of the scales of the\\nT-Rex. As our kernel size increases, the scales become less\\npronounced. The black and brown stripes on the legs and\\ntail of the T-Rex especially lose their detail, all without cre-\\nating a motion blur.\\n115'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 127, 'page_label': '116', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\n8.4 bilateral\\nThe last method we are going to explore is bilateral blur-\\nring.\\nThus far, the intention of our blurring methods has been\\nto reduce noise and detail in an image; however, we tend to\\nlose edges in the image.\\nIn order to reduce noise while still maintaining edges, we\\ncan use bilateral blurring. Bilateral blurring accomplishes\\nthis by introducing two Gaussian distributions.\\nThe ﬁrst Gaussian function only considers spatial neigh-\\nbors, that is, pixels that appear close together in the (x, y)\\ncoordinate space of the image. The second Gaussian then\\nmodels the pixel intensity of the neighborhood, ensuring\\nthat only pixels with similar intensity are included in the\\nactual computation of the blur.\\nOverall, this method is able to preserve edges of an im-\\nage, while still reducing noise. The largest downside to this\\nmethod is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 127, 'page_label': '116', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='method is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py\\n30 blurred = np.hstack([\\n31 cv2.bilateralFilter(image, 5, 21, 21),\\n32 cv2.bilateralFilter(image, 7, 31, 31),\\n33 cv2.bilateralFilter(image, 9, 41, 41)])\\n34 cv2.imshow(\"Bilateral\", blurred)\\n35 cv2.waitKey(0)\\n116'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 128, 'page_label': '117', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nFigure 8.5: Applying Bilateral blurring to our\\nbeach image. As the diameter of the\\nneighborhood, color σ, and space σ\\nincreases (from left to right), our im-\\nage has noise removed, yet still re-\\ntains edges and does not appear to\\nbe “motion blurred”.\\nWe apply bilateral blurring by calling thecv2.bilateralFil\\nter function on Lines 31-33. The ﬁrst parameter we supply\\nis the image we want to blur. Then, we need to deﬁne the\\ndiameter of our pixel neighborhood. The third argument\\nis our color σ. A larger value for color σ means that more\\ncolors in the neighborhood will be considered when com-\\nputing the blur. Finally, we need to supply the space σ. A\\nlarger value of space σ means that pixels farther out from\\nthe central pixel will inﬂuence the blurring calculation, pro-\\nvided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 128, 'page_label': '117', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='vided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be\\nseen in Figure 8.5. As the size of our parameters increases,\\nour image has noise removed, yet the edges still remain.\\n117'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 129, 'page_label': '118', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nNow that we know how to blur our images, we can move\\non to thresholding in the next chapter. You can be sure that\\nwe’ll make use of blurring throughout the rest of this book!\\nFurther Reading\\nOne topic that I didn’t get a chance to cover in detail in-\\nside Practical Python and OpenCV is the convolution op-\\neration. Whether you are smoothing an image, sharp-\\nening details, or detecting edges, convolutions are being\\napplied.\\nTo learn more convolutions, and the role they play in\\ncomputer vision, image processing, and deep learning,\\nbe sure to refer to the Chapter 8 supplementary mate-\\nrial:\\nhttp://pyimg.co/y454z\\n118'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 130, 'page_label': '119', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9\\nT H R E S H O L D I N G\\nThresholding is the binarization of an image. In general,\\nwe seek to convert a grayscale image to a binary image,\\nwhere the pixels are either 0 or 255.\\nA simple thresholding example would be selecting a pixel\\nvalue p, and then setting all pixel intensities less than p to\\nzero, and all pixel values greater than p to 255. In this way,\\nwe are able to create a binary representation of the image.\\nNormally, we use thresholding to focus on objects or ar-\\neas of particular interest in an image. In the examples in the\\nsections below, we will empty our pockets and look at our\\nspare change. Using thresholding methods, we’ll be able to\\nﬁnd the coins in an image.\\n9.1 simple thresholding\\nApplying simple thresholding methods requires human in-\\ntervention. We must specify a threshold value T. All pixel\\nintensities below T are set to 0. And all pixel intensities\\ngreater than T are set to 255.\\n119'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 131, 'page_label': '120', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nWe can also apply the inverse of this binarization by set-\\nting all pixels below T to 255 and all pixel intensities greater\\nthan T to 0.\\nLet’s explore some code to apply simple thresholding\\nmethods:\\nListing 9.1: simple_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\nOn Lines 1-10 we import our packages, parse our argu-\\nments, and load our image. From there, we convert the\\nimage from the RGB color space to grayscale on Line 11.\\nAt this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 131, 'page_label': '120', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='At this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.\\nListing 9.2: simple_thresholding.py\\n14 (T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\\n15 cv2.imshow(\"Threshold Binary\", thresh)\\n16\\n17 (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.\\nTHRESH_BINARY_INV)\\n120'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 132, 'page_label': '121', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nFigure 9.1: Top-Left: The original coins image in\\ngrayscale. Top-Right: Applying sim-\\nple binary thresholding. The coins\\nare shown in black and the back-\\nground in white. Bottom-Left: Apply-\\ning inverse binary thresholding. The\\ncoins are now white and the back-\\nground is black. Bottom-Right: Ap-\\nplying the inverse binary threshold\\nas a mask to the grayscale image. We\\nare now focused on only the coins in\\nthe image.\\n121'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 133, 'page_label': '122', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\n18 cv2.imshow(\"Threshold Binary Inverse\", threshInv)\\n19\\n20 cv2.imshow(\"Coins\", cv2.bitwise_and(image, image, mask =\\nthreshInv))\\n21 cv2.waitKey(0)\\nAfter the image is blurred, we compute the thresholded\\nimage on Line 14 using the cv2.threshold function. This\\nmethod requires four arguments. The ﬁrst is the grayscale\\nimage that we wish to threshold. We supply our blurred\\nimage here.\\nThen, we manually supply our T threshold value. We\\nuse a value of T = 155.\\nOur third argument is our maximum value applied dur-\\ning thresholding. Any pixel intensity p that is greater than\\nT, is set to this value. In our example, any pixel value that\\nis greater than 155 is set to 255. Any value that is less than\\n155 is set to zero.\\nFinally, we must provide a thresholding method. We use\\nthe cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 133, 'page_label': '122', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst\\nis T, the value we manually speciﬁed for thresholding. The\\nsecond is our actual thresholded image.\\nWe then show our thresholded image in Figure 9.1, Top-\\nRight. We can see that our coins are now black pixels and\\nthe white pixels are the background.\\n122'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 134, 'page_label': '123', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nOn Line 17 we apply inverse thresholding rather than\\nnormal thresholding by using cv2.THRESH_BINARY_INV as\\nour thresholding method. As we can see in Figure 9.1,\\nBottom-Left, our coins are now white and the background\\nis black. This is convenient as we will see in a second.\\nThe last task we are going to perform is to reveal the\\ncoins in the image and hide everything else.\\nRemember when we discussed masking? That will come\\nin handy here.\\nOn Line 20 we perform masking by using thecv2.bitwise_\\nand function. We supply our original coin image as the ﬁrst\\ntwo arguments, and then our inverted thresholded image as\\nour mask. Remember, a mask only considers pixels in the\\noriginal image where the mask is greater than zero. Since\\nour inverted thresholded image on Line 17 does a good job\\nat approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 134, 'page_label': '123', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='at approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our\\nmask – the coins are clearly revealed while the rest of the\\nimage is hidden.\\n9.2 adaptive thresholding\\nOne of the downsides of using simple thresholding meth-\\nods is that we need to manually supply our threshold value\\nT. Not only does ﬁnding a good value of T require a lot of\\nmanual experiments and parameter tunings, it’s not very\\n123'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 135, 'page_label': '124', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nFigure 9.2: Left: The grayscale coins image. Mid-\\ndle: Applying adaptive thresholding\\nusing mean neighborhood values.\\nRight: Applying adaptive threshold-\\ning using Gaussian neighborhood\\nvalues.\\nhelpful if the image exhibits a lot of range in pixel intensi-\\nties.\\nSimply put, having just one value of T might not sufﬁce.\\nIn order to overcome this problem, we can use adap-\\ntive thresholding, which considers small neighbors of pixels\\nand then ﬁnds an optimal threshold value T for each neigh-\\nbor. This method allows us to handle cases where there\\nmay be dramatic ranges of pixel intensities and the optimal\\nvalue of T may change for different parts of the image.\\nLet’s go ahead and jump into some code that applies\\nadaptive thresholding:\\n124'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 136, 'page_label': '125', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nListing 9.3: adaptive_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\n14\\n15 thresh = cv2.adaptiveThreshold(blurred, 255,\\n16 cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\\n17 cv2.imshow(\"Mean Thresh\", thresh)\\n18\\n19 thresh = cv2.adaptiveThreshold(blurred, 255,\\n20 cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\\n21 cv2.imshow(\"Gaussian Thresh\", thresh)\\n22 cv2.waitKey(0)\\nLines 1-10 once again handle setting up our example. We\\nimport our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 136, 'page_label': '125', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='import our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it\\nslightly on Lines 11 and 12.\\nWe then apply adaptive thresholding to our blurred im-\\nage using the cv2.adaptiveThreshold function on Line 15.\\nThe ﬁrst parameter we supply is the image we want to\\nthreshold. Then, we supply our maximum value of 255,\\nsimilar to simple thresholding mentioned above.\\nThe third argument is our method to compute the thresh-\\nold for the current neighborhood of pixels. By supplying\\ncv2.ADAPTIVE_THRESH_MEAN_C, we indicate that we want to\\ncompute the mean of the neighborhood of pixels and treat\\n125'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 137, 'page_label': '126', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nit as our T value.\\nNext, we need our thresholding method. Again, the de-\\nscription of this parameter is identical to the simple thresh-\\nolding method mentioned above. We usecv2.THRESH_BINAR\\nY_INV to indicate that any pixel intensity greater than T in\\nthe neighborhood should be set to 255, otherwise it should\\nbe set to 0.\\nThe next parameter is our neighborhood size. This inte-\\nger value must be odd and indicates how large our neigh-\\nborhood of pixels is going to be. We supply a value of 11,\\nindicating that we are going to examine 11 × 11 pixel re-\\ngions of the image, instead of trying to threshold the image\\nglobally, as in simple thresholding methods.\\nFinally, we supply a parameter simply called C. This\\nvalue is an integer that is subtracted from the mean, allow-\\ning us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 137, 'page_label': '126', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ing us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.\\nBesides applying standard mean thresholding, we can\\nalso apply Gaussian (weighted mean) thresholding, as we\\ndo on Line 19. The order of the parameters are identical to\\nLine 15, but now we are tuning a few of the values.\\nInstead of supplying a value of cv2.ADAPTIVE_THRESH_\\nMEAN_C, we instead use cv2.ADAPTIVE_THRESH_GAUSSIAN_C\\nto indicate we want to use the weighted mean. We are\\nalso using a 15 × 15 pixel neighborhood size rather than\\n126'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 138, 'page_label': '127', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nan 11 × 11 neighborhood size as in the previous example.\\nWe also alter our C value (the value we subtract from the\\nmean) slightly and use 3 rather than 4.\\nThe results of applying Gaussian adaptive thresholding\\ncan be seen in the right image of Figure 9.2. There is little\\ndifference between the two images.\\nIn general, choosing between mean adaptive threshold-\\ning and Gaussian adaptive thresholding requires a few ex-\\nperiments on your end. The most important parameters\\nto vary are the neighborhood size and C, the value you\\nsubtract from the mean. By experimenting with this value,\\nyou will be able to dramatically change the results of your\\nthresholding.\\n9.3 otsu and riddler -calvard\\nAnother way we can automatically compute the threshold\\nvalue of T is to use Otsu’s method.\\nOtsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 138, 'page_label': '127', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Otsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.\\nWhile OpenCV provides support for Otsu’s method, I\\nprefer the implementation by Luis Pedro Coelho in themahotas\\npackage since it is more Pythonic.\\nLet’s jump into some sample code:\\n127'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 139, 'page_label': '128', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nListing 9.4: otsu_and_riddler.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import mahotas\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n15 cv2.imshow(\"Image\", image)\\n16\\n17 T = mahotas.thresholding.otsu(blurred)\\n18 print(\"Otsu’s threshold: {}\".format(T))\\nOn Lines 1-5 we import the packages we will utilize. We\\nhave seen numpy, argparse, and cv2 before. We are now\\nintroducing mahotas, another image processing package.\\nLines 7-12 then handle our standard practice of parsing\\narguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 139, 'page_label': '128', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='arguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-\\ntion in the mahotas.thresholding package. As our output\\nwill later show us, Otsu’s method ﬁnds a value of T = 137\\nthat we will use for thresholding.\\nListing 9.5: otsu_and_riddler.py\\n19 thresh = image.copy()\\n20 thresh[thresh > T] = 255\\n128'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 140, 'page_label': '129', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\n21 thresh[thresh < 255] = 0\\n22 thresh = cv2.bitwise_not(thresh)\\n23 cv2.imshow(\"Otsu\", thresh)\\n24\\n25 T = mahotas.thresholding.rc(blurred)\\n26 print(\"Riddler-Calvard: {}\".format(T))\\n27 thresh = image.copy()\\n28 thresh[thresh > T] = 255\\n29 thresh[thresh < 255] = 0\\n30 thresh = cv2.bitwise_not(thresh)\\n31 cv2.imshow(\"Riddler-Calvard\", thresh)\\n32 cv2.waitKey(0)\\nApplying the thresholding is accomplished on Lines 19-\\n22. First, we make a copy of our grayscale image so that we\\nhave an image to threshold. Line 20 then makes any values\\ngreater than T white, whereas Line 21 makes all remaining\\npixels that are not white into black pixels. We then invert\\nour threshold by using cv2.bitwise_not. This is equivalent\\nto applying a cv2.THRESH_BINARY_INV thresholding type as\\nin previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 140, 'page_label': '129', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='in previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.\\nAnother method to keep in mind when ﬁnding optimal\\nvalues for T is the Riddler-Calvard method. Just as in\\nOtsu’s method, the Riddler-Calvard method also computes\\nan optimal value of 137 for T. We apply this method on\\nLine 25 using the rc function in mahotas.thresholding. Fi-\\nnally, the actual thresholding of the image takes place on\\nLines 27-30, as in the previous example. Given that the\\nvalues of T are identical for Otsu and Riddler-Calvard, the\\nthresholded image in Figure 9.3 (right) is identical to the\\nthresholded image in the center.\\n129'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 141, 'page_label': '130', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFigure 9.3: Left: The original grayscale coins\\nimage. Middle: Applying Otsu’s\\nmethod to ﬁnd an optimal value of T.\\nRight: Applying the Riddler-Calvard\\nmethod to ﬁnd an optimal value of\\nT.\\nListing 9.6: otsu_and_riddler.py\\nOtsu’s threshold: 137\\nRiddler-Calvard: 137\\nNow that we have explored thresholding, we will move\\non to another powerful image processing technique – edge\\ndetection.\\n130'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 142, 'page_label': '131', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFurther Reading\\nThresholding is often used as a method to segment the\\nforeground of an image from the background. This\\nworks ﬁne for foreground objects that can be cleanly\\nsegmented. But what if your foreground objects “touch”,\\nthereby making segmentation more difﬁcult. What do\\nyou do then?\\nThe answer is to apply the watershed algorithm, which I\\ncover inside the Chapter 9 supplementary material:\\nhttp://pyimg.co/z1ef6\\n131'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 143, 'page_label': '132', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10\\nG R A D I E N T S A N D E D G E D E T E C T I O N\\nThis chapter is primarily concerned with gradients and\\nedge detection. Formally, edge detection embodies math-\\nematical methods to ﬁnd points in an image where the\\nbrightness of pixel intensities changes distinctly.\\nThe ﬁrst thing we are going to do is ﬁnd the “gradient” of\\nthe grayscale image, allowing us to ﬁnd edge-like regions\\nin the x and y direction.\\nWe’ll then apply Canny edge detection, a multi-stage pro-\\ncess of noise reduction (blurring), ﬁnding the gradient of\\nthe image (utilizing the Sobel kernel in both the horizon-\\ntal and vertical direction), non-maximum suppression, and\\nhysteresis thresholding.\\nIf that sounds like a mouthful, it’s because it is. Again,\\nwe won’t jump too far into the details since this book is con-\\ncerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 143, 'page_label': '132', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the\\nalgorithms. Overall, they are not complicated and can be\\n132'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 144, 'page_label': '133', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.1: Left: The original coins image.\\nRight: Applying the Laplacian\\nmethod to obtain the gradient of the\\nimage.\\ninsightful to the behind-the-scenes action of OpenCV .\\n10.1 laplacian and sobel\\nLet’s go ahead and explore some code:\\nListing 10.1: sobel_and_laplacian.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 cv2.imshow(\"Original\", image)\\n133'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 145, 'page_label': '134', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\n13\\n14 lap = cv2.Laplacian(image, cv2.CV_64F)\\n15 lap = np.uint8(np.absolute(lap))\\n16 cv2.imshow(\"Laplacian\", lap)\\n17 cv2.waitKey(0)\\nLines 1-8 import our packages and set up our argument\\nparser. From there, we load our image and convert it to\\ngrayscale on Lines 10 and 11. When computing gradients\\nand edges, we (normally) compute them on a single chan-\\nnel – in this case, we are using the grayscale image; how-\\never, we can also compute gradients for each channel of\\nthe RGB image. For the sake of simplicity, let’s stick with\\nthe grayscale image since that is what you will use in most\\ncases.\\nOn Line 14, we use the Laplacian method to compute the\\ngradient magnitude image by calling the cv2.Laplacian\\nfunction. The ﬁrst argument is our grayscale image – the\\nimage we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 145, 'page_label': '134', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='image we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-\\nsigned integers. Why are we using a 64-bit ﬂoat now?\\nThe reason involves the transition of black-to-white and\\nwhite-to-black in the image.\\nTransitioning from black-to-white is considered a posi-\\ntive slope, whereas a transition from white-to-black is a\\nnegative slope. If you remember our discussion of image\\narithmetic in Chapter 6, you’ll know that an 8-bit unsigned\\ninteger does not represent negative values. Either it will be\\nclipped to zero if you are using OpenCV or a modulus op-\\n134'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 146, 'page_label': '135', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\neration will be performed using NumPy.\\nThe short answer here is that if you don’t use a ﬂoating\\npoint data type when computing the gradient magnitude\\nimage, you will miss edges, speciﬁcally the white-to-black\\ntransitions.\\nIn order to ensure you catch all edges, use a ﬂoating point\\ndata type, then take the absolute value of the gradient im-\\nage and convert it back to an 8-bit unsigned integer, as in\\nLine 15. This is deﬁnitely an important technique to take\\nnote of – otherwise you’ll be missing edges in your image!\\nTo see the results of our gradient processing, take a look\\nat Figure 10.1.\\nLet’s move on to computing the Sobel gradient represen-\\ntation:\\nListing 10.2: sobel_and_laplacian.py\\n18 sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\\n19 sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\\n20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 146, 'page_label': '135', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)\\n27 cv2.imshow(\"Sobel Y\", sobelY)\\n28 cv2.imshow(\"Sobel Combined\", sobelCombined)\\n29 cv2.waitKey(0)\\nUsing the Sobel operator, we can compute gradient mag-\\nnitude representations along the x and y axis, allowing us\\n135'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 147, 'page_label': '136', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.2: Top-Left: The original coins image.\\nTop-Right: Computing the Sobel gra-\\ndient magnitude along the x-axis\\n(ﬁnding vertical edges). Bottom-\\nLeft: Computing the Sobel gradient\\nalong the y-axis (ﬁnding horizontal\\nedges). Bottom-Right: Applying a\\nbitwise OR to combine the two So-\\nbel representations.\\n136'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 148, 'page_label': '137', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nto ﬁnd both horizontal and vertical edge-like regions.\\nIn fact, that’s exactly what Lines 18 and 19 do by us-\\ning the cv2.Sobel method. The ﬁrst argument to the Sobel\\noperator is the image we want to compute the gradient rep-\\nresentation for. Then, just like in the Laplacian example\\nabove, we use a ﬂoating point data type. The last two argu-\\nments are the order of the derivatives in the x and y direc-\\ntion, respectively. Specify a value of 1 and 0 to ﬁnd vertical\\nedge-like regions and 0 and 1 to ﬁnd horizontal edge-like\\nregions\\nOn Lines 21 and 22 we then ensure we ﬁnd all edges by\\ntaking the absolute value of the ﬂoating point image and\\nthen converting it to an 8-bit unsigned integer.\\nIn order to combine the gradient images in both the x\\nand y direction, we can apply a bitwise OR. Remember, an\\nOR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 148, 'page_label': '137', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='OR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.\\nFinally, we show our gradient images on Lines 26-29.\\nYou can see the result of our work in Figure 10.2. We\\nstart with our original image, Top-Left, and then ﬁnd vertical\\nedges, Top-Right, and horizontal edges, Bottom-Left. Finally,\\nwe compute a bitwise OR to combine the two directions\\ninto a single image, Bottom-Right.\\nOne thing you’ll notice is that the edges are very “noisy”.\\nThey are not clean and crisp. We’ll remedy that by using\\n137'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 149, 'page_label': '138', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFigure 10.3: Left: Our coins image in grayscale\\nand blurred slightly. Right: Apply-\\ning the Canny edge detector to the\\nblurred image to ﬁnd edges. No-\\ntice how our edges are more “crisp”\\nand the outlines of the coins are\\nfound.\\nthe Canny edge detector in the next section.\\n10.2 canny edge detector\\nThe Canny edge detector is a multi-step process. It involves\\nblurring the image to remove noise, computing Sobel gradi-\\nent images in the x and y direction, suppressing edges, and\\nﬁnally a hysteresis thresholding stage that determines if a\\npixel is “edge-like” or not.\\n138'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 150, 'page_label': '139', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nWe won’t get into all these steps in detail. Instead, we’ll\\njust look at some code and show how it’s done:\\nListing 10.3: canny.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 image = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Blurred\", image)\\n14\\n15 canny = cv2.Canny(image, 30, 150)\\n16 cv2.imshow(\"Canny\", canny)\\n17 cv2.waitKey(0)\\nThe ﬁrst thing we do is import our packages and parse\\nour arguments. We then load our image, convert it to graysc-\\nale, and blur it using the Gaussian blurring method. By ap-\\nplying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 150, 'page_label': '139', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='plying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.\\nApplying the Canny edge detector is performed on Line\\n15 using the cv2.Canny function. The ﬁrst argument we\\nsupply is our blurred, grayscale image. Then, we need to\\nprovide two values: threshold1 and threshold2.\\nAny gradient value larger than threshold2 is considered\\nto be an edge. Any value below threshold1 is consid-\\nered not to be an edge. Values in between threshold1\\nand threshold2 are either classiﬁed as edges or non-edges\\n139'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 151, 'page_label': '140', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nbased on how their intensities are “connected”. In this case,\\nany gradient values below 30 are considered non-edges wh-\\nereas any values above 150 are considered edges.\\nWe then show the results of our edge detection on Line\\n16.\\nFigure 10.3 shows the results of the Canny edge detector.\\nThe image on the left is the grayscale, blurred image that\\nwe pass into the Canny operator. The image on the right is\\nthe result of applying the Canny operator.\\nNotice how the edges are more “crisp”. We have substan-\\ntially less noise than when we used the Laplacian or Sobel\\ngradient images. Furthermore, the outline of our coins are\\nclearly revealed.\\nIn the next chapter, we’ll continue to make use of the\\nCanny edge detector and use it to count the number of\\ncoins in our image.\\n140'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 152, 'page_label': '141', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFurther Reading\\nJust like thresholding is a common method for seg-\\nmenting foreground objects from background objects,\\nthe same can be said for edge detection – only instead\\nof obtaining a large blob representing the foreground,\\nthe Canny detector gives us the outline.\\nHowever, a common challenge of using the Canny edge\\ndetector is getting the lower and upper edge thresh-\\nolds just right. In order to help you (automatically)\\ndetermine these lower and upper boundaries, be sure\\nto read about the automatic Canny edge detector in this\\nsupplementary material:\\nhttp://pyimg.co/91daw\\n141'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 153, 'page_label': '142', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11\\nC O N T O U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in the curve. Contours are extremely useful for such\\nthings as shape approximation and analysis.\\nIn order to ﬁnd contours in an image, you need to ﬁrst ob-\\ntain a binarization of the image, using either edge detection\\nmethods or thresholding. In the examples below, we’ll use\\nthe Canny edge detector to ﬁnd the outlines of the coins,\\nand then ﬁnd the actual contours of the coins.\\nReady?\\nHere we go:\\n11.1 counting coins\\n142'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 154, 'page_label': '143', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nListing 11.1: counting_coins.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n13 blurred = cv2.GaussianBlur(gray, (11, 11), 0)\\n14 cv2.imshow(\"Image\", image)\\n15\\n16 edged = cv2.Canny(blurred, 30, 150)\\n17 cv2.imshow(\"Edges\", edged)\\nThe ﬁrst 11 lines of code simply set up our environment\\nby importing packages, parsing arguments, and loading the\\nimage.\\nJust as in the edge detection methods discussed in the\\nprevious chapter, we are going to convert our image to\\ngrayscale and then apply a Gaussian blur, making it eas-\\nier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 154, 'page_label': '143', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.\\nWe then obtain the edged image by applying the Canny\\nedge detector on Line 16. Again, just as in previous edge\\ndetection examples, any gradient values below 30 are con-\\nsidered non-edges whereas any values above 150 are con-\\nsidered sure edges.\\nListing 11.2: counting_coins.py\\n143'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 155, 'page_label': '144', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n18 (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2\\n.CHAIN_APPROX_SIMPLE)\\n19\\n20 print(\"I count {} coins in this image\".format(len(cnts)))\\n21\\n22 coins = image.copy()\\n23 cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\\n24 cv2.imshow(\"Coins\", coins)\\n25 cv2.waitKey(0)\\nNow that we have the outlines of the coins, we can ﬁnd\\nthe contours of the outlines. We do this using the cv2.\\nfindContours function on Line 18. This method returns\\na 3-tuple of: ( 1) our image after applying contour detec-\\ntion (which is modiﬁed and essentially destroyed), ( 2) the\\ncontours themselves, cnts, and (3) the hierarchy of the con-\\ntours (see below).\\nThe ﬁrst argument to cv2.findContours is our edged im-\\nage. It’s important to note that this function is destructive\\nto the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 155, 'page_label': '144', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='to the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.\\nWe use cv2.RETR_EXTERNAL to retrieve only the outermost\\ncontours (i.e., the contours that follow the outline of the\\ncoin). We can also pass in cv2.RETR_LIST to grab all con-\\ntours. Other methods include hierarchical contours using\\ncv2.RETR_COMP and cv2.RETR_TREE, but hierarchical con-\\ntours are outside the scope of this book.\\nOur last argument is how we want to approximate the\\ncontour. We use cv2.CHAIN_APPROX_SIMPLE to compress\\nhorizontal, vertical, and diagonal segments into their end-\\npoints only. This saves both computation and memory. If\\n144'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 156, 'page_label': '145', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nwe wanted all the points along the contour, without com-\\npression, we can pass in cv2.CHAIN_APPROX_NONE; however,\\nbe very sparing when using this function. Retrieving all\\npoints along a contour is often unnecessary and is wasteful\\nof resources.\\nOur contours cnts is simply a Python list. We can use\\nthe len function on it to count the number of contours that\\nwere returned. We do this on Line 20 to show how many\\ncontours we have found.\\nWhen we execute our script, we will have the output “I\\ncount 9 coins in this image” printed out to our console.\\nNow, we are able to draw our contours. In order not to\\ndraw on our original image, we make a copy of the original\\nimage, called coins on Line 22.\\nA call to cv2.drawContours draws the actual contours on\\nour image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 156, 'page_label': '145', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='our image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative\\nvalue of −1, we are indicating that we want to draw all of\\nthe contours. However, we would also supply an index i,\\nwhich would be the i’th contour in cnts. This would allow\\nus to draw only a single contour rather than all of them.\\nFor example, here is some code to draw the ﬁrst, second,\\nand third contours, respectively:\\nListing 11.3: Drawing Contours via an Index\\n1 cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)\\n145'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 157, 'page_label': '146', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n2 cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)\\n3 cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)\\nThe fourth argument to the cv2.drawContours function\\nis the color of the line we are going to draw. Here, we use\\na green color.\\nFinally, our last argument is the thickness of the line we\\nare drawing. We’ll draw the contour with a thickness of\\ntwo pixels.\\nNow that our contours are drawn on the image, we can\\nvisualize them on Line 24.\\nTake a look at Figure 11.1 to see the results of our work.\\nOn the left is our original image. Then, we apply Canny\\nedge detection to ﬁnd the outlines of the coins ( middle). Fi-\\nnally, we ﬁnd the contours of the coin outlines and draw\\nthem. You can see that each contour has been drawn with\\na two-pixel thick green line.\\nBut we’re not done yet!\\nLet’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 157, 'page_label': '146', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Let’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))\\n30 coin = image[y:y + h, x:x + w]\\n31 cv2.imshow(\"Coin\", coin)\\n32\\n33 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n34 ((centerX, centerY), radius) = cv2.minEnclosingCircle(c)\\n146'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 158, 'page_label': '147', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nFigure 11.1: Left: The original coin image. Mid-\\ndle: Applying the Canny edge detec-\\ntor to ﬁnd the outlines of the coins.\\nRight: Finding the contours of the\\ncoin outlines and then drawing the\\ncontours. We have now success-\\nfully found the coins and are able\\nto count them.\\n147'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 159, 'page_label': '148', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n35 cv2.circle(mask, (int(centerX), int(centerY)), int(radius),\\n255, -1)\\n36 mask = mask[y:y + h, x:x + w]\\n37 cv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask =\\nmask))\\n38 cv2.waitKey(0)\\nWe start off on Line 26 by looping over our contours.\\nWe then use the cv2.boundingRect function on the cur-\\nrent contour. This method ﬁnds the “enclosing box” that\\nour contour will ﬁt into, allowing us to crop it from the\\nimage. The function takes a single parameter, a contour,\\nand then returns a tuple of the x and y position that the\\nrectangle starts at, followed by the width and height of the\\nrectangle.\\nWe then crop the coin from the image using our bound-\\ning box coordinates and NumPy array slicing on Line 30.\\nThe coin itself is shown to us on Line 31.\\nIf we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 159, 'page_label': '148', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='If we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array\\nof zeros, with the same width and height of our original\\nimage.\\nA call to cv2.minEnclosingCircle on Line 34 ﬁts a circle\\nto our contour. We pass in a circle variable, the current\\ncontour, and are given the x and y coordinates of the circle,\\nalong with its radius.\\nUsing the (x, y) coordinates and the radius, we can draw\\na circle on our mask, representing the coin. Drawing circles\\n148'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 160, 'page_label': '149', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work. The\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 160, 'page_label': '149', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2 contours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 161, 'page_label': '150', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nFigure 11.2: Top: Cropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing. Bottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 162, 'page_label': '151', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, thegrab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6 if len(cnts) == 2:\\n7 cnts = cnts[0]\\n8\\n9 elif len(cnts) == 3:\\n10 cnts = cnts[1]\\n11\\n12 else:\\n13 raise Exception((\"Contours tuple must have length 2 or \"\\n14 \"3, otherwise OpenCV changed their cv2.findContours \"\\n15 \"return signature yet again. Refer to OpenCV’s\\n16 documentation in that case.\"))\\n17\\n18 return cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 162, 'page_label': '151', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)\\nOn Line 1 we call the cv2.findContours function to de-\\ntect contours in an image.\\nFrom there, Line 2 utilizes the grab_contours function\\nto inspect the tuple returned by cv2.findContours and ex-\\n151'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 163, 'page_label': '152', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 163, 'page_label': '152', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplementary material for this chap-\\nter – be sure to take a look:\\nhttp://pyimg.co/saz76\\n152'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 164, 'page_label': '153', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12\\nW H E R E T O N O W ?\\nIn this book, we’ve explored many image processing and\\ncomputer vision techniques, including basic image process-\\ning, such as translation, rotating, and resizing. We learned\\nall about image arithmetic and how to apply bitwise op-\\nerations. Then, we explored how a simple technique like\\nmasking can be used to focus our attention and computa-\\ntion to only a single part of an image.\\nTo better understand the pixel intensity distribution of an\\nimage, we then explored histograms. We started by com-\\nputing grayscale histograms, then worked our way up to\\ncolor, including 2D and 3D color histograms. We adjusted\\nthe contrast of images using histogram equalization, then\\nmoved on to blurring our images, using different methods,\\nsuch as averaging, Gaussian, and median ﬁltering.\\nWe thresholded our images to ﬁnd objects of interest,\\nthen applied edge detection.\\nFinally we learned how to use contours to count the num-\\nber of coins in the image.\\n153'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 165, 'page_label': '154', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='where to now ?\\nSo, where do you go from here?\\nYou continue learning, exploring, and experimenting!\\nUse the source code and images provided in this book to\\ncreate projects of your own. That’s the best way to learn!\\nIf you need project ideas, be sure to contact me. I love\\ntalking with readers and helping out when I can. You can\\nreach me at adrian@pyimagesearch.com.\\nFinally, I constantly post on my blog, www.PyImageSear\\nch.com, sharing new and interesting techniques related to\\ncomputer vision and image search engines. Be sure to fol-\\nlow the blog for new posts, as well as new books and courses\\nas I write them.\\n154'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 0, 'page_label': '1', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='SQL-QUERIES\\nTables\\nYou\\tneed\\tto\\tcreate\\tand\\tpopulate\\tthe\\tfollowing\\ttables\\tto\\tstart\\tworking\\ton\\tthe\\nqueries.\\n1.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEmp\\ttable\\tdata'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 3, 'page_label': '4', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.\\t\\t\\t\\tExercises\\twith\\tAnswers\\n2.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tinformation\\tof\\tthe\\tEMP\\ttable?\\nA)\\tselect\\t*\\tfrom\\temp;\\n2.2.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tunique\\tJobs\\tfrom\\tEMP\\ttable?\\nA)\\t\\t\\t\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp;\\nB)\\t\\t\\t\\tselect\\tunique\\tjob\\tfrom\\temp;\\n2.3.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\ttheir\\tSalaries?\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\torder\\tby\\tsal\\tasc;\\n2.4.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tasc\\torder\\tof\\tthe\\tDptnos\\tand\\tdesc\\tof\\nJobs?\\nA)select\\t*\\tfrom\\temp\\torder\\tby\\tdeptno\\tasc,job\\tdesc;\\n2.5.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tunique\\tjob\\tgroups\\tin\\tthe\\tdescending\\torder?\\nA)select\\tdistinct\\tjob\\tfrom\\temp\\torder\\tby\\tjob\\tdesc;\\n2.6.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tall\\t‘Mgrs’\\nA)Select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(\\tselect\\t\\tmgr\\t\\tfrom\\temp)\\t;\\n2.7.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tbefore\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(’01-jan-81’);\\n2.8.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDaily\\tsal\\tof\\tall\\temps\\tin\\tthe\\tasc\\torder\\tof\\nAnnsal.\\nA)\\tselect\\tempno\\t,ename\\t,sal,sal/30,12*sal\\tannsal\\tfrom\\temp\\torder\\tby\\tannsal\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 4, 'page_label': '5', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.9.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tjob,\\tHiredate,\\tExp\\tof\\tall\\tMgrs\\t\\nA)\\tselect\\t\\tempno,ename\\t,job,hiredate,\\tmonths_between(sysdate,hiredate)\\t\\texp\\nfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n2.10.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tExp\\tof\\tall\\temps\\tworking\\tfor\\tMgr\\t7369.\\nA)\\tselect\\tempno,ename,sal,exp\\tfrom\\temp\\twhere\\tmgr\\t=\\t7369;\\n2.11.\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tComm.\\tIs\\tmore\\tthan\\ttheir\\tSal.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tcomm.\\t>\\tsal;\\n2.12.\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\tDesignations\\tof\\tthose\\tjoined\\tafter\\tthe\\nsecond\\thalf\\tof\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t>\\t(’30-jun-81’)\\tand\\nto_char(hiredate,’YYYY’)\\t=\\t1981\\torder\\tby\\tjob\\tasc;\\n2.13.\\t\\t\\t\\t\\tList\\tthe\\temps\\talong\\twith\\ttheir\\tExp\\tand\\tDaily\\tSal\\tis\\tmore\\tthan\\tRs.100.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 4, 'page_label': '5', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;\\n2.15.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\ton\\t1-MAY-81,3-DEC-81,17-DEC-81,19-JAN-\\n80\\tin\\tasc\\torder\\tof\\tseniority.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\tin\\t(’01-may-81’,’03-dec-81’,’17-dec-\\n81’,’19-jan-80’)\\t\\torder\\tby\\thiredate\\tasc;\\n2.16.\\t\\t\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tworking\\tfor\\tthe\\tDeptno\\t10\\tor20.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 5, 'page_label': '6', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\t\\tor\\tdeptno\\t=\\t20\\t;\\n2.17.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\thiredate\\tbetween\\t’01-jan-81’\\tand\\t’31-dec-81’;\\n2.18.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tmonth\\tof\\tAug\\t1980.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-aug-80’\\tand\\t’31-aug-80’;\\t\\t\\n(OR)\\nselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon-yyyy’)\\t=’aug-1980;\\n2.19.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWho\\tAnnual\\tsal\\tranging\\tfrom\\t22000\\tand\\t45000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t12*sal\\tbetween\\t22000\\tand\\t45000;\\n2.20.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\thaving\\tfive\\tcharacters\\tin\\ttheir\\tNames.\\nA)\\tselect\\t\\tename\\tfrom\\temp\\twhere\\t\\tlength\\t(ename)\\t=\\t5;\\n2.21.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\tstarting\\twith\\t‘S’\\tand\\twith\\tfive\\tcharacters.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘S%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 5, 'page_label': '6', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;\\n2.23.\\t\\t\\t\\t\\tList\\tthe\\tFive\\tcharacter\\tnames\\tstarting\\twith\\t‘S’\\tand\\tending\\twith\\t‘H’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t5\\tand\\tename\\tlike\\t\\t‘S%H’;\\n2.24.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tJanuary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’mon’)\\t=\\t‘jan’;\\n2.25.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\twhich\\tsecond\\tcharacter\\tis\\t‘a’.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\t\\tlike\\t‘_a_’;\\t(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 6, 'page_label': '7', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='B)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\tlike\\t‘_a%’;\\n2.26.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tSal\\tis\\tfour\\tdigit\\tnumber\\tending\\twith\\tZero.\\nA)\\tselect\\t\\t*\\t\\tfrom\\t\\temp\\twhere\\t\\tlength\\t(sal)\\t=\\t4\\tand\\tsal\\tlike\\t‘%0’;\\n2.27.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\thaving\\ta\\tcharacter\\tset\\t‘ll’\\ttogether.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘%LL%’;\\n2.28.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\t80’s.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’yy’)\\t\\tlike\\t‘8%’;\\n2.29.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tdoes\\tnot\\tbelong\\tto\\tDeptno\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\tnot\\tin\\t(20);\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\t!=\\t20;\\t(OR)\\nC)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t<>20;\\t(OR)\\nD)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tlike\\t‘20’;\\n2.30.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\texcept\\t‘PRESIDENT’\\t&\\t‘MGR”\\tin\\tasc\\torder\\tof\\nSalaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 6, 'page_label': '7', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Salaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;\\nC)\\tSelect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t‘PRESIDENT’\\tand\\tjob\\t<>\\t‘MANAGER’\\t\\norder\\t\\tby\\t\\tsal\\t\\tasc;\\n2.31.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\twho\\tjoined\\tbefore\\tor\\tafter\\t1981.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 7, 'page_label': '8', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’YYYY’)\\t\\tnot\\tin\\t(‘1981’);\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\t(\\thiredate,’YYYY’)\\t\\t!=\\t\\t‘1981’;\\t\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t\\t<>\\t\\t‘1981’\\t;\\t(OR)\\nD)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate\\t,’YYYY’)\\t\\tnot\\tlike\\t‘1981’;\\n2.32.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tEmpno\\tnot\\tstarting\\twith\\tdigit78.\\nA)\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tnot\\tlike\\t‘78%’;\\n2.33.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tunder\\t‘MGR’.\\nA)\\tselect\\te.ename\\t||\\t‘\\tworks\\tfor\\t‘\\t||\\tm.ename\\t\\tfrom\\temp\\te\\t,emp\\tm\\twhere\\te.mgr\\t=\\nm.empno\\t;\\t\\t\\t\\t\\t\\t\\t\\t(OR)\\nB)\\tselect\\t\\te.ename\\t||\\t‘\\thas\\tan\\temployee\\t‘||\\tm.ename\\tfrom\\temp\\te\\t,\\temp\\tm\\twhere\\ne.empno\\t=\\tm.mgr;\\n2.34.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tany\\tyear\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tof\\nMarch.\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\t\\tto_char\\t(hiredate,’MON’)\\tnot\\tin\\t(‘MAR’);\\t\\t(OR)\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 7, 'page_label': '8', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='F)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\t<>\\t‘MAR’;\\n2.35.\\t\\t\\t\\t\\tList\\tall\\tthe\\tClerks\\tof\\tDeptno\\t20.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\t=‘CLERK’\\tand\\tdeptno\\t=\\t20;\\n2.36.\\t\\t\\t\\t\\tList\\tthe\\temps\\tof\\tDeptno\\t30\\tor\\t10\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’\\tand\\t(deptno'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 8, 'page_label': '9', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='=30\\tor\\tdeptno\\t=10)\\t;\\t\\t(OR)\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\n(hiredate,’YYYY’)\\t\\tin\\t(‘1981’)\\t\\tand\\t\\t(deptno\\t=\\t30\\tor\\tdeptno\\t=10\\t)\\t;\\n2.37.\\t\\t\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tSMITH.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’\\t;\\n2.38.\\t\\t\\t\\t\\tDisplay\\tthe\\tlocation\\tof\\t\\tSMITH.\\nA)\\tselect\\tloc\\tfrom\\temp\\t\\te\\t,\\tdept\\td\\twhere\\t\\te.ename\\t=\\t‘SMITH’\\tand\\t\\te.deptno\\t=\\nd.deptno\\t;\\n2.39.\\t\\t\\t\\t\\tList\\tthe\\ttotal\\tinformation\\tof\\tEMP\\ttable\\talong\\twith\\tDNAME\\tand\\tLoc\\tof\\nall\\tthe\\temps\\tWorking\\tUnder\\t‘ACCOUNTING’\\t&\\t‘RESEARCH’\\tin\\tthe\\tasc\\nDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t(dname\\t=\\t‘ACCOUNTING’\\tor\\tdname\\n=’RESEARCH’\\t)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\tasc;\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.dname\\tin\\n(‘ACCOUNTING’,’RESEARCH’)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\nasc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 8, 'page_label': '9', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='asc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,d.dname\\t\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\n(‘NEW\\tYORK’,’DALLAS’)\\tand\\te.deptno\\t=\\td.deptno\\tand\\te.empno\\tin\\t(select\\ne.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\t(‘MANAGER’,’ANALYST’)\\tand\\t\\n(months_between(sysdate,e.hiredate)/12)>\\t7\\t\\tand\\t\\te.comm.\\tis\\tnull)\\norder\\tby\\td.loc\\t\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 9, 'page_label': '10', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.41.\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tLoc,\\tDeptno,\\tJob\\tof\\tall\\temps\\nworking\\tat\\tCJICAGO\\tor\\tworking\\tfor\\tACCOUNTING\\tdept\\twith\\tAnn\\nSal>28000,\\tbut\\tthe\\tSal\\tshould\\tnot\\tbe=3000\\tor\\t2800\\twho\\tdoesn’t\\tbelongs\\tto\\tthe\\nMgr\\tand\\twhose\\tno\\tis\\thaving\\ta\\tdigit\\t‘7’\\tor\\t‘8’\\tin\\t3rd\\tposition\\tin\\tthe\\tasc\\torder\\tof\\nDeptno\\tand\\tdesc\\torder\\tof\\tjob.\\nA)\\tselect\\tE.empno,E.ename,E.sal,D.dname,D.loc,E.deptno,E.job\\nfrom\\temp\\tE,dept\\tD\\nwhere\\t(D.loc\\t=\\t'CHICAGO'\\tor\\tD.dname\\t=\\t'ACCOUNTING')\\tand\\nE.deptno=D.deptno\\tand\\tE.empno\\tin\\n(select\\tE.empno\\tfrom\\temp\\tE\\twhere\\t(12*E.sal)\\t>\\t28000\\tand\\t\\tE.sal\\tnot\\tin\\n(3000,2800)\\t\\tand\\tE.job\\t!='MANAGER'\\nand\\t(\\tE.empno\\tlike\\t'__7%'\\tor\\tE.empno\\tlike\\t'__8%'))\\norder\\tby\\tE.deptno\\tasc\\t,\\tE.job\\tdesc;\\n2.42.\\t\\t\\t\\t\\tDisplay\\tthe\\ttotal\\tinformation\\tof\\tthe\\temps\\talong\\twith\\tGrades\\tin\\tthe\\tasc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 9, 'page_label': '10', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='order.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\\t\\norder\\tby\\ts.grade\\t\\tasc;\\t\\t\\t\\t\\t\\t\\t\\t(using\\tbetween\\tand\\tis\\ta\\tbit\\tsimple)\\n2.43.\\t\\t\\t\\t\\tList\\tall\\tthe\\tGrade2\\tand\\tGrade\\t3\\temps.\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ns\\twhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin(2,3));\\t(OR)\\t\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 10, 'page_label': '11', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='s.grade\\tin\\t(2,3)\\t;\\n2.44.\\t\\t\\t\\t\\tDisplay\\tall\\tGrade\\t4,5\\tAnalyst\\tand\\tMgr.\\nA)\\tselect\\t*\\tfrom\\temp\\te,\\tsalgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand\\ns.grade\\tin\\t(4,5)\\tand\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\n(‘MANAGER’,’ANALYST’)\\t);\\n2.45.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tGrade,\\tExp,\\tand\\tAnn\\tSal\\tof\\temps\\nworking\\tfor\\tDept10\\tor20.\\nA)\\nselectE.empno,E.ename,E.sal,S.grade,D.dname,\\n(months_between(sysdate,E.hiredate)/12)\\t\"EXP\"\\t,12*E.sal\\t\\t“ANN\\tSAL”\\nfrom\\temp\\tE,dept\\tD\\t,salgrade\\tS\\nwhere\\tE.deptno\\tin\\t(10,20)\\tand\\tE.deptno\\t=\\tD.deptno\\t\\tand\\tE.sal\\tbetween\\tS.losal\\nand\\tS.hisal\\t;\\n2.46.\\t\\t\\t\\t\\tList\\tall\\tthe\\tinformation\\tof\\temp\\twith\\tLoc\\tand\\tthe\\tGrade\\tof\\tall\\tthe\\temps\\nbelong\\tto\\tthe\\tGrade\\trange\\tfrom\\t2\\tto\\t4\\tworking\\tat\\tthe\\tDept\\tthose\\tare\\tnot\\tstarting\\nwith\\tchar\\tset\\t‘OP’\\tand\\tnot\\tending\\twith\\t‘S’\\twith\\tthe\\tdesignation\\thaving\\ta\\tchar\\t‘a’\\nany\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 10, 'page_label': '11', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"any\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades\\nA)\\t\\tselect\\te.empno,e.ename,d.loc,s.grade,e.sal\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\nand\\t(d.dname\\tnot\\tlike\\t'OP%'\\tand\\td.dname\\tnot\\tlike\\t'%S')\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin\\t(2,3,4)\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tjob\\tlike\\t'%A%'and\\tsal\\tnot\\tlike\\n'%00'\\tand\\t(to_char\\t(hiredate,'YYYY')\\t=\\t'1981'\\nand\\tto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP')));\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 11, 'page_label': '12', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.47.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tDepts\\talong\\twith\\tEmpno,\\tEname\\tor\\twithout\\tthe\\nemps\\nA)\\tselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno(+)=\\td.deptno;\\n2.48.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tSalaries\\tmore\\tthan\\tthe\\temployee\\nBLAKE.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>\\t(select\\t\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\n‘BLAKE’);\\n2.49.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tJobs\\tare\\tsame\\tas\\tALLEN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘ALLEN’);\\n2.50.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tKing.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\n=\\t‘KING’);\\n2.51.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tMGRS.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\t\\tand\\tw.hiredate\\t<\\t\\nm.hiredate\\t;\\t(OR)\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.empno=\\tm.mgr\\tand\\nw.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 11, 'page_label': '12', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='w.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand\\ne.job\\tin\\t(\\tselect\\te.job\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\tand\\td.deptno\\n=10);\\n2.53.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\tsame\\tas\\tFORD\\tor\\tSMITH\\tin\\tdesc\\torder\\tof'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 12, 'page_label': '13', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Sal.\\nA)\\nSelect\\t*\\t\\tfrom\\t\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\t(\\tename\\t=\\t‘SMITH’\\nor\\t\\tename\\t=\\t‘FORD’\\t))\\t\\torder\\tby\\tsal\\tdesc;\\n2.54.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\tJobs\\tare\\tsame\\tas\\tMILLER\\tor\\tSal\\tis\\tmore\\tthan\\nALLEN.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\t\\twhere\\tjob\\t=\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘MILLER’\\t)\\tor\\t\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’);\\n2.55.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\t>\\tthe\\ttotal\\tremuneration\\tof\\tthe\\tSALESMAN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>(select\\tsum(nvl2(comm,sal+comm,sal))\\tfrom\\nemp\\t\\twhere\\tjob\\t=\\t‘SALESMAN’);\\n2.56.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tBLAKE\\tworking\\tat\\tCHICAGO\\t&\\nBOSTON.\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\t(‘CHICAGO’,’BOSTON’)\\tand\\ne.deptno\\t=\\td.deptno\\tand\\te.hiredate\\t<(select\\te.hiredate\\tfrom\\temp\\te\\twhere\\te.ename\\n=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 12, 'page_label': '13', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.deptno\\tin\\t(select\\td.deptno\\t\\tfrom\\tdept\\td\\twhere\\nd.dname\\t\\tin\\t(‘ACCOUNTING’,’RESEARCH’)\\t)\\tand\\t\\ne.sal\\t>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’)\\t\\tand\\t\\ne.hiredate\\t<(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’)\\tand\\ne.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\t\\tand\\ts.grade\\tin\\t(3,4)\\t)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 13, 'page_label': '14', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='order\\tby\\te.hiredate\\tdesc;\\n2.58.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tjobs\\tsame\\tas\\tSMITH\\tor\\tALLEN.\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘SMITH’\\tor\\tename\\t=\\t‘ALLEN’);\\t\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\tin\\n(‘SMITH’,’ALLEN’);\\n2.59.\\t\\t\\t\\t\\tWrite\\ta\\tQuery\\tto\\tdisplay\\tthe\\tdetails\\tof\\temps\\twhose\\tSal\\tis\\tsame\\tas\\tof\\nb)\\t\\t\\t\\t\\tEmployee\\tSal\\tof\\tEMP1\\ttable.\\nc)\\t\\t\\t\\t\\t\\t¾\\tSal\\tof\\tany\\tMgr\\tof\\tEMP2\\ttable.\\nd)\\t\\t\\t\\t\\tThe\\tsal\\tof\\tany\\tperson\\twith\\texp\\tof\\t5\\tyears\\tbelongs\\tto\\tthe\\tsales\\tdept\\tof\\temp3\\ntable.\\ne)\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\temployee\\tof\\temp4\\ttable.\\nf)\\t\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\tand\\t3\\temployee\\tworking\\tfro\\tsales\\tdept\\tor\\toperations\\tdept\\njoined\\tin\\t89.\\n2.60.\\t\\t\\t\\t\\tAny\\tjobs\\tof\\tdeptno\\t10\\tthose\\tthat\\tare\\tnot\\tfound\\tin\\tdeptno\\t20.\\nA)\\tselect\\t\\te.job\\tfrom\\temp\\te\\twhere\\te.deptno\\t=\\t10\\tand\\te.job\\tnot\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=20);\\n2.61.\\t\\t\\t\\t\\tList\\tof\\temps\\tof\\temp1\\twho\\tare\\tnot\\tfound\\tin\\temp2.\\n2.62.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tsal\\tof\\tEMP\\ttable.\\nA)\\tselect\\tmax(sal)\\tfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 14, 'page_label': '15', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.63.\\t\\t\\t\\t\\tFind\\tdetails\\tof\\thighest\\tpaid\\temployee.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\t\\tmax(sal)\\tfrom\\temp);\\n2.64.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tpaid\\temployee\\tof\\tsales\\tdepartment.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp\\twhere\\tdeptno\\tin\\n(select\\td.deptno\\tfrom\\ndept\\td\\twhere\\td.dname\\t=\\t'SALES'));\\n2.65.\\t\\t\\t\\t\\tList\\tthe\\tmost\\trecently\\thired\\temp\\tof\\tgrade3\\tbelongs\\tto\\t\\tlocation\\nCHICAGO.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t\\te.deptno\\tin\\t(\\tselect\\t\\td.deptno\\tfrom\\tdept\\td\\twhere\\nd.loc\\t=\\t'CHICAGO')\\tand\\ne.hiredate\\tin\\t\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tempno\\nfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3))\\t;\\t(or)\\nselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\td.loc='chicago'\\nand\\thiredate\\tin(select\\tmax(hiredate)\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\tsal\\tbetween\\tlosal\\tand\\thisal\\tand\\tgrade=3);\\n2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 14, 'page_label': '15', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'))\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 15, 'page_label': '16', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.67.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temployee\\tbelongs\\tto\\tnewyork\\twith\\tgrade\\t3\\tto\\t5\\nexcept\\t‘PRESIDENT’\\twhose\\tsal>\\tthe\\thighest\\tpaid\\temployee\\tof\\tChicago\\tin\\ta\\ngroup\\twhere\\tthere\\tis\\tmanager\\tand\\tsalesman\\tnot\\tworking\\tunder\\tking\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\n='NEW\\tYORK')\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\tand\\ns.grade\\tin\\t(3,4,5)\\t)\\tand\\tjob\\t!=\\t'PRESIDENT'\\tand\\tsal\\t>(select\\tmax(sal)\\tfrom\\temp\\nwhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\t'CHICAGO')\\tand\\tjob\\tin\\n('MANAGER','SALESMAN')\\tand\\nmgr\\tnot\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\\n2.68.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tsenior\\temployee\\tbelongs\\tto\\t1981.\\nB)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\t\\nwhere\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 15, 'page_label': '16', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='where\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\\n2.69.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tjoined\\tin\\t1981\\twith\\tthe\\tjob\\tsame\\tas\\tthe\\tmost\\nsenior\\tperson\\tof\\tthe\\tyear\\t1981.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=’1981’));'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 16, 'page_label': '17', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.70.\\t\\t\\t\\t\\tList\\tthe\\tmost\\tsenior\\templ\\tworking\\tunder\\tthe\\tking\\tand\\tgrade\\tis\\tmore\\t\\nthan\\t3.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\nempno\\tin\\n(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\tin\\t(4,5)))\\nand\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING');\\n2.71.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tsal\\tgiven\\tto\\tthe\\tMGR.\\nD)\\t\\t\\t\\tselect\\tsum\\t(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(OR)\\nB)\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp);\\n2.72.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tannual\\tsal\\tto\\tdistribute\\tjob\\twise\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\tjob,sum(12*sal)\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t=\\t'1981'\\ngroup\\tby\\tjob\\t;\\n2.73.\\t\\t\\t\\t\\tDisplay\\ttotal\\tsal\\temployee\\tbelonging\\tto\\tgrade\\t3.\\nE)\\t\\t\\t\\t\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\nin\\t\\t(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3)\\n2.74.\\t\\t\\t\\t\\tDisplay\\tthe\\taverage\\tsalaries\\tof\\tall\\tthe\\tclerks.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 17, 'page_label': '18', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\tavg(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n2.75.\\t\\t\\t\\t\\tList\\tthe\\temployeein\\tdept\\t20\\twhose\\tsal\\tis\\t>the\\taverage\\tsal\\t0f\\tdept\\t10\\nemps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=20\\tand\\tsal\\t>(select\\tavg\\t(sal)\\tfrom\\temp\\nwhere\\t\\tdeptno\\t=\\t10);\\n2.76.\\t\\t\\t\\t\\tDisplay\\tthe\\tnumber\\tof\\temployee\\t\\tfor\\teach\\tjob\\tgroup\\tdeptno\\twise.\\nF)\\t\\t\\t\\t\\tselect\\t\\tdeptno\\t,job\\t,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\t\\tdeptno,job;\\t(or)\\nB)\\tselect\\td.deptno,e.job,count(e.job)\\tfrom\\temp\\te,dept\\td\\twhere\\ne.deptno(+)=d.deptno\\tgroup\\tby\\te.job,d.deptno;\\n2.77.\\t\\t\\t\\t\\tList\\tthe\\tmanage\\trno\\tand\\tthe\\tnumber\\tof\\temployees\\tworking\\tfor\\tthose\\nmgrs\\tin\\tthe\\tascending\\tMgrno.\\nG)\\t\\t\\t\\tselect\\tw.mgr\\t,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\ngroup\\tby\\tw.mgr\\norder\\tby\\tw.mgr\\tasc;\\n2.78.\\t\\t\\t\\t\\tList\\tthe\\tdepartment,details\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tworking\\nH)\\t\\t\\t\\tselect\\tdeptno\\t,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tcount(*)\\t>=\\t2;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 18, 'page_label': '19', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.79.\\t\\t\\t\\t\\tDisplay\\tthe\\tGrade,\\tNumber\\tof\\temps,\\tand\\tmax\\tsal\\tof\\teach\\tgrade.\\nA)\\tselect\\ts.grade\\t,count(*),max(sal)\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\ngroup\\tby\\ts.grade;\\n2.80.\\t\\t\\t\\t\\tDisplay\\tdname,\\tgrade,\\tNo.\\tof\\temps\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tclerks.\\nA)\\tselect\\td.dname,s.grade,count(*)\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\twhere\\te.deptno\\n=\\td.deptno\\tand\\ne.job\\t=\\t'CLERK'\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tgroup\\tby\\td.dname,s.grade\\nhaving\\tcount(*)\\t>=\\t2;\\n2.81.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tdepartment\\twhere\\tmaximum\\tnumber\\tof\\temps\\tare\\nworking.\\nI)\\t\\t\\t\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\t(OR)\\nJ)\\t\\t\\t\\t\\t\\tselect\\td.deptno,d.dname,d.loc,count(*)\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 18, 'page_label': '19', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='where\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\\nK)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 19, 'page_label': '20', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\t(OR)\\nL)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\t=\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\n2.83.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twhose\\tsalary\\tis\\tmore\\tthan\\t3000\\tafter\\tgiving\\t20%\\nincrement.\\nM)\\t\\tSELECT\\t*\\tFROM\\tEMP\\tWHERE\\t(1.2*SAL)\\t>\\t3000\\t;\\n2.84.\\t\\t\\t\\t\\tList\\tthe\\temps\\twith\\tdept\\tnames.\\nA)\\tselect\\ne.empno,e.ename,e.job,e.mgr,e.hiredate,e.sal,e.comm,e.deptno,d.dname\\nfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno;\\n2.85.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tnot\\tworking\\tin\\tsales\\tdept.\\nN)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tin\\n(select\\tdeptno\\tfrom\\temp\\twhere\\tdname\\t=\\t‘SALES’);\\n2.86.\\t\\t\\t\\t\\tList\\tthe\\temps\\tname\\t,dept,\\tsal\\tand\\tcomm.\\tFor\\tthose\\twhose\\tsalary\\tis\\nbetween\\t2000\\tand\\t5000\\twhile\\tloc\\tis\\tChicago.\\nA)\\tselect\\te.ename,e.deptno,e.sal,e.comm\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\nd.deptno\\tand\\nd.loc\\t=\\t'CHICAGO'\\tand\\te.sal\\tbetween\\t2000\\tand\\t5000;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 20, 'page_label': '21', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.87.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tgreater\\tthan\\this\\tmanagers\\tsalary\\nA)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n2.88.\\t\\t\\t\\t\\tList\\tthe\\tgrade,\\tEMP\\tname\\tfor\\tthe\\tdeptno\\t10\\tor\\tdeptno\\t30\\tbut\\tsal\\tgrade\\tis\\nnot\\t4\\twhile\\tthey\\tjoined\\tthe\\tcompany\\tbefore\\t’31-dec-82’.\\nA)\\tselect\\ts.grade\\t,e.ename\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.deptno\\tin\\t(10,20)\\tand\\nhiredate\\t<\\t('31-DEC-82')\\tand\\t(e.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tnot\\tin\\n(4));\\n2.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\t,job,\\tdname,\\tlocation\\tfor\\tthose\\twho\\tare\\tworking\\tas\\tMGRS.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\ne.empno\\tin\\t(select\\tmgr\\tfrom\\temp\\t)\\t;\\n3.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tmgr\\tname\\tis\\tjones\\tand\\talso\\tlist\\ttheir\\tmanager\\tname.\\nA)\\tselect\\tw.empno,w.ename,w.job,w.mgr,w.hiredate,w.sal,w.deptno,m.ename\\nfrom\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 20, 'page_label': '21', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"from\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\\nA)\\tselect\\te.ename,e.sal\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.ename\\t=\\t'FORD'\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\te.sal\\t=\\ts.hisal\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 21, 'page_label': '22', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"5.\\t\\t\\t\\t\\t\\tLit\\tthe\\tname,\\tjob,\\tdname\\t,sal,\\tgrade\\tdept\\twise\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,e.sal,s.grade\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\norder\\tby\\te.deptno\\t;\\n6.\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\tname,\\tjob,\\tsal,\\tgrade\\tand\\tdname\\texcept\\tclerks\\tand\\tsort\\ton\\tthe\\nbasis\\tof\\thighest\\tsal.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,e.sal,s.grade,d.dname\\tfrom\\temp\\te\\t,dept\\td\\t,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.job\\tnot\\tin('CLERK')\\norder\\tby\\te.sal\\tdesc;\\n7.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tname,\\tjob\\t\\twho\\tare\\twith\\tout\\tmanager.\\nA)\\tselect\\te.ename,e.job\\tfrom\\temp\\te\\twhere\\tmgr\\tis\\tnull;\\n8.\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tthe\\temps\\twho\\tare\\tgetting\\tthe\\thighest\\tsal\\tdept\\twise.\\nA)\\t\\t\\t\\tselect\\te.ename,e.deptno\\tfrom\\temp\\te\\twhere\\te.sal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t;\\n9.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tequal\\tto\\tthe\\taverage\\tof\\tmax\\tand\\tminimum\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=(select\\t(max(sal)+min(sal))/2\\tfrom\\temp);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 22, 'page_label': '23', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='10.\\t\\tList\\tthe\\tno.\\tof\\temps\\tin\\teach\\tdepartment\\twhere\\tthe\\tno.\\tis\\tmore\\tthan\\t3.\\nA)\\tselect\\tdeptno,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\thaving\\tcount(*)\\t<\\t3;\\n11.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tdepts.\\tWhere\\tatleast\\t3\\tare\\tworking\\tin\\tthat\\tdepartment.\\nA)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\\nhaving\\tcount(*)\\t>=\\t3\\t\\t;\\n12.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twhose\\tsal\\tis\\tmore\\tthan\\this\\temployess\\tavg\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tm\\t\\twhere\\tm.empno\\tin\\t(select\\tmgr\\tfrom\\temp)\\nand\\tm.sal\\t>\\t(select\\tavg(e.sal)\\tfrom\\temp\\te\\twhere\\te.mgr\\t=\\tm.empno\\n)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\nThe\\tsubquery\\tdoes\\tthe\\tsame\\tas\\t\\t\\t(select\\t(avg(e.sal)),m.ename\\tfrom\\temp\\te,emp\\tm\\nwhere\\te.mgr=m.empno\\tgroup\\tby\\te.mgr,m.ename);\\n13.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname,salary,comm.\\tFor\\tthose\\temployees\\twhose\\tnet\\tpay\\tis\\ngreater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 22, 'page_label': '23', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='greater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\tename,sal,comm.\\tfrom\\temp\\twhere\\tsal+nvl(comm.,0)\\t>=\\tany\\t(select\\nsal\\tfrom\\temp);/\\n14.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\twhose\\tsal<his\\tmanager\\tbut\\tmore\\tthan\\tany\\tother\\tmanager.\\na)select\\t\\tdistinct\\tW.empno,W.ename,W.sal'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 23, 'page_label': '24', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='from\\t(select\\tw.empno,w.ename,w.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\t\\nw.mgr\\t=\\tm.empno\\tand\\tw.sal<m.sal)\\tW,\\n(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp))\\tA\\nwhere\\tW.sal\\t>\\tA.sal;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t<\\tm.sal\\nand\\tw.sal\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp));\\n15.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temployee\\tnames\\tand\\this\\taverage\\tsalary\\tdepartment\\twise.\\nA)\\nselect\\td.deptno,\\tround(avg(nvl2(e1.comm,\\te1.sal+e1.comm,\\te1.sal)))\\tavg,\\ne2.ename\\tfrom\\temp\\te1,\\temp\\te2,\\tdept\\td\\twhere\\td.deptno\\t=e1.deptno\\tand\\td.deptno\\n=\\te2.deptno\\tgroup\\tby\\td.deptno,\\te2.ename;\\t(or)\\nB)\\tselect\\td.maxsal,e.ename,e.deptno\\tas\\t\"current\\tsal\"\\tfrom\\temp\\te,\\n(select\\tavg(Sal)\\tmaxsal,deptno\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\td\\nwhere\\te.deptno=d.deptno;\\n16.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\tleast\\t5\\tearners\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t5>\\t(select\\tcount(*)\\tfrom\\temp\\twhere\\te.sal\\t>sal);\\n(or)\\nB)\\t\\t\\t\\tselect\\trownum\\trank,empno,ename,job,sal\\tfrom\\t(select\\t*\\tfrom\\temp\\torder\\tby\\nsal\\tasc)\\twhere\\trownum\\t<\\t6\\t;\\t(or)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 24, 'page_label': '25', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"C)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t\\twhere\\t5\\t>(select\\tcount(distinct\\tsal)\\tfrom\\temp\\twhere\\ne.sal\\t>\\tsal);\\n17.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\temps\\twhose\\tsalaries\\tgreater\\tthan\\tsalaries\\tof\\ttheir\\tmanagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal>\\tm.sal;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\nemp))\\ta\\nwhere\\te.sal\\t>a.sal\\tand\\te.mgr\\t=\\ta.empno\\n18.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twho\\tare\\tnot\\tworking\\tunder\\tthe\\tpresident.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp)\\tand\\tmgr\\tnot\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tjob\\t=\\t'PRESIDENT')\\n19.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\trecords\\tfrom\\temp\\twhose\\tdeptno\\tisnot\\tin\\tdept.\\n20.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tName\\t,\\tSalary,\\tComm\\tand\\tNet\\tPay\\tis\\tmore\\tthan\\tany\\tother\\nemployee.\\nA)\\t\\t\\t\\tSelect\\te.ename,e.sal,e.comm,nvl2(comm,sal+comm,sal)\\tNETPAY\\nfrom\\temp\\te\\t\\nwhere\\tnvl2(comm,sal+comm,sal)\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\n=e.empno)\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 25, 'page_label': '26', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"21.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEnames\\twho\\tare\\tretiring\\tafter\\t31-Dec-89\\tthe\\tmax\\tJob\\tperiod\\tis\\n20Y.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\tadd_months(hiredate,240)\\t>\\t'31-DEC-89';\\nB)\\tselect\\tename\\tfrom\\temp\\nwhere\\tadd_months(hiredate,240)\\t>\\tto_date(’31-DEC-89’,’DD-MON-RR’);\\t\\n22.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthose\\tEmps\\twhose\\tSalary\\tis\\todd\\tvalue.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tmod(sal,2)\\t=\\t1;\\n23.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp’s\\twhose\\tSalary\\tcontain\\t3\\tdigits.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\twhere\\tlength\\t(sal)\\t=\\t3;\\n24.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tDEC.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=’DEC’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\tin\\t(‘DEC’);\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MONTH’)\\tlike\\t‘DEC%’;\\n25.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\tcontains\\t‘A’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%A%’;\\n26.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tDeptno\\tis\\tavailable\\tin\\this\\tSalary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(sal,deptno)\\t>\\t0;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 26, 'page_label': '27', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"27.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tfirst\\t2\\tchars\\tfrom\\tHiredate=last\\t2\\tcharacters\\tof\\nSalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsubstr(hiredate,1,2)\\t=\\tsubstr(sal,length(sal)-1,length(sal));\\n28.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\t10%\\tof\\tSalary\\tis\\tequal\\tto\\tyear\\tof\\tjoining.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YY')\\tin\\t(select\\t.1*sal\\tfrom\\temp);\\n29.\\t\\t\\t\\t\\t\\t\\t\\tList\\tfirst\\t50%\\tof\\tchars\\tof\\tEname\\tin\\tLower\\tCase\\tand\\tremaining\\tare\\tupper\\nCase.\\nA)\\t\\t\\t\\t\\t\\t\\t\\t\\nselect\\tlower(substr(ename,1,round(length(ename)/2)))\\n||substr(ename,round(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\t\\t(OR)\\nB)\\tselect\\tlower(substr(ename,1,ciel(length(ename)/2)))\\n||\\tsubstr(ename,ciel(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\n30.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname\\twhose\\tNo.\\tof\\tEmps\\tis\\t=to\\tnumber\\tof\\tchars\\tin\\tthe\\nDname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 27, 'page_label': '28', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\te\\nwhere\\te.deptno\\t=\\td.deptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\t\\ngroup\\tby\\td.dname\\thaving\\tcount(*)\\t=\\tlength\\t(d.dname);\\n31.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\tcompany\\tbefore\\t15th\\tof\\tthe\\tmonth.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,\\'DD\\')\\t<\\t\\'15\\';\\n32.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname,\\tno\\tof\\tchars\\tof\\twhich\\tis\\t=\\tno.\\tof\\temp’s\\tin\\tany\\tother\\nDept.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\t\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tlength(dname)\\t=\\tany\\t(select\\tcount(*)\\tfrom\\temp\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\t,\\t(select\\tcount(*)\\ts,e.deptno\\t\\t\"M\"from\\temp\\te\\tgroup\\tby\\ne.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 27, 'page_label': '28', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='e.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp\\t);\\n34.\\t\\t\\t\\t\\t\\t\\t\\tList\\tTHE\\tName\\tof\\tdept\\twhere\\thighest\\tno.of\\temps\\tare\\tworking.\\nA)\\tselect\\tdname\\tfrom\\tdept\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 28, 'page_label': '29', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tdeptno\\t\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\n35.\\t\\t\\t\\t\\t\\t\\t\\tCount\\tthe\\tNo.of\\temps\\twho\\tare\\tworking\\tas\\t‘Managers’(using\\tset\\toption).\\nA)select\\tcount(*)\\nfrom(select\\t*\\tfrom\\temp\\tminus\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t'MANAGER')\\n36.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\ton\\tthe\\tsame\\tdate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\tin\\n(select\\thiredate\\tfrom\\temp\\twhere\\te.empno\\t<>\\tempno);\\n37.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tGrade\\tis\\tequal\\tto\\tone\\ttenth\\tof\\tSales\\nDept.\\nA)\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t0.1*\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdname\\t=\\t'SALES');\\n38.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tof\\tthe\\tdept\\twhere\\tmore\\tthan\\taverage\\tno.\\tof\\temps\\tare\\nworking.\\nA)\\tselect\\td.dname\\tfrom\\tdept\\td,\\temp\\te\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 29, 'page_label': '30', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='having\\tcount(*)\\t>\\t(select\\tavg(count(*))\\tfrom\\temp\\t\\tgroup\\tby\\tdeptno);\\n39.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tManagers\\tname\\twho\\tis\\thaving\\tmax\\tno.of\\temps\\tworking\\tunder\\nhim.\\nA)select\\tm.ename,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\t\\ngroup\\tby\\tm.ename\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr);\\t\\t\\t\\t\\t\\n(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\t=\\t(select\\tmgr\\tfrom\\temp\\tgroup\\tby\\tmgr\\thaving\\ncount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr))\\t;\\n40.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEname\\tand\\tSal\\tis\\tincreased\\tby\\t15%\\tand\\texpressed\\tas\\tno.of\\nDollars.\\nA)\\tselect\\tename,to_char(1.15*sal,\\'$99,999\\')\\tas\\t\"SAL\"\\t\\tfrom\\temp;\\t(only\\tfor\\t$\\tit\\nworks)\\nB)\\tselect\\tename,\\'$\\'||1.15*sal\\t\\t“SAL”\\tfrom\\temp;\\n41.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\toutput\\tof\\tEMP\\ttable\\t‘EMP_AND_JOB’\\tfor\\tEname\\tand\\tJob.\\nA)\\tselect\\tename||\\tjob\\tas\\t\"EMP_AND_JOB\"\\tfrom\\temp\\t;\\n42.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\tfollowing\\toutput\\tfrom\\tEMP.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 30, 'page_label': '31', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='I.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEMPLOYEE\\nSMITH\\t(clerk)\\nALLEN\\t(Salesman)\\nA)\\t\\tselect\\tename\\t||\\t‘(‘||\\tlower(job)||’)’\\tas\\t“EMPLOYEE”\\tfrom\\temp;\\n130)\\t\\t\\tList\\tthe\\temps\\twith\\tHire\\tdate\\tin\\tformat\\tJune\\t4,\\t1988.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal,\\tto_char(hiredate,\\'MONTH\\tDD,YYYY\\')\\tfrom\\temp;\\n131)\\t\\t\\tPrint\\ta\\tlist\\tof\\temp’s\\tListing\\t‘just\\tsalary’\\tif\\tSalary\\tis\\tmore\\tthan\\t1500,\\ton\\ntarget\\tif\\tSalary\\tis\\t1500\\tand\\t‘Below\\t1500’\\tif\\tSalary\\tis\\tless\\tthan\\t1500.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal||\\t‘JUST\\tSALARY’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t>\\n1500\\tunion\\nselect\\tempno,ename,\\tsal||\\t‘ON\\tTARGET’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t=\\t1500\\t\\t\\t\\t\\t\\t\\t\\nunion\\nselect\\tempno,ename,\\tsal||\\t‘BELOW\\t1500’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t<\\t1500;\\t\\n(OR)\\nB)select\\tempno,ename,sal,job,\\ncase\\nwhen\\tsal\\t=\\t1500\\tthen\\t\\'ON\\tTARGET\\'\\nwhen\\tsal\\t<\\t1500\\tthen\\t\\'BELOW\\t1500\\'\\nwhen\\tsal\\t>\\t1500\\tthen\\t\\'JUST\\tSALARY\\'\\nelse\\t\\'nothing\\'\\nend\\t\\t\"REVISED\\tSALARY\"\\nfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 31, 'page_label': '32', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"132)\\t\\t\\tWrite\\ta\\tquery\\twhich\\treturn\\tthe\\tday\\tof\\tthe\\tweek\\tfor\\tany\\tdate\\tentered\\tin\\nformat\\t‘DD-MM-YY’.\\nA)\\tselect\\tto_char(to_date('&\\ts','dd-mm-yy'),'day')\\tfrom\\tdual\\t;\\n133)\\t\\t\\tWrite\\ta\\tquery\\tto\\tcalculate\\tthe\\tlength\\tof\\tservice\\tof\\tany\\temployee\\twith\\tthe\\ncompany,\\tuse\\tDEFINE\\tto\\tavoid\\trepetitive\\ttyping\\tof\\tfunctions.\\nA)\\t\\t\\t\\tDEFINE\\t\\tservice\\t=\\t((months_between(sysdate,hiredate))/12)\\nB)\\t\\t\\t\\tSelect\\t\\tempno,ename,&service\\tfrom\\temp\\twhere\\tename\\t=\\t‘&\\tname’;\\n134)\\t\\t\\tGive\\ta\\tstring\\tof\\tformat\\t‘NN/NN’,\\tverify\\tthat\\tthe\\tfirst\\tand\\tlast\\ttwo\\ncharacters\\tare\\tnumbers\\tand\\tthat\\tthe\\tmiddle\\tcharacter\\tis’/’.\\tPrint\\tthe\\texpression\\n‘YES’\\tif\\tvalid,\\t‘NO’\\tif\\tnot\\tvalid.\\tUse\\tthe\\tfollowing\\tvalues\\tto\\ttest\\tyour\\tsolution.\\n‘12/34’,’01/1a’,\\t‘99/98’.\\nA)\\n135)\\t\\t\\tEmps\\thired\\ton\\tor\\tbefore\\t15th\\tof\\tany\\tmonth\\tare\\tpaid\\ton\\tthe\\tlast\\tFriday\\tof\\nthat\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 31, 'page_label': '32', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"that\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\\nA)\\tselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')-7\\tfrom\\temp\\nwhere\\tto_char(hiredate,'DD')\\t<=15\\nunion\\nselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')\\tfrom\\temp\\twhere\\nto_char(hiredate,'DD')\\t>\\t15;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 32, 'page_label': '33', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"136)\\t\\t\\tCount\\tthe\\tno.\\tof\\tcharacters\\twith\\tout\\tconsidering\\tspaces\\tfor\\teach\\tname.\\nA)\\t\\t\\t\\tselect\\tlength(replace(ename,’\\t‘,null))\\tfrom\\temp;\\n137)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tare\\tgetting\\tdecimal\\tvalue\\tin\\ttheir\\tSal\\twithout\\tusing\\nlike\\toperator.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tinstr(sal,’.’,1,1)\\t>\\t0;\\n138)\\t\\t\\tList\\tthose\\temps\\twhose\\tSalary\\tcontains\\tfirst\\tfour\\tdigit\\tof\\ttheir\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(sal,,9999),deptno,1,1)>0\\tand\\ninstr(to_char(sal,9999),deptno,1,2)>\\t0\\t;\\n139)\\t\\t\\tList\\tthose\\tManagers\\twho\\tare\\tgetting\\tless\\tthan\\this\\temps\\tSalary.\\nA)\\t\\t\\t\\tselect\\tdistinct\\tm.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\nand\\tw.sal>m.sal;\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tsal\\t\\t<\\tany\\t(\\tselect\\tsal\\tfrom\\temp\\twhere\\nw.empno=mgr);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tempno\\tin\\t\\t(\\tselect\\tmgr\\tfrom\\temp\\twhere\\t\\t\\t\\nw.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 32, 'page_label': '33', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"w.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\\n141)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers\\tusing\\tco-related\\tsub-query.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n142)\\t\\t\\tList\\tthe\\temps\\twhose\\tMgr\\tname\\tis\\t‘Jones’\\tand\\talso\\twith\\this\\tManager\\nname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 33, 'page_label': '34', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\tw.ename,m.ename,(select\\tename\\tfrom\\temp\\twhere\\tm.mgr\\t=\\tempno)\\n\"his\\tMANAGER\"\\nfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t\\'JONES\\';\\t(or)\\nB)\\tselect\\te.ename,w.ename,m.ename\\tfrom\\temp\\te,emp\\tw,emp\\tm\\twhere\\te.mgr\\t=\\nw.empno\\tand\\tw.ename\\t=\\t‘JONES’\\tand\\tw.mgr\\t=\\tm.empno;\\n143)\\t\\t\\tDefine\\ta\\tvariable\\trepresenting\\tthe\\texpression\\tused\\tto\\tcalculate\\ton\\temps\\ntotal\\tannual\\tremuneration\\tuse\\tthe\\tvariable\\tin\\ta\\tstatement,\\twhich\\tfinds\\tall\\temps\\nwho\\tcan\\tearn\\t30000\\ta\\tyear\\tor\\tmore.\\nA)\\t\\t\\t\\tSet\\tdefine\\ton\\nB)\\t\\t\\t\\tDefine\\t\\tannual\\t=\\t12*nvl2(comm.,sal+comm.,sal)\\t\\t(here\\tdefine\\tvariable\\tis\\ta\\nsession\\tvariable)\\nC)\\t\\t\\t\\tSelect\\t*\\tfrom\\temp\\twhere\\t&annual\\t>\\t30000;\\n144)\\t\\t\\tFind\\tout\\thow\\tmay\\tManagers\\tare\\ttheir\\tin\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\t(or)\\nC)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 33, 'page_label': '34', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='C)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.\\nRemember\\tSalesman\\tearn\\tcommission.secommm\\nA)\\tselect\\tavg(sal),avg(sal+nvl(comm,0))\\tfrom\\temp;\\n146)\\t\\t\\tCheck\\twhether\\tall\\tthe\\temps\\tnumbers\\tare\\tindeed\\tunique.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 34, 'page_label': '35', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t\\t\\tempno,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\tempno;\\n147)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tdrawing\\tless\\tthan\\t1000\\tSort\\tthe\\toutput\\tby\\tSalary.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\t<\\t1000\\torder\\tby\\tsal;\\n148)\\t\\t\\tList\\tthe\\temployee\\tName,\\tJob,\\tAnnual\\tSalary,\\tdeptno,\\tDept\\tname\\tand\\ngrade\\twho\\tearn\\t36000\\ta\\tyear\\tor\\twho\\tare\\tnot\\tCLERKS.\\nA)selecte.ename,e.job,(12*e.sal)\"ANNUALSALARY\",\\ne.deptno,d.dname,s.grade\\nfrom\\temp\\te,dept\\td\\t,salgrade\\ts\\twhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\nand\\t(((12*e.sal)>=\\t36000)\\tor\\t(e.job\\t!=\\t\\'CLERK\\'))\\n149)\\t\\t\\tFind\\tout\\tthe\\tJob\\tthat\\twas\\tfilled\\tin\\tthe\\tfirst\\thalf\\tof\\t1983\\tand\\tsame\\tjob\\tthat\\nwas\\tfilled\\tduring\\tthe\\tsame\\tperiod\\tof\\t1984.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\twhere\\t(to_char(hiredate,\\'MM\\t\\')\\t<=\\t06\\t\\tand\\nto_char(hiredate,\\'YYYY\\')\\t=\\t1984)\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\nto_char(hiredate,\\'MM\\'\\t)\\t<=\\t06\\tand\\tto_char(hiredate,\\'YYYY\\')\\t<=\\t1983)\\t;\\t\\n150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 34, 'page_label': '35', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate<\\tm.hiredate;(or)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\t<\\t(select\\t\\thiredate\\tfrom\\temp\\twhere\\nempno\\t=\\te.mgr)\\n151)\\t\\t\\tList\\tall\\tthe\\temps\\tby\\tname\\tand\\tnumber\\talong\\twith\\ttheir\\tManager’s\\tname\\nand\\tnumber.\\tAlso\\tList\\tKING\\twho\\thas\\tno\\t‘Manager’.\\nA)\\tselect\\tw.empno,w.ename,m.empno,m.ename\\tfrom\\temp\\tw,emp\\tm\\twhere'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 35, 'page_label': '36', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='w.mgr=\\tm.empno(+);\\n152)\\t\\t\\tFind\\tall\\tthe\\temps\\twho\\tearn\\tthe\\tminimum\\tSalary\\tfor\\teach\\tjob\\twise\\tin\\nascending\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmin(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tasc;\\n153)\\t\\t\\tFind\\tout\\tall\\tthe\\temps\\twho\\tearn\\thighest\\tsalary\\tin\\teach\\tjob\\ttype.\\tSort\\tin\\ndescending\\tsalary\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tdesc;\\n154)\\t\\t\\tFind\\tout\\tthe\\tmost\\trecently\\thired\\temps\\tin\\teach\\tDept\\torder\\tby\\tHiredate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\te\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\te.deptno\\t=\\t\\tdeptno\\t)\\norder\\tby\\thiredate;\\n155)\\t\\t\\tList\\tthe\\temployee\\tname,Salary\\tand\\tDeptno\\tfor\\teach\\temployee\\twho\\tearns\\na\\tsalary\\tgreater\\tthan\\tthe\\taverage\\tfor\\ttheir\\tdepartment\\torder\\tby\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\tsal\\t>\\t\\t(select\\tavg(sal)\\tfrom\\temp\\twhere\\te.deptno\\t=\\tdeptno\\t);\\nB)\\t\\t\\t\\tselect\\te.ename,e.sal,e.deptno\\tfrom\\temp\\te,(select\\tavg(sal)\\tA,deptno\\tD\\tfrom\\t\\t\\nemp\\tgroup\\tby\\tdeptno)\\tD1\\twhere\\tD1.D\\t=\\te.deptno\\tand\\te.sal\\t>\\tD1.A;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 36, 'page_label': '37', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"156)\\t\\t\\tList\\tthe\\tDeptno\\twhere\\tthere\\tare\\tno\\temps.\\nA)\\t\\t\\t\\tselect\\t\\tdeptno\\t,count(*)\\tfrom\\temp\\ngroup\\tby\\tdeptno\\t\\nhaving\\tcount(*)\\t=\\t0;\\n157)\\t\\t\\tList\\tthe\\tNo.of\\temp’s\\tand\\tAvg\\tsalary\\twithin\\teach\\tdepartment\\tfor\\teach\\tjob.\\nA)\\t\\t\\t\\tselect\\tcount(*),avg(sal),deptno,job\\tfrom\\temp\\ngroup\\tby\\tdeptno,job;\\n158)\\t\\t\\tFind\\tthe\\tmaximum\\taverage\\tsalary\\tdrawn\\tfor\\teach\\tjob\\texcept\\tfor\\n‘President’.\\nA)\\tselect\\tmax(avg(sal))\\tfrom\\temp\\t\\twhere\\tjob\\t!=\\t'PRESIDENT'\\tgroup\\tby\\tjob;\\n159)\\t\\t\\tFind\\tthe\\tname\\tand\\tJob\\tof\\tthe\\temps\\twho\\tearn\\tMax\\tsalary\\tand\\tCommission.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=\\t(select\\tmax(sal)\\tfrom\\temp)\\tand\\tcomm.\\tis\\tnot\\nnull;\\n160)\\t\\t\\tList\\tthe\\tName,\\tJob\\tand\\tSalary\\tof\\tthe\\temps\\twho\\tare\\tnot\\tbelonging\\tto\\tthe\\ndepartment\\t10\\tbut\\twho\\thave\\tthe\\tsame\\tjob\\tand\\tSalary\\tas\\tthe\\temps\\tof\\tdept\\t10.\\nA)\\tselect\\tename,job,sal\\tfrom\\temp\\twhere\\tdeptno\\t!=\\t10\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=\\t10)\\nand\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10);\\n161)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\tSALESMAN\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 37, 'page_label': '38', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='who\\tare\\tearning\\tmaximum\\tsalary\\tand\\tcommission\\tin\\tdescending\\torder.\\nA)select\\t\\tdeptno,name,job,sal,sal+nvl(comm.,0)\\tfrom\\temp\\twhere\\tjob\\t=\\n‘SALESMAN’\\tand\\tsal\\tin\\t(select\\tmax(sal+nvl(comm.,0))\\tfrom\\temp\\twhere\\ncomm.\\tis\\tnot\\tnull)\\nOrder\\tby\\t(sal\\t+nvl(comm.,0))\\tdesc;\\n162)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\temps\\twho\\tearn\\nthe\\tsecond\\thighest\\tearnings\\t(sal\\t+\\tcomm.).\\nA)\\tselect\\tdeptno,ename,sal,job,sal+nvl(comm,0)\\tfrom\\temp\\te\\twhere\\t\\t2\\t=\\t(select\\ncount(distinct\\tsal+nvl(comm,0))\\tfrom\\temp\\twhere\\t(e.sal+nvl(comm.,0))\\n<(sal+nvl(comm.,0));\\n163)\\t\\t\\tList\\tthe\\tDeptno\\tand\\ttheir\\taverage\\tsalaries\\tfor\\tdept\\twith\\tthe\\taverage\\tsalary\\nless\\tthan\\tthe\\taverages\\tfor\\tall\\tdepartment\\nA)\\t\\t\\t\\tselect\\tdeptno,avg(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tavg(sal)\\t<(select\\tavg(Sal)\\tfrom\\temp);\\n164)\\t\\t\\tList\\tout\\tthe\\tNames\\tand\\tSalaries\\tof\\tthe\\temps\\talong\\twith\\ttheir\\tmanager\\nnames\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 37, 'page_label': '38', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='names\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n165)\\t\\t\\tList\\tout\\tthe\\tName,\\tJob,\\tSalary\\tof\\tthe\\temps\\tin\\tthe\\tdepartment\\twith\\tthe\\nhighest\\taverage\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 38, 'page_label': '39', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='(select\\tdeptno\\tfrom\\temp\\te\\t\\nhaving\\tavg(sal)\\t=(select\\tmax(avg(sal))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t\\t\\ngroup\\tby\\tdeptno);\\n166)\\t\\t\\tList\\tthe\\tempno,sal,comm.\\tOf\\temps.\\nA)\\tselect\\tempno,sal,comm.\\tfrom\\temp;\\n167)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tsal.\\nA)\\tselect\\t*\\tfrom\\temp\\torder\\tby\\tsal\\tasc;\\n168)\\t\\t\\tList\\tthe\\tdept\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tjob\\tand\\tthe\\tdesc\\torder\\tof\\tthe\\nemps\\tprint\\tempno,\\tename.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t\\torder\\tby\\te.job\\tasc,e.empno\\tdesc\\t;\\n169)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\tof\\tthe\\temps.\\nA)select\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\t(select\\tunique\\tdeptno\\tfrom\\temp);\\n170)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\twith\\tjobs.\\nA)\\tselect\\tunique\\tdeptno\\t,job\\tfrom\\temp\\t;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 39, 'page_label': '40', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='171)\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tthe\\tblake.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’;\\n172)\\t\\t\\tList\\tall\\tthe\\tclerks.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n173)\\t\\t\\tlist\\tall\\tthe\\temployees\\tjoined\\ton\\t1st\\tmay\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t=\\t’01-MAY-81’;\\n174)\\t\\t\\tList\\tthe\\tempno,ename,sal,deptno\\tof\\tthe\\tdept\\t10\\temps\\tin\\tthe\\tascending\\norder\\tof\\tsalary.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,e.deptno\\tfrom\\temp\\twhere\\te.deptno\\t=\\t10\\norder\\tby\\te.sal\\tasc;\\n175)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalaries\\tare\\tless\\tthan\\t3500.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t<3500;\\n176)\\t\\t\\tList\\tthe\\tempno,ename,sal\\tof\\tall\\tthe\\temp\\tjoined\\tbefore\\t1\\tapr\\t81.\\nA)\\tselect\\te.empno\\t,e.ename\\t.e.sal\\tfrom\\temp\\twhere\\thiredate\\t<’01-APR-81’;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 40, 'page_label': '41', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='177)\\t\\t\\tList\\tthe\\temp\\twhose\\tannual\\tsal\\tis\\t<25000\\tin\\tthe\\tasc\\torder\\tof\\tthe\\tsalaries.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*sal)\\t<\\t25000\\torder\\tby\\tsal\\tasc;\\n178)\\t\\t\\tList\\tthe\\tempno,ename,annsal,dailysal\\t\\tof\\tall\\tthe\\tsalesmen\\tin\\tthe\\tasc\\tann\\nsal\\nA)\\tselect\\te.empno,e.ename\\t,12*sal\\t\"ANN\\tSAL\"\\t,\\t(12*sal)/365\\t\"DAILY\\tSAL\"\\nfrom\\temp\\te\\nwhere\\te.job\\t=\\t\\'SALESMAN\\'\\norder\\tby\\t\"ANN\\tSAL\"\\tasc\\t;\\n179)\\t\\t\\tList\\tthe\\tempno,ename,hiredate,current\\tdate\\t&\\texp\\tin\\tthe\\tascending\\torder\\nof\\tthe\\texp.\\nA)\\t\\t\\t\\tselect\\tempno,ename,hiredate,(select\\tsysdate\\tfrom\\tdual),\\n((months_between(sysdate,hiredate))/12)\\tEXP\\nfrom\\temp\\norder\\tby\\tEXP\\tasc;\\n180)\\t\\t\\tList\\tthe\\temps\\twhose\\texp\\tis\\tmore\\tthan\\t10\\tyears.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t((months_between(sysdate,hiredate))/12)\\t>\\t10;\\n181)\\t\\t\\tList\\tthe\\tempno,ename,sal,TA30%,DA\\t40%,HRA\\n50%,GROSS,LIC,PF,net,deduction,net\\tallow\\tand\\tnet\\tsal\\tin\\tthe\\tascending\\torder\\nof\\tthe\\tnet\\tsalary.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 41, 'page_label': '42', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='182)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\n183)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\tclerks\\tor\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(‘CLERK’,’MANAGER’);\\n184)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\ton\\tthe\\tfollowing\\tdates\\t1\\tmay\\t81,17\\tnov\\n81,30\\tdec\\t81\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’DD-MON-YY’)\\t\\tin\\n(’01-MAY-81’,’17-NOV-81’,’30-DEC-81’);\\n185)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’;\\n186)\\t\\t\\tList\\tthe\\temps\\twhose\\tannual\\tsal\\tranging\\tfrom\\t23000\\tto\\t40000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*\\tsal)\\tbetween\\t23000\\tand\\t40000;\\n187)\\t\\t\\tList\\tthe\\temps\\tworking\\tunder\\tthe\\tmgrs\\t7369,7890,7654,7900.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 42, 'page_label': '43', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin\\t(\\t7369,7890,7654,7900);\\n188)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tsecond\\thalf\\tof\\t82.\\nA)select\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-JUL-82’\\tand\\t’31-DEC-82’;\\n189)\\t\\t\\tList\\tall\\tthe\\t4char\\temps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(ename)\\t=\\t4;\\n190)\\t\\t\\tList\\tthe\\temp\\tnames\\tstarting\\twith\\t‘M’\\twith\\t5\\tchars.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n191)\\t\\t\\tList\\tthe\\temps\\tend\\twith\\t‘H’\\tall\\ttogether\\t5\\tchars.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%H’\\tand\\tlength\\t(ename)\\t=\\t5;\\n192)\\t\\t\\tList\\tnames\\tstart\\twith\\t‘M’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’;\\n193)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tyear\\t81.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 43, 'page_label': '44', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t=\\t‘81’;\\n194)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tending\\twith\\t00.\\nA)\\t\\tselect\\t*\\tfrom\\twhere\\t\\tsal\\t\\tlike\\t\\t‘%00’;\\n195)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tJAN.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MM’)\\t=\\t1;\\n196)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tchar\\t‘a’.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MONTH’)\\tlike’%A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MONTH’),’A’)\\t>0;\\n197)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tsecond\\tchar\\t‘a’\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\tlike\\t‘_A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MON’),’A’)\\t=\\t2;\\n198)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalary\\tis\\t4\\tdigit\\tnumber.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(sal)\\t=\\t4;(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tsal\\tbetween\\t999\\tand\\t9999;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 44, 'page_label': '45', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='199)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\t80’s.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t\\tbetween\\t‘80’\\tand\\t’89’;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t>=\\t‘80’\\tand\\nto_char(hiredate,’YY’)\\t<\\t‘90’;\\n200)\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tclerks\\twho\\thave\\texp\\tmore\\tthan\\t8ys.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tand\\n(months_between(sysdate,hiredate)\\t/12)\\t>\\t8;\\n201)\\t\\t\\tList\\tthe\\tmgrs\\tof\\tdept\\t10\\tor\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’\\tand\\t(deptno\\t=\\t10\\tor\\tdeptno\\n=20);\\n202)\\t\\t\\tList\\tthe\\temps\\tjoined\\tin\\tjan\\twith\\tsalary\\tranging\\tfrom\\t1500\\tto\\t4000.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’\\tand\\tsal\\nbetween\\t1500\\tand\\t4000;\\n203)\\t\\t\\tList\\tthe\\tunique\\tjobs\\tof\\tdept\\t20\\tand\\t30\\tin\\tdesc\\torder.\\nA)\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(20,30)\\torder\\tby\\tjob\\tdesc;\\n204)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\texp\\tof\\tthose\\tworking\\tunder\\tthe\\tmgr\\twhose\\nnumber\\tis\\tstarting\\twith\\t7\\tbut\\tshould\\tnot\\thave\\ta\\t9\\tjoined\\tbefore\\t1983.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 45, 'page_label': '46', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t(mgr\\tlike\\t'7%'\\tand\\tmgr\\tnot\\tlike\\t'%9%')\\nand\\tto_char(hiredate,'YY')\\t<\\t'83';\\n205)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\teither\\tmgr\\tor\\tanalyst\\twith\\tthe\\tsalary\\nranging\\tfrom\\t2000\\tto\\t5000\\tand\\twith\\tout\\tcomm.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\t(job\\t\\tin\\t(‘MANAGER’\\t,’ANALYST’)\\t)\\tand\\tsal\\nbetween\\t\\t2000\\tand\\t5000\\tand\\tcomm\\tis\\tnull;\\n206)\\t\\t\\tList\\tthe\\tempno,ename,sal,job\\tof\\tthe\\temps\\twith\\t/ann\\tsal\\t<34000\\tbut\\nreceiving\\tsome\\tcomm.\\tWhich\\tshould\\tnot\\tbe>sal\\tand\\tdesg\\tshould\\tbe\\tsales\\tman\\nworking\\tfor\\tdept\\t30.\\nA)\\tselect\\tempno,ename,sal,job\\tfrom\\temp\\twhere\\n12*(sal+nvl(comm,0))\\t<\\t34000\\tand\\tcomm\\tis\\tnot\\tnull\\tand\\tcomm<sal\\tand\\tjob\\t=\\n'SALESMAN'\\tand\\tdeptno\\t=\\t30;\\t\\t\\n207)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tfor\\tdept\\t10\\tor\\t20\\twith\\tdesgs\\tas\\tclerk\\tor\\nanalyst\\twith\\ta\\tsal\\tis\\teither\\t3\\tor\\t4\\tdigits\\twith\\tan\\texp>8ys\\tbut\\tdoes\\tnot\\tbelong\\tto\\nmons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 45, 'page_label': '46', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"mons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\\n((months_between(sysdate,hiredate))/12)>\\t8\\tand\\nto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP','APR')\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 46, 'page_label': '47', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(mgr\\tnot\\tlike\\t'%88'\\tand\\tmgr\\tnot\\tlike\\t'%56');\\n208)\\t\\t\\tList\\tthe\\tempno,ename,sal,job,deptno&exp\\tof\\tall\\tthe\\temps\\tbelongs\\tto\\tdept\\n10\\tor\\t20\\twith\\tan\\texp\\t6\\tto\\t10\\ty\\tworking\\tunder\\tthe\\tsame\\tmgr\\twith\\tout\\tcomm.\\nWith\\ta\\tjob\\tnot\\tending\\tirrespective\\tof\\tthe\\tposition\\twith\\tcomm.>200\\twith\\nexp>=7y\\tand\\tsal<2500\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tsep\\tor\\tnov\\tworking\\tunder\\nthe\\tmgr\\twhose\\tno\\tis\\tnot\\thaving\\tdigits\\teither\\t9\\tor\\t0\\tin\\tthe\\tasc\\tdept&\\tdesc\\tdept\\nA)\\n209)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tworking\\tat\\tChicago.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\n‘CHICAGO’);\\n210)\\t\\t\\tList\\tthe\\tempno,ename,deptno,loc\\tof\\tall\\tthe\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t;\\n211)\\t\\t\\tList\\tthe\\tempno,ename,loc,dname\\tof\\tall\\tthe\\tdepts.,10\\tand\\t20.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc,d.dname\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 46, 'page_label': '47', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"where\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\\nwith\\tan\\texp>6ys.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\tand\\td.loc\\tin\\t('CHICAGO','DALLAS')\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 47, 'page_label': '48', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t(months_between(sysdate,hiredate)/12)>\\t6\\t;\\n213)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\tloc\\tof\\tthose\\twho\\tbelongs\\tto\\tdallas\\t,newyork\\twith\\nsal\\tranging\\tfrom\\t2000\\tto\\t5000\\tjoined\\tin\\t81.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.loc\\tin\\t('NEW\\tYORK','DALLAS')\\nand\\tto_char(e.hiredate,'YY')\\t=\\t'81'\\t\\tand\\t\\te.sal\\tbetween\\t2000\\tand\\t5000;\\n214)\\t\\t\\tList\\tthe\\tempno,ename,sal,grade\\tof\\tall\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,s.grade\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\nwhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\t;\\n215)\\t\\t\\tList\\tthe\\tgrade\\t2\\tand\\t3\\temp\\tof\\tChicago.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ns.hisal\\t\\tand\\ts.grade\\tin\\t(2,3));\\n216)\\t\\t\\tList\\tthe\\temps\\twith\\tloc\\tand\\tgrade\\tof\\taccounting\\tdept\\tor\\tthe\\tlocs\\tdallas\\tor\\nChicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 47, 'page_label': '48', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Chicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\\nwheree.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\ts.grade\\tin\\t(3,5)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 48, 'page_label': '49', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t((months_between(sysdate,hiredate))/12)\\t>\\t6\\nand\\t(\\td.dname\\t=\\t'ACCOUNTING'\\tor\\tD.loc\\tin\\t('DALLAS','CHICAGO'))\\n217)\\t\\t\\tList\\tthe\\tgrades\\t3\\temps\\tof\\tresearch\\tand\\toperations\\tdepts..\\tjoined\\tafter\\t1987\\nand\\twhose\\tnames\\tshould\\tnot\\tbe\\teither\\tmiller\\tor\\tallen.\\nA)\\t\\t\\t\\tselect\\te.ename\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.dname\\tin\\t('OPERATIONS','RESEARCH')\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\te.ename\\tnot\\tin\\t('MILLER','ALLEN')\\nand\\tto_char(hiredate,'YYYY')\\t>1987;\\n218)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\tsmith.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n'SMITH');\\n219)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tmiller.\\nA)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\t\\twhere\\t\\thiredate\\t<(select\\thiredate\\tfrom\\temp\\twhere\\nename\\t=\\t‘MILLER’);\\n220)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\teither\\tallen\\tor\\tsal>allen.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN')\\nor\\tsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 49, 'page_label': '50', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"221)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tmanager.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate\\t<\\tm.hiredate;\\n222)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tgreater\\tthan\\tblakes\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’);\\n223)\\t\\t\\tList\\tthe\\tdept\\t10\\temps\\twhose\\tsal>allen\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\tand\\nsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\\n224)\\t\\t\\tList\\tthe\\tmgrs\\twho\\tare\\tsenior\\tto\\tking\\tand\\twho\\tare\\tjunior\\tto\\tsmith.\\nA)select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tmgr\\tfrom\\temp\\nwhere\\thiredate<(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'\\t)\\nand\\thiredate\\t>\\t(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t\\t'SMITH'))\\tand\\tmgr\\nis\\t\\t\\t\\t\\t\\t\\t\\nnot\\tnull;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 50, 'page_label': '51', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"225)\\t\\t\\tList\\tthe\\tempno,ename,loc,sal,dname,loc\\tof\\tthe\\tall\\tthe\\temps\\tbelonging\\tto\\nking\\tdept.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,d.loc,e.sal,d.dname\\tfrom\\temp\\te,dept\\td\\nwhere\\te.deptno=d.deptno\\tand\\te.deptno\\tin\\n(select\\tdeptno\\tfrom\\t\\temp\\twhere\\tename\\t=\\t'KING'and\\temp.empno\\t<>\\te.empno);\\n226)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalgrade\\tare\\tgreater\\tthan\\tthe\\tgrade\\tof\\tmiller.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t>\\n(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.ename\\t=\\t'MILLER')\\t;\\n227)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tbelonging\\tdallas\\tor\\tChicago\\twith\\tthe\\tgrade\\tsame\\tas\\nadamsor\\texp\\tmore\\tthan\\tsmith.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno=\\td.deptno\\tand\\td.loc\\tin\\t('DALLAS','CHICAGO')\\tand\\te.sal\\nbetween\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 50, 'page_label': '51', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"between\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\\nmonths_between(sysdate,hiredate)\\tfrom\\temp\\twhere\\tename\\t=\\t'SMITH'))\\t;\\n228)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tford\\tor\\tblake.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\te\\twhere\\te.ename\\tin\\n('FORD','BLAKE')and\\temp.empno\\t<>\\te.empno);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 51, 'page_label': '52', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"229)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tany\\tone\\tof\\tthe\\tfollowing.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t\\tin\\t\\n(select\\tsal\\tfrom\\temp\\te\\twhere\\temp.empno\\t<>\\te.empno);\\n230)\\t\\t\\tSal\\tof\\tany\\tclerk\\tof\\temp1\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n231)\\t\\t\\tAny\\temp\\tof\\temp2\\tjoined\\tbefore\\t82.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t<\\t1982;\\n232)\\t\\t\\tThe\\ttotal\\tremuneration\\t(sal+comm.)\\tof\\tall\\tsales\\tperson\\tof\\tSales\\tdept\\nbelonging\\tto\\temp3\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\t(sal+nvl(comm,0))\\tin\\n(select\\tsal+nvl(comm,0)\\t\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno=d.deptno\\t\\nand\\td.dname\\t=\\t'SALES'and\\te.job\\t=\\t'SALESMAN');\\n233)\\t\\t\\tAny\\tGrade\\t4\\temps\\tSal\\tof\\temp\\t4\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp4\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t4;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 52, 'page_label': '53', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='234)\\t\\t\\tAny\\temp\\tSal\\tof\\temp5\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp5;\\n235)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp);\\n236)\\t\\t\\tList\\tthe\\tdetails\\tof\\tmost\\trecently\\thired\\temp\\tof\\tdept\\t30.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tdeptno\\t=\\t30);\\n237)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tof\\tChicago\\tjoined\\tbefore\\tthe\\tmost\\t\\trecently\\nhired\\temp\\tof\\tgrade\\t2.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal\\t=\\t(\\tselect\\tmax(sal)\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\t\\nd.deptno\\tand\\td.loc\\t=\\t‘CHICAGO’\\tand\\nhiredate\\t<(select\\tmax(hiredate)\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\t\\t\\t\\t\\t\\t\\t\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t2))\\n238)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tworking\\tunder\\tking.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\twhere\\tmgr\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 53, 'page_label': '54', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fe1e5",
   "metadata": {},
   "source": [
    "## embedding and vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80010df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### embedding and vectorStoreDB\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict,Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412c9650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x18bc191dbe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205fd6c1",
   "metadata": {},
   "source": [
    "## VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7a3102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x18bc191dd30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fbfed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 1, 'page_label': 'i', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 2, 'page_label': 'ii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 3, 'page_label': 'iii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N T E N T S\\n1 introduction 1\\n2 python and required packages 5\\n2.1 A note on Python & OpenCV Versions . . . . 6\\n2.2 NumPy and SciPy . . . . . . . . . . . . . . . . 7\\n2.2.1 Windows . . . . . . . . . . . . . . . . . 7\\n2.2.2 OSX . . . . . . . . . . . . . . . . . . . 7\\n2.2.3 Linux . . . . . . . . . . . . . . . . . . . 8\\n2.3 Matplotlib . . . . . . . . . . . . . . . . . . . . 8\\n2.3.1 All Platforms . . . . . . . . . . . . . . 8\\n2.4 OpenCV . . . . . . . . . . . . . . . . . . . . . . 9\\n2.4.1 Linux and OSX . . . . . . . . . . . . . 9\\n2.4.2 Windows . . . . . . . . . . . . . . . . . 10\\n2.5 Mahotas . . . . . . . . . . . . . . . . . . . . . . 10\\n2.5.1 All Platforms . . . . . . . . . . . . . . 10\\n2.6 scikit-learn . . . . . . . . . . . . . . . . . . . . 11\\n2.6.1 All Platforms . . . . . . . . . . . . . . 11\\n2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 3, 'page_label': 'iii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19\\n4.1 So, What’s a Pixel? . . . . . . . . . . . . . . . 19\\n4.2 Overview of the Coordinate System . . . . . 22\\n4.3 Accessing and Manipulating Pixels . . . . . . 22\\n5 drawing 31\\n5.1 Lines and Rectangles . . . . . . . . . . . . . . 31\\n5.2 Circles . . . . . . . . . . . . . . . . . . . . . . 36\\n6 image processing 42\\n6.1 Image Transformations . . . . . . . . . . . . . 42\\niii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 4, 'page_label': 'iv', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\n6.1.1 Translation . . . . . . . . . . . . . . . . 43\\n6.1.2 Rotation . . . . . . . . . . . . . . . . . 48\\n6.1.3 Resizing . . . . . . . . . . . . . . . . . 53\\n6.1.4 Flipping . . . . . . . . . . . . . . . . . 59\\n6.1.5 Cropping . . . . . . . . . . . . . . . . 62\\n6.2 Image Arithmetic . . . . . . . . . . . . . . . . 64\\n6.3 Bitwise Operations . . . . . . . . . . . . . . . 71\\n6.4 Masking . . . . . . . . . . . . . . . . . . . . . 74\\n6.5 Splitting and Merging Channels . . . . . . . . 81\\n6.6 Color Spaces . . . . . . . . . . . . . . . . . . . 85\\n7 histograms 89\\n7.1 Using OpenCV to Compute Histograms . . . 90\\n7.2 Grayscale Histograms . . . . . . . . . . . . . . 91\\n7.3 Color Histograms . . . . . . . . . . . . . . . . 93\\n7.4 Histogram Equalization . . . . . . . . . . . . . 99\\n7.5 Histograms and Masks . . . . . . . . . . . . . 101\\n8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 4, 'page_label': 'iv', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112\\n8.3 Median . . . . . . . . . . . . . . . . . . . . . . 113\\n8.4 Bilateral . . . . . . . . . . . . . . . . . . . . . . 116\\n9 thresholding 119\\n9.1 Simple Thresholding . . . . . . . . . . . . . . 119\\n9.2 Adaptive Thresholding . . . . . . . . . . . . . 123\\n9.3 Otsu and Riddler-Calvard . . . . . . . . . . . 127\\n10 gradients and edge detection 132\\n10.1 Laplacian and Sobel . . . . . . . . . . . . . . . 133\\n10.2 Canny Edge Detector . . . . . . . . . . . . . . 138\\n11 contours 142\\n11.1 Counting Coins . . . . . . . . . . . . . . . . . 142\\n11.2 Contours and OpenCV Version Caveats . . . 149\\n12 where to now ? 153\\niv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 5, 'page_label': 'v', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O M PA N I O N W E B S I T E & S U P P L E M E N TA R Y\\nM AT E R I A L\\nThank you for picking up a copy of the 4th edition of\\nPractical Python and OpenCV!\\nIn this latest edition, I’m excited to announce the creation\\nof a companion website which includes supplementary mate-\\nrial that I could not ﬁt inside the book.\\nAt the end of nearly every chapter inside Practical Python\\nand OpenCV + Case Studies, you’ll ﬁnd a link to a supplemen-\\ntary webpage that includes additional information, such as\\nmy commentary on methods to extend your knowledge,\\ndiscussions of common error messages, recommendations\\non various algorithms to try, and optional quizzes to test\\nyour knowledge.\\nRegistration to the companion website is free with your\\npurchase of Practical Python and OpenCV.\\nTo create your companion website account, just use this\\nlink:\\nhttp://pyimg.co/o1y7e\\nTake a second to create your account now so you’ll have\\naccess to the supplementary materials as you work through\\nthe book.\\nv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 6, 'page_label': 'vi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E FA C E\\nWhen I ﬁrst set out to write this book, I wanted it to be\\nas hands-on as possible. I wanted lots of visual examples\\nwith lots of code. I wanted to write something that you\\ncould easily learn from, without all the rigor and detail of\\nmathematics associated with college level computer vision\\nand image processing courses.\\nI know from all my years spent in the classroom that the\\nway I learned best was from simply opening up an editor\\nand writing some code. Sure, the theory and examples in\\nmy textbooks gave me a solid starting point. But I never\\nreally “learned” something until I did it myself. I was very\\nhands-on. And that’s exactly how I wanted this book to be.\\nVery hands-on, with all the code easily modiﬁable and well\\ndocumented so you could play with it on your own. That’s\\nwhy I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 6, 'page_label': 'vi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='why I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst\\nstarted learning computer vision – it was a daunting task.\\nBut I learned a lot. And I had a lot of fun.\\nI hope this book helps you in your journey into computer\\nvision. I had a blast writing it. If you have any questions,\\nsuggestions, or comments, or if you simply want to say\\nhello, shoot me an email at adrian@pyimagesearch.com, or\\nvi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 7, 'page_label': 'vii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Contents\\nyou can visit my website at www.PyImageSearch.com and\\nleave a comment. I look forward to hearing from you soon!\\n-Adrian Rosebrock\\nvii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 8, 'page_label': 'viii', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='P R E R E Q U I S I T E S\\nIn order to make the most of this, you will need to have\\na little bit of programming experience. All examples in this\\nbook are in the Python programming language. Familiarity\\nwith Python or other scripting languages is suggested, but\\nnot required.\\nYou’ll also need to know some basic mathematics. This\\nbook is hands-on and example driven: lots of examples and\\nlots of code, so even if your math skills are not up to par,\\ndo not worry! The examples are very detailed and heavily\\ndocumented to help you follow along.\\nviii'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 9, 'page_label': 'ix', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='C O N V E N T I O N S U S E D I N T H I S B O O K\\nThis book includes many code listings and terms to aid\\nyou in your journey to learn computer vision and image\\nprocessing. Below are the typographical conventions used\\nin this book:\\nItalic\\nIndicates key terms and important information that\\nyou should take note of. May also denote mathemati-\\ncal equations or formulas based on connotation.\\nBold\\nImportant information that you should take note of.\\nConstant width\\nUsed for source code listings, as well as paragraphs\\nthat make reference to the source code, such as func-\\ntion and method names.\\nix'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 10, 'page_label': 'x', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='U S I N G T H E C O D E E X A M P L E S\\nThis book is meant to be a hands-on approach to com-\\nputer vision and machine learning. The code included in\\nthis book, along with the source code distributed with this\\nbook, are free for you to modify, explore, and share as you\\nwish.\\nIn general, you do not need to contact me for permis-\\nsion if you are using the source code in this book. Writing\\na script that uses chunks of code from this book is totally\\nand completely okay with me.\\nHowever, selling or distributing the code listings in this\\nbook, whether as information product or in your product’s\\ndocumentation, does require my permission.\\nIf you have any questions regarding the fair use of the\\ncode examples in this book, please feel free to shoot me an\\nemail. You can reach me at adrian@pyimagesearch.com.\\nx'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 11, 'page_label': 'xi', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='H O W T O C O N TA C T M E\\nWant to ﬁnd me online? Look no further:\\nWebsite: www.PyImageSearch.com\\nEmail: adrian@pyimagesearch.com\\nTwitter: @PyImageSearch\\nGoogle+: +AdrianRosebrock\\nLinkedIn: Adrian Rosebrock\\nxi'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 12, 'page_label': '1', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='1\\nI N T R O D U C T I O N\\nThe goal of computer vision is to understand the story\\nunfolding in a picture. As humans, this is quite simple. But\\nfor computers, the task is extremely difﬁcult.\\nSo why bother learning computer vision?\\nWell, images are everywhere!\\nWhether it be personal photo albums on your smartphone,\\npublic photos on Facebook, or videos on YouTube, we now\\nhave more images than ever – and we need methods to an-\\nalyze, categorize, and quantify the contents of these images.\\nFor example, have you recently tagged a photo of your-\\nself or a friend on Facebook lately? How does Facebook\\nseem to “know” where the faces are in an image?\\nFacebook has implemented facial recognition algorithms\\ninto their website, meaning that they cannot only ﬁnd faces\\nin an image, they can also identify whose face it is as well!\\nFacial recognition is an application of computer vision in\\nthe real world.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 13, 'page_label': '2', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nWhat other types of useful applications of computer vi-\\nsion are there?\\nWell, we could build representations of our 3D world us-\\ning public image repositories like Flickr. We could down-\\nload thousands and thousands of pictures of Manhattan,\\ntaken by citizens with their smartphones and cameras, and\\nthen analyze them and organize them to construct a 3D rep-\\nresentation of the city. We would then virtually navigate\\nthis city through our computers. Sound cool?\\nAnother popular application of computer vision is surveil-\\nlance.\\nWhile surveillance tends to have a negative connotation\\nof sorts, there are many different types. One type of surveil-\\nlance is related to analyzing security videos, looking for\\npossible suspects after a robbery.\\nBut a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 13, 'page_label': '2', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='But a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.\\nOn your last visit to your favorite clothing retailer, did\\nyou stop to examine the spring’s latest jeans trends? How\\nlong did you look at the jeans? What was your facial expres-\\nsion as you looked at the jeans? Did you then pick up a pair\\nand head to the dressing room? These are all types of ques-\\ntions that computer vision surveillance systems can answer.\\nComputer vision can also be applied to the medical ﬁeld.\\nA year ago, I consulted with the National Cancer Institute\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 14, 'page_label': '3', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\nto develop methods to automatically analyze breast histol-\\nogy images for cancer risk factors. Normally, a task like\\nthis would require a trained pathologist with years of expe-\\nrience – and it would be extremely time consuming!\\nOur research demonstrated that computer vision algo-\\nrithms could be applied to these images and could auto-\\nmatically analyze and quantify cellular structures – without\\nhuman intervention! Now, we can analyze breast histology\\nimages for cancer risk factors much faster.\\nOf course, computer vision can also be applied to other\\nareas of the medical ﬁeld. Analyzing X-rays, MRI scans,\\nand cellular structures all can be performed using computer\\nvision algorithms.\\nPerhaps the biggest success computer vision success story\\nyou may have heard of is the X-Box 360 Kinect. The Kinect\\ncan use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 14, 'page_label': '3', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='can use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.\\nThe list doesn’t stop there.\\nComputer vision is now prevalent in many areas of your\\nlife, whether you realize it or not. We apply computer vi-\\nsion algorithms to analyze movies, football games, hand\\ngesture recognition (for sign language), license plates (just\\nin case you were driving too fast), medicine, surgery, mili-\\ntary, and retail.\\nWe even use computer visions in space! NASA’s Mars\\nRover includes capabilities to model the terrain of the planet,\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 15, 'page_label': '4', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='introduction\\ndetect obstacles in its path, and stitch together panoramic\\nimages.\\nThis list will continue to grow in the coming years.\\nCertainly, computer vision is an exciting ﬁeld with end-\\nless possibilities.\\nWith this in mind, ask yourself: what does your imagina-\\ntion want to build? Let it run wild. And let the computer\\nvision techniques introduced in this book help you build it.\\nFurther Reading\\nWelcome to the supplementary material portion of the\\nchapter! If you haven’t already registered and created\\nyour account for the companion website, please do so\\nusing the following link:\\nhttp://pyimg.co/o1y7e\\nFrom there, you can ﬁnd the Chapter 1 supplemen-\\ntary material page here:\\nhttp://pyimg.co/rhsgi\\nThis page serves as an introduction to the companion\\nwebsite and details how to use it and what to expect\\nas you work through the rest of Practical Python and\\nOpenCV.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 16, 'page_label': '5', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2\\nP Y T H O N A N D R E Q U I R E D PA C K A G E S\\nIn order to explore the world of computer vision, we’ll\\nﬁrst need to install some packages and libraries. As a ﬁrst-\\ntimer in computer vision, installing some of these packages\\n(especially OpenCV) can be quite tedious, depending on\\nwhat operating system you are using. I’ve tried to consoli-\\ndate the installation instructions into a short how-to guide,\\nbut as you know, projects change, websites change, and in-\\nstallation instructions change! If you run into problems, be\\nsure to consult the package’s website for the most up-to-\\ndate installation instructions.\\nI highly recommend that you use either easy_install or\\npip to manage the installation of your packages. It will\\nmake your life much easier! You can read more about pip\\nhere: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 16, 'page_label': '5', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='here: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image\\nprocessing packages you need to run the examples in this\\nbook pre-installed! Using this virtual machine allows you\\nto jump right in to the examples in this book, without hav-\\ning to worry about package managers, installation instruc-\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 17, 'page_label': '6', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1 a note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 17, 'page_label': '6', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Inside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the\\nPython 2.7 and the Python 3+ environments!\\nIf you are looking for the OpenCV 2.4.X and Python 2.7\\nversion of this book, please look in the download directory\\nassociated with your purchase – inside you will ﬁnd the\\nOpenCV 2.4.X + Python 2.7 edition.\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 18, 'page_label': '7', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.2 numpy and scipy\\n2.2 numpy and scipy\\nNumPy is a library for the Python programming language\\nthat (among other things) provides support for large, multi-\\ndimensional arrays. Why is that important? Using NumPy,\\nwe can express images as multi-dimensional arrays. Repre-\\nsenting images as NumPy arrays is not only computation-\\nally and resource efﬁcient, many other image processing\\nand machine learning libraries use NumPy array represen-\\ntations as well. Furthermore, by using NumPy’s built-in\\nhigh-level mathematical functions, we can quickly and eas-\\nily perform numerical analysis on an image.\\nGoing hand-in-hand with NumPy, we also have SciPy.\\nSciPy adds further support for scientiﬁc and technical com-\\nputing.\\n2.2.1 Windows\\nBy far, the easiest way to install NumPy and SciPy on your\\nWindows system is to download and install the binary dis-\\ntribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 18, 'page_label': '7', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='tribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.\\nYou can also install NumPy and SciPy using pip:\\nListing 2.1: Install NumPy and SciPy on OSX\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 19, 'page_label': '8', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.3 matplotlib\\n$ pip install numpy\\n$ pip install scipy\\n2.2.3 Linux\\nOn many Linux distributions, such as Ubuntu, NumPy comes\\npre-installed and conﬁgured.\\nIf you want the latest versions of NumPy and SciPy, you\\ncan build the libraries from source, but the easiest method\\nis to use a pip:\\nListing 2.2: Install NumPy and SciPy on Linux\\n$ pip install numpy\\n$ pip install scipy\\n2.3 matplotlib\\nSimply put, matplotlib is a plotting library. If you’ve ever\\nused MATLAB before, you’ll probably feel very comfort-\\nable in the matplotlib environment. When analyzing im-\\nages, we’ll make use of matplotlib. Whether plotting image\\nhistograms or simply viewing the image itself, matplotlib\\nis a great tool to have in your toolbox.\\n2.3.1 All Platforms\\nMatplotlib is available from http://matplotlib.org/. The\\nmatplotlib package is also pip-installable:\\nListing 2.3: Install matplotlib\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 20, 'page_label': '9', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4 opencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 20, 'page_label': '9', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='website at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in\\nprevious years, but has luckily gotten much easier. I have\\naccumulated OpenCV installation instructions on the PyIm-\\nageSearch blog for Debian-based Linux distributions (such\\nas Ubuntu) and OSX here:\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 21, 'page_label': '10', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.5 mahotas\\nhttp://pyimg.co/vvlpy\\nJust scroll down the “Install OpenCV 3 and Python” and\\n“Install OpenCV 4 and Python” sections, select the oper-\\nating system and Python version that you want to install\\nOpenCV for, and you’ll be on your way!\\n2.4.2 Windows\\nThe OpenCV Docs provide fantastic tutorials on how to in-\\nstall OpenCV in Windows using binary distributions. You\\ncan check out the installation instructions here:\\nhttp://pyimg.co/l2q6s\\n2.5 mahotas\\nMahotas, just like OpenCV , relies on NumPy arrays. Much\\nof the functionality implemented in Mahotas can be found\\nin OpenCV , but in some cases, the Mahotas interface is just\\neasier to use. We’ll use Mahotas to complement OpenCV .\\n2.5.1 All Platforms\\nInstalling Mahotas is extremely easy on all platforms. As-\\nsuming you already have NumPy and SciPy installed, all\\nyou need is a single call to the pip command:\\nListing 2.4: Install Mahotas\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 22, 'page_label': '11', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.6 scikit -learn\\n$ pip install mahotas\\n2.6 scikit -learn\\nAlright, you got me, scikit-learn isn’t an image processing\\nor computer vision library – it’s a machine learning library.\\nThat said, you can’t have advanced computer vision tech-\\nniques without some sort of machine learning, whether it\\nbe clustering, vector quantization, classiﬁcation models, etc.\\nScikit-learn also includes a handful of image feature extrac-\\ntion functions as well. We don’t use the scikit-learn library\\nin Practical Python and OpenCV, but it’s heavily used inCase\\nStudies.\\n2.6.1 All Platforms\\nInstalling scikit-learn on all platforms is dead-simple using\\npip:\\nListing 2.5: Install scikit-learn\\n$ pip install scikit-learn\\n2.7 scikit -image\\nThe algorithms included in scikit-image (I would argue) fol-\\nlow closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 22, 'page_label': '11', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='low closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-\\nrithms, you need to have developed some rigor and under-\\nstanding in the computer vision ﬁeld. If you already have\\nsome experience in computer vision and image processing,\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 23, 'page_label': '12', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\ndeﬁnitely check out scikit-image; otherwise, I would con-\\ntinue working with OpenCV to start. Again, scikit-image\\nwon’t be used in of Practical Python and OpenCV, but it will\\nbe used in Case Studies, especially when we perform hand-\\nwritten digit recognition.\\nAssuming you already have NumPy and SciPy installed,\\nyou can install scikit-image using pip:\\nListing 2.6: Install scikit-image\\n$ pip install -U scikit-image\\nNow that we have all our packages installed, let’s start\\nexploring the world of computer vision!\\n2.8 skip the installation\\nAs I’ve mentioned above, installing all these packages can\\nbe time consuming and tedious. If you want to skip the\\ninstallation process and jump right into the world of im-\\nage processing and computer vision, I have set up a pre-\\nconﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 23, 'page_label': '12', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='conﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 24, 'page_label': '13', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='2.8 skip the installation\\nFurther Reading\\nTo learn more about installing OpenCV , Python virtual\\nenvironments, and choosing a code editor, please see\\nthe Chapter 2 supplementary material webpage:\\nhttp://pyimg.co/f0sxq\\nIn particular, I think you’ll be interested in learning\\nhow the PyCharm IDE can be utilized with Python vir-\\ntual environments to create the perfect computer vision\\ndevelopment environment.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 25, 'page_label': '14', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='3\\nL O A D I N G , D I S P L AY I N G , A N D S AV I N G\\nThis book is meant to be a hands-on, how-to guide to get-\\nting started with computer vision using Python and OpenCV .\\nWith that said, let’s not waste any time. We’ll get our feet\\nwet by writing some simple code to load an image off disk,\\ndisplay it on our screen, and write it to ﬁle in a different\\nformat. When executed, our Python script should show\\nour image on screen, like in Figure 3.1.\\nFirst, let’s create a ﬁle named load_display_save.py to\\ncontain our code. Now we can start writing some code:\\nListing 3.1: load_display_save.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\nThe ﬁrst thing we are going to do is import the packages\\nwe will need for this example.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 26, 'page_label': '15', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nFigure 3.1: Example of loading and displaying\\na Tyrannosaurus Rex image on our\\nscreen.\\nThroughout this book you’ll see us importing the print_\\nfunction from the __future__ package. We’ll be using the\\nactual print() function rather than the print statement so\\nthat our code will work with both Python 2.7 and Python\\n3 – just something to keep in mind as we work through the\\nexamples!\\nWe’ll useargparse to handle parsing our command line\\narguments. Then, cv2 is imported – cv2 is our OpenCV li-\\nbrary and contains our image processing functions.\\nFrom there, Lines 5-8 handle parsing the command line\\narguments. The only argument we need is --image: the\\npath to our image on disk. Finally, we parse the arguments\\nand store them in a dictionary.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 27, 'page_label': '16', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nListing 3.2: load_display_save.py\\n9 image = cv2.imread(args[\"image\"])\\n10 print(\"width: {} pixels\".format(image.shape[1]))\\n11 print(\"height: {} pixels\".format(image.shape[0]))\\n12 print(\"channels: {}\".format(image.shape[2]))\\n13\\n14 cv2.imshow(\"Image\", image)\\n15 cv2.waitKey(0)\\nNow that we have the path to the image, we can load it\\noff the disk using the cv2.imread function on Line 9. The\\ncv2.imread function returns a NumPy array representing\\nthe image.\\nLines 10-12 examine the dimensions of the image. Again,\\nsince images are represented as NumPy arrays, we can sim-\\nply use the shape attribute to examine the width, height,\\nand the number of channels.\\nFinally, Lines 14 and 15 handle displaying the actual\\nimage on our screen. The ﬁrst parameter is a string, the\\n“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 27, 'page_label': '16', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until\\nwe press a key on our keyboard. Using a parameter of 0\\nindicates that any keypress will un-pause the execution.\\nThe last thing we are going to do is write our image to\\nﬁle in JPG format:\\nListing 3.3: load_display_save.py\\n16 cv2.imwrite(\"newimage.jpg\", image)\\nAll we are doing here is providing the path to the ﬁle\\n(the ﬁrst argument) and then the image we want to save\\n16'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 28, 'page_label': '17', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\n(the second argument). It’s that simple.\\nTo run our script and display our image, we simply open\\nup a terminal window and execute the following command:\\nListing 3.4: load_display_save.py\\n$ python load_display_save.py --image ../images/trex.png\\nIf everything has worked correctly, you should see the T-\\nRex on your screen as in Figure 3.1. To stop the script from\\nexecuting, simply click on the image window and press any\\nkey.\\nExamining the output of the script, you should also see\\nsome basic information on our image. You’ll note that the\\nimage has a width of 350 pixels, a height of 228 pixels, and 3\\nchannels (the RGB components of the image). Represented\\nas a NumPy array, our image has a shape of (228,350,3).\\nThe NumPy shape may seem reversed to you (specifying\\nthe height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 28, 'page_label': '17', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).\\nHere, our image has a height of 228 pixels (the number of\\nrows) and a width of 350 pixels (the number of columns) –\\nthus, the NumPy shape makes sense (although it may seen\\na bit confusing at ﬁrst).\\nFinally, note the contents of your directory. You’ll see a\\nnew ﬁle there: newimage.jpg. OpenCV has automatically\\nconverted our PNG image to JPG for us! No further effort\\nis needed on our part to convert between image formats.\\n17'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 29, 'page_label': '18', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='loading , displaying , and saving\\nNext up, we’ll explore how to access and manipulate the\\npixel values in an image.\\nFurther Reading\\nYou can ﬁnd the Chapter 3 supplementary material, re-\\nsources, and quizzes here:\\nhttp://pyimg.co/xh73h\\nSpeciﬁcally, I discuss some common “gotchas” that may\\ntrip you up when utilizing OpenCV for the ﬁrst time –\\nthese tips and tricks are especially useful if this is your\\nﬁrst exposure to OpenCV .\\nBe sure to take the quiz to test your knowledge after\\nreading this chapter!\\n18'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 30, 'page_label': '19', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4\\nI M A G E B A S I C S\\nIn this chapter we are going to review the building blocks\\nof an image – the pixel. We’ll discuss exactly what a pixel\\nis, how pixels are used to form an image, and then how to\\naccess and manipulate pixels in OpenCV .\\n4.1 so , what ’s a pixel?\\nEvery image consists of a set of pixels. Pixels are the raw\\nbuilding blocks of an image. There is no ﬁner granularity\\nthan the pixel.\\nNormally, we think of a pixel as the “color” or the “inten-\\nsity” of light that appears in a given place in our image.\\nIf we think of an image as a grid, each square in the grid\\ncontains a single pixel.\\nFor example, let’s pretend we have an image with a res-\\nolution of 500 × 300. This means that our image is repre-\\nsented as a grid of pixels, with 500 rows and 300 columns.\\nOverall, there are 500 × 300 = 150, 000 pixels in our image.\\n19'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 31, 'page_label': '20', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nMost pixels are represented in two ways: grayscale and\\ncolor. In a grayscale image, each pixel has a value between\\n0 and 255, where zero corresponds to “black” and 255 cor-\\nresponds to “white”. The values in between 0 and 255 are\\nvarying shades of gray, where values closer to 0 are darker\\nand values closer to 255 are lighter.\\nColor pixels are normally represented in the RGB color\\nspace – one value for the Red component, one for Green,\\nand one for Blue. Other color spaces exist, but let’s start\\nwith the basics and move our way up from there.\\nEach of the three colors is represented by an integer in\\nthe range 0 to 255, which indicates how “much” of the color\\nthere is. Given that the pixel value only needs to be in the\\nrange [0, 255], we normally use an 8-bit unsigned integer to\\nrepresent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 31, 'page_label': '20', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='represent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.\\nTo construct a white color, we would ﬁll up each of the\\nred, green, and blue buckets completely, like this: (255,\\n255,255).\\nThen, to create a black color, we would empty each of the\\nbuckets out: (0,0,0).\\nTo create a pure red color, we would ﬁll up the red bucket\\n(and only the red bucket) up completely: (255,0,0).\\nAre you starting to see a pattern?\\n20'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 32, 'page_label': '21', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.1 so, what ’s a pixel?\\nFor your reference, here are some common colors repre-\\nsented as RGB tuples:\\n• Black: (0,0,0)\\n• White: (255,255,255)\\n• Red: (255,0,0)\\n• Green: (0,255,0)\\n• Blue: (0,0,255)\\n• Aqua: (0,255,255)\\n• Fuchsia: (255,0,255)\\n• Maroon: (128,0,0)\\n• Navy: (0,0,128)\\n• Olive: (128,128,0)\\n• Purple: (128,0,128)\\n• Teal: (0,128,128)\\n• Yellow: (255,255,0)\\nNow that we have a good understanding of pixels, let’s\\nhave a quick review of the coordinate system.\\n21'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 33, 'page_label': '22', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.2 overview of the coordinate system\\n4.2 overview of the coordinate system\\nAs I mentioned above, an image is represented as a grid of\\npixels. Imagine our grid as a piece of graph paper. Using\\nthis graph paper, the point (0, 0) corresponds to the upper\\nleft corner of the image. As we move down and to the right,\\nboth the x and y values increase.\\nLet’s take a look at the image in Figure 4.1 to make this\\npoint clearer.\\nHere we have the letter “I” on a piece of graph paper. We\\nsee that we have an 8 × 8 grid with a total of 64 pixels.\\nThe point (0, 0) corresponds to the top left pixel in our\\nimage, whereas the point (7, 7) corresponds to the bottom\\nright corner.\\nFinally, the point (3, 4) is the pixel three columns to the\\nright and four rows down, once again keeping in mind that\\nwe start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 33, 'page_label': '22', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='we start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.\\n4.3 accessing and manipulating pixels\\nAdmittedly, the example from Chapter 3 wasn’t very excit-\\ning. All we did was load an image off disk, display it, and\\n22'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 34, 'page_label': '23', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.1: The letter “I” placed on a piece of\\ngraph paper. Pixels are accessed by\\ntheir (x, y) coordinates, where we go\\nx columns to the right and y rows\\ndown, keeping in mind that Python\\nis zero-indexed: we start counting\\nfrom zero rather than one.\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 35, 'page_label': '24', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nthen write it back to disk in a different image ﬁle format.\\nLet’s do something a little more exciting and see how we\\ncan access and manipulate the pixels in an image:\\nListing 4.1: getting_and_setting.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nSimilar to our example in the previous chapter, Lines 1-8\\nhandle importing the packages we need, along with setting\\nup our argument parser. There is only one command line\\nargument needed: the path to the image we are going to\\nwork with.\\nLines 10 and 11 handle loading the actual image off disk\\nand displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 35, 'page_label': '24', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='and displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.\\nConceptually, we can think of this representation as a ma-\\ntrix, as discussed in Section 4.1 above. In order to access a\\npixel value, we just need to supply the x and y coordinates\\nof the pixel we are interested in. From there, we are given\\na tuple representing the Red, Green, and Blue components\\n24'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 36, 'page_label': '25', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nof the image.\\nHowever, it’s important to note that OpenCV stores RGB\\nchannels in reverse order. While we normally think in terms\\nof Red, Green, and Blue, OpenCV actually stores them in\\nthe order of Blue, Green, and Red. This is important to\\nnote since it could cause some confusion later.\\nAlright, let’s explore some code that can be used to ac-\\ncess and manipulate pixels:\\nListing 4.2: getting_and_setting.py\\n12 (b, g, r) = image[0, 0]\\n13 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\n14\\n15 image[0, 0] = (0, 0, 255)\\n16 (b, g, r) = image[0, 0]\\n17 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\nOn Line 12, we grab the pixel located at (0, 0) – the top-\\nleft corner of the image. This pixel is represented as a tuple.\\nAgain, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 36, 'page_label': '25', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Again, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out\\nthe values of each channel to our console.\\nAs you can see, accessing pixel values is quite easy! Num-\\nPy takes care of all the hard work for us. All we are doing\\nis providing indexes into the array.\\nJust as NumPy makes it easy to access pixel values, it also\\nmakes it easy to manipulate pixel values.\\n25'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 37, 'page_label': '26', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nOn Line 15 we manipulate the top-left pixel in the im-\\nage, which is located at coordinate (0, 0) and set it to have\\na value of (0, 0, 255). If we were reading this pixel value\\nin RGB format, we would have a value of 0 for red, 0 for\\ngreen, and 255 for blue, thus making it a pure blue color.\\nHowever, as I mentioned above, we need to take special\\ncare when working with OpenCV . Our pixels are actually\\nstored in BGR format, not RGB format.\\nWe actually read this pixel as255 for red, 0 for green, and\\n0 for blue, making it a red color, not a blue color.\\nAfter setting the top-left pixel to have a red color on Line\\n15, we then grab the pixel value and print it back to con-\\nsole on Lines 16 and 17, just to demonstrate that we have\\nindeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 37, 'page_label': '26', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='indeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-\\nbilities to access larger rectangular portions of the image?\\nThe code below demonstrates how we can do this:\\nListing 4.3: getting_and_setting.py\\n18 corner = image[0:100, 0:100]\\n19 cv2.imshow(\"Corner\", corner)\\n20\\n21 image[0:100, 0:100] = (0, 255, 0)\\n22\\n23 cv2.imshow(\"Updated\", image)\\n24 cv2.waitKey(0)\\nOn Line 18 we grab a 100 × 100 pixel region of the image.\\nIn fact, this is the top-left corner of the image! In order to\\ngrab chunks of an image, NumPy expects we provide four\\n26'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 38, 'page_label': '27', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nindexes:\\n1. Start y: The ﬁrst value is the starting y coordinate.\\nThis is where our array slice will start along the y-axis.\\nIn our example above, our slice starts at y = 0.\\n2. End y:Just as we supplied a starting y value, we must\\nprovide an ending y value. Our slice stops along the\\ny-axis when y = 100.\\n3. Start x:The third value we must supply is the starting\\nx coordinate for the slice. In order to grab the top-left\\nregion of the image, we start at x = 0.\\n4. End x:Finally, we need to provide an x-axis value for\\nour slice to stop. We stop when x = 100.\\nOnce we have extracted the top-left corner of the image,\\nLine 19 shows us the result of the cropping. Notice how\\nour image is just the 100 × 100 pixel region from the top-\\nleft corner of our original image.\\nThe last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 38, 'page_label': '27', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='The last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the\\nimage; however, this time we are setting this region to have\\na value of (0, 255, 0) (green).\\nLines 23 and 24 then show us the results of our work.\\nSo how do we run our Python script?\\nAssuming you have downloaded the source code listings\\nfor this book, simply navigate to the chapter-04 directory\\n27'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 39, 'page_label': '28', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nand execute the command below:\\nListing 4.4: getting_and_setting.py\\n$ python getting_and_setting.py --image ../images/trex.png\\nOnce our script starts running, you should see some out-\\nput printed to your console ( Line 13). The ﬁrst line of out-\\nput tells us that the pixel located at (0, 0) has a value of\\n254 for all three red, green, and blue channels. This pixel\\nappears to be almost pure white.\\nThe second line of output shows us that we have success-\\nfully changed the pixel located at (0, 0) to be red rather than\\nwhite (Lines 15-17).\\nListing 4.5: getting_and_setting.py\\nPixel at (0, 0) - Red: 254, Green: 254, Blue: 254\\nPixel at (0, 0) - Red: 255, Green: 0, Blue: 0\\nWe can see the results of our work in Figure 4.2. The Top-\\nLeft image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 39, 'page_label': '28', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Left image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if\\nyou look closely, you can see that the top-left pixel located\\nat (0, 0) is red!\\nFinally, the bottom image shows that we have successfully\\ndrawn a green square on our image.\\nIn this chapter, we have explored how to access and ma-\\nnipulate the pixels in an image using NumPy’s built-in ar-\\nray slicing functionality. We were even able to draw a green\\n28'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 40, 'page_label': '29', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nFigure 4.2: Top-Left: Our original image. Top-\\nRight: Cropping our image using\\nNumPy array slicing. Bottom: Draw-\\ning a 100 ×100 pixel green square on\\nour image by using basic NumPy in-\\ndexing.\\n29'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 41, 'page_label': '30', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='4.3 accessing and manipulating pixels\\nsquare using nothing but NumPy array manipulation!\\nHowever, we won’t get very far using only NumPy func-\\ntions. The next chapter will show you how to draw lines,\\nrectangles, and circles using OpenCV methods.\\nFurther Reading\\nOne of the most common errors I see with developers\\njust starting to learn OpenCV is the (x, y) -coordinate\\nordering passed into images. I also tend to see a lot of\\nconfusion regarding the BGR versus RGB channel or-\\ndering.\\nTo learn more about these common errors (and how\\nyou can avoid) then, be sure to refer to the Chapter 4\\nsupplementary material:\\nhttp://pyimg.co/mtemn\\nI’ve also included a quiz that you can use to test your\\nknowledge on image basics.\\n30'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 42, 'page_label': '31', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5\\nD R AW I N G\\nUsing NumPy array slices in Chapter 4, we were able to\\ndraw a green square on our image. But what if we wanted\\nto draw a single line? Or a circle? NumPy does not provide\\nthat type of functionality – it’s only a numerical processing\\nlibrary after all!\\nLuckily, OpenCV provides convenient, easy-to-use meth-\\nods to draw shapes on an image. In this chapter, we’ll re-\\nview the three most basic methods to draw shapes: cv2.\\nline, cv2.rectangle, and cv2.circle.\\nWhile this chapter is by no means a complete, exhaus-\\ntive overview of the drawing capabilities of OpenCV , it will\\nnonetheless provide a quick, hands-on approach to get you\\nstarted drawing immediately.\\n5.1 lines and rectangles\\nBefore we start exploring the the drawing capabilities of\\nOpenCV , let’s ﬁrst deﬁne our canvas in which we will draw\\nour masterpieces.\\n31'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 43, 'page_label': '32', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nUp until this point, we have only loaded images off disk.\\nHowever, we can also deﬁne our images manually using\\nNumPy arrays. Given that OpenCV interprets an image as\\na NumPy array, there is no reason why we can’t manually\\ndeﬁne the image ourselves!\\nIn order to initialize our image, let’s examine the code\\nbelow:\\nListing 5.1: drawing.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\nLines 1 and 2 imports the packages we will be using.\\nAs a shortcut, we’ll create an alias for numpy as np. We’ll\\ncontinue this convention throughout the rest of the book.\\nIn fact, you’ll commonly see this convention in the Python\\ncommunity as well! We’ll also import cv2, so we can have\\naccess to the OpenCV library.\\nInitializing our image is handled on Line 4. We construct\\na NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 43, 'page_label': '32', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,\\nrespectively. As the name suggests, the zeros method ﬁlls\\nevery element in the array with an initial value of zero.\\nIt’s important to draw your attention to the second argu-\\nment of the np.zeros method: the data type, dtype. Since\\nwe are representing our image as an RGB image with pixels\\nin the range [0, 255], it’s important that we use an 8-bit un-\\nsigned integer, or uint8. There are many other data types\\n32'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 44, 'page_label': '33', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nthat we can use (common ones include 32-bit integers, and\\n32-bit or 64-bit ﬂoats), but we’ll mainly be using uint8 for\\nthe majority of the examples in this book.\\nNow that we have our canvas initialized, we can do some\\ndrawing:\\nListing 5.2: drawing.py\\n5 green = (0, 255, 0)\\n6 cv2.line(canvas, (0, 0), (300, 300), green)\\n7 cv2.imshow(\"Canvas\", canvas)\\n8 cv2.waitKey(0)\\n9\\n10 red = (0, 0, 255)\\n11 cv2.line(canvas, (300, 0), (0, 300), red, 3)\\n12 cv2.imshow(\"Canvas\", canvas)\\n13 cv2.waitKey(0)\\nThe ﬁrst thing we do on Line 5 is deﬁne a tuple used to\\nrepresent the color “green”. Then, we draw a green line\\nfrom point (0, 0) (the top-left corner of the image) to point\\n(300, 300), the bottom-right corner of the image on Line 6.\\nIn order to draw the line, we make use of the cv2.line\\nmethod. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 44, 'page_label': '33', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='method. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose\\nto start our line from the top-left corner of the image, at\\npoint (0, 0). We also need to supply an ending point for the\\nline (the third argument). We deﬁne our ending point to be\\n(300, 300), the bottom-right corner of the image. The last ar-\\ngument is the color of our line, which, in this case, is green.\\nLines 7 and 8 show our image and then wait for a keypress.\\n33'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 45, 'page_label': '34', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\nFigure 5.1: Examples of drawing lines and rect-\\nangles using OpenCV .\\nAs you can see, drawing a line is quite simple! But\\nthere is one other important argument to consider in the\\ncv2.line method: the thickness.\\nOn Lines 10-13 we deﬁne a red color as a tuple (again,\\nin BGR rather than RGB format). We then draw a red line\\nfrom the top-right corner of the image to the bottom left.\\nThe last parameter to the method controls the thickness of\\nthe line – we decide to make the thickness 3 pixels. Again,\\nwe show our image and wait for a keypress.\\nDrawing a line was simple enough. Now we can move on\\nto drawing rectangles. Check out the code below for more\\ndetails:\\nListing 5.3: drawing.py\\n14 cv2.rectangle(canvas, (10, 10), (60, 60), green)\\n15 cv2.imshow(\"Canvas\", canvas)\\n34'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 46, 'page_label': '35', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.1 lines and rectangles\\n16 cv2.waitKey(0)\\n17\\n18 cv2.rectangle(canvas, (50, 200), (200, 225), red, 5)\\n19 cv2.imshow(\"Canvas\", canvas)\\n20 cv2.waitKey(0)\\n21\\n22 blue = (255, 0, 0)\\n23 cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)\\n24 cv2.imshow(\"Canvas\", canvas)\\n25 cv2.waitKey(0)\\nOn Line 14 we make use of the cv2.rectangle method.\\nThe signature of this method is identical to the cv2.line\\nmethod above, but let’s explore each argument anyway.\\nThe ﬁrst argument is the image we want to draw our rect-\\nangle on. We want to draw on ourcanvas, so we pass it into\\nthe method. The second argument is the starting (x, y) po-\\nsition of our rectangle – here, we are starting our rectangle\\nat point (10, 10). Then, we must provide an ending (x, y)\\npoint for the rectangle. We decide to end our rectangle at\\n(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 46, 'page_label': '35', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also\\ncontrol the thickness of a rectangle. Line 18 provides one\\nadded argument: the thickness. Here, we draw a red rect-\\nangle that is 5 pixels thick, starting from point (50, 200) and\\nending at (200, 225).\\nAt this point, we have only drawn the outline of a rect-\\nangle. How do we draw a rectangle that is “ﬁlled in”, like\\nwhen using NumPy array slices in Chapter 4?\\n35'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 47, 'page_label': '36', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.2: Drawing a simple bullseye with the\\ncv2.circle function.\\nSimple. We just pass in a negative value for the thickness\\nargument.\\nLine 23 demonstrates how to draw a rectangle of a solid\\ncolor. We draw a blue rectangle, starting from (200, 50) and\\nending at (225, 125). By specifying -1 as the thickness, our\\nrectangle is drawn as a solid blue.\\nCongratulations! You now have a solid grasp of drawing\\nrectangles. In the next section, we’ll move on to drawing\\ncircles.\\n5.2 circles\\nDrawing circles is just as simple as drawing rectangles, but\\nthe function arguments are a little different. Let’s go ahead\\nand get started:\\n36'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 48, 'page_label': '37', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nListing 5.4: drawing.py\\n26 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\n27 (centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\\n28 white = (255, 255, 255)\\n29\\n30 for r in range(0, 175, 25):\\n31 cv2.circle(canvas, (centerX, centerY), r, white)\\n32\\n33 cv2.imshow(\"Canvas\", canvas)\\n34 cv2.waitKey(0)\\nOn Line 26 we re-initialize our canvas to be blank. The\\nrectangles are gone! We need a fresh canvas to draw our\\ncircles.\\nLine 27 calculates two variables: centerX and centerY.\\nThese two variables represent the (x, y) coordinates of the\\ncenter of the image. We calculate the center by examining\\nthe shape of our NumPy array, and then dividing by two.\\nThe height of the image can be found in canvas.shape[0]\\nand the width in canvas.shape[1]. Finally, Line 28 deﬁnes\\na white pixel.\\nNow, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 48, 'page_label': '37', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Now, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.\\nLine 31 handles the actual drawing of the circle. The ﬁrst\\nparameter is our canvas, the image we want to draw the\\ncircle on. We then need to supply the point in which our\\ncircle will be drawn around. We pass in a tuple of(centerX,\\ncenterY) so that our circles will be centered at the middle\\nof the image. The third argument is the radius of the circle\\nwe wish to draw. Finally, we pass in the color of our circle,\\n37'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 49, 'page_label': '38', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nin this case, white.\\nLines 33 and 34 then show our image and wait for a key-\\npress.\\nSo what does our image look like?\\nCheck out Figure 5.2 and you will see that we have drawn\\na simple bullseye! The “dot” in the very center of the image\\nis drawn with a radius of 0. The larger circles are drawn\\nwith every increasing radii sizes from our for loop.\\nNot too bad. But what else can we do?\\nLet’s do some abstract drawing:\\nListing 5.5: drawing.py\\n35 for i in range(0, 25):\\n36 radius = np.random.randint(5, high = 200)\\n37 color = np.random.randint(0, high = 256, size = (3,)).tolist\\n()\\n38 pt = np.random.randint(0, high = 300, size = (2,))\\n39\\n40 cv2.circle(canvas, tuple(pt), radius, color, -1)\\n41\\n42 cv2.imshow(\"Canvas\", canvas)\\n43 cv2.waitKey(0)\\nOur code starts off on Line 35 with more looping. This\\ntime we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 49, 'page_label': '38', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='time we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.\\nIn order to draw a random circle, we need to generate\\nthree values: the radius of the circle, the color of the circle,\\n38'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 50, 'page_label': '39', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFigure 5.3: The results of our masterpiece. No-\\ntice that each circle is randomly\\nplaced on the canvas with a random\\ncolor.\\nand the pt – the (x, y) coordinate of where the circle will be\\ndrawn.\\nWe generate a radius value in the range [5, 200) on Line\\n36. This value controls how large our circle will be.\\nNext, we randomly generate a color on Line 37. As we\\nknow, the color of an RGB pixel consists of three values in\\nthe range [0, 255]. In order to get three random integers\\nrather than only one integer, we pass the keyword argu-\\nment size=(3,), instructing NumPy to return a list of three\\nnumbers.\\n39'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 51, 'page_label': '40', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFinally, we need an (x, y) point to draw our circle. We’ll\\ngenerate a point in the range [0, 300), again using NumPy’s\\nnp.random.randint function.\\nThe drawing of our circle then takes place on Line 40,\\nusing the radius, color, and pt that we randomly gener-\\nated. Notice how we use a thickness of -1, so our circles\\nare drawn as a solid color and not just an outline.\\nOur masterpiece is then shown to us on Lines 42 and 43.\\nYou can check out our work in Figure 5.3. Notice how\\neach circle has a different size, color, and placement on our\\ncanvas.\\nIn this chapter, you were introduced to basic drawing\\nfunctions using OpenCV . We explored how to draw shapes\\nusing the cv2.line, cv2.rectangle, and cv2.circle meth-\\nods.\\nWhile these functions seem extremely basic and simple,\\nmake sure you understand them! They are essential build-\\ning blocks that will come in handy later in this book.\\n40'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 52, 'page_label': '41', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5.2 circles\\nFurther Reading\\nWhy are we bothering learning how to draw rectangles,\\ncircles, and lines in a book on computer vision and im-\\nage processing?\\nIsn’t the point of computer vision to write software that\\nunderstands the contents of an image? And if so, why\\nin the world do we need to know how to draw various\\nshapes on images?\\nThese are excellent questions – and I address each of\\nthem (and provide examples of how drawing methods\\nare used in object detection and extraction) in side the\\nChapter 5 supplementary material:\\nhttp://pyimg.co/rlpak\\n41'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 53, 'page_label': '42', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6\\nI M A G E P R O C E S S I N G\\nNow that you have a solid foundation to build upon, we\\ncan start to exploring simple image processing techniques.\\nFirst, we’ll start off with basic image transformations,\\nsuch as translation, rotation, resizing, ﬂipping, and crop-\\nping. Then, we’ll explore other types of image processing\\ntechniques, including image arithmetic, bitwise operations,\\nand masking.\\nFinally, we’ll explore how to split an image into its re-\\nspective channels and then merge them back together again.\\nWe’ll conclude this chapter with a discussion of different\\ncolor spaces that OpenCV supports and the beneﬁts and\\nlimitations of each of them.\\n6.1 image transformations\\nIn this section, we’ll cover basic image transformations. These\\nare common techniques that you’ll likely apply to images,\\nincluding translation, rotation, resizing, ﬂipping, and crop-\\nping. We’ll explore each of these techniques in detail.\\n42'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 54, 'page_label': '43', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nMake sure you have a good grasp of these methods! They\\nare important in nearly all areas of computer vision.\\n6.1.1 Translation\\nThe ﬁrst method we are going to explore is translation.\\nTranslation is the shifting of an image along the x and y\\naxis. Using translation, we can shift an image up, down,\\nleft, or right, along with any combination of the above!\\nThis concept is better explained through some code:\\nListing 6.1: translation.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 M = np.float32([[1, 0, 25], [0, 1, 50]])\\n15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 54, 'page_label': '43', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])\\n19 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n20 cv2.imshow(\"Shifted Up and Left\", shifted)\\nOn Lines 1-4, we simply import the packages we will\\nmake use of. At this point, using numpy, argparse, and\\n43'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 55, 'page_label': '44', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\ncv2 should feel commonplace already. However, I am intro-\\nducing a new package here: imutils. This isn’t a package\\nincluded in NumPy or OpenCV . Rather, it’s a library that\\nwe are going to write ourselves and create “convenience”\\nmethods to do common tasks like translation, rotation, and\\nresizing.\\nAfter we have the necessary packages imported, we con-\\nstruct our argument parser and load our image on Lines\\n6-12.\\nThe actual translation takes place on Lines 14-16. We ﬁrst\\ndeﬁne our translation matrix M. This matrix tells us how\\nmany pixels to the left or right, and up or down, the image\\nwill be shifted.\\nOur translation matrix M is deﬁned as a ﬂoating point\\narray – this is important because OpenCV expects this ma-\\ntrix to be of ﬂoating point type. The ﬁrst row of the matrix\\nis [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 55, 'page_label': '44', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='is [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to\\nthe right.\\nThen, we deﬁne the second row of the matrix as [0, 1,ty],\\nwhere ty is the number of pixels we will shift the image up\\nor down. Negative value of ty will shift the image up and\\npositive values will shift the image down.\\nUsing this notation, we can see on Line 14 that tx = 25\\nand ty = 50, implying that we are shifting the image 25 pix-\\nels to the right and 50 pixels down.\\n44'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 56, 'page_label': '45', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nNow that we have our translation matrix deﬁned, the\\nactual translation takes place on Line 15 using the cv2.\\nwarpAffine function. The ﬁrst argument is the image we\\nwish to shift and the second argument is our translation ma-\\ntrix M. Finally, we manually supply the dimensions (width\\nand height) of our image as the third argument. Line 16\\nshows the results of the translation.\\nMoving on to Lines 18-20, we perform another transla-\\ntion. Here, we set tx = −50 and ty = −90, implying that\\nwe are shifting the image 50 pixels to the left and 90 pixels\\nup. The image is shifted left and up rather than right and\\ndown, because we are providing a negative values for both\\ntx and ty.\\nHowever, manually constructing this translation matrix\\nand calling the cv2.warpAffine method takes a fair amount\\nof code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 56, 'page_label': '45', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='of code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently\\ncall them without writing a lot of code.\\nThe ﬁrst method we are going to deﬁne is a translate\\nfunction:\\nListing 6.2: imutils.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 def translate(image, x, y):\\n5 M = np.float32([[1, 0, x], [0, 1, y]])\\n6 shifted = cv2.warpAffine(image, M, (image.shape[1], image.\\nshape[0]))\\n45'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 57, 'page_label': '46', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n7\\n8 return shifted\\nOur translate method takes three parameters: the image\\nwe are going to translate, the number of pixels that we are\\ngoing to shift along the x-axis, and the number of pixels we\\nare going to shift along the y-axis.\\nThis method then deﬁnes our translation matrix M on\\nLine 5 and then applies the actual shift on Line 6. Finally,\\nwe return the shifted image on Line 8.\\nLet’s apply our translate method and compare to the\\nmethods discussed above:\\nListing 6.3: translation.py\\n21 shifted = imutils.translate(image, 0, 100)\\n22 cv2.imshow(\"Shifted Down\", shifted)\\n23 cv2.waitKey(0)\\nUsing our convenience translate method, we are able\\nto shift the image 100 pixels down using a single line of\\ncode. Furthermore, this translate method is much easier\\nto use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 57, 'page_label': '46', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='to use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.\\nOur original image is on the top-left. On the top-right, we\\nshift our image 25 pixels to the right and 50 pixels down.\\nNext, we translate our image 50 pixels to the left and 90\\npixels up by using negative values for tx and ty. Finally, on\\nthe bottom-right, we shift our T-Rex 100 pixels down using\\n46'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 58, 'page_label': '47', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.1: Top-Left: Our original T-Rex image.\\nTop-Right: Translating our image 25\\npixels to the right and 50 pixels\\ndown. Bottom-Left: Shifting T-Rex\\n50 pixels to the left and 90 pix-\\nels up. Bottom-Right: Shifting the\\nT-Rex down using our convenience\\nmethod.\\n47'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 59, 'page_label': '48', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nour convenient translate method deﬁned above.\\nIn this section we explored how to shift an image up,\\ndown, left, and right. Next up, we’ll explore how to rotate\\nan image.\\n6.1.2 Rotation\\nRotation is exactly what it sounds like: rotating an image\\nby some angle θ. In this section, we’ll explore how to rotate\\nan image. We’ll use θ to represent by how many degrees\\nwe are rotating the image. Later, I’ll provide another con-\\nvenience method, rotate, to make performing rotations on\\nimages easier.\\nListing 6.4: rotate.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 59, 'page_label': '48', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))\\n19 cv2.imshow(\"Rotated by 45 Degrees\", rotated)\\n20\\n21 M = cv2.getRotationMatrix2D(center, -90, 1.0)\\n48'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 60, 'page_label': '49', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n22 rotated = cv2.warpAffine(image, M, (w, h))\\n23 cv2.imshow(\"Rotated by -90 Degrees\", rotated)\\nLines 1-4 again import the packages we need. You should\\ntake note of imutils. Once again, we will be deﬁning a con-\\nvenience method to make our lives easier.\\nLines 6-12 construct our argument parser. We only need\\none argument: the path to the image we are going to use.\\nWe then load our image off disk and display it.\\nWhen we rotate an image, we need to specify around\\nwhich point we want to rotate. In most cases, you will want\\nto rotate around the center of an image; however, OpenCV\\nallows you to specify any arbitrary point you want to rotate\\naround. Let’s just go ahead and rotate around the center of\\nthe image. Lines 14 and 15 grabs the width and height of\\nthe image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 60, 'page_label': '49', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.\\nJust as we deﬁned a matrix to translate an image, we\\nalso deﬁne a matrix to rotate the image. Instead of manu-\\nally constructing the matrix using NumPy, we’ll just make\\na call to the cv2.getRotationMatrix2D method on Line 17.\\nThe cv2.getRotationMatrix2D function takes three argu-\\nments: the point at which we want to rotate the image\\naround (in this case, the center of the image). We then\\nspecify θ, the number of degrees we are going to rotate the\\nimage by. In this case, we are going to rotate the image 45\\ndegrees. The last argument is the scale of the image. We\\nhaven’t discussed resizing an image yet, but here you can\\nspecify a ﬂoating point value, where 1.0 means the same di-\\n49'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 61, 'page_label': '50', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nmensions of the image are used. However, if you speciﬁed\\na value of 2.0 the image would be doubled in size. Similarly,\\na value of 0.5 halves the size of the image.\\nOnce we have our rotation matrixM from the cv2.getRot\\nationMatrix2D function, we can apply the rotation to our\\nimage using the cv2.warpAffine method on Line 18. The\\nﬁrst argument to this function is the image we want to ro-\\ntate. We then specify our rotation matrix M along with the\\noutput dimensions (width and height) of our image. Line\\n19 then shows our image rotated by 45 degrees. Check out\\nFigure 6.2 Top-Right to see our rotated image.\\nLet’s not waste any time. We’ll go ahead and jump into\\nsome code to perform rotations:\\nOn Lines 21-23, we perform another rotation. The code\\nis identical to that in Lines 17-19, only this time we are ro-\\ntating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 61, 'page_label': '50', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='tating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-\\nage isn’t the most pretty and Pythonic. Let’s change that\\nand deﬁne our own custom rotate method:\\nListing 6.5: imutils.py\\n27 def rotate(image, angle, center = None, scale = 1.0):\\n28 (h, w) = image.shape[:2]\\n29\\n30 if center is None:\\n31 center = (w // 2, h // 2)\\n32\\n33 M = cv2.getRotationMatrix2D(center, angle, scale)\\n34 rotated = cv2.warpAffine(image, M, (w, h))\\n50'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 62, 'page_label': '51', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.2: Top-Left: Our original T-Rex image.\\nTop-Right: Rotating the image by 45\\ndegrees. Bottom-Left: Rotating the\\nimage by −90 degrees. Bottom-Right:\\nFlipping T-Rex upside down by rotat-\\ning the image by 180 degrees.\\n51'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 63, 'page_label': '52', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n35\\n36 return rotated\\nOur rotate method takes four arguments. The ﬁrst is\\nour image. The second is the angle θ in which we want\\nto rotate the image. We provide two optional keyword ar-\\nguments, center and scale. The center parameter is the\\npoint which we wish to rotate our image around. If a value\\nof None is provided, the method automatically determines\\nthe center of the image on Lines 30-31. Finally, the scale\\nparameter is used to handle if the size of the image should\\nbe changed during the rotation. The scale parameter has\\na default value of 1.0, implying that no resizing should be\\ndone.\\nThe actual rotation of the image takes place on Lines 33\\nand 34, where we construct our rotation matrix M and ap-\\nply it to the image. Finally, our image is returned on Line\\n36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 63, 'page_label': '52', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)\\nHere, we are rotating our image by 180 degrees. Fig-\\nure 6.2 Bottom-Right shows that our T-Rex has indeed been\\nﬂipped upside down. The code for our rotate method is\\nmuch easier to read and maintain than making calls to\\ncv2.getRotationMatrix2D and cv2.warpAffine each time\\nwe want to rotate an image.\\n52'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 64, 'page_label': '53', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6.1.3 Resizing\\nSo far we’ve covered two image transformations: transla-\\ntion and rotation. Now, we are going to explore how to\\nresize an image. We’ll also deﬁne one last method for our\\nimutils.py ﬁle, a convenience method to help us resize im-\\nages with ease.\\nPerhaps, not surprisingly, we will be using thecv2.resize\\nfunction to resize our images. But we need to keep in mind\\nthe aspect ratio of the image when we are using this func-\\ntion. Before we get too deep into the details, let’s jump right\\ninto an example:\\nListing 6.7: resize.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 64, 'page_label': '53', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n18 cv2.imshow(\"Resized (Width)\", resized)\\nLines 1-12 should start to feel quite redundant at this\\npoint. We are importing our packages, setting up our argu-\\nment parser, and ﬁnally loading our image and displaying\\n53'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 65, 'page_label': '54', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nit.\\nThe actual interesting code doesn’t start until Lines 14\\nand 15. When resizing an image, we need to keep in mind\\nthe aspect ratio of the image. The aspect ratio is the propor-\\ntional relationship of the width and the height of the image.\\nIf we aren’t mindful of the aspect ratio, our resizing will\\nreturn results that don’t look correct.\\nComputing the aspect ratio is handled on Line 14. In\\nthis line of code, we deﬁne our new image width to be 150\\npixels. In order to compute the ratio of the new height to\\nthe old height, we simply deﬁne our ratio r to be the new\\nwidth (150 pixels) divided by the old width, which we ac-\\ncess using image.shape[1].\\nNow that we have our ratio, we can compute the new di-\\nmensions of the image on Line 15. Again, the width of the\\nnew image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 65, 'page_label': '54', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='new image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.\\nThe ﬁrst argument is the image we wish to resize and the\\nsecond is our computed dimensions for the new image.The\\nlast parameter is our interpolation method, which is the\\nalgorithm working behind the scenes to handle how the\\nactual image is resized. In general, I ﬁnd that using cv2.\\nINTER_AREA obtains the best results when resizing; how-\\never, other appropriate choices include cv2.INTER_LINEAR,\\ncv2.INTER_CUBIC, and cv2.INTER_NEAREST.\\n54'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 66, 'page_label': '55', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFinally, we show our resized image on Line 18.\\nIn the example we just explored, we only resized the im-\\nage by specifying the width. But what if we wanted to\\nresize the image by specifying the height? All that requires\\nis a change to computing the aspect ratio:\\nListing 6.8: resize.py\\n19 r = 50.0 / image.shape[0]\\n20 dim = (int(image.shape[1] * r), 50)\\n21\\n22 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n23 cv2.imshow(\"Resized (Height)\", resized)\\n24 cv2.waitKey(0)\\nOn Line 19 we deﬁne our ratio r. Our new image will\\nhave a height of 50 pixels. To determine the ratio of the new\\nheight to the old height, we divide 50 by the old height.\\nThen, we deﬁne the dimensions of our new image. We\\nalready know that the new image will have a height of 50\\npixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 66, 'page_label': '55', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='pixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.\\nResizing an image is simple enough, but having to com-\\npute the aspect ratio, deﬁne the dimensions of the new im-\\nage, and then perform the resizing takes three lines of code.\\nThis looks like the perfect time to deﬁne a resize method\\nin our imutils.py ﬁle:\\nListing 6.9: resize.py\\n25 resized = imutils.resize(image, width = 100)\\n55'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 67, 'page_label': '56', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 cv2.imshow(\"Resized via Function\", resized)\\n27 cv2.waitKey(0)\\nIn this example, you can see that the resizing of the im-\\nage is handled by a single function: imutils.resize. The\\nﬁrst argument we pass in is the image we want to resize.\\nThen, we specify the keyword argument width, which is\\nthe width of our new image. The function then handles the\\nresizing for us.\\nOf course, we can also resize via the height of the image\\nby changing the function call to:\\nListing 6.10: resize.py\\n1 resized = imutils.resize(image, height = 50)\\nLet’s take this function apart and see what’s going on un-\\nder the hood:\\nListing 6.11: imutils.py\\n9 def resize(image, width = None, height = None, inter = cv2.\\nINTER_AREA):\\n10 dim = None\\n11 (h, w) = image.shape[:2]\\n12\\n13 if width is None and height is None:\\n14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 67, 'page_label': '56', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23\\n24 resized = cv2.resize(image, dim, interpolation = inter)\\n25\\n56'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 68, 'page_label': '57', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n26 return resized\\nAs you can see, we have deﬁned our resize function.\\nThe ﬁrst argument is the image we want to resize. Then, we\\ndeﬁne two keyword arguments, width and height. Both of\\nthese arguments cannot be None, otherwise we won’t know\\nhow to resize the image. We also provide inter, which is\\nour interpolation method and defaults to cv2.INTER_AREA.\\nOn Lines 10 and 11, we deﬁne the dimensions of our new,\\nresized image and grab the dimensions of the original im-\\nage.\\nWe perform a quick check on Lines 13-14 to ensure that\\na numerical value has been provided for either the width\\nor the height.\\nThe computation of the ratio and new, resized image di-\\nmensions are handled on Lines 16-22, depending on whether\\nwe are resizing via width or via height.\\nLine 24 handles the actual resizing of the image, then\\nLine 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 68, 'page_label': '57', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Line 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.\\nThen, on the Top-Right we have our T-Rex resized to have a\\nwidth of 150 pixels. The Middle-Right image then shows our\\nimage resized to have a height of 50 pixels. Finally, Bottom-\\nRight shows the output of our resize function – the T-Rex\\nis now resized to have a width of 100 pixels using only a\\nsingle line of code.\\n57'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 69, 'page_label': '58', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.3: Top-Left: Our original T-Rex image.\\nTop-Right: The T-Rex resized to have\\na width of 150 pixels. Middle-Right:\\nOur image resized to have a height\\nof 50 pixels. Bottom-Right: Resizing\\nour image to have a width of 100 pix-\\nels using our helper function. In all\\ncases, the aspect ratio of the image is\\nmaintained.\\n58'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 70, 'page_label': '59', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nTranslation, rotation, and resizing are certainly the more\\nchallenging and involved image transformation tasks. The\\nnext two we will explore, ﬂipping and cropping, are sub-\\nstantially easier.\\n6.1.4 Flipping\\nNext up on our image transformations to explore is ﬂip-\\nping an image. We can ﬂip an image around either the x or\\ny axis, or even both.\\nIn fact, I think explaining how to ﬂip an image is better\\nexplained by viewing the output of an image ﬂip, before\\nwe get into the code. Check out Figure 6.4 to see our T-Rex\\nimage ﬂipped horizontally, vertically, and both horizontally\\nand vertically at the same time.\\nNow that you see what an image ﬂip looks like, we can\\nexplore the code:\\nListing 6.12: ﬂipping.py\\n1 import argparse\\n2 import cv2\\n3\\n4 ap = argparse.ArgumentParser()\\n5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 70, 'page_label': '59', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11\\n12 flipped = cv2.flip(image, 1)\\n13 cv2.imshow(\"Flipped Horizontally\", flipped)\\n14\\n59'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 71, 'page_label': '60', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.4: Top-Left: Our original T-Rex image.\\nTop-Right: Flipping the T-Rex image\\nhorizontally. Bottom-Left: Flipping\\nthe T-Rex vertically. Bottom-Right:\\nFlipping the image both horizontally\\nand vertically.\\n60'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 72, 'page_label': '61', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n15 flipped = cv2.flip(image, 0)\\n16 cv2.imshow(\"Flipped Vertically\", flipped)\\n17\\n18 flipped = cv2.flip(image, -1)\\n19 cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\\n20 cv2.waitKey(0)\\nLines 1-10 handle our standard procedure of importing\\nour packages, parsing arguments, and loading our image\\nfrom disk.\\nFlipping an image is accomplished by making a call to\\nthe cv2.flip function on Line 12. The cv2.flip method\\nrequires two arguments: the image we want to ﬂip and a\\nﬂip code that is used to determine how we are going to ﬂip\\nthe image.\\nUsing a ﬂip code value of 1 indicates that we are going\\nto ﬂip the image horizontally, around the y-axis ( Line 12).\\nSpecifying a ﬂip code of 0 indicates that we want to ﬂip the\\nimage vertically, around the x-axis (Line 15). Finally, using\\na negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 72, 'page_label': '61', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-\\nzontally, vertically, and around both axes.\\nFlipping an image is very simple, perhaps one of the sim-\\nplest examples in this book! Next up, we’ll go over crop-\\nping an image and how to extract regions of an image using\\nNumPy array slices.\\n61'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 73, 'page_label': '62', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\nFigure 6.5: Top: Our original T-Rex image. Bot-\\ntom: Cropping the face of the T-Rex\\nusing NumPy array slices.\\n6.1.5 Cropping\\nWhen we crop an image, we want to remove the outer parts\\nof the image that we are not interested in. We can accom-\\nplish image cropping by using NumPy array slicing. In fact,\\nwe already performed image cropping in Chapter 4!\\nHowever, let’s review it again and make sure we under-\\nstand what is going on:\\nListing 6.13: crop.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n62'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 74, 'page_label': '63', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.1 image transformations\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 cropped = image[30:120 , 240:335]\\n14 cv2.imshow(\"T-Rex Face\", cropped)\\n15 cv2.waitKey(0)\\nLines 1-11 handle importing our packages, parsing our\\narguments, and loading our images. For our cropping ex-\\nample, we will use our T-Rex image.\\nThe actual cropping takes place on a single line of code:\\nLine 13. We are supplying NumPy array slices to extract\\na rectangular region of the image, starting at (240, 30) and\\nending at (335, 120). The order in which we supply the\\nindexes to the crop may seem counterintuitive; however, re-\\nmember that OpenCV represents images as NumPy arrays\\nwith the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 74, 'page_label': '63', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='with the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:\\n1. Start y: The starting y coordinate. In this case, we\\nstart at y = 30.\\n2. End y:The ending y coordinate. We will end our crop\\nat y = 120.\\n3. Start x:The starting x coordinate of the slice. We start\\nthe crop at x = 240.\\n63'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 75, 'page_label': '64', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\n4. End x: The ending x-axis coordinate of the slice. Our\\nslice ends at x = 335.\\nExecuting our code detailed above, we will see from Fig-\\nure 6.5 that we have cropped out the face of our T-Rex!\\nWhile the T-Rex might seem a little scary, cropping sure\\nisn’t! In fact, it’s quite simple when you consider all we are\\ndoing is performing array slices on NumPy arrays.\\n6.2 image arithmetic\\nWe all know basic arithmetic operations like addition and\\nsubtraction. But when working with images, we need to\\nkeep in mind the limits of our color space and data type.\\nFor example, RGB images have pixels that fall within the\\nrange [0, 255]. So what happens if we are examining a pixel\\nwith intensity 250 and we try to add 10 to it?\\nUnder normal arithmetic rules, we would end up with a\\nvalue of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 75, 'page_label': '64', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='value of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check\\nof some sort to ensure no pixel falls outside the range of\\n[0, 255], thus clipping all pixels to have a minimum value of\\n0 and a maximum value of 255?\\nOr do we apply a modulus operation, and “wrap around”?\\nUnder modulus rules, adding 10 to 250 would simply wrap\\naround to a value of 4.\\n64'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 76, 'page_label': '65', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWhich way is the “correct” way to handle image addi-\\ntions and subtractions that fall outside the range of [0, 255]?\\nThe answer is there is no correct way – it simply depends\\non how you are manipulate your pixels and what you want\\nthe desired results to be.\\nHowever, be sure to keep in mind that there is a differ-\\nence between OpenCV and NumPy addition. NumPy will\\nperform modulo arithmetic and “wrap around”. OpenCV ,\\non the other hand, will perform clipping and ensure pixel\\nvalues never fall outside the range [0, 255].\\nBut don’t worry! These nuances will become clearer as\\nwe explore some code below.\\nListing 6.14: arithmetic.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 76, 'page_label': '65', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 print(\"max of 255: {}\".format(cv2.add(np.uint8([200]), np.uint8\\n([100]))))\\n15 print(\"min of 0: {}\".format(cv2.subtract(np.uint8([50]), np.uint8\\n([100]))))\\n16\\n17 print(\"wrap around: {}\".format(np.uint8([200]) + np.uint8([100]))\\n)\\n18 print(\"wrap around: {}\".format(np.uint8([50]) - np.uint8([100])))\\n65'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 77, 'page_label': '66', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nWe are going to perform our standard procedure onLines\\n1-12 by importing our packages, setting up our argument\\nparser, and loading our image.\\nRemember how I mentioned the difference between OpenCV\\nand NumPy addition above? Well, now we are going to ex-\\nplore it further and provide a concrete example to ensure\\nwe fully understand it.\\nOn Line 14, we deﬁne two NumPy arrays that are 8-\\nbit unsigned integers. The ﬁrst array has one element: a\\nvalue of 200. The second array also has only one element,\\nbut with a value of 100. We then use OpenCV’s cv2.add\\nmethod to add the values together.\\nWhat do you think the output is going to be?\\nWell, according to standard arithmetic rules, we would\\nthink the result should be 300, but, remember that we are\\nworking with 8-bit unsigned integers that only have a range\\nbetween [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 77, 'page_label': '66', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='between [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-\\necute this code, we can see the result on the ﬁrst line of\\nListing 6.15. Sure enough, the addition returned a value of\\n255.\\nLine 15 then performs subtraction using cv2.subtract.\\nAgain, we deﬁne two NumPy arrays, each with a single ele-\\nment, and of the 8-bit unsigned integer data type. The ﬁrst\\narray has a value of 50 and the second a value of 100.\\n66'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 78, 'page_label': '67', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nAccording to our arithmetic rules, the subtraction should\\nreturn a value of −50; however, OpenCV once again per-\\nforms clipping for us. We ﬁnd that the value is clipped to a\\nvalue of 0. The second line of Listing 6.15 veriﬁes this: sub-\\ntracting 100 from 50 using cv2.subtract returns a value of\\n0.\\nListing 6.15: arithmetic.py\\nmax of 255: [[255]]\\nmin of 0: [[0]]\\nBut what happens if we use NumPy to perform the arith-\\nmetic instead of OpenCV?\\nLine 17 and 18 explore this question.\\nFirst, we deﬁne two NumPy arrays, each with a single\\nelement, and of the 8-bit unsigned integer data type. The\\nﬁrst array has a value of 200, and the second has a value\\nof 100. Using the cv2.add function, our addition would be\\nclipped and a value of 255 returned.\\nHowever, NumPy does not perform clipping – it instead\\nperforms modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 78, 'page_label': '67', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='performs modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been\\nreached. You can see this is true via the ﬁrst line of output\\non Listing 6.16.\\nThen, we deﬁne two more NumPy arrays: one has a value\\nof 50 and the other 100. Using the cv2.subtract method,\\nthis subtraction would be clipped to return a value of 0.\\nHowever, we know that NumPy performs modulo arith-\\n67'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 79, 'page_label': '68', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nmetic rather than clipping. Instead, once 0 is reached dur-\\ning the subtraction, the modulos operations wraps around\\nand starts counting backwards from 255 – thus the result\\non the second line of output on Listing 6.16.\\nListing 6.16: arithmetic.py\\nwrap around: [44]\\nwrap around: [206]\\nWhen performing integer arithmetic, it is important to\\nkeep in mind your desired output.\\nDo you want all values to be clipped if they fall outside\\nthe range [0, 255]? Then use OpenCV’s built-in methods for\\nimage arithmetic.\\nDo you want modulus arithmetic operations and have\\nvalues wrap around if they fall outside the range of [0, 255]?\\nThen simply add and subtract the NumPy arrays as you\\nnormally would.\\nNow that we have explored the caveats of image arith-\\nmetic in OpenCV and NumPy, let’s perform the arithmetic\\non actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 79, 'page_label': '68', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='on actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)\\n22\\n23 M = np.ones(image.shape, dtype = \"uint8\") * 50\\n24 subtracted = cv2.subtract(image, M)\\n25 cv2.imshow(\"Subtracted\", subtracted)\\n26 cv2.waitKey(0)\\n68'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 80, 'page_label': '69', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nFigure 6.6: Top-Left: Our original T-Rex image.\\nTop-Right: Adding 100 to every pixel\\nin the image. Notice how the image\\nlooks more “washed out” and is sub-\\nstantially brighter than the original.\\nBottom: Subtracting 50 from every\\npixel in the image. Notice that the\\nimage is now darker than the origi-\\nnal.\\n69'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 81, 'page_label': '70', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.2 image arithmetic\\nLine 19 deﬁnes a NumPy array of ones, with the same\\nsize as our image. Again, we are sure to use 8-bit unsigned\\nintegers as our data type. In order to ﬁll our matrix with\\nvalues of 100’s rather than 1’s, we simply multiply our ma-\\ntrix of 1’s by 100. Finally, we use the cv2.add function to\\nadd our matrix of 100’s to the original image – thus increas-\\ning every pixel intensity in the image by 100, but ensuring\\nall values are clipped to the range [0, 255] if they attempt to\\nexceed 255.\\nThe result of our operation can be found in Figure 6.6\\nTop-Right. Notice how the image looks more “washed out”\\nand is substantially brighter than the original. This is be-\\ncause we are increasing the pixel intensities by adding 100\\nto them and pushing them towards brighter colors.\\nWe then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 81, 'page_label': '70', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='We then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image\\nin Figure 6.6 shows the results of this subtraction. Our im-\\nage now looks considerably darker than the original T-Rex.\\nPixels that were once white now look gray. This is because\\nwe are subtracting 50 from the pixels and pushing them to-\\nwards the darker regions of the RGB color space.\\nIn this section, we explored the peculiarities of image\\narithmetic using OpenCV and NumPy. These caveats are\\nimportant to keep in mind, otherwise you may get unwanted\\nresults when performing arithmetic operations on your im-\\nages.\\n70'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 82, 'page_label': '71', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\n6.3 bitwise operations\\nNow we will review four bitwise operations: AND, OR,\\nXOR, and NOT. These four operations, while very basic\\nand low level, are paramount to image processing, espe-\\ncially when we start working with masks in Section 6.4.\\nBitwise operations operate in a binary manner and are\\nrepresented as grayscale images. A given pixel is turned\\n“off” if it has a value of zero, and it is turned “on” if the\\npixel has a value greater than zero.\\nLet’s go ahead and jump into some code:\\nListing 6.18: bitwise.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 rectangle = np.zeros((300, 300), dtype = \"uint8\")\\n5 cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\\n6 cv2.imshow(\"Rectangle\", rectangle)\\n7\\n8 circle = np.zeros((300, 300), dtype = \"uint8\")\\n9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 82, 'page_label': '71', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image\\nas a 300 × 300 NumPy array on Line 4. We then draw a\\n250 × 250 white rectangle at the center of the image.\\nSimilarly, on Line 8, we initialize another image to con-\\ntain our circle, which we draw on Line 9, again centered at\\nthe center of the image, with a radius of 150 pixels.\\n71'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 83, 'page_label': '72', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nFigure 6.7: Left: Our rectangle image. Right: Our\\ncircle image. We will explore how\\nthese two images can be combined\\nusing bitwise operations.\\nFigure 6.7 shows our two shapes. We will make use of\\nthese shapes to demonstrate our bitwise operations:\\nListing 6.19: bitwise.py\\n11 bitwiseAnd = cv2.bitwise_and(rectangle, circle)\\n12 cv2.imshow(\"AND\", bitwiseAnd)\\n13 cv2.waitKey(0)\\n14\\n15 bitwiseOr = cv2.bitwise_or(rectangle, circle)\\n16 cv2.imshow(\"OR\", bitwiseOr)\\n17 cv2.waitKey(0)\\n18\\n19 bitwiseXor = cv2.bitwise_xor(rectangle, circle)\\n20 cv2.imshow(\"XOR\", bitwiseXor)\\n21 cv2.waitKey(0)\\n22\\n23 bitwiseNot = cv2.bitwise_not(circle)\\n24 cv2.imshow(\"NOT\", bitwiseNot)\\n25 cv2.waitKey(0)\\n72'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 84, 'page_label': '73', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.3 bitwise operations\\nAs I mentioned above, a given pixel is turned “on” if it\\nhas a value greater than zero, and it is turned “off” if it has\\na value of zero. Bitwise functions operate on these binary\\nconditions.\\nIn order to utilize bitwise functions, we assume (in most\\ncases) that we are comparing two pixels (the only exception\\nis the NOT function). We’ll compare each of the pixels and\\nthen construct our bitwise representation.\\nLet’s quickly review our binary operations:\\n1. AND: A bitwise AND is true if and only if both pixels\\nare greater than zero.\\n2. OR: A bitwise OR is true if either of the two pixels\\nare greater than zero.\\n3. XOR: A bitwise XOR is true if and only if either of the\\ntwo pixels are greater than zero, but not both.\\n4. NOT: A bitwise NOT inverts the “on” and “off” pixels\\nin an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 84, 'page_label': '73', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='in an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if\\nboth pixels are greater than zero. The output of our bitwise\\nAND can be seen in Figure 6.8 Top-Left. We can see that\\nedges of our square are lost – this makes sense because our\\nrectangle does not cover as large of an area as the circle,\\nand thus both pixels are not “on”.\\n73'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 85, 'page_label': '74', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nWe then apply a bitwise OR on Line 15 using the cv2.\\nbitwise_or function. A bitwise OR is true if either of the\\ntwo pixels are greater than zero. Figure 6.8 Top-Right shows\\nthe output of our bitwise OR. In this case, our square and\\nrectangle have been combined together.\\nNext up is the bitwise XOR function, applied on Line 19\\nusing the cv2.bitwise_xor function. An XOR operation\\nis true if both pixels are greater than zero, but both pixels\\ncannot be greater than zero. The output of the XOR oper-\\nation is displayed on Figure 6.8 Bottom-Right. Here we see\\nthat the center of the square has been removed. Again, this\\nmakes sense because an XOR operation cannot have both\\npixels greater than zero.\\nFinally, we apply the NOT function on Line 23 using the\\ncv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 85, 'page_label': '74', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are\\nset to 255. Figure 6.8 Bottom-Right ﬂips our white circle to a\\nblack circle.\\nOverall, bitwise functions are extremely simple, yet very\\npowerful. And they are absolutely essential when we start\\nto discuss masking in Section 6.4.\\n6.4 masking\\nIn the previous section, we explored bitwise functions. Now\\nwe are ready to explore masking, an extremely powerful\\nand useful technique in computer vision and image pro-\\n74'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 86, 'page_label': '75', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.8: Top-Left: Applying a bitwise AND to\\nour rectangle and circle image. Top-\\nRight: A bitwise OR applied to our\\nsquare and circle. Bottom-Left: An\\nXOR applied to our shapes. Bottom-\\nRight: Flipping pixel values of our\\ncircle using a bitwise NOT.\\n75'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 87, 'page_label': '76', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ncessing.\\nUsing a mask allows us to focus only on the portions of\\nthe image that interests us.\\nFor example, let’s say that we were building a computer\\nvision system to recognize faces. The only part of the image\\nwe are interested in ﬁnding and describing are the parts of\\nthe image that contain faces – we simply don’t care about\\nthe rest of the content of the image. Provided that we could\\nﬁnd the faces in the image, we might construct a mask to\\nshow only the faces in the image.\\nLet’s make this example a little more concrete.\\nIn Figure 6.9, we have an image of a beach on the Top-Left.\\nBut I’m not interested in the beach in the image. I’m only\\ninterested in the sky and the palm tree. We could apply a\\ncropping to extract that region of the image. Or, we could\\napply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 87, 'page_label': '76', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='apply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-\\ning our rectangle mask, we have focused only on the sky\\nand palm tree in the image.\\nLet’s examine the code to accomplish the masking in Fig-\\nure 6.9:\\nListing 6.20: masking.py\\n1 import numpy as np\\n76'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 88, 'page_label': '77', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.9: Top-Left: Our image of a peaceful\\nbeach scene. Top-Right: Our mask im-\\nage – a white rectangle at the center\\nof the image. Bottom: Applying the\\nrectangular mask to the beach image.\\nOnly the parts of the image where\\nthe mask pixels are greater than zero\\nare shown.\\n77'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 89, 'page_label': '78', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n14 (cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\\n15 cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255,\\n-1)\\n16 cv2.imshow(\"Mask\", mask)\\n17\\n18 masked = cv2.bitwise_and(image, image, mask = mask)\\n19 cv2.imshow(\"Mask Applied to Image\", masked)\\n20 cv2.waitKey(0)\\nOn Lines 1-11 we import the packages we need, parse\\nour arguments, and load our image.\\nWe then construct a NumPy array, ﬁlled with zeros, with\\nthe same width and height as our beach image on Line 13.\\nIn order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 89, 'page_label': '78', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='In order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-\\nsion. Finally, we draw our white rectangle on Line 15.\\nRemember reviewing the cv2.bitwise_and function in\\nthe previous section? It’s a function that is used extensively\\nwhen applying masks to images.\\nWe apply our mask on Line 18 using the cv2.bitwise_\\nand function. The ﬁrst two parameters are the image it-\\nself. Obviously, the AND function will be True for all pix-\\nels in the image; however, the important part of this func-\\n78'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 90, 'page_label': '79', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\ntion is the mask keyword argument. By supplying a mask,\\nthe cv2.bitwise_and function only examines pixels that are\\n“on” in the mask. In this case, only pixels that are part of\\nthe white rectangle.\\nLet’s look at another example:\\nListing 6.21: masking.py\\n21 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n22 cv2.circle(mask, (cX, cY), 100, 255, -1)\\n23 masked = cv2.bitwise_and(image, image, mask = mask)\\n24 cv2.imshow(\"Mask\", mask)\\n25 cv2.imshow(\"Mask Applied to Image\", masked)\\n26 cv2.waitKey(0)\\nOn Line 21 we re-initialize our mask to be ﬁlled with ze-\\nros and the same dimensions as our beach image. Then, we\\ndraw a white circle on our mask image, starting at the cen-\\nter of the image and a radius of 100 pixels. Applying the\\ncircular mask is then performed on Line 23, again using the\\ncv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 90, 'page_label': '79', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on\\nthe Bottom. Instead of a rectangular region of the beach be-\\ning shown, we now have a circular region.\\nRight now masking may not seem very interesting. But\\nwe’ll return to it once we start computing histograms in\\nChapter 7. Again, the key point of masks is that they allow\\nus to focus our computation only on regions of the image\\nthat interests us.\\n79'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 91, 'page_label': '80', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.4 masking\\nFigure 6.10: Applying the circular mask to the\\nbeach image. Only pixels within\\nthe circular white region are shown.\\n80'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 92, 'page_label': '81', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\n6.5 splitting and merging channels\\nA color image consists of multiple channels: a Red, a Green,\\nand a Blue component. We have seen that we can access\\nthese components via indexing into NumPy arrays. But\\nwhat if we wanted to split an image into its respective com-\\nponents?\\nAs you’ll see, we’ll make use of thecv2.split function.\\nFor the time being, let’s take a look at a sample image in\\nFigure 6.11.\\nWe have an image of a wave crashing down. This image\\nis very “blue” due to the ocean. How do we interpret the\\ndifferent channels of the image?\\nThe Red channel (Top-Left) is very dark. This makes sense,\\nbecause an ocean scene has very few red colors in it. The\\nred colors present are either very dark, and thus not repre-\\nsented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 92, 'page_label': '81', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='sented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.\\nFinally, the Blue channel ( Bottom-Left) is extremely light,\\nand near pure white in some locations. This is because\\nshades of blue are heavily represented in our image.\\nNow that we have visualized our channels, let’s examine\\nsome code to accomplish this for us:\\n81'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 93, 'page_label': '82', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.11: The three RGB channels of our\\nwave image are shown on the\\nBottom-Right. The Red channel is on\\nthe Top-Left, the Green channel on\\nthe Top-Right, and the Blue channel\\non the Bottom-Left.\\n82'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 94, 'page_label': '83', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nListing 6.22: splitting_and_merging.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 (B, G, R) = cv2.split(image)\\n12\\n13 cv2.imshow(\"Red\", R)\\n14 cv2.imshow(\"Green\", G)\\n15 cv2.imshow(\"Blue\", B)\\n16 cv2.waitKey(0)\\n17\\n18 merged = cv2.merge([B, G, R])\\n19 cv2.imshow(\"Merged\", merged)\\n20 cv2.waitKey(0)\\n21 cv2.destroyAllWindows()\\nLines 1-10 imports our packages, sets up our argument\\nparser, and then loads our image. Splitting the channels is\\ndone using a call to cv2.split on Line 11.\\nNormally, we think of images in the RGB color space –\\nthe red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 94, 'page_label': '83', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image\\nin RGB order, it instead stores the image in BGR order; thus\\nwe unpack the tuple in reverse order.\\nLines 13-16 then show each channel individually, as in\\nFigure 6.11.\\nWe can also merge the channels back together again us-\\ning the cv2.merge function. We simply specify our chan-\\n83'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 95, 'page_label': '84', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.5 splitting and merging channels\\nFigure 6.12: Representing the Red, Green, and\\nBlue channels of our wave image.\\nnels, again in BGR order, and then cv2.merge takes care of\\nthe rest for us ( Line 18).\\nListing 6.23: splitting_and_merging.py\\n22 zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\\n23 cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\\n24 cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\\n25 cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\\n26 cv2.waitKey(0)\\nAn alternative method to visualize the channels of an im-\\nage can be seen in Figure 6.12. In order to show the actual\\n“color” of the channel, we ﬁrst need to take apart the image\\nusing cv2.split. Then, we need to re-construct the image,\\nbut this time setting all pixels but the current channel as zero.\\nOn Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 95, 'page_label': '84', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='On Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-\\nage, we make a call to cv2.merge, but specifying our zeros\\narray for the Green and Blue channels. We take similar ap-\\nproaches to the other channels in Line 24 and 25.\\n84'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 96, 'page_label': '85', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n6.6 color spaces\\nIn this book, we have only explored the RGB color space;\\nhowever, there are many other color spaces that we can uti-\\nlize.\\nThe Hue-Saturation-Value (HSV) color space is more sim-\\nilar to how humans think and conceive of color. Then there\\nis the L*a*b* color space, which is more tuned to how hu-\\nmans perceive color.\\nOpenCV provides support for many, many different color\\nspaces. And understanding how color is perceived by hu-\\nmans and represented by computers occupies an entire li-\\nbrary of literature itself.\\nIn order to not get bogged down in the details, I’ll just\\nshow you how to convert color spaces. If you think your\\napplication of image processing and computer vision might\\nneed a different color space than RGB, I will leave that as\\nan exercise to the reader to explore the peculiarities of each\\ncolor space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 96, 'page_label': '85', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='color space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n85'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 97, 'page_label': '86', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Gray\", gray)\\n15\\n16 hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\\n17 cv2.imshow(\"HSV\", hsv)\\n18\\n19 lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\\n20 cv2.imshow(\"L*a*b*\", lab)\\n21 cv2.waitKey(0)\\nLines 1-11 imports the packages we need, parses our ar-\\nguments, and loads our image. Then, on Line 13, we con-\\nvert our image from the RGB color space to grayscale by\\nspecifying the cv2.COLOR_BGR2GRAY ﬂag.\\nConverting our image to the HSV color space is performed\\non Line 16 by specifying the cv2.COLOR_BGR2HSV ﬂag. Fi-\\nnally, on Line 19, we convert to the L*a*b* color space by\\nusing the cv2.COLOR_BGR2LAB ﬂag.\\nWe can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 97, 'page_label': '86', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='We can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.\\nIf you are just getting started in computer vision, it’s likely\\na good idea to stick to the RGB color space for the time\\nbeing. However, I have included this section as a matter\\nof completeness – it’s good to show an example of how to\\nconvert color spaces for when you decide the time is right!\\n86'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 98, 'page_label': '87', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFigure 6.13: Top-Left: An image of beach scenery.\\nTop-Right: The grayscale represen-\\ntation of the beach image. Bottom-\\nLeft: Converting the beach image to\\nthe HSV color space. Bottom-Right:\\nConverting our image to the L*a*b*\\ncolor space.\\n87'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 99, 'page_label': '88', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='6.6 color spaces\\nFurther Reading\\nChapter 6 is by far the longest chapter inPractical Python\\nand OpenCV – and with good reason. In this chapter,\\nwe covered a lot of important image processing con-\\ncepts that form the foundation on which the rest of\\nyour computer vision education will be built.\\nTo ensure that you have a thorough grasp on these con-\\ncepts, be sure to go through the Chapter 6 supplemen-\\ntary material:\\nhttp://pyimg.co/s3fm7\\n88'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 100, 'page_label': '89', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7\\nH I S T O G R A M S\\nSo, what exactly is a histogram? A histogram represents\\nthe distribution of pixel intensities (whether color or gray-\\nscale) in an image. It can be visualized as a graph (or plot)\\nthat gives a high-level intuition of the intensity (pixel value)\\ndistribution. We are going to assume an RGB color space in\\nthis example, so these pixel values will be in the range of 0\\nto 255.\\nWhen plotting the histogram, the X-axis serves as our\\n“bins”. If we construct a histogram with 256 bins, then\\nwe are effectively counting the number of times each pixel\\nvalue occurs. In contrast, if we use only 2 (equally spaced)\\nbins, then we are counting the number of times a pixel is in\\nthe range [0, 128) or [128, 255]. The number of pixels binned\\nto the x-axis value is then plotted on the y-axis.\\nBy simply examining the histogram of an image, you get\\na general understanding regarding the contrast, brightness,\\n89'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 101, 'page_label': '90', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1 using opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms. Before we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 101, 'page_label': '90', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='provided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.\\n4. histSize: This is the number of bins we want to use\\nwhen computing a histogram. Again, this is a list, one\\nfor each channel we are computing a histogram for.\\nThe bin sizes do not all have to be the same. Here is\\nan example of 32 bins for each channel: [32,32,32].\\n90'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 102, 'page_label': '91', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use thecv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2 grayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet. All we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 102, 'page_label': '91', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Original\", image)\\n91'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 103, 'page_label': '92', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.2 grayscale histograms\\n15\\n16 hist = cv2.calcHist([image], [0], None, [256], [0, 256])\\n17\\n18 plt.figure()\\n19 plt.title(\"Grayscale Histogram\")\\n20 plt.xlabel(\"Bins\")\\n21 plt.ylabel(\"# of Pixels\")\\n22 plt.plot(hist)\\n23 plt.xlim([0, 256])\\n24 plt.show()\\n25 cv2.waitKey(0)\\nNow things are getting a little more interesting. On Line\\n13, we convert the image from the RGB colorspace to graysc-\\nale. Line 16 computes the actual histogram. Go ahead and\\nmatch the arguments of the code up with the function docu-\\nmentation above. We can see that our ﬁrst parameter is the\\ngrayscale image. A grayscale image has only one channel,\\nhence we have a value of [0] for channels. We don’t have\\na mask, so we set the mask value to None. We will use 256\\nbins in our histogram, and the possible values range from\\n0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 103, 'page_label': '92', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the\\nbins (0-255) are plotted on the x-axis. And the y-axis counts\\nthe number of pixels in each bin. The majority of the pixels\\nfall in the range of roughly 60 to 120. Looking at the right\\ntail of the histogram, we see very few pixels in the range\\n200 to 255. This means that there are very few “white” pix-\\nels in the image.\\n92'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 104, 'page_label': '93', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.1: Computing a grayscale histogram of\\nour beach image.\\n7.3 color histograms\\nIn the previous section, we explored grayscale histograms.\\nNow let’s move on to computing a histogram for each chan-\\nnel of the image.\\nListing 7.3: color_histograms.py\\n1 from __future__ import print_function\\n2 from matplotlib import pyplot as plt\\n3 import numpy as np\\n4 import argparse\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 cv2.imshow(\"Original\", image)\\n93'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 105, 'page_label': '94', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nAgain, we’ll import the packages that we’ll need, utiliz-\\ning matplotlib once more to plot the histograms.\\nLet’s examine some code:\\nListing 7.4: color_histograms.py\\n14 chans = cv2.split(image)\\n15 colors = (\"b\", \"g\", \"r\")\\n16 plt.figure()\\n17 plt.title(\"’Flattened’ Color Histogram\")\\n18 plt.xlabel(\"Bins\")\\n19 plt.ylabel(\"# of Pixels\")\\n20\\n21 for (chan, color) in zip(chans, colors):\\n22 hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\\n23 plt.plot(hist, color = color)\\n24 plt.xlim([0, 256])\\nThe ﬁrst thing we are going to do is split the image into\\nits three channels: blue, green, and red. Normally, we read\\nthis is red, green, blue (RGB). However, OpenCV stores the\\nimage as a NumPy array in reverse order: BGR. This is\\nimportant to note. We then initialize a tuple of strings rep-\\nresenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 105, 'page_label': '94', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='resenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into\\neach bin on the y-axis.\\nWe then reach a for loop on Line 21, where we start loop-\\ning over each of the channels in the image.\\nThen, for each channel, we compute a histogram on Line\\n22. The code is identical to that of computing a histogram\\nfor the grayscale image; however, we are doing it for each\\nRed, Green, and Blue channel, allowing us to characterize\\n94'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 106, 'page_label': '95', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.2: Color histograms for each Red,\\nGreen, and Blue channel of the beach\\nimage.\\nthe distribution of pixel intensities. We add our histogram\\nto the plot on Line 23.\\nWe can examine our color histogram in Figure 7.2. We\\nsee there is a sharp peak in the green histogram around bin\\n100. This indicates a darker green value, from the green\\nvegetation and trees in the beach image.\\nWe also see a lot of blue pixels in the range 170 to 225.\\nConsidering these pixels are much lighter, we know that\\nthey are from the blue sky in our beach image. Similarly,\\nwe see a much smaller range of blue pixels in the range 25\\nto 50 – these pixels are much darker, and are therefore the\\nocean pixels in the bottom-left corner of the image.\\nUp until this point, we have computed a histogram for\\nonly one channel at a time. Now we move on to multi-\\ndimensional histograms and take into consideration two\\n95'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 107, 'page_label': '96', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nchannels at a time.\\nI like to explain multi-dimensional histograms by using\\nthe word AND.\\nFor example, we can ask a question such as, “How many\\npixels have a Red value of 10 AND a Blue value of 30?”.\\nHow many pixels have a Green value of 200 AND a Red\\nvalue of 130? By using the conjunctive AND, we are able to\\nconstruct multi-dimensional histograms.\\nIt’s that simple. Let’s check out some code to automate\\nthe process of building a 2D histogram:\\nListing 7.5: color_histograms.py\\n25 fig = plt.figure()\\n26\\n27 ax = fig.add_subplot(131)\\n28 hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None,\\n29 [32, 32], [0, 256, 0, 256])\\n30 p = ax.imshow(hist, interpolation = \"nearest\")\\n31 ax.set_title(\"2D Color Histogram for G and B\")\\n32 plt.colorbar(p)\\n33\\n34 ax = fig.add_subplot(132)\\n35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 107, 'page_label': '96', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")\\n39 plt.colorbar(p)\\n40\\n41 ax = fig.add_subplot(133)\\n42 hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None,\\n43 [32, 32], [0, 256, 0, 256])\\n44 p = ax.imshow(hist, interpolation = \"nearest\")\\n45 ax.set_title(\"2D Color Histogram for B and R\")\\n46 plt.colorbar(p)\\n47\\n48 print(\"2D histogram shape: {}, with {} values\".format(\\n96'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 108, 'page_label': '97', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\n49 hist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using. In previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 108, 'page_label': '97', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='The most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 109, 'page_label': '98', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.3 color histograms\\nFigure 7.3: Computing 2D color histograms for\\neach combination of Red, Green, and\\nBlue channels.\\nof red represent large pixel counts (i.e., peaks in the 2D his-\\ntogram). We tend to see many peaks in the Green and Blue\\nhistogram, where x = 22 and y = 12. This corresponds to\\nthe green pixels of the vegetation and trees and the blue of\\nthe sky and ocean.\\nUsing a 2D histogram takes into account two channels at\\na time. But what if we wanted to account for all three RGB\\nchannels? You guessed it. We’re now going to build a 3D\\nhistogram.\\nListing 7.6: color_histograms.py\\n50 hist = cv2.calcHist([image], [0, 1, 2],\\n51 None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\\n52 print(\"3D histogram shape: {}, with {} values\".format(\\n53 hist.shape, hist.flatten().shape[0]))\\n54\\n55 plt.show()\\n98'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 110, 'page_label': '99', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4 histogram equalization\\nHistogram equalization improves the contrast of an image\\nby “stretching” the distribution of pixels. Consider a his-\\ntogram with a large peak at the center of it. Applying his-\\ntogram equalization will stretch the peak out towards the\\ncorner of the image, thus improving the global contrast of\\nthe image. Histogram equalization is applied to grayscale\\nimages.\\nThis method is useful when an image contains foregroun-\\nds and backgrounds that are both dark or both light. It\\ntends to produce unrealistic effects in photographs; how-\\never, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 110, 'page_label': '99', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ever, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n99'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 111, 'page_label': '100', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12\\n13 eq = cv2.equalizeHist(image)\\n14\\n15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\\n16 cv2.waitKey(0)\\nLines 1-10 handle our standard practice of importing pack-\\nages, parsing arguments, and loading our image. We then\\nconvert our image to grayscale on Line 11.\\nPerforming histogram equalization is done using just a\\nsingle function: cv2.equalizeHist, which accepts a single\\nparameter, the grayscale image we want to perform his-\\ntogram equalization on. The last couple lines of code dis-\\nplay our histogram equalized image.\\n100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 112, 'page_label': '101', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nThe result of applying histogram equalization can be seen\\nin Figure 7.4. On the left, we have our original beach image.\\nThen, on the right, we have our histogram-equalized beach\\nimage. Notice how the contrast of the image has been radi-\\ncally changed and now spans the entire range of [0, 255].\\n7.5 histograms and masks\\nIn Chapter 6, Section 6.4, I mentioned that masks can be\\nused to focus on speciﬁc regions of an image that interest\\nus. We are now going to construct a mask and compute\\ncolor histograms for the masked region only.\\nFirst, we need to deﬁne a convenience function to save us\\nfrom writing repetitive lines of code:\\nListing 7.8: histogram_with_mask.py\\n1 from matplotlib import pyplot as plt\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 112, 'page_label': '101', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13\\n14 for (chan, color) in zip(chans, colors):\\n15 hist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16 plt.plot(hist, color = color)\\n17 plt.xlim([0, 256])\\n101'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 113, 'page_label': '102', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nOn Lines 1-4 we import our packages; then on Line 6 we\\ndeﬁne plot_histogram. This function accepts three param-\\neters: an image, the title of our plot, and a mask. The mask\\ndefaults to None if we do not have a mask for the image.\\nThe body of our plot_histogram function simply com-\\nputes a histogram for each channel in the image and plots\\nit, just as in previous examples in this chapter.\\nNow that we have a function to help us easily plot his-\\ntograms, let’s move into the bulk of our code:\\nListing 7.9: histogram_with_mask.py\\n18 ap = argparse.ArgumentParser()\\n19 ap.add_argument(\"-i\", \"--image\", required = True,\\n20 help = \"Path to the image\")\\n21 args = vars(ap.parse_args())\\n22\\n23 image = cv2.imread(args[\"image\"])\\n24 cv2.imshow(\"Original\", image)\\n25 plot_histogram(image, \"Histogram for Original Image\")\\nLines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 113, 'page_label': '102', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Lines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot\\nfor our image can be seen in Figure 7.5. We will refer to\\nthis histogram again once we compute a histogram for the\\nmasked region.\\nListing 7.10: histogram_with_mask.py\\n26 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n27 cv2.rectangle(mask, (15, 15), (130, 100), 255, -1)\\n28 cv2.imshow(\"Mask\", mask)\\n29\\n30 masked = cv2.bitwise_and(image, image, mask = mask)\\n31 cv2.imshow(\"Applying the Mask\", masked)\\n102'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 114, 'page_label': '103', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.5: Left: The original beach image. Right:\\nColor histograms for the red, green,\\nand blue channels. Compare these\\nhistograms to the histograms of the\\nmasked region of blue sky in Figure\\n7.7.\\n103'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 115, 'page_label': '104', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.6: Left: Our rectangular mask. Right:\\nApplying our mask to the beach im-\\nage using a bitwise AND. Now we\\nsee only the blue sky – the rest of the\\nimage is ignored.\\nNow we are ready to construct a mask for the image. We\\ndeﬁne our mask as a NumPy array, with the same width\\nand height as our beach image on Line 26. We then draw a\\nwhite rectangle starting from point(15, 15) to point (130, 100)\\non Line 27. This rectangle will serve as our mask – only pix-\\nels in our original image belonging to the masked region\\nwill be considered in the histogram computation.\\nTo visualize our mask, we apply a bitwise AND to the\\nbeach image ( Line 30), the results of which can be seen in\\nFigure 7.6. Notice how the image on the left is simply a\\nwhite rectangle, but when we apply our mask to the beach\\nimage, we only see the blue sky ( right).\\nListing 7.11: histogram_with_mask.py\\n32 plot_histogram(image, \"Histogram for Masked Image\", mask = mask)\\n104'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 116, 'page_label': '105', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\n33\\n34 plt.show()\\nFinally, we compute a histogram for our masked image\\nusing our plot_histogram function and show our results\\n(Lines 32-34).\\nWe can see our masked histogram in Figure 7.7. Most\\nred pixels fall in the range [0, 80], indicating that red pixels\\ncontribute very little to our image. This makes sense, since\\nour sky is blue. Green pixels are then present, but again,\\nare towards the darker end of the RGB spectrum. Finally,\\nour blue pixels fall in the brighter range and are obviously\\nour blue sky.\\nMost importantly, compare our masked color histograms\\nin Figure 7.5 to the unmasked color histograms in Figure\\n7.7 above. Notice how dramatically different the color his-\\ntograms are. By utilizing masks, we are able to apply our\\ncomputation only to the speciﬁc regions of the image that\\ninterest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 116, 'page_label': '105', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='interest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.\\nHistograms are simple, but are used extensively in image\\nprocessing and computer vision. Make sure you have a\\ngood grasp of histograms; you’ll certainly be using them in\\nthe future!\\n105'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 117, 'page_label': '106', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFigure 7.7: The resulting histogram of the\\nmasked image in Figure 7.6. Red\\ncontributes little to our image and is\\ntowards the darker end of the spec-\\ntrum. Some lighter green values are\\npresent, and many light blue colors\\ncorrespond to the sky in the image.\\n106'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 118, 'page_label': '107', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='7.5 histograms and masks\\nFurther Reading\\nThe purpose of Chapter 7 was to learn how to extract\\nand visualize color histograms from an image. But\\nother than simply visualizing the color distributions of\\nan image, what else can we do? What are the actual\\napplications of utilizing color histograms?\\nTo learn how to compare color histograms for similar-\\nity, and even build an image search engine, take a look\\nat the Chapter 7 supplementary page:\\nhttp://pyimg.co/aa4ax\\n107'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 119, 'page_label': '108', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8\\nS M O O T H I N G A N D B L U R R I N G\\nI’m pretty sure we all know what blurring is. It’s what\\nhappens when your camera takes a picture out of focus.\\nSharper regions in the image lose their detail, normally as\\na disc/circular shape.\\nPractically, this means that each pixel in the image is\\nmixed in with its surrounding pixel intensities. This “mix-\\nture” of pixels in a neighborhood becomes our blurred pixel.\\nWhile this effect is usually unwanted in our photographs,\\nit’s actually quite helpful when performing image process-\\ning tasks.\\nIn fact, many image processing and computer vision func-\\ntions, such as thresholding and edge detection, perform bet-\\nter if the image is ﬁrst smoothed or blurred.\\nIn order to explore different types of blurring methods,\\nlet’s start with a baseline of our original T-Rex image in Fig-\\nure 8.1.\\nListing 8.1: blurring.py\\n108'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 120, 'page_label': '109', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='smoothing and blurring\\nFigure 8.1: Our original T-Rex image before ap-\\nplying any blurring effects.\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nIn order to perform image blurring, we ﬁrst need to im-\\nport our packages and parse our arguments (Lines 1-8). We\\nthen load our image and show it as a baseline to compare\\nour blurring methods to on Lines 10 and 11.\\n109'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 121, 'page_label': '110', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nNow that our image is loaded, we can start blurring our\\nimages.\\n8.1 averaging\\nThe ﬁrst blurring method we are going to explore is averag-\\ning.\\nAs the name suggests, we are going to deﬁne a k × k slid-\\ning window on top of our image, where k is always an odd\\nnumber. This window is going to slide from left-to-right\\nand from top-to-bottom. The pixel at the center of this ma-\\ntrix (we have to use an odd number, otherwise there would\\nnot be a true “center”) is then set to be the average of all\\nother pixels surrounding it.\\nWe call this sliding window a “convolution kernel” or\\njust a “kernel”. We’ll continue to use this terminology throu-\\nghout this chapter.\\nAs we will see, as the size of the kernel increases, the\\nmore blurred our image will become.\\nLet’s check out some code to perform average blurring:\\nListing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 121, 'page_label': '110', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Listing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)\\n17 cv2.waitKey(0)\\n110'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 122, 'page_label': '111', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.1 averaging\\nFigure 8.2: Performing averaging blurring with\\na 3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right).\\nIn order to average blur an image, we use the cv2.blur\\nfunction. This function requires two arguments: the image\\nwe want to blur and the size of the kernel. As Lines 13-15\\nshow, we blur our image with increasing-sized kernels. The\\nlarger our kernel becomes, the more blurred our image will\\nappear.\\nWe make use of the np.hstack function to stack our out-\\nput images together. This method “horizontally stacks” our\\nthree images into a row. This is useful since we don’t want\\nto create three separate windows using thecv2.imshow func-\\ntion.\\nThe output of our averaged blur can be seen in Figure 8.2.\\nThe image on the left is barely blurred, but by the time we\\nreach a kernel of size 7 × 7, we see that our T-Rex is very\\nblurry indeed. Perhaps he was running at a high speed and\\nchasing a jeep?\\n111'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 123, 'page_label': '112', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.2 gaussian\\nFigure 8.3: Performing Gaussian blurring with a\\n3 × 3 kernel ( left), 5 × 5 kernel ( mid-\\ndle), and 7 × 7 kernel ( right). Again,\\nour image becomes more blurred as\\nthe kernel size increases, but is less\\nblurred than the average method in\\nFigure 8.2.\\n8.2 gaussian\\nNext up, we are going to review Gaussian blurring. Gaus-\\nsian blurring is similar to average blurring, but instead of\\nusing a simple mean, we are now using a weighted mean,\\nwhere neighborhood pixels that are closer to the central\\npixel contribute more “weight” to the average.\\nThe end result is that our image is less blurred, but more\\nnaturally blurred, than using the average method discussed\\nin the previous section.\\nLet’s look at some code to perform Gaussian blurring:\\nListing 8.3: blurring.py\\n18 blurred = np.hstack([\\n19 cv2.GaussianBlur(image, (3, 3), 0),\\n112'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 124, 'page_label': '113', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\n20 cv2.GaussianBlur(image, (5, 5), 0),\\n21 cv2.GaussianBlur(image, (7, 7), 0)])\\n22 cv2.imshow(\"Gaussian\", blurred)\\n23 cv2.waitKey(0)\\nHere you can see that we are making use of the cv2.\\nGaussianBlur function on Lines 19-21. The ﬁrst argument\\nto the function is the image we want to blur. Then, simi-\\nlar to cv2.blur, we provide a tuple representing our kernel\\nsize. Again, we start with a small kernel size of 3 × 3 and\\nstart to increase it.\\nThe last parameter is our σ, the standard deviation in the\\nx-axis direction. By setting this value to 0, we are instruct-\\ning OpenCV to automatically compute them based on our\\nkernel size.\\nWe can see the output of our Gaussian blur in Figure 8.3.\\nOur images have less of a blur effect than when using the\\naveraging method in Figure 8.2; however, the blur itself is\\nmore natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 124, 'page_label': '113', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='more natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median\\nTraditionally, the median blur method has been most ef-\\nfective when removing salt-and-pepper noise. This type of\\nnoise is exactly what it sounds like: imagine taking a photo-\\ngraph, putting it on your dining room table, and sprinkling\\nsalt and pepper on top of it. Using the median blur method,\\nyou could remove the salt and pepper from your image.\\n113'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 125, 'page_label': '114', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nWhen applying a median blur, we ﬁrst deﬁne our kernel\\nsize k. Then, as in the averaging blurring method, we con-\\nsider all pixels in the neighborhood of sizek ×k. But, unlike\\nthe averaging method, instead of replacing the central pixel\\nwith the average of the neighborhood, we instead replace\\nthe central pixel with the median of the neighborhood.\\nMedian blurring is more effective at removing salt-and-\\npepper style noise from an image because each central pixel\\nis always replaced with a pixel intensity that exists in the\\nimage.\\nAveraging and Gaussian methods can compute means or\\nweighted means for the neighborhood – this average pixel\\nintensity may or may not be present in the neighborhood.\\nBut by deﬁnition, the median pixel must exist in our neigh-\\nborhood. By replacing our central pixel with a median\\nrather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack(['),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 125, 'page_label': '114', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='rather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([\\n25 cv2.medianBlur(image, 3),\\n26 cv2.medianBlur(image, 5),\\n27 cv2.medianBlur(image, 7)])\\n28 cv2.imshow(\"Median\", blurred)\\n29 cv2.waitKey(0)\\nApplying a median blur is accomplished by making a call\\nto the cv2.medianBlur function. This method takes two pa-\\nrameters: the image we want to blur and the size of our\\nkernel. On Lines 25-27, we start off with a kernel size of\\n3, then increase it to 5 and 7. The resulting blurred images\\n114'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 126, 'page_label': '115', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.3 median\\nFigure 8.4: Applying the median blur method to\\nour T-Rex image with increasing ker-\\nnel sizes of 3 ( left), 5 ( middle), and\\n7 ( right), respectively. Notice that\\nwe are no longer creating a “motion\\nblur”.\\nare then stacked and displayed to us.\\nOur median blurred images can be seen in Figure 8.4.\\nNotice that we are no longer creating a “motion blur” ef-\\nfect like in averaging and Gaussian blurring – instead, we\\nare removing detail and noise.\\nFor example, take a look at the color of the scales of the\\nT-Rex. As our kernel size increases, the scales become less\\npronounced. The black and brown stripes on the legs and\\ntail of the T-Rex especially lose their detail, all without cre-\\nating a motion blur.\\n115'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 127, 'page_label': '116', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\n8.4 bilateral\\nThe last method we are going to explore is bilateral blur-\\nring.\\nThus far, the intention of our blurring methods has been\\nto reduce noise and detail in an image; however, we tend to\\nlose edges in the image.\\nIn order to reduce noise while still maintaining edges, we\\ncan use bilateral blurring. Bilateral blurring accomplishes\\nthis by introducing two Gaussian distributions.\\nThe ﬁrst Gaussian function only considers spatial neigh-\\nbors, that is, pixels that appear close together in the (x, y)\\ncoordinate space of the image. The second Gaussian then\\nmodels the pixel intensity of the neighborhood, ensuring\\nthat only pixels with similar intensity are included in the\\nactual computation of the blur.\\nOverall, this method is able to preserve edges of an im-\\nage, while still reducing noise. The largest downside to this\\nmethod is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 127, 'page_label': '116', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='method is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py\\n30 blurred = np.hstack([\\n31 cv2.bilateralFilter(image, 5, 21, 21),\\n32 cv2.bilateralFilter(image, 7, 31, 31),\\n33 cv2.bilateralFilter(image, 9, 41, 41)])\\n34 cv2.imshow(\"Bilateral\", blurred)\\n35 cv2.waitKey(0)\\n116'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 128, 'page_label': '117', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nFigure 8.5: Applying Bilateral blurring to our\\nbeach image. As the diameter of the\\nneighborhood, color σ, and space σ\\nincreases (from left to right), our im-\\nage has noise removed, yet still re-\\ntains edges and does not appear to\\nbe “motion blurred”.\\nWe apply bilateral blurring by calling thecv2.bilateralFil\\nter function on Lines 31-33. The ﬁrst parameter we supply\\nis the image we want to blur. Then, we need to deﬁne the\\ndiameter of our pixel neighborhood. The third argument\\nis our color σ. A larger value for color σ means that more\\ncolors in the neighborhood will be considered when com-\\nputing the blur. Finally, we need to supply the space σ. A\\nlarger value of space σ means that pixels farther out from\\nthe central pixel will inﬂuence the blurring calculation, pro-\\nvided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 128, 'page_label': '117', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='vided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be\\nseen in Figure 8.5. As the size of our parameters increases,\\nour image has noise removed, yet the edges still remain.\\n117'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 129, 'page_label': '118', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='8.4 bilateral\\nNow that we know how to blur our images, we can move\\non to thresholding in the next chapter. You can be sure that\\nwe’ll make use of blurring throughout the rest of this book!\\nFurther Reading\\nOne topic that I didn’t get a chance to cover in detail in-\\nside Practical Python and OpenCV is the convolution op-\\neration. Whether you are smoothing an image, sharp-\\nening details, or detecting edges, convolutions are being\\napplied.\\nTo learn more convolutions, and the role they play in\\ncomputer vision, image processing, and deep learning,\\nbe sure to refer to the Chapter 8 supplementary mate-\\nrial:\\nhttp://pyimg.co/y454z\\n118'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 130, 'page_label': '119', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9\\nT H R E S H O L D I N G\\nThresholding is the binarization of an image. In general,\\nwe seek to convert a grayscale image to a binary image,\\nwhere the pixels are either 0 or 255.\\nA simple thresholding example would be selecting a pixel\\nvalue p, and then setting all pixel intensities less than p to\\nzero, and all pixel values greater than p to 255. In this way,\\nwe are able to create a binary representation of the image.\\nNormally, we use thresholding to focus on objects or ar-\\neas of particular interest in an image. In the examples in the\\nsections below, we will empty our pockets and look at our\\nspare change. Using thresholding methods, we’ll be able to\\nﬁnd the coins in an image.\\n9.1 simple thresholding\\nApplying simple thresholding methods requires human in-\\ntervention. We must specify a threshold value T. All pixel\\nintensities below T are set to 0. And all pixel intensities\\ngreater than T are set to 255.\\n119'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 131, 'page_label': '120', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nWe can also apply the inverse of this binarization by set-\\nting all pixels below T to 255 and all pixel intensities greater\\nthan T to 0.\\nLet’s explore some code to apply simple thresholding\\nmethods:\\nListing 9.1: simple_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\nOn Lines 1-10 we import our packages, parse our argu-\\nments, and load our image. From there, we convert the\\nimage from the RGB color space to grayscale on Line 11.\\nAt this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 131, 'page_label': '120', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='At this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.\\nListing 9.2: simple_thresholding.py\\n14 (T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\\n15 cv2.imshow(\"Threshold Binary\", thresh)\\n16\\n17 (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.\\nTHRESH_BINARY_INV)\\n120'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 132, 'page_label': '121', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\nFigure 9.1: Top-Left: The original coins image in\\ngrayscale. Top-Right: Applying sim-\\nple binary thresholding. The coins\\nare shown in black and the back-\\nground in white. Bottom-Left: Apply-\\ning inverse binary thresholding. The\\ncoins are now white and the back-\\nground is black. Bottom-Right: Ap-\\nplying the inverse binary threshold\\nas a mask to the grayscale image. We\\nare now focused on only the coins in\\nthe image.\\n121'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 133, 'page_label': '122', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.1 simple thresholding\\n18 cv2.imshow(\"Threshold Binary Inverse\", threshInv)\\n19\\n20 cv2.imshow(\"Coins\", cv2.bitwise_and(image, image, mask =\\nthreshInv))\\n21 cv2.waitKey(0)\\nAfter the image is blurred, we compute the thresholded\\nimage on Line 14 using the cv2.threshold function. This\\nmethod requires four arguments. The ﬁrst is the grayscale\\nimage that we wish to threshold. We supply our blurred\\nimage here.\\nThen, we manually supply our T threshold value. We\\nuse a value of T = 155.\\nOur third argument is our maximum value applied dur-\\ning thresholding. Any pixel intensity p that is greater than\\nT, is set to this value. In our example, any pixel value that\\nis greater than 155 is set to 255. Any value that is less than\\n155 is set to zero.\\nFinally, we must provide a thresholding method. We use\\nthe cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 133, 'page_label': '122', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='the cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst\\nis T, the value we manually speciﬁed for thresholding. The\\nsecond is our actual thresholded image.\\nWe then show our thresholded image in Figure 9.1, Top-\\nRight. We can see that our coins are now black pixels and\\nthe white pixels are the background.\\n122'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 134, 'page_label': '123', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nOn Line 17 we apply inverse thresholding rather than\\nnormal thresholding by using cv2.THRESH_BINARY_INV as\\nour thresholding method. As we can see in Figure 9.1,\\nBottom-Left, our coins are now white and the background\\nis black. This is convenient as we will see in a second.\\nThe last task we are going to perform is to reveal the\\ncoins in the image and hide everything else.\\nRemember when we discussed masking? That will come\\nin handy here.\\nOn Line 20 we perform masking by using thecv2.bitwise_\\nand function. We supply our original coin image as the ﬁrst\\ntwo arguments, and then our inverted thresholded image as\\nour mask. Remember, a mask only considers pixels in the\\noriginal image where the mask is greater than zero. Since\\nour inverted thresholded image on Line 17 does a good job\\nat approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 134, 'page_label': '123', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='at approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our\\nmask – the coins are clearly revealed while the rest of the\\nimage is hidden.\\n9.2 adaptive thresholding\\nOne of the downsides of using simple thresholding meth-\\nods is that we need to manually supply our threshold value\\nT. Not only does ﬁnding a good value of T require a lot of\\nmanual experiments and parameter tunings, it’s not very\\n123'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 135, 'page_label': '124', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nFigure 9.2: Left: The grayscale coins image. Mid-\\ndle: Applying adaptive thresholding\\nusing mean neighborhood values.\\nRight: Applying adaptive threshold-\\ning using Gaussian neighborhood\\nvalues.\\nhelpful if the image exhibits a lot of range in pixel intensi-\\nties.\\nSimply put, having just one value of T might not sufﬁce.\\nIn order to overcome this problem, we can use adap-\\ntive thresholding, which considers small neighbors of pixels\\nand then ﬁnds an optimal threshold value T for each neigh-\\nbor. This method allows us to handle cases where there\\nmay be dramatic ranges of pixel intensities and the optimal\\nvalue of T may change for different parts of the image.\\nLet’s go ahead and jump into some code that applies\\nadaptive thresholding:\\n124'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 136, 'page_label': '125', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nListing 9.3: adaptive_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\n14\\n15 thresh = cv2.adaptiveThreshold(blurred, 255,\\n16 cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\\n17 cv2.imshow(\"Mean Thresh\", thresh)\\n18\\n19 thresh = cv2.adaptiveThreshold(blurred, 255,\\n20 cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\\n21 cv2.imshow(\"Gaussian Thresh\", thresh)\\n22 cv2.waitKey(0)\\nLines 1-10 once again handle setting up our example. We\\nimport our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 136, 'page_label': '125', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='import our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it\\nslightly on Lines 11 and 12.\\nWe then apply adaptive thresholding to our blurred im-\\nage using the cv2.adaptiveThreshold function on Line 15.\\nThe ﬁrst parameter we supply is the image we want to\\nthreshold. Then, we supply our maximum value of 255,\\nsimilar to simple thresholding mentioned above.\\nThe third argument is our method to compute the thresh-\\nold for the current neighborhood of pixels. By supplying\\ncv2.ADAPTIVE_THRESH_MEAN_C, we indicate that we want to\\ncompute the mean of the neighborhood of pixels and treat\\n125'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 137, 'page_label': '126', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.2 adaptive thresholding\\nit as our T value.\\nNext, we need our thresholding method. Again, the de-\\nscription of this parameter is identical to the simple thresh-\\nolding method mentioned above. We usecv2.THRESH_BINAR\\nY_INV to indicate that any pixel intensity greater than T in\\nthe neighborhood should be set to 255, otherwise it should\\nbe set to 0.\\nThe next parameter is our neighborhood size. This inte-\\nger value must be odd and indicates how large our neigh-\\nborhood of pixels is going to be. We supply a value of 11,\\nindicating that we are going to examine 11 × 11 pixel re-\\ngions of the image, instead of trying to threshold the image\\nglobally, as in simple thresholding methods.\\nFinally, we supply a parameter simply called C. This\\nvalue is an integer that is subtracted from the mean, allow-\\ning us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 137, 'page_label': '126', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ing us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.\\nBesides applying standard mean thresholding, we can\\nalso apply Gaussian (weighted mean) thresholding, as we\\ndo on Line 19. The order of the parameters are identical to\\nLine 15, but now we are tuning a few of the values.\\nInstead of supplying a value of cv2.ADAPTIVE_THRESH_\\nMEAN_C, we instead use cv2.ADAPTIVE_THRESH_GAUSSIAN_C\\nto indicate we want to use the weighted mean. We are\\nalso using a 15 × 15 pixel neighborhood size rather than\\n126'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 138, 'page_label': '127', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nan 11 × 11 neighborhood size as in the previous example.\\nWe also alter our C value (the value we subtract from the\\nmean) slightly and use 3 rather than 4.\\nThe results of applying Gaussian adaptive thresholding\\ncan be seen in the right image of Figure 9.2. There is little\\ndifference between the two images.\\nIn general, choosing between mean adaptive threshold-\\ning and Gaussian adaptive thresholding requires a few ex-\\nperiments on your end. The most important parameters\\nto vary are the neighborhood size and C, the value you\\nsubtract from the mean. By experimenting with this value,\\nyou will be able to dramatically change the results of your\\nthresholding.\\n9.3 otsu and riddler -calvard\\nAnother way we can automatically compute the threshold\\nvalue of T is to use Otsu’s method.\\nOtsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 138, 'page_label': '127', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Otsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.\\nWhile OpenCV provides support for Otsu’s method, I\\nprefer the implementation by Luis Pedro Coelho in themahotas\\npackage since it is more Pythonic.\\nLet’s jump into some sample code:\\n127'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 139, 'page_label': '128', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nListing 9.4: otsu_and_riddler.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import mahotas\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n15 cv2.imshow(\"Image\", image)\\n16\\n17 T = mahotas.thresholding.otsu(blurred)\\n18 print(\"Otsu’s threshold: {}\".format(T))\\nOn Lines 1-5 we import the packages we will utilize. We\\nhave seen numpy, argparse, and cv2 before. We are now\\nintroducing mahotas, another image processing package.\\nLines 7-12 then handle our standard practice of parsing\\narguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 139, 'page_label': '128', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='arguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-\\ntion in the mahotas.thresholding package. As our output\\nwill later show us, Otsu’s method ﬁnds a value of T = 137\\nthat we will use for thresholding.\\nListing 9.5: otsu_and_riddler.py\\n19 thresh = image.copy()\\n20 thresh[thresh > T] = 255\\n128'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 140, 'page_label': '129', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\n21 thresh[thresh < 255] = 0\\n22 thresh = cv2.bitwise_not(thresh)\\n23 cv2.imshow(\"Otsu\", thresh)\\n24\\n25 T = mahotas.thresholding.rc(blurred)\\n26 print(\"Riddler-Calvard: {}\".format(T))\\n27 thresh = image.copy()\\n28 thresh[thresh > T] = 255\\n29 thresh[thresh < 255] = 0\\n30 thresh = cv2.bitwise_not(thresh)\\n31 cv2.imshow(\"Riddler-Calvard\", thresh)\\n32 cv2.waitKey(0)\\nApplying the thresholding is accomplished on Lines 19-\\n22. First, we make a copy of our grayscale image so that we\\nhave an image to threshold. Line 20 then makes any values\\ngreater than T white, whereas Line 21 makes all remaining\\npixels that are not white into black pixels. We then invert\\nour threshold by using cv2.bitwise_not. This is equivalent\\nto applying a cv2.THRESH_BINARY_INV thresholding type as\\nin previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 140, 'page_label': '129', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='in previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.\\nAnother method to keep in mind when ﬁnding optimal\\nvalues for T is the Riddler-Calvard method. Just as in\\nOtsu’s method, the Riddler-Calvard method also computes\\nan optimal value of 137 for T. We apply this method on\\nLine 25 using the rc function in mahotas.thresholding. Fi-\\nnally, the actual thresholding of the image takes place on\\nLines 27-30, as in the previous example. Given that the\\nvalues of T are identical for Otsu and Riddler-Calvard, the\\nthresholded image in Figure 9.3 (right) is identical to the\\nthresholded image in the center.\\n129'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 141, 'page_label': '130', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFigure 9.3: Left: The original grayscale coins\\nimage. Middle: Applying Otsu’s\\nmethod to ﬁnd an optimal value of T.\\nRight: Applying the Riddler-Calvard\\nmethod to ﬁnd an optimal value of\\nT.\\nListing 9.6: otsu_and_riddler.py\\nOtsu’s threshold: 137\\nRiddler-Calvard: 137\\nNow that we have explored thresholding, we will move\\non to another powerful image processing technique – edge\\ndetection.\\n130'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 142, 'page_label': '131', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='9.3 otsu and riddler -calvard\\nFurther Reading\\nThresholding is often used as a method to segment the\\nforeground of an image from the background. This\\nworks ﬁne for foreground objects that can be cleanly\\nsegmented. But what if your foreground objects “touch”,\\nthereby making segmentation more difﬁcult. What do\\nyou do then?\\nThe answer is to apply the watershed algorithm, which I\\ncover inside the Chapter 9 supplementary material:\\nhttp://pyimg.co/z1ef6\\n131'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 143, 'page_label': '132', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10\\nG R A D I E N T S A N D E D G E D E T E C T I O N\\nThis chapter is primarily concerned with gradients and\\nedge detection. Formally, edge detection embodies math-\\nematical methods to ﬁnd points in an image where the\\nbrightness of pixel intensities changes distinctly.\\nThe ﬁrst thing we are going to do is ﬁnd the “gradient” of\\nthe grayscale image, allowing us to ﬁnd edge-like regions\\nin the x and y direction.\\nWe’ll then apply Canny edge detection, a multi-stage pro-\\ncess of noise reduction (blurring), ﬁnding the gradient of\\nthe image (utilizing the Sobel kernel in both the horizon-\\ntal and vertical direction), non-maximum suppression, and\\nhysteresis thresholding.\\nIf that sounds like a mouthful, it’s because it is. Again,\\nwe won’t jump too far into the details since this book is con-\\ncerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 143, 'page_label': '132', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='cerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the\\nalgorithms. Overall, they are not complicated and can be\\n132'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 144, 'page_label': '133', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.1: Left: The original coins image.\\nRight: Applying the Laplacian\\nmethod to obtain the gradient of the\\nimage.\\ninsightful to the behind-the-scenes action of OpenCV .\\n10.1 laplacian and sobel\\nLet’s go ahead and explore some code:\\nListing 10.1: sobel_and_laplacian.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 cv2.imshow(\"Original\", image)\\n133'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 145, 'page_label': '134', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\n13\\n14 lap = cv2.Laplacian(image, cv2.CV_64F)\\n15 lap = np.uint8(np.absolute(lap))\\n16 cv2.imshow(\"Laplacian\", lap)\\n17 cv2.waitKey(0)\\nLines 1-8 import our packages and set up our argument\\nparser. From there, we load our image and convert it to\\ngrayscale on Lines 10 and 11. When computing gradients\\nand edges, we (normally) compute them on a single chan-\\nnel – in this case, we are using the grayscale image; how-\\never, we can also compute gradients for each channel of\\nthe RGB image. For the sake of simplicity, let’s stick with\\nthe grayscale image since that is what you will use in most\\ncases.\\nOn Line 14, we use the Laplacian method to compute the\\ngradient magnitude image by calling the cv2.Laplacian\\nfunction. The ﬁrst argument is our grayscale image – the\\nimage we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 145, 'page_label': '134', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='image we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-\\nsigned integers. Why are we using a 64-bit ﬂoat now?\\nThe reason involves the transition of black-to-white and\\nwhite-to-black in the image.\\nTransitioning from black-to-white is considered a posi-\\ntive slope, whereas a transition from white-to-black is a\\nnegative slope. If you remember our discussion of image\\narithmetic in Chapter 6, you’ll know that an 8-bit unsigned\\ninteger does not represent negative values. Either it will be\\nclipped to zero if you are using OpenCV or a modulus op-\\n134'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 146, 'page_label': '135', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\neration will be performed using NumPy.\\nThe short answer here is that if you don’t use a ﬂoating\\npoint data type when computing the gradient magnitude\\nimage, you will miss edges, speciﬁcally the white-to-black\\ntransitions.\\nIn order to ensure you catch all edges, use a ﬂoating point\\ndata type, then take the absolute value of the gradient im-\\nage and convert it back to an 8-bit unsigned integer, as in\\nLine 15. This is deﬁnitely an important technique to take\\nnote of – otherwise you’ll be missing edges in your image!\\nTo see the results of our gradient processing, take a look\\nat Figure 10.1.\\nLet’s move on to computing the Sobel gradient represen-\\ntation:\\nListing 10.2: sobel_and_laplacian.py\\n18 sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\\n19 sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\\n20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 146, 'page_label': '135', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)\\n27 cv2.imshow(\"Sobel Y\", sobelY)\\n28 cv2.imshow(\"Sobel Combined\", sobelCombined)\\n29 cv2.waitKey(0)\\nUsing the Sobel operator, we can compute gradient mag-\\nnitude representations along the x and y axis, allowing us\\n135'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 147, 'page_label': '136', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nFigure 10.2: Top-Left: The original coins image.\\nTop-Right: Computing the Sobel gra-\\ndient magnitude along the x-axis\\n(ﬁnding vertical edges). Bottom-\\nLeft: Computing the Sobel gradient\\nalong the y-axis (ﬁnding horizontal\\nedges). Bottom-Right: Applying a\\nbitwise OR to combine the two So-\\nbel representations.\\n136'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 148, 'page_label': '137', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.1 laplacian and sobel\\nto ﬁnd both horizontal and vertical edge-like regions.\\nIn fact, that’s exactly what Lines 18 and 19 do by us-\\ning the cv2.Sobel method. The ﬁrst argument to the Sobel\\noperator is the image we want to compute the gradient rep-\\nresentation for. Then, just like in the Laplacian example\\nabove, we use a ﬂoating point data type. The last two argu-\\nments are the order of the derivatives in the x and y direc-\\ntion, respectively. Specify a value of 1 and 0 to ﬁnd vertical\\nedge-like regions and 0 and 1 to ﬁnd horizontal edge-like\\nregions\\nOn Lines 21 and 22 we then ensure we ﬁnd all edges by\\ntaking the absolute value of the ﬂoating point image and\\nthen converting it to an 8-bit unsigned integer.\\nIn order to combine the gradient images in both the x\\nand y direction, we can apply a bitwise OR. Remember, an\\nOR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 148, 'page_label': '137', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='OR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.\\nFinally, we show our gradient images on Lines 26-29.\\nYou can see the result of our work in Figure 10.2. We\\nstart with our original image, Top-Left, and then ﬁnd vertical\\nedges, Top-Right, and horizontal edges, Bottom-Left. Finally,\\nwe compute a bitwise OR to combine the two directions\\ninto a single image, Bottom-Right.\\nOne thing you’ll notice is that the edges are very “noisy”.\\nThey are not clean and crisp. We’ll remedy that by using\\n137'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 149, 'page_label': '138', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFigure 10.3: Left: Our coins image in grayscale\\nand blurred slightly. Right: Apply-\\ning the Canny edge detector to the\\nblurred image to ﬁnd edges. No-\\ntice how our edges are more “crisp”\\nand the outlines of the coins are\\nfound.\\nthe Canny edge detector in the next section.\\n10.2 canny edge detector\\nThe Canny edge detector is a multi-step process. It involves\\nblurring the image to remove noise, computing Sobel gradi-\\nent images in the x and y direction, suppressing edges, and\\nﬁnally a hysteresis thresholding stage that determines if a\\npixel is “edge-like” or not.\\n138'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 150, 'page_label': '139', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nWe won’t get into all these steps in detail. Instead, we’ll\\njust look at some code and show how it’s done:\\nListing 10.3: canny.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 image = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Blurred\", image)\\n14\\n15 canny = cv2.Canny(image, 30, 150)\\n16 cv2.imshow(\"Canny\", canny)\\n17 cv2.waitKey(0)\\nThe ﬁrst thing we do is import our packages and parse\\nour arguments. We then load our image, convert it to graysc-\\nale, and blur it using the Gaussian blurring method. By ap-\\nplying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 150, 'page_label': '139', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='plying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.\\nApplying the Canny edge detector is performed on Line\\n15 using the cv2.Canny function. The ﬁrst argument we\\nsupply is our blurred, grayscale image. Then, we need to\\nprovide two values: threshold1 and threshold2.\\nAny gradient value larger than threshold2 is considered\\nto be an edge. Any value below threshold1 is consid-\\nered not to be an edge. Values in between threshold1\\nand threshold2 are either classiﬁed as edges or non-edges\\n139'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 151, 'page_label': '140', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nbased on how their intensities are “connected”. In this case,\\nany gradient values below 30 are considered non-edges wh-\\nereas any values above 150 are considered edges.\\nWe then show the results of our edge detection on Line\\n16.\\nFigure 10.3 shows the results of the Canny edge detector.\\nThe image on the left is the grayscale, blurred image that\\nwe pass into the Canny operator. The image on the right is\\nthe result of applying the Canny operator.\\nNotice how the edges are more “crisp”. We have substan-\\ntially less noise than when we used the Laplacian or Sobel\\ngradient images. Furthermore, the outline of our coins are\\nclearly revealed.\\nIn the next chapter, we’ll continue to make use of the\\nCanny edge detector and use it to count the number of\\ncoins in our image.\\n140'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 152, 'page_label': '141', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='10.2 canny edge detector\\nFurther Reading\\nJust like thresholding is a common method for seg-\\nmenting foreground objects from background objects,\\nthe same can be said for edge detection – only instead\\nof obtaining a large blob representing the foreground,\\nthe Canny detector gives us the outline.\\nHowever, a common challenge of using the Canny edge\\ndetector is getting the lower and upper edge thresh-\\nolds just right. In order to help you (automatically)\\ndetermine these lower and upper boundaries, be sure\\nto read about the automatic Canny edge detector in this\\nsupplementary material:\\nhttp://pyimg.co/91daw\\n141'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 153, 'page_label': '142', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11\\nC O N T O U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in the curve. Contours are extremely useful for such\\nthings as shape approximation and analysis.\\nIn order to ﬁnd contours in an image, you need to ﬁrst ob-\\ntain a binarization of the image, using either edge detection\\nmethods or thresholding. In the examples below, we’ll use\\nthe Canny edge detector to ﬁnd the outlines of the coins,\\nand then ﬁnd the actual contours of the coins.\\nReady?\\nHere we go:\\n11.1 counting coins\\n142'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 154, 'page_label': '143', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nListing 11.1: counting_coins.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n13 blurred = cv2.GaussianBlur(gray, (11, 11), 0)\\n14 cv2.imshow(\"Image\", image)\\n15\\n16 edged = cv2.Canny(blurred, 30, 150)\\n17 cv2.imshow(\"Edges\", edged)\\nThe ﬁrst 11 lines of code simply set up our environment\\nby importing packages, parsing arguments, and loading the\\nimage.\\nJust as in the edge detection methods discussed in the\\nprevious chapter, we are going to convert our image to\\ngrayscale and then apply a Gaussian blur, making it eas-\\nier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 154, 'page_label': '143', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.\\nWe then obtain the edged image by applying the Canny\\nedge detector on Line 16. Again, just as in previous edge\\ndetection examples, any gradient values below 30 are con-\\nsidered non-edges whereas any values above 150 are con-\\nsidered sure edges.\\nListing 11.2: counting_coins.py\\n143'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 155, 'page_label': '144', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n18 (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2\\n.CHAIN_APPROX_SIMPLE)\\n19\\n20 print(\"I count {} coins in this image\".format(len(cnts)))\\n21\\n22 coins = image.copy()\\n23 cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\\n24 cv2.imshow(\"Coins\", coins)\\n25 cv2.waitKey(0)\\nNow that we have the outlines of the coins, we can ﬁnd\\nthe contours of the outlines. We do this using the cv2.\\nfindContours function on Line 18. This method returns\\na 3-tuple of: ( 1) our image after applying contour detec-\\ntion (which is modiﬁed and essentially destroyed), ( 2) the\\ncontours themselves, cnts, and (3) the hierarchy of the con-\\ntours (see below).\\nThe ﬁrst argument to cv2.findContours is our edged im-\\nage. It’s important to note that this function is destructive\\nto the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 155, 'page_label': '144', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='to the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.\\nWe use cv2.RETR_EXTERNAL to retrieve only the outermost\\ncontours (i.e., the contours that follow the outline of the\\ncoin). We can also pass in cv2.RETR_LIST to grab all con-\\ntours. Other methods include hierarchical contours using\\ncv2.RETR_COMP and cv2.RETR_TREE, but hierarchical con-\\ntours are outside the scope of this book.\\nOur last argument is how we want to approximate the\\ncontour. We use cv2.CHAIN_APPROX_SIMPLE to compress\\nhorizontal, vertical, and diagonal segments into their end-\\npoints only. This saves both computation and memory. If\\n144'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 156, 'page_label': '145', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nwe wanted all the points along the contour, without com-\\npression, we can pass in cv2.CHAIN_APPROX_NONE; however,\\nbe very sparing when using this function. Retrieving all\\npoints along a contour is often unnecessary and is wasteful\\nof resources.\\nOur contours cnts is simply a Python list. We can use\\nthe len function on it to count the number of contours that\\nwere returned. We do this on Line 20 to show how many\\ncontours we have found.\\nWhen we execute our script, we will have the output “I\\ncount 9 coins in this image” printed out to our console.\\nNow, we are able to draw our contours. In order not to\\ndraw on our original image, we make a copy of the original\\nimage, called coins on Line 22.\\nA call to cv2.drawContours draws the actual contours on\\nour image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 156, 'page_label': '145', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='our image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative\\nvalue of −1, we are indicating that we want to draw all of\\nthe contours. However, we would also supply an index i,\\nwhich would be the i’th contour in cnts. This would allow\\nus to draw only a single contour rather than all of them.\\nFor example, here is some code to draw the ﬁrst, second,\\nand third contours, respectively:\\nListing 11.3: Drawing Contours via an Index\\n1 cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)\\n145'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 157, 'page_label': '146', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n2 cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)\\n3 cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)\\nThe fourth argument to the cv2.drawContours function\\nis the color of the line we are going to draw. Here, we use\\na green color.\\nFinally, our last argument is the thickness of the line we\\nare drawing. We’ll draw the contour with a thickness of\\ntwo pixels.\\nNow that our contours are drawn on the image, we can\\nvisualize them on Line 24.\\nTake a look at Figure 11.1 to see the results of our work.\\nOn the left is our original image. Then, we apply Canny\\nedge detection to ﬁnd the outlines of the coins ( middle). Fi-\\nnally, we ﬁnd the contours of the coin outlines and draw\\nthem. You can see that each contour has been drawn with\\na two-pixel thick green line.\\nBut we’re not done yet!\\nLet’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 157, 'page_label': '146', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='Let’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))\\n30 coin = image[y:y + h, x:x + w]\\n31 cv2.imshow(\"Coin\", coin)\\n32\\n33 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n34 ((centerX, centerY), radius) = cv2.minEnclosingCircle(c)\\n146'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 158, 'page_label': '147', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\nFigure 11.1: Left: The original coin image. Mid-\\ndle: Applying the Canny edge detec-\\ntor to ﬁnd the outlines of the coins.\\nRight: Finding the contours of the\\ncoin outlines and then drawing the\\ncontours. We have now success-\\nfully found the coins and are able\\nto count them.\\n147'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 159, 'page_label': '148', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.1 counting coins\\n35 cv2.circle(mask, (int(centerX), int(centerY)), int(radius),\\n255, -1)\\n36 mask = mask[y:y + h, x:x + w]\\n37 cv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask =\\nmask))\\n38 cv2.waitKey(0)\\nWe start off on Line 26 by looping over our contours.\\nWe then use the cv2.boundingRect function on the cur-\\nrent contour. This method ﬁnds the “enclosing box” that\\nour contour will ﬁt into, allowing us to crop it from the\\nimage. The function takes a single parameter, a contour,\\nand then returns a tuple of the x and y position that the\\nrectangle starts at, followed by the width and height of the\\nrectangle.\\nWe then crop the coin from the image using our bound-\\ning box coordinates and NumPy array slicing on Line 30.\\nThe coin itself is shown to us on Line 31.\\nIf we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 159, 'page_label': '148', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='If we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array\\nof zeros, with the same width and height of our original\\nimage.\\nA call to cv2.minEnclosingCircle on Line 34 ﬁts a circle\\nto our contour. We pass in a circle variable, the current\\ncontour, and are given the x and y coordinates of the circle,\\nalong with its radius.\\nUsing the (x, y) coordinates and the radius, we can draw\\na circle on our mask, representing the coin. Drawing circles\\n148'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 160, 'page_label': '149', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work. The\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 160, 'page_label': '149', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='ages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2 contours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 161, 'page_label': '150', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\nFigure 11.2: Top: Cropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing. Bottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 162, 'page_label': '151', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, thegrab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6 if len(cnts) == 2:\\n7 cnts = cnts[0]\\n8\\n9 elif len(cnts) == 3:\\n10 cnts = cnts[1]\\n11\\n12 else:\\n13 raise Exception((\"Contours tuple must have length 2 or \"\\n14 \"3, otherwise OpenCV changed their cv2.findContours \"\\n15 \"return signature yet again. Refer to OpenCV’s\\n16 documentation in that case.\"))\\n17\\n18 return cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 162, 'page_label': '151', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)\\nOn Line 1 we call the cv2.findContours function to de-\\ntect contours in an image.\\nFrom there, Line 2 utilizes the grab_contours function\\nto inspect the tuple returned by cv2.findContours and ex-\\n151'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 163, 'page_label': '152', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 163, 'page_label': '152', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='a clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplementary material for this chap-\\nter – be sure to take a look:\\nhttp://pyimg.co/saz76\\n152'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 164, 'page_label': '153', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='12\\nW H E R E T O N O W ?\\nIn this book, we’ve explored many image processing and\\ncomputer vision techniques, including basic image process-\\ning, such as translation, rotating, and resizing. We learned\\nall about image arithmetic and how to apply bitwise op-\\nerations. Then, we explored how a simple technique like\\nmasking can be used to focus our attention and computa-\\ntion to only a single part of an image.\\nTo better understand the pixel intensity distribution of an\\nimage, we then explored histograms. We started by com-\\nputing grayscale histograms, then worked our way up to\\ncolor, including 2D and 3D color histograms. We adjusted\\nthe contrast of images using histogram equalization, then\\nmoved on to blurring our images, using different methods,\\nsuch as averaging, Gaussian, and median ﬁltering.\\nWe thresholded our images to ﬁnd objects of interest,\\nthen applied edge detection.\\nFinally we learned how to use contours to count the num-\\nber of coins in the image.\\n153'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.16', 'creator': 'LaTeX with hyperref package', 'creationdate': '2019-01-06T06:31:50-05:00', 'author': '', 'title': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-09T20:13:54+06:30', 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1', 'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf', 'total_pages': 166, 'page': 165, 'page_label': '154', 'source_file': 'Practical Python and OpenCV.pdf', 'file_type': 'pdf'}, page_content='where to now ?\\nSo, where do you go from here?\\nYou continue learning, exploring, and experimenting!\\nUse the source code and images provided in this book to\\ncreate projects of your own. That’s the best way to learn!\\nIf you need project ideas, be sure to contact me. I love\\ntalking with readers and helping out when I can. You can\\nreach me at adrian@pyimagesearch.com.\\nFinally, I constantly post on my blog, www.PyImageSear\\nch.com, sharing new and interesting techniques related to\\ncomputer vision and image search engines. Be sure to fol-\\nlow the blog for new posts, as well as new books and courses\\nas I write them.\\n154'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 0, 'page_label': '1', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='SQL-QUERIES\\nTables\\nYou\\tneed\\tto\\tcreate\\tand\\tpopulate\\tthe\\tfollowing\\ttables\\tto\\tstart\\tworking\\ton\\tthe\\nqueries.\\n1.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEmp\\ttable\\tdata'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 3, 'page_label': '4', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.\\t\\t\\t\\tExercises\\twith\\tAnswers\\n2.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tinformation\\tof\\tthe\\tEMP\\ttable?\\nA)\\tselect\\t*\\tfrom\\temp;\\n2.2.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tunique\\tJobs\\tfrom\\tEMP\\ttable?\\nA)\\t\\t\\t\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp;\\nB)\\t\\t\\t\\tselect\\tunique\\tjob\\tfrom\\temp;\\n2.3.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\ttheir\\tSalaries?\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\torder\\tby\\tsal\\tasc;\\n2.4.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tasc\\torder\\tof\\tthe\\tDptnos\\tand\\tdesc\\tof\\nJobs?\\nA)select\\t*\\tfrom\\temp\\torder\\tby\\tdeptno\\tasc,job\\tdesc;\\n2.5.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tunique\\tjob\\tgroups\\tin\\tthe\\tdescending\\torder?\\nA)select\\tdistinct\\tjob\\tfrom\\temp\\torder\\tby\\tjob\\tdesc;\\n2.6.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tall\\t‘Mgrs’\\nA)Select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(\\tselect\\t\\tmgr\\t\\tfrom\\temp)\\t;\\n2.7.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tbefore\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(’01-jan-81’);\\n2.8.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDaily\\tsal\\tof\\tall\\temps\\tin\\tthe\\tasc\\torder\\tof\\nAnnsal.\\nA)\\tselect\\tempno\\t,ename\\t,sal,sal/30,12*sal\\tannsal\\tfrom\\temp\\torder\\tby\\tannsal\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 4, 'page_label': '5', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.9.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tjob,\\tHiredate,\\tExp\\tof\\tall\\tMgrs\\t\\nA)\\tselect\\t\\tempno,ename\\t,job,hiredate,\\tmonths_between(sysdate,hiredate)\\t\\texp\\nfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n2.10.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tExp\\tof\\tall\\temps\\tworking\\tfor\\tMgr\\t7369.\\nA)\\tselect\\tempno,ename,sal,exp\\tfrom\\temp\\twhere\\tmgr\\t=\\t7369;\\n2.11.\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tComm.\\tIs\\tmore\\tthan\\ttheir\\tSal.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tcomm.\\t>\\tsal;\\n2.12.\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\tDesignations\\tof\\tthose\\tjoined\\tafter\\tthe\\nsecond\\thalf\\tof\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t>\\t(’30-jun-81’)\\tand\\nto_char(hiredate,’YYYY’)\\t=\\t1981\\torder\\tby\\tjob\\tasc;\\n2.13.\\t\\t\\t\\t\\tList\\tthe\\temps\\talong\\twith\\ttheir\\tExp\\tand\\tDaily\\tSal\\tis\\tmore\\tthan\\tRs.100.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 4, 'page_label': '5', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;\\n2.15.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\ton\\t1-MAY-81,3-DEC-81,17-DEC-81,19-JAN-\\n80\\tin\\tasc\\torder\\tof\\tseniority.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\tin\\t(’01-may-81’,’03-dec-81’,’17-dec-\\n81’,’19-jan-80’)\\t\\torder\\tby\\thiredate\\tasc;\\n2.16.\\t\\t\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tworking\\tfor\\tthe\\tDeptno\\t10\\tor20.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 5, 'page_label': '6', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\t\\tor\\tdeptno\\t=\\t20\\t;\\n2.17.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\thiredate\\tbetween\\t’01-jan-81’\\tand\\t’31-dec-81’;\\n2.18.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tmonth\\tof\\tAug\\t1980.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-aug-80’\\tand\\t’31-aug-80’;\\t\\t\\n(OR)\\nselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon-yyyy’)\\t=’aug-1980;\\n2.19.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWho\\tAnnual\\tsal\\tranging\\tfrom\\t22000\\tand\\t45000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t12*sal\\tbetween\\t22000\\tand\\t45000;\\n2.20.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\thaving\\tfive\\tcharacters\\tin\\ttheir\\tNames.\\nA)\\tselect\\t\\tename\\tfrom\\temp\\twhere\\t\\tlength\\t(ename)\\t=\\t5;\\n2.21.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\tstarting\\twith\\t‘S’\\tand\\twith\\tfive\\tcharacters.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘S%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 5, 'page_label': '6', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;\\n2.23.\\t\\t\\t\\t\\tList\\tthe\\tFive\\tcharacter\\tnames\\tstarting\\twith\\t‘S’\\tand\\tending\\twith\\t‘H’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t5\\tand\\tename\\tlike\\t\\t‘S%H’;\\n2.24.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tJanuary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’mon’)\\t=\\t‘jan’;\\n2.25.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\twhich\\tsecond\\tcharacter\\tis\\t‘a’.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\t\\tlike\\t‘_a_’;\\t(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 6, 'page_label': '7', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='B)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\tlike\\t‘_a%’;\\n2.26.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tSal\\tis\\tfour\\tdigit\\tnumber\\tending\\twith\\tZero.\\nA)\\tselect\\t\\t*\\t\\tfrom\\t\\temp\\twhere\\t\\tlength\\t(sal)\\t=\\t4\\tand\\tsal\\tlike\\t‘%0’;\\n2.27.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\thaving\\ta\\tcharacter\\tset\\t‘ll’\\ttogether.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘%LL%’;\\n2.28.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\t80’s.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’yy’)\\t\\tlike\\t‘8%’;\\n2.29.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tdoes\\tnot\\tbelong\\tto\\tDeptno\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\tnot\\tin\\t(20);\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\t!=\\t20;\\t(OR)\\nC)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t<>20;\\t(OR)\\nD)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tlike\\t‘20’;\\n2.30.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\texcept\\t‘PRESIDENT’\\t&\\t‘MGR”\\tin\\tasc\\torder\\tof\\nSalaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 6, 'page_label': '7', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Salaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;\\nC)\\tSelect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t‘PRESIDENT’\\tand\\tjob\\t<>\\t‘MANAGER’\\t\\norder\\t\\tby\\t\\tsal\\t\\tasc;\\n2.31.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\twho\\tjoined\\tbefore\\tor\\tafter\\t1981.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 7, 'page_label': '8', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’YYYY’)\\t\\tnot\\tin\\t(‘1981’);\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\t(\\thiredate,’YYYY’)\\t\\t!=\\t\\t‘1981’;\\t\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t\\t<>\\t\\t‘1981’\\t;\\t(OR)\\nD)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate\\t,’YYYY’)\\t\\tnot\\tlike\\t‘1981’;\\n2.32.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tEmpno\\tnot\\tstarting\\twith\\tdigit78.\\nA)\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tnot\\tlike\\t‘78%’;\\n2.33.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tunder\\t‘MGR’.\\nA)\\tselect\\te.ename\\t||\\t‘\\tworks\\tfor\\t‘\\t||\\tm.ename\\t\\tfrom\\temp\\te\\t,emp\\tm\\twhere\\te.mgr\\t=\\nm.empno\\t;\\t\\t\\t\\t\\t\\t\\t\\t(OR)\\nB)\\tselect\\t\\te.ename\\t||\\t‘\\thas\\tan\\temployee\\t‘||\\tm.ename\\tfrom\\temp\\te\\t,\\temp\\tm\\twhere\\ne.empno\\t=\\tm.mgr;\\n2.34.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tany\\tyear\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tof\\nMarch.\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\t\\tto_char\\t(hiredate,’MON’)\\tnot\\tin\\t(‘MAR’);\\t\\t(OR)\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 7, 'page_label': '8', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='F)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\t<>\\t‘MAR’;\\n2.35.\\t\\t\\t\\t\\tList\\tall\\tthe\\tClerks\\tof\\tDeptno\\t20.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\t=‘CLERK’\\tand\\tdeptno\\t=\\t20;\\n2.36.\\t\\t\\t\\t\\tList\\tthe\\temps\\tof\\tDeptno\\t30\\tor\\t10\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’\\tand\\t(deptno'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 8, 'page_label': '9', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='=30\\tor\\tdeptno\\t=10)\\t;\\t\\t(OR)\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\n(hiredate,’YYYY’)\\t\\tin\\t(‘1981’)\\t\\tand\\t\\t(deptno\\t=\\t30\\tor\\tdeptno\\t=10\\t)\\t;\\n2.37.\\t\\t\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tSMITH.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’\\t;\\n2.38.\\t\\t\\t\\t\\tDisplay\\tthe\\tlocation\\tof\\t\\tSMITH.\\nA)\\tselect\\tloc\\tfrom\\temp\\t\\te\\t,\\tdept\\td\\twhere\\t\\te.ename\\t=\\t‘SMITH’\\tand\\t\\te.deptno\\t=\\nd.deptno\\t;\\n2.39.\\t\\t\\t\\t\\tList\\tthe\\ttotal\\tinformation\\tof\\tEMP\\ttable\\talong\\twith\\tDNAME\\tand\\tLoc\\tof\\nall\\tthe\\temps\\tWorking\\tUnder\\t‘ACCOUNTING’\\t&\\t‘RESEARCH’\\tin\\tthe\\tasc\\nDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t(dname\\t=\\t‘ACCOUNTING’\\tor\\tdname\\n=’RESEARCH’\\t)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\tasc;\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.dname\\tin\\n(‘ACCOUNTING’,’RESEARCH’)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\nasc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 8, 'page_label': '9', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='asc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,d.dname\\t\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\n(‘NEW\\tYORK’,’DALLAS’)\\tand\\te.deptno\\t=\\td.deptno\\tand\\te.empno\\tin\\t(select\\ne.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\t(‘MANAGER’,’ANALYST’)\\tand\\t\\n(months_between(sysdate,e.hiredate)/12)>\\t7\\t\\tand\\t\\te.comm.\\tis\\tnull)\\norder\\tby\\td.loc\\t\\tasc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 9, 'page_label': '10', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.41.\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tLoc,\\tDeptno,\\tJob\\tof\\tall\\temps\\nworking\\tat\\tCJICAGO\\tor\\tworking\\tfor\\tACCOUNTING\\tdept\\twith\\tAnn\\nSal>28000,\\tbut\\tthe\\tSal\\tshould\\tnot\\tbe=3000\\tor\\t2800\\twho\\tdoesn’t\\tbelongs\\tto\\tthe\\nMgr\\tand\\twhose\\tno\\tis\\thaving\\ta\\tdigit\\t‘7’\\tor\\t‘8’\\tin\\t3rd\\tposition\\tin\\tthe\\tasc\\torder\\tof\\nDeptno\\tand\\tdesc\\torder\\tof\\tjob.\\nA)\\tselect\\tE.empno,E.ename,E.sal,D.dname,D.loc,E.deptno,E.job\\nfrom\\temp\\tE,dept\\tD\\nwhere\\t(D.loc\\t=\\t'CHICAGO'\\tor\\tD.dname\\t=\\t'ACCOUNTING')\\tand\\nE.deptno=D.deptno\\tand\\tE.empno\\tin\\n(select\\tE.empno\\tfrom\\temp\\tE\\twhere\\t(12*E.sal)\\t>\\t28000\\tand\\t\\tE.sal\\tnot\\tin\\n(3000,2800)\\t\\tand\\tE.job\\t!='MANAGER'\\nand\\t(\\tE.empno\\tlike\\t'__7%'\\tor\\tE.empno\\tlike\\t'__8%'))\\norder\\tby\\tE.deptno\\tasc\\t,\\tE.job\\tdesc;\\n2.42.\\t\\t\\t\\t\\tDisplay\\tthe\\ttotal\\tinformation\\tof\\tthe\\temps\\talong\\twith\\tGrades\\tin\\tthe\\tasc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 9, 'page_label': '10', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='order.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\\t\\norder\\tby\\ts.grade\\t\\tasc;\\t\\t\\t\\t\\t\\t\\t\\t(using\\tbetween\\tand\\tis\\ta\\tbit\\tsimple)\\n2.43.\\t\\t\\t\\t\\tList\\tall\\tthe\\tGrade2\\tand\\tGrade\\t3\\temps.\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ns\\twhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin(2,3));\\t(OR)\\t\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 10, 'page_label': '11', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='s.grade\\tin\\t(2,3)\\t;\\n2.44.\\t\\t\\t\\t\\tDisplay\\tall\\tGrade\\t4,5\\tAnalyst\\tand\\tMgr.\\nA)\\tselect\\t*\\tfrom\\temp\\te,\\tsalgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand\\ns.grade\\tin\\t(4,5)\\tand\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\n(‘MANAGER’,’ANALYST’)\\t);\\n2.45.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tGrade,\\tExp,\\tand\\tAnn\\tSal\\tof\\temps\\nworking\\tfor\\tDept10\\tor20.\\nA)\\nselectE.empno,E.ename,E.sal,S.grade,D.dname,\\n(months_between(sysdate,E.hiredate)/12)\\t\"EXP\"\\t,12*E.sal\\t\\t“ANN\\tSAL”\\nfrom\\temp\\tE,dept\\tD\\t,salgrade\\tS\\nwhere\\tE.deptno\\tin\\t(10,20)\\tand\\tE.deptno\\t=\\tD.deptno\\t\\tand\\tE.sal\\tbetween\\tS.losal\\nand\\tS.hisal\\t;\\n2.46.\\t\\t\\t\\t\\tList\\tall\\tthe\\tinformation\\tof\\temp\\twith\\tLoc\\tand\\tthe\\tGrade\\tof\\tall\\tthe\\temps\\nbelong\\tto\\tthe\\tGrade\\trange\\tfrom\\t2\\tto\\t4\\tworking\\tat\\tthe\\tDept\\tthose\\tare\\tnot\\tstarting\\nwith\\tchar\\tset\\t‘OP’\\tand\\tnot\\tending\\twith\\t‘S’\\twith\\tthe\\tdesignation\\thaving\\ta\\tchar\\t‘a’\\nany\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 10, 'page_label': '11', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"any\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades\\nA)\\t\\tselect\\te.empno,e.ename,d.loc,s.grade,e.sal\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\nand\\t(d.dname\\tnot\\tlike\\t'OP%'\\tand\\td.dname\\tnot\\tlike\\t'%S')\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin\\t(2,3,4)\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tjob\\tlike\\t'%A%'and\\tsal\\tnot\\tlike\\n'%00'\\tand\\t(to_char\\t(hiredate,'YYYY')\\t=\\t'1981'\\nand\\tto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP')));\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 11, 'page_label': '12', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='2.47.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tDepts\\talong\\twith\\tEmpno,\\tEname\\tor\\twithout\\tthe\\nemps\\nA)\\tselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno(+)=\\td.deptno;\\n2.48.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tSalaries\\tmore\\tthan\\tthe\\temployee\\nBLAKE.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>\\t(select\\t\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\n‘BLAKE’);\\n2.49.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tJobs\\tare\\tsame\\tas\\tALLEN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘ALLEN’);\\n2.50.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tKing.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\n=\\t‘KING’);\\n2.51.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tMGRS.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\t\\tand\\tw.hiredate\\t<\\t\\nm.hiredate\\t;\\t(OR)\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.empno=\\tm.mgr\\tand\\nw.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 11, 'page_label': '12', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='w.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand\\ne.job\\tin\\t(\\tselect\\te.job\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\tand\\td.deptno\\n=10);\\n2.53.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\tsame\\tas\\tFORD\\tor\\tSMITH\\tin\\tdesc\\torder\\tof'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 12, 'page_label': '13', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Sal.\\nA)\\nSelect\\t*\\t\\tfrom\\t\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\t(\\tename\\t=\\t‘SMITH’\\nor\\t\\tename\\t=\\t‘FORD’\\t))\\t\\torder\\tby\\tsal\\tdesc;\\n2.54.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\tJobs\\tare\\tsame\\tas\\tMILLER\\tor\\tSal\\tis\\tmore\\tthan\\nALLEN.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\t\\twhere\\tjob\\t=\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘MILLER’\\t)\\tor\\t\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’);\\n2.55.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\t>\\tthe\\ttotal\\tremuneration\\tof\\tthe\\tSALESMAN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>(select\\tsum(nvl2(comm,sal+comm,sal))\\tfrom\\nemp\\t\\twhere\\tjob\\t=\\t‘SALESMAN’);\\n2.56.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tBLAKE\\tworking\\tat\\tCHICAGO\\t&\\nBOSTON.\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\t(‘CHICAGO’,’BOSTON’)\\tand\\ne.deptno\\t=\\td.deptno\\tand\\te.hiredate\\t<(select\\te.hiredate\\tfrom\\temp\\te\\twhere\\te.ename\\n=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 12, 'page_label': '13', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.deptno\\tin\\t(select\\td.deptno\\t\\tfrom\\tdept\\td\\twhere\\nd.dname\\t\\tin\\t(‘ACCOUNTING’,’RESEARCH’)\\t)\\tand\\t\\ne.sal\\t>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’)\\t\\tand\\t\\ne.hiredate\\t<(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’)\\tand\\ne.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\t\\tand\\ts.grade\\tin\\t(3,4)\\t)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 13, 'page_label': '14', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='order\\tby\\te.hiredate\\tdesc;\\n2.58.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tjobs\\tsame\\tas\\tSMITH\\tor\\tALLEN.\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘SMITH’\\tor\\tename\\t=\\t‘ALLEN’);\\t\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\tin\\n(‘SMITH’,’ALLEN’);\\n2.59.\\t\\t\\t\\t\\tWrite\\ta\\tQuery\\tto\\tdisplay\\tthe\\tdetails\\tof\\temps\\twhose\\tSal\\tis\\tsame\\tas\\tof\\nb)\\t\\t\\t\\t\\tEmployee\\tSal\\tof\\tEMP1\\ttable.\\nc)\\t\\t\\t\\t\\t\\t¾\\tSal\\tof\\tany\\tMgr\\tof\\tEMP2\\ttable.\\nd)\\t\\t\\t\\t\\tThe\\tsal\\tof\\tany\\tperson\\twith\\texp\\tof\\t5\\tyears\\tbelongs\\tto\\tthe\\tsales\\tdept\\tof\\temp3\\ntable.\\ne)\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\temployee\\tof\\temp4\\ttable.\\nf)\\t\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\tand\\t3\\temployee\\tworking\\tfro\\tsales\\tdept\\tor\\toperations\\tdept\\njoined\\tin\\t89.\\n2.60.\\t\\t\\t\\t\\tAny\\tjobs\\tof\\tdeptno\\t10\\tthose\\tthat\\tare\\tnot\\tfound\\tin\\tdeptno\\t20.\\nA)\\tselect\\t\\te.job\\tfrom\\temp\\te\\twhere\\te.deptno\\t=\\t10\\tand\\te.job\\tnot\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=20);\\n2.61.\\t\\t\\t\\t\\tList\\tof\\temps\\tof\\temp1\\twho\\tare\\tnot\\tfound\\tin\\temp2.\\n2.62.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tsal\\tof\\tEMP\\ttable.\\nA)\\tselect\\tmax(sal)\\tfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 14, 'page_label': '15', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.63.\\t\\t\\t\\t\\tFind\\tdetails\\tof\\thighest\\tpaid\\temployee.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\t\\tmax(sal)\\tfrom\\temp);\\n2.64.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tpaid\\temployee\\tof\\tsales\\tdepartment.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp\\twhere\\tdeptno\\tin\\n(select\\td.deptno\\tfrom\\ndept\\td\\twhere\\td.dname\\t=\\t'SALES'));\\n2.65.\\t\\t\\t\\t\\tList\\tthe\\tmost\\trecently\\thired\\temp\\tof\\tgrade3\\tbelongs\\tto\\t\\tlocation\\nCHICAGO.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t\\te.deptno\\tin\\t(\\tselect\\t\\td.deptno\\tfrom\\tdept\\td\\twhere\\nd.loc\\t=\\t'CHICAGO')\\tand\\ne.hiredate\\tin\\t\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tempno\\nfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3))\\t;\\t(or)\\nselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\td.loc='chicago'\\nand\\thiredate\\tin(select\\tmax(hiredate)\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\tsal\\tbetween\\tlosal\\tand\\thisal\\tand\\tgrade=3);\\n2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 14, 'page_label': '15', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'))\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 15, 'page_label': '16', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.67.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temployee\\tbelongs\\tto\\tnewyork\\twith\\tgrade\\t3\\tto\\t5\\nexcept\\t‘PRESIDENT’\\twhose\\tsal>\\tthe\\thighest\\tpaid\\temployee\\tof\\tChicago\\tin\\ta\\ngroup\\twhere\\tthere\\tis\\tmanager\\tand\\tsalesman\\tnot\\tworking\\tunder\\tking\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\n='NEW\\tYORK')\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\tand\\ns.grade\\tin\\t(3,4,5)\\t)\\tand\\tjob\\t!=\\t'PRESIDENT'\\tand\\tsal\\t>(select\\tmax(sal)\\tfrom\\temp\\nwhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\t'CHICAGO')\\tand\\tjob\\tin\\n('MANAGER','SALESMAN')\\tand\\nmgr\\tnot\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\\n2.68.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tsenior\\temployee\\tbelongs\\tto\\t1981.\\nB)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\t\\nwhere\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 15, 'page_label': '16', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='where\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\\n2.69.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tjoined\\tin\\t1981\\twith\\tthe\\tjob\\tsame\\tas\\tthe\\tmost\\nsenior\\tperson\\tof\\tthe\\tyear\\t1981.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=’1981’));'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 16, 'page_label': '17', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.70.\\t\\t\\t\\t\\tList\\tthe\\tmost\\tsenior\\templ\\tworking\\tunder\\tthe\\tking\\tand\\tgrade\\tis\\tmore\\t\\nthan\\t3.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\nempno\\tin\\n(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\tin\\t(4,5)))\\nand\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING');\\n2.71.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tsal\\tgiven\\tto\\tthe\\tMGR.\\nD)\\t\\t\\t\\tselect\\tsum\\t(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(OR)\\nB)\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp);\\n2.72.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tannual\\tsal\\tto\\tdistribute\\tjob\\twise\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\tjob,sum(12*sal)\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t=\\t'1981'\\ngroup\\tby\\tjob\\t;\\n2.73.\\t\\t\\t\\t\\tDisplay\\ttotal\\tsal\\temployee\\tbelonging\\tto\\tgrade\\t3.\\nE)\\t\\t\\t\\t\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\nin\\t\\t(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3)\\n2.74.\\t\\t\\t\\t\\tDisplay\\tthe\\taverage\\tsalaries\\tof\\tall\\tthe\\tclerks.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 17, 'page_label': '18', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\tavg(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n2.75.\\t\\t\\t\\t\\tList\\tthe\\temployeein\\tdept\\t20\\twhose\\tsal\\tis\\t>the\\taverage\\tsal\\t0f\\tdept\\t10\\nemps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=20\\tand\\tsal\\t>(select\\tavg\\t(sal)\\tfrom\\temp\\nwhere\\t\\tdeptno\\t=\\t10);\\n2.76.\\t\\t\\t\\t\\tDisplay\\tthe\\tnumber\\tof\\temployee\\t\\tfor\\teach\\tjob\\tgroup\\tdeptno\\twise.\\nF)\\t\\t\\t\\t\\tselect\\t\\tdeptno\\t,job\\t,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\t\\tdeptno,job;\\t(or)\\nB)\\tselect\\td.deptno,e.job,count(e.job)\\tfrom\\temp\\te,dept\\td\\twhere\\ne.deptno(+)=d.deptno\\tgroup\\tby\\te.job,d.deptno;\\n2.77.\\t\\t\\t\\t\\tList\\tthe\\tmanage\\trno\\tand\\tthe\\tnumber\\tof\\temployees\\tworking\\tfor\\tthose\\nmgrs\\tin\\tthe\\tascending\\tMgrno.\\nG)\\t\\t\\t\\tselect\\tw.mgr\\t,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\ngroup\\tby\\tw.mgr\\norder\\tby\\tw.mgr\\tasc;\\n2.78.\\t\\t\\t\\t\\tList\\tthe\\tdepartment,details\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tworking\\nH)\\t\\t\\t\\tselect\\tdeptno\\t,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tcount(*)\\t>=\\t2;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 18, 'page_label': '19', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.79.\\t\\t\\t\\t\\tDisplay\\tthe\\tGrade,\\tNumber\\tof\\temps,\\tand\\tmax\\tsal\\tof\\teach\\tgrade.\\nA)\\tselect\\ts.grade\\t,count(*),max(sal)\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\ngroup\\tby\\ts.grade;\\n2.80.\\t\\t\\t\\t\\tDisplay\\tdname,\\tgrade,\\tNo.\\tof\\temps\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tclerks.\\nA)\\tselect\\td.dname,s.grade,count(*)\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\twhere\\te.deptno\\n=\\td.deptno\\tand\\ne.job\\t=\\t'CLERK'\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tgroup\\tby\\td.dname,s.grade\\nhaving\\tcount(*)\\t>=\\t2;\\n2.81.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tdepartment\\twhere\\tmaximum\\tnumber\\tof\\temps\\tare\\nworking.\\nI)\\t\\t\\t\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\t(OR)\\nJ)\\t\\t\\t\\t\\t\\tselect\\td.deptno,d.dname,d.loc,count(*)\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 18, 'page_label': '19', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='where\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\\nK)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 19, 'page_label': '20', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\t(OR)\\nL)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\t=\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\n2.83.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twhose\\tsalary\\tis\\tmore\\tthan\\t3000\\tafter\\tgiving\\t20%\\nincrement.\\nM)\\t\\tSELECT\\t*\\tFROM\\tEMP\\tWHERE\\t(1.2*SAL)\\t>\\t3000\\t;\\n2.84.\\t\\t\\t\\t\\tList\\tthe\\temps\\twith\\tdept\\tnames.\\nA)\\tselect\\ne.empno,e.ename,e.job,e.mgr,e.hiredate,e.sal,e.comm,e.deptno,d.dname\\nfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno;\\n2.85.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tnot\\tworking\\tin\\tsales\\tdept.\\nN)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tin\\n(select\\tdeptno\\tfrom\\temp\\twhere\\tdname\\t=\\t‘SALES’);\\n2.86.\\t\\t\\t\\t\\tList\\tthe\\temps\\tname\\t,dept,\\tsal\\tand\\tcomm.\\tFor\\tthose\\twhose\\tsalary\\tis\\nbetween\\t2000\\tand\\t5000\\twhile\\tloc\\tis\\tChicago.\\nA)\\tselect\\te.ename,e.deptno,e.sal,e.comm\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\nd.deptno\\tand\\nd.loc\\t=\\t'CHICAGO'\\tand\\te.sal\\tbetween\\t2000\\tand\\t5000;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 20, 'page_label': '21', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"2.87.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tgreater\\tthan\\this\\tmanagers\\tsalary\\nA)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n2.88.\\t\\t\\t\\t\\tList\\tthe\\tgrade,\\tEMP\\tname\\tfor\\tthe\\tdeptno\\t10\\tor\\tdeptno\\t30\\tbut\\tsal\\tgrade\\tis\\nnot\\t4\\twhile\\tthey\\tjoined\\tthe\\tcompany\\tbefore\\t’31-dec-82’.\\nA)\\tselect\\ts.grade\\t,e.ename\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.deptno\\tin\\t(10,20)\\tand\\nhiredate\\t<\\t('31-DEC-82')\\tand\\t(e.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tnot\\tin\\n(4));\\n2.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\t,job,\\tdname,\\tlocation\\tfor\\tthose\\twho\\tare\\tworking\\tas\\tMGRS.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\ne.empno\\tin\\t(select\\tmgr\\tfrom\\temp\\t)\\t;\\n3.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tmgr\\tname\\tis\\tjones\\tand\\talso\\tlist\\ttheir\\tmanager\\tname.\\nA)\\tselect\\tw.empno,w.ename,w.job,w.mgr,w.hiredate,w.sal,w.deptno,m.ename\\nfrom\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 20, 'page_label': '21', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"from\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\\nA)\\tselect\\te.ename,e.sal\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.ename\\t=\\t'FORD'\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\te.sal\\t=\\ts.hisal\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 21, 'page_label': '22', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"5.\\t\\t\\t\\t\\t\\tLit\\tthe\\tname,\\tjob,\\tdname\\t,sal,\\tgrade\\tdept\\twise\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,e.sal,s.grade\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\norder\\tby\\te.deptno\\t;\\n6.\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\tname,\\tjob,\\tsal,\\tgrade\\tand\\tdname\\texcept\\tclerks\\tand\\tsort\\ton\\tthe\\nbasis\\tof\\thighest\\tsal.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,e.sal,s.grade,d.dname\\tfrom\\temp\\te\\t,dept\\td\\t,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.job\\tnot\\tin('CLERK')\\norder\\tby\\te.sal\\tdesc;\\n7.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tname,\\tjob\\t\\twho\\tare\\twith\\tout\\tmanager.\\nA)\\tselect\\te.ename,e.job\\tfrom\\temp\\te\\twhere\\tmgr\\tis\\tnull;\\n8.\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tthe\\temps\\twho\\tare\\tgetting\\tthe\\thighest\\tsal\\tdept\\twise.\\nA)\\t\\t\\t\\tselect\\te.ename,e.deptno\\tfrom\\temp\\te\\twhere\\te.sal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t;\\n9.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tequal\\tto\\tthe\\taverage\\tof\\tmax\\tand\\tminimum\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=(select\\t(max(sal)+min(sal))/2\\tfrom\\temp);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 22, 'page_label': '23', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='10.\\t\\tList\\tthe\\tno.\\tof\\temps\\tin\\teach\\tdepartment\\twhere\\tthe\\tno.\\tis\\tmore\\tthan\\t3.\\nA)\\tselect\\tdeptno,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\thaving\\tcount(*)\\t<\\t3;\\n11.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tdepts.\\tWhere\\tatleast\\t3\\tare\\tworking\\tin\\tthat\\tdepartment.\\nA)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\\nhaving\\tcount(*)\\t>=\\t3\\t\\t;\\n12.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twhose\\tsal\\tis\\tmore\\tthan\\this\\temployess\\tavg\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tm\\t\\twhere\\tm.empno\\tin\\t(select\\tmgr\\tfrom\\temp)\\nand\\tm.sal\\t>\\t(select\\tavg(e.sal)\\tfrom\\temp\\te\\twhere\\te.mgr\\t=\\tm.empno\\n)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\nThe\\tsubquery\\tdoes\\tthe\\tsame\\tas\\t\\t\\t(select\\t(avg(e.sal)),m.ename\\tfrom\\temp\\te,emp\\tm\\nwhere\\te.mgr=m.empno\\tgroup\\tby\\te.mgr,m.ename);\\n13.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname,salary,comm.\\tFor\\tthose\\temployees\\twhose\\tnet\\tpay\\tis\\ngreater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 22, 'page_label': '23', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='greater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\tename,sal,comm.\\tfrom\\temp\\twhere\\tsal+nvl(comm.,0)\\t>=\\tany\\t(select\\nsal\\tfrom\\temp);/\\n14.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\twhose\\tsal<his\\tmanager\\tbut\\tmore\\tthan\\tany\\tother\\tmanager.\\na)select\\t\\tdistinct\\tW.empno,W.ename,W.sal'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 23, 'page_label': '24', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='from\\t(select\\tw.empno,w.ename,w.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\t\\nw.mgr\\t=\\tm.empno\\tand\\tw.sal<m.sal)\\tW,\\n(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp))\\tA\\nwhere\\tW.sal\\t>\\tA.sal;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t<\\tm.sal\\nand\\tw.sal\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp));\\n15.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temployee\\tnames\\tand\\this\\taverage\\tsalary\\tdepartment\\twise.\\nA)\\nselect\\td.deptno,\\tround(avg(nvl2(e1.comm,\\te1.sal+e1.comm,\\te1.sal)))\\tavg,\\ne2.ename\\tfrom\\temp\\te1,\\temp\\te2,\\tdept\\td\\twhere\\td.deptno\\t=e1.deptno\\tand\\td.deptno\\n=\\te2.deptno\\tgroup\\tby\\td.deptno,\\te2.ename;\\t(or)\\nB)\\tselect\\td.maxsal,e.ename,e.deptno\\tas\\t\"current\\tsal\"\\tfrom\\temp\\te,\\n(select\\tavg(Sal)\\tmaxsal,deptno\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\td\\nwhere\\te.deptno=d.deptno;\\n16.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\tleast\\t5\\tearners\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t5>\\t(select\\tcount(*)\\tfrom\\temp\\twhere\\te.sal\\t>sal);\\n(or)\\nB)\\t\\t\\t\\tselect\\trownum\\trank,empno,ename,job,sal\\tfrom\\t(select\\t*\\tfrom\\temp\\torder\\tby\\nsal\\tasc)\\twhere\\trownum\\t<\\t6\\t;\\t(or)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 24, 'page_label': '25', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"C)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t\\twhere\\t5\\t>(select\\tcount(distinct\\tsal)\\tfrom\\temp\\twhere\\ne.sal\\t>\\tsal);\\n17.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\temps\\twhose\\tsalaries\\tgreater\\tthan\\tsalaries\\tof\\ttheir\\tmanagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal>\\tm.sal;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\nemp))\\ta\\nwhere\\te.sal\\t>a.sal\\tand\\te.mgr\\t=\\ta.empno\\n18.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twho\\tare\\tnot\\tworking\\tunder\\tthe\\tpresident.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp)\\tand\\tmgr\\tnot\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tjob\\t=\\t'PRESIDENT')\\n19.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\trecords\\tfrom\\temp\\twhose\\tdeptno\\tisnot\\tin\\tdept.\\n20.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tName\\t,\\tSalary,\\tComm\\tand\\tNet\\tPay\\tis\\tmore\\tthan\\tany\\tother\\nemployee.\\nA)\\t\\t\\t\\tSelect\\te.ename,e.sal,e.comm,nvl2(comm,sal+comm,sal)\\tNETPAY\\nfrom\\temp\\te\\t\\nwhere\\tnvl2(comm,sal+comm,sal)\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\n=e.empno)\\t;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 25, 'page_label': '26', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"21.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEnames\\twho\\tare\\tretiring\\tafter\\t31-Dec-89\\tthe\\tmax\\tJob\\tperiod\\tis\\n20Y.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\tadd_months(hiredate,240)\\t>\\t'31-DEC-89';\\nB)\\tselect\\tename\\tfrom\\temp\\nwhere\\tadd_months(hiredate,240)\\t>\\tto_date(’31-DEC-89’,’DD-MON-RR’);\\t\\n22.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthose\\tEmps\\twhose\\tSalary\\tis\\todd\\tvalue.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tmod(sal,2)\\t=\\t1;\\n23.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp’s\\twhose\\tSalary\\tcontain\\t3\\tdigits.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\twhere\\tlength\\t(sal)\\t=\\t3;\\n24.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tDEC.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=’DEC’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\tin\\t(‘DEC’);\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MONTH’)\\tlike\\t‘DEC%’;\\n25.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\tcontains\\t‘A’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%A%’;\\n26.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tDeptno\\tis\\tavailable\\tin\\this\\tSalary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(sal,deptno)\\t>\\t0;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 26, 'page_label': '27', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"27.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tfirst\\t2\\tchars\\tfrom\\tHiredate=last\\t2\\tcharacters\\tof\\nSalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsubstr(hiredate,1,2)\\t=\\tsubstr(sal,length(sal)-1,length(sal));\\n28.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\t10%\\tof\\tSalary\\tis\\tequal\\tto\\tyear\\tof\\tjoining.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YY')\\tin\\t(select\\t.1*sal\\tfrom\\temp);\\n29.\\t\\t\\t\\t\\t\\t\\t\\tList\\tfirst\\t50%\\tof\\tchars\\tof\\tEname\\tin\\tLower\\tCase\\tand\\tremaining\\tare\\tupper\\nCase.\\nA)\\t\\t\\t\\t\\t\\t\\t\\t\\nselect\\tlower(substr(ename,1,round(length(ename)/2)))\\n||substr(ename,round(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\t\\t(OR)\\nB)\\tselect\\tlower(substr(ename,1,ciel(length(ename)/2)))\\n||\\tsubstr(ename,ciel(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\n30.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname\\twhose\\tNo.\\tof\\tEmps\\tis\\t=to\\tnumber\\tof\\tchars\\tin\\tthe\\nDname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 27, 'page_label': '28', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\te\\nwhere\\te.deptno\\t=\\td.deptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\t\\ngroup\\tby\\td.dname\\thaving\\tcount(*)\\t=\\tlength\\t(d.dname);\\n31.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\tcompany\\tbefore\\t15th\\tof\\tthe\\tmonth.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,\\'DD\\')\\t<\\t\\'15\\';\\n32.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname,\\tno\\tof\\tchars\\tof\\twhich\\tis\\t=\\tno.\\tof\\temp’s\\tin\\tany\\tother\\nDept.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\t\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tlength(dname)\\t=\\tany\\t(select\\tcount(*)\\tfrom\\temp\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\t,\\t(select\\tcount(*)\\ts,e.deptno\\t\\t\"M\"from\\temp\\te\\tgroup\\tby\\ne.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 27, 'page_label': '28', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='e.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp\\t);\\n34.\\t\\t\\t\\t\\t\\t\\t\\tList\\tTHE\\tName\\tof\\tdept\\twhere\\thighest\\tno.of\\temps\\tare\\tworking.\\nA)\\tselect\\tdname\\tfrom\\tdept\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 28, 'page_label': '29', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tdeptno\\t\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\n35.\\t\\t\\t\\t\\t\\t\\t\\tCount\\tthe\\tNo.of\\temps\\twho\\tare\\tworking\\tas\\t‘Managers’(using\\tset\\toption).\\nA)select\\tcount(*)\\nfrom(select\\t*\\tfrom\\temp\\tminus\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t'MANAGER')\\n36.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\ton\\tthe\\tsame\\tdate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\tin\\n(select\\thiredate\\tfrom\\temp\\twhere\\te.empno\\t<>\\tempno);\\n37.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tGrade\\tis\\tequal\\tto\\tone\\ttenth\\tof\\tSales\\nDept.\\nA)\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t0.1*\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdname\\t=\\t'SALES');\\n38.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tof\\tthe\\tdept\\twhere\\tmore\\tthan\\taverage\\tno.\\tof\\temps\\tare\\nworking.\\nA)\\tselect\\td.dname\\tfrom\\tdept\\td,\\temp\\te\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 29, 'page_label': '30', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='having\\tcount(*)\\t>\\t(select\\tavg(count(*))\\tfrom\\temp\\t\\tgroup\\tby\\tdeptno);\\n39.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tManagers\\tname\\twho\\tis\\thaving\\tmax\\tno.of\\temps\\tworking\\tunder\\nhim.\\nA)select\\tm.ename,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\t\\ngroup\\tby\\tm.ename\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr);\\t\\t\\t\\t\\t\\n(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\t=\\t(select\\tmgr\\tfrom\\temp\\tgroup\\tby\\tmgr\\thaving\\ncount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr))\\t;\\n40.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEname\\tand\\tSal\\tis\\tincreased\\tby\\t15%\\tand\\texpressed\\tas\\tno.of\\nDollars.\\nA)\\tselect\\tename,to_char(1.15*sal,\\'$99,999\\')\\tas\\t\"SAL\"\\t\\tfrom\\temp;\\t(only\\tfor\\t$\\tit\\nworks)\\nB)\\tselect\\tename,\\'$\\'||1.15*sal\\t\\t“SAL”\\tfrom\\temp;\\n41.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\toutput\\tof\\tEMP\\ttable\\t‘EMP_AND_JOB’\\tfor\\tEname\\tand\\tJob.\\nA)\\tselect\\tename||\\tjob\\tas\\t\"EMP_AND_JOB\"\\tfrom\\temp\\t;\\n42.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\tfollowing\\toutput\\tfrom\\tEMP.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 30, 'page_label': '31', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='I.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEMPLOYEE\\nSMITH\\t(clerk)\\nALLEN\\t(Salesman)\\nA)\\t\\tselect\\tename\\t||\\t‘(‘||\\tlower(job)||’)’\\tas\\t“EMPLOYEE”\\tfrom\\temp;\\n130)\\t\\t\\tList\\tthe\\temps\\twith\\tHire\\tdate\\tin\\tformat\\tJune\\t4,\\t1988.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal,\\tto_char(hiredate,\\'MONTH\\tDD,YYYY\\')\\tfrom\\temp;\\n131)\\t\\t\\tPrint\\ta\\tlist\\tof\\temp’s\\tListing\\t‘just\\tsalary’\\tif\\tSalary\\tis\\tmore\\tthan\\t1500,\\ton\\ntarget\\tif\\tSalary\\tis\\t1500\\tand\\t‘Below\\t1500’\\tif\\tSalary\\tis\\tless\\tthan\\t1500.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal||\\t‘JUST\\tSALARY’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t>\\n1500\\tunion\\nselect\\tempno,ename,\\tsal||\\t‘ON\\tTARGET’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t=\\t1500\\t\\t\\t\\t\\t\\t\\t\\nunion\\nselect\\tempno,ename,\\tsal||\\t‘BELOW\\t1500’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t<\\t1500;\\t\\n(OR)\\nB)select\\tempno,ename,sal,job,\\ncase\\nwhen\\tsal\\t=\\t1500\\tthen\\t\\'ON\\tTARGET\\'\\nwhen\\tsal\\t<\\t1500\\tthen\\t\\'BELOW\\t1500\\'\\nwhen\\tsal\\t>\\t1500\\tthen\\t\\'JUST\\tSALARY\\'\\nelse\\t\\'nothing\\'\\nend\\t\\t\"REVISED\\tSALARY\"\\nfrom\\temp;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 31, 'page_label': '32', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"132)\\t\\t\\tWrite\\ta\\tquery\\twhich\\treturn\\tthe\\tday\\tof\\tthe\\tweek\\tfor\\tany\\tdate\\tentered\\tin\\nformat\\t‘DD-MM-YY’.\\nA)\\tselect\\tto_char(to_date('&\\ts','dd-mm-yy'),'day')\\tfrom\\tdual\\t;\\n133)\\t\\t\\tWrite\\ta\\tquery\\tto\\tcalculate\\tthe\\tlength\\tof\\tservice\\tof\\tany\\temployee\\twith\\tthe\\ncompany,\\tuse\\tDEFINE\\tto\\tavoid\\trepetitive\\ttyping\\tof\\tfunctions.\\nA)\\t\\t\\t\\tDEFINE\\t\\tservice\\t=\\t((months_between(sysdate,hiredate))/12)\\nB)\\t\\t\\t\\tSelect\\t\\tempno,ename,&service\\tfrom\\temp\\twhere\\tename\\t=\\t‘&\\tname’;\\n134)\\t\\t\\tGive\\ta\\tstring\\tof\\tformat\\t‘NN/NN’,\\tverify\\tthat\\tthe\\tfirst\\tand\\tlast\\ttwo\\ncharacters\\tare\\tnumbers\\tand\\tthat\\tthe\\tmiddle\\tcharacter\\tis’/’.\\tPrint\\tthe\\texpression\\n‘YES’\\tif\\tvalid,\\t‘NO’\\tif\\tnot\\tvalid.\\tUse\\tthe\\tfollowing\\tvalues\\tto\\ttest\\tyour\\tsolution.\\n‘12/34’,’01/1a’,\\t‘99/98’.\\nA)\\n135)\\t\\t\\tEmps\\thired\\ton\\tor\\tbefore\\t15th\\tof\\tany\\tmonth\\tare\\tpaid\\ton\\tthe\\tlast\\tFriday\\tof\\nthat\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 31, 'page_label': '32', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"that\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\\nA)\\tselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')-7\\tfrom\\temp\\nwhere\\tto_char(hiredate,'DD')\\t<=15\\nunion\\nselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')\\tfrom\\temp\\twhere\\nto_char(hiredate,'DD')\\t>\\t15;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 32, 'page_label': '33', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"136)\\t\\t\\tCount\\tthe\\tno.\\tof\\tcharacters\\twith\\tout\\tconsidering\\tspaces\\tfor\\teach\\tname.\\nA)\\t\\t\\t\\tselect\\tlength(replace(ename,’\\t‘,null))\\tfrom\\temp;\\n137)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tare\\tgetting\\tdecimal\\tvalue\\tin\\ttheir\\tSal\\twithout\\tusing\\nlike\\toperator.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tinstr(sal,’.’,1,1)\\t>\\t0;\\n138)\\t\\t\\tList\\tthose\\temps\\twhose\\tSalary\\tcontains\\tfirst\\tfour\\tdigit\\tof\\ttheir\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(sal,,9999),deptno,1,1)>0\\tand\\ninstr(to_char(sal,9999),deptno,1,2)>\\t0\\t;\\n139)\\t\\t\\tList\\tthose\\tManagers\\twho\\tare\\tgetting\\tless\\tthan\\this\\temps\\tSalary.\\nA)\\t\\t\\t\\tselect\\tdistinct\\tm.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\nand\\tw.sal>m.sal;\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tsal\\t\\t<\\tany\\t(\\tselect\\tsal\\tfrom\\temp\\twhere\\nw.empno=mgr);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tempno\\tin\\t\\t(\\tselect\\tmgr\\tfrom\\temp\\twhere\\t\\t\\t\\nw.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 32, 'page_label': '33', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"w.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\\n141)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers\\tusing\\tco-related\\tsub-query.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n142)\\t\\t\\tList\\tthe\\temps\\twhose\\tMgr\\tname\\tis\\t‘Jones’\\tand\\talso\\twith\\this\\tManager\\nname.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 33, 'page_label': '34', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\t\\t\\t\\tselect\\tw.ename,m.ename,(select\\tename\\tfrom\\temp\\twhere\\tm.mgr\\t=\\tempno)\\n\"his\\tMANAGER\"\\nfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t\\'JONES\\';\\t(or)\\nB)\\tselect\\te.ename,w.ename,m.ename\\tfrom\\temp\\te,emp\\tw,emp\\tm\\twhere\\te.mgr\\t=\\nw.empno\\tand\\tw.ename\\t=\\t‘JONES’\\tand\\tw.mgr\\t=\\tm.empno;\\n143)\\t\\t\\tDefine\\ta\\tvariable\\trepresenting\\tthe\\texpression\\tused\\tto\\tcalculate\\ton\\temps\\ntotal\\tannual\\tremuneration\\tuse\\tthe\\tvariable\\tin\\ta\\tstatement,\\twhich\\tfinds\\tall\\temps\\nwho\\tcan\\tearn\\t30000\\ta\\tyear\\tor\\tmore.\\nA)\\t\\t\\t\\tSet\\tdefine\\ton\\nB)\\t\\t\\t\\tDefine\\t\\tannual\\t=\\t12*nvl2(comm.,sal+comm.,sal)\\t\\t(here\\tdefine\\tvariable\\tis\\ta\\nsession\\tvariable)\\nC)\\t\\t\\t\\tSelect\\t*\\tfrom\\temp\\twhere\\t&annual\\t>\\t30000;\\n144)\\t\\t\\tFind\\tout\\thow\\tmay\\tManagers\\tare\\ttheir\\tin\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\t(or)\\nC)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 33, 'page_label': '34', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='C)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.\\nRemember\\tSalesman\\tearn\\tcommission.secommm\\nA)\\tselect\\tavg(sal),avg(sal+nvl(comm,0))\\tfrom\\temp;\\n146)\\t\\t\\tCheck\\twhether\\tall\\tthe\\temps\\tnumbers\\tare\\tindeed\\tunique.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 34, 'page_label': '35', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t\\t\\tempno,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\tempno;\\n147)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tdrawing\\tless\\tthan\\t1000\\tSort\\tthe\\toutput\\tby\\tSalary.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\t<\\t1000\\torder\\tby\\tsal;\\n148)\\t\\t\\tList\\tthe\\temployee\\tName,\\tJob,\\tAnnual\\tSalary,\\tdeptno,\\tDept\\tname\\tand\\ngrade\\twho\\tearn\\t36000\\ta\\tyear\\tor\\twho\\tare\\tnot\\tCLERKS.\\nA)selecte.ename,e.job,(12*e.sal)\"ANNUALSALARY\",\\ne.deptno,d.dname,s.grade\\nfrom\\temp\\te,dept\\td\\t,salgrade\\ts\\twhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\nand\\t(((12*e.sal)>=\\t36000)\\tor\\t(e.job\\t!=\\t\\'CLERK\\'))\\n149)\\t\\t\\tFind\\tout\\tthe\\tJob\\tthat\\twas\\tfilled\\tin\\tthe\\tfirst\\thalf\\tof\\t1983\\tand\\tsame\\tjob\\tthat\\nwas\\tfilled\\tduring\\tthe\\tsame\\tperiod\\tof\\t1984.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\twhere\\t(to_char(hiredate,\\'MM\\t\\')\\t<=\\t06\\t\\tand\\nto_char(hiredate,\\'YYYY\\')\\t=\\t1984)\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\nto_char(hiredate,\\'MM\\'\\t)\\t<=\\t06\\tand\\tto_char(hiredate,\\'YYYY\\')\\t<=\\t1983)\\t;\\t\\n150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 34, 'page_label': '35', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate<\\tm.hiredate;(or)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\t<\\t(select\\t\\thiredate\\tfrom\\temp\\twhere\\nempno\\t=\\te.mgr)\\n151)\\t\\t\\tList\\tall\\tthe\\temps\\tby\\tname\\tand\\tnumber\\talong\\twith\\ttheir\\tManager’s\\tname\\nand\\tnumber.\\tAlso\\tList\\tKING\\twho\\thas\\tno\\t‘Manager’.\\nA)\\tselect\\tw.empno,w.ename,m.empno,m.ename\\tfrom\\temp\\tw,emp\\tm\\twhere'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 35, 'page_label': '36', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='w.mgr=\\tm.empno(+);\\n152)\\t\\t\\tFind\\tall\\tthe\\temps\\twho\\tearn\\tthe\\tminimum\\tSalary\\tfor\\teach\\tjob\\twise\\tin\\nascending\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmin(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tasc;\\n153)\\t\\t\\tFind\\tout\\tall\\tthe\\temps\\twho\\tearn\\thighest\\tsalary\\tin\\teach\\tjob\\ttype.\\tSort\\tin\\ndescending\\tsalary\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tdesc;\\n154)\\t\\t\\tFind\\tout\\tthe\\tmost\\trecently\\thired\\temps\\tin\\teach\\tDept\\torder\\tby\\tHiredate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\te\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\te.deptno\\t=\\t\\tdeptno\\t)\\norder\\tby\\thiredate;\\n155)\\t\\t\\tList\\tthe\\temployee\\tname,Salary\\tand\\tDeptno\\tfor\\teach\\temployee\\twho\\tearns\\na\\tsalary\\tgreater\\tthan\\tthe\\taverage\\tfor\\ttheir\\tdepartment\\torder\\tby\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\tsal\\t>\\t\\t(select\\tavg(sal)\\tfrom\\temp\\twhere\\te.deptno\\t=\\tdeptno\\t);\\nB)\\t\\t\\t\\tselect\\te.ename,e.sal,e.deptno\\tfrom\\temp\\te,(select\\tavg(sal)\\tA,deptno\\tD\\tfrom\\t\\t\\nemp\\tgroup\\tby\\tdeptno)\\tD1\\twhere\\tD1.D\\t=\\te.deptno\\tand\\te.sal\\t>\\tD1.A;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 36, 'page_label': '37', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"156)\\t\\t\\tList\\tthe\\tDeptno\\twhere\\tthere\\tare\\tno\\temps.\\nA)\\t\\t\\t\\tselect\\t\\tdeptno\\t,count(*)\\tfrom\\temp\\ngroup\\tby\\tdeptno\\t\\nhaving\\tcount(*)\\t=\\t0;\\n157)\\t\\t\\tList\\tthe\\tNo.of\\temp’s\\tand\\tAvg\\tsalary\\twithin\\teach\\tdepartment\\tfor\\teach\\tjob.\\nA)\\t\\t\\t\\tselect\\tcount(*),avg(sal),deptno,job\\tfrom\\temp\\ngroup\\tby\\tdeptno,job;\\n158)\\t\\t\\tFind\\tthe\\tmaximum\\taverage\\tsalary\\tdrawn\\tfor\\teach\\tjob\\texcept\\tfor\\n‘President’.\\nA)\\tselect\\tmax(avg(sal))\\tfrom\\temp\\t\\twhere\\tjob\\t!=\\t'PRESIDENT'\\tgroup\\tby\\tjob;\\n159)\\t\\t\\tFind\\tthe\\tname\\tand\\tJob\\tof\\tthe\\temps\\twho\\tearn\\tMax\\tsalary\\tand\\tCommission.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=\\t(select\\tmax(sal)\\tfrom\\temp)\\tand\\tcomm.\\tis\\tnot\\nnull;\\n160)\\t\\t\\tList\\tthe\\tName,\\tJob\\tand\\tSalary\\tof\\tthe\\temps\\twho\\tare\\tnot\\tbelonging\\tto\\tthe\\ndepartment\\t10\\tbut\\twho\\thave\\tthe\\tsame\\tjob\\tand\\tSalary\\tas\\tthe\\temps\\tof\\tdept\\t10.\\nA)\\tselect\\tename,job,sal\\tfrom\\temp\\twhere\\tdeptno\\t!=\\t10\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=\\t10)\\nand\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10);\\n161)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\tSALESMAN\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 37, 'page_label': '38', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='who\\tare\\tearning\\tmaximum\\tsalary\\tand\\tcommission\\tin\\tdescending\\torder.\\nA)select\\t\\tdeptno,name,job,sal,sal+nvl(comm.,0)\\tfrom\\temp\\twhere\\tjob\\t=\\n‘SALESMAN’\\tand\\tsal\\tin\\t(select\\tmax(sal+nvl(comm.,0))\\tfrom\\temp\\twhere\\ncomm.\\tis\\tnot\\tnull)\\nOrder\\tby\\t(sal\\t+nvl(comm.,0))\\tdesc;\\n162)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\temps\\twho\\tearn\\nthe\\tsecond\\thighest\\tearnings\\t(sal\\t+\\tcomm.).\\nA)\\tselect\\tdeptno,ename,sal,job,sal+nvl(comm,0)\\tfrom\\temp\\te\\twhere\\t\\t2\\t=\\t(select\\ncount(distinct\\tsal+nvl(comm,0))\\tfrom\\temp\\twhere\\t(e.sal+nvl(comm.,0))\\n<(sal+nvl(comm.,0));\\n163)\\t\\t\\tList\\tthe\\tDeptno\\tand\\ttheir\\taverage\\tsalaries\\tfor\\tdept\\twith\\tthe\\taverage\\tsalary\\nless\\tthan\\tthe\\taverages\\tfor\\tall\\tdepartment\\nA)\\t\\t\\t\\tselect\\tdeptno,avg(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tavg(sal)\\t<(select\\tavg(Sal)\\tfrom\\temp);\\n164)\\t\\t\\tList\\tout\\tthe\\tNames\\tand\\tSalaries\\tof\\tthe\\temps\\talong\\twith\\ttheir\\tmanager\\nnames\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 37, 'page_label': '38', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='names\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n165)\\t\\t\\tList\\tout\\tthe\\tName,\\tJob,\\tSalary\\tof\\tthe\\temps\\tin\\tthe\\tdepartment\\twith\\tthe\\nhighest\\taverage\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 38, 'page_label': '39', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='(select\\tdeptno\\tfrom\\temp\\te\\t\\nhaving\\tavg(sal)\\t=(select\\tmax(avg(sal))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t\\t\\ngroup\\tby\\tdeptno);\\n166)\\t\\t\\tList\\tthe\\tempno,sal,comm.\\tOf\\temps.\\nA)\\tselect\\tempno,sal,comm.\\tfrom\\temp;\\n167)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tsal.\\nA)\\tselect\\t*\\tfrom\\temp\\torder\\tby\\tsal\\tasc;\\n168)\\t\\t\\tList\\tthe\\tdept\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tjob\\tand\\tthe\\tdesc\\torder\\tof\\tthe\\nemps\\tprint\\tempno,\\tename.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t\\torder\\tby\\te.job\\tasc,e.empno\\tdesc\\t;\\n169)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\tof\\tthe\\temps.\\nA)select\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\t(select\\tunique\\tdeptno\\tfrom\\temp);\\n170)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\twith\\tjobs.\\nA)\\tselect\\tunique\\tdeptno\\t,job\\tfrom\\temp\\t;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 39, 'page_label': '40', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='171)\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tthe\\tblake.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’;\\n172)\\t\\t\\tList\\tall\\tthe\\tclerks.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n173)\\t\\t\\tlist\\tall\\tthe\\temployees\\tjoined\\ton\\t1st\\tmay\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t=\\t’01-MAY-81’;\\n174)\\t\\t\\tList\\tthe\\tempno,ename,sal,deptno\\tof\\tthe\\tdept\\t10\\temps\\tin\\tthe\\tascending\\norder\\tof\\tsalary.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,e.deptno\\tfrom\\temp\\twhere\\te.deptno\\t=\\t10\\norder\\tby\\te.sal\\tasc;\\n175)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalaries\\tare\\tless\\tthan\\t3500.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t<3500;\\n176)\\t\\t\\tList\\tthe\\tempno,ename,sal\\tof\\tall\\tthe\\temp\\tjoined\\tbefore\\t1\\tapr\\t81.\\nA)\\tselect\\te.empno\\t,e.ename\\t.e.sal\\tfrom\\temp\\twhere\\thiredate\\t<’01-APR-81’;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 40, 'page_label': '41', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='177)\\t\\t\\tList\\tthe\\temp\\twhose\\tannual\\tsal\\tis\\t<25000\\tin\\tthe\\tasc\\torder\\tof\\tthe\\tsalaries.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*sal)\\t<\\t25000\\torder\\tby\\tsal\\tasc;\\n178)\\t\\t\\tList\\tthe\\tempno,ename,annsal,dailysal\\t\\tof\\tall\\tthe\\tsalesmen\\tin\\tthe\\tasc\\tann\\nsal\\nA)\\tselect\\te.empno,e.ename\\t,12*sal\\t\"ANN\\tSAL\"\\t,\\t(12*sal)/365\\t\"DAILY\\tSAL\"\\nfrom\\temp\\te\\nwhere\\te.job\\t=\\t\\'SALESMAN\\'\\norder\\tby\\t\"ANN\\tSAL\"\\tasc\\t;\\n179)\\t\\t\\tList\\tthe\\tempno,ename,hiredate,current\\tdate\\t&\\texp\\tin\\tthe\\tascending\\torder\\nof\\tthe\\texp.\\nA)\\t\\t\\t\\tselect\\tempno,ename,hiredate,(select\\tsysdate\\tfrom\\tdual),\\n((months_between(sysdate,hiredate))/12)\\tEXP\\nfrom\\temp\\norder\\tby\\tEXP\\tasc;\\n180)\\t\\t\\tList\\tthe\\temps\\twhose\\texp\\tis\\tmore\\tthan\\t10\\tyears.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t((months_between(sysdate,hiredate))/12)\\t>\\t10;\\n181)\\t\\t\\tList\\tthe\\tempno,ename,sal,TA30%,DA\\t40%,HRA\\n50%,GROSS,LIC,PF,net,deduction,net\\tallow\\tand\\tnet\\tsal\\tin\\tthe\\tascending\\torder\\nof\\tthe\\tnet\\tsalary.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 41, 'page_label': '42', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='182)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\n183)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\tclerks\\tor\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(‘CLERK’,’MANAGER’);\\n184)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\ton\\tthe\\tfollowing\\tdates\\t1\\tmay\\t81,17\\tnov\\n81,30\\tdec\\t81\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’DD-MON-YY’)\\t\\tin\\n(’01-MAY-81’,’17-NOV-81’,’30-DEC-81’);\\n185)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’;\\n186)\\t\\t\\tList\\tthe\\temps\\twhose\\tannual\\tsal\\tranging\\tfrom\\t23000\\tto\\t40000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*\\tsal)\\tbetween\\t23000\\tand\\t40000;\\n187)\\t\\t\\tList\\tthe\\temps\\tworking\\tunder\\tthe\\tmgrs\\t7369,7890,7654,7900.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 42, 'page_label': '43', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin\\t(\\t7369,7890,7654,7900);\\n188)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tsecond\\thalf\\tof\\t82.\\nA)select\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-JUL-82’\\tand\\t’31-DEC-82’;\\n189)\\t\\t\\tList\\tall\\tthe\\t4char\\temps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(ename)\\t=\\t4;\\n190)\\t\\t\\tList\\tthe\\temp\\tnames\\tstarting\\twith\\t‘M’\\twith\\t5\\tchars.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n191)\\t\\t\\tList\\tthe\\temps\\tend\\twith\\t‘H’\\tall\\ttogether\\t5\\tchars.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%H’\\tand\\tlength\\t(ename)\\t=\\t5;\\n192)\\t\\t\\tList\\tnames\\tstart\\twith\\t‘M’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’;\\n193)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tyear\\t81.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 43, 'page_label': '44', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='A)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t=\\t‘81’;\\n194)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tending\\twith\\t00.\\nA)\\t\\tselect\\t*\\tfrom\\twhere\\t\\tsal\\t\\tlike\\t\\t‘%00’;\\n195)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tJAN.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MM’)\\t=\\t1;\\n196)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tchar\\t‘a’.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MONTH’)\\tlike’%A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MONTH’),’A’)\\t>0;\\n197)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tsecond\\tchar\\t‘a’\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\tlike\\t‘_A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MON’),’A’)\\t=\\t2;\\n198)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalary\\tis\\t4\\tdigit\\tnumber.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(sal)\\t=\\t4;(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tsal\\tbetween\\t999\\tand\\t9999;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 44, 'page_label': '45', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='199)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\t80’s.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t\\tbetween\\t‘80’\\tand\\t’89’;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t>=\\t‘80’\\tand\\nto_char(hiredate,’YY’)\\t<\\t‘90’;\\n200)\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tclerks\\twho\\thave\\texp\\tmore\\tthan\\t8ys.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tand\\n(months_between(sysdate,hiredate)\\t/12)\\t>\\t8;\\n201)\\t\\t\\tList\\tthe\\tmgrs\\tof\\tdept\\t10\\tor\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’\\tand\\t(deptno\\t=\\t10\\tor\\tdeptno\\n=20);\\n202)\\t\\t\\tList\\tthe\\temps\\tjoined\\tin\\tjan\\twith\\tsalary\\tranging\\tfrom\\t1500\\tto\\t4000.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’\\tand\\tsal\\nbetween\\t1500\\tand\\t4000;\\n203)\\t\\t\\tList\\tthe\\tunique\\tjobs\\tof\\tdept\\t20\\tand\\t30\\tin\\tdesc\\torder.\\nA)\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(20,30)\\torder\\tby\\tjob\\tdesc;\\n204)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\texp\\tof\\tthose\\tworking\\tunder\\tthe\\tmgr\\twhose\\nnumber\\tis\\tstarting\\twith\\t7\\tbut\\tshould\\tnot\\thave\\ta\\t9\\tjoined\\tbefore\\t1983.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 45, 'page_label': '46', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t(mgr\\tlike\\t'7%'\\tand\\tmgr\\tnot\\tlike\\t'%9%')\\nand\\tto_char(hiredate,'YY')\\t<\\t'83';\\n205)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\teither\\tmgr\\tor\\tanalyst\\twith\\tthe\\tsalary\\nranging\\tfrom\\t2000\\tto\\t5000\\tand\\twith\\tout\\tcomm.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\t(job\\t\\tin\\t(‘MANAGER’\\t,’ANALYST’)\\t)\\tand\\tsal\\nbetween\\t\\t2000\\tand\\t5000\\tand\\tcomm\\tis\\tnull;\\n206)\\t\\t\\tList\\tthe\\tempno,ename,sal,job\\tof\\tthe\\temps\\twith\\t/ann\\tsal\\t<34000\\tbut\\nreceiving\\tsome\\tcomm.\\tWhich\\tshould\\tnot\\tbe>sal\\tand\\tdesg\\tshould\\tbe\\tsales\\tman\\nworking\\tfor\\tdept\\t30.\\nA)\\tselect\\tempno,ename,sal,job\\tfrom\\temp\\twhere\\n12*(sal+nvl(comm,0))\\t<\\t34000\\tand\\tcomm\\tis\\tnot\\tnull\\tand\\tcomm<sal\\tand\\tjob\\t=\\n'SALESMAN'\\tand\\tdeptno\\t=\\t30;\\t\\t\\n207)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tfor\\tdept\\t10\\tor\\t20\\twith\\tdesgs\\tas\\tclerk\\tor\\nanalyst\\twith\\ta\\tsal\\tis\\teither\\t3\\tor\\t4\\tdigits\\twith\\tan\\texp>8ys\\tbut\\tdoes\\tnot\\tbelong\\tto\\nmons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 45, 'page_label': '46', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"mons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\\n((months_between(sysdate,hiredate))/12)>\\t8\\tand\\nto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP','APR')\\tand\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 46, 'page_label': '47', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(mgr\\tnot\\tlike\\t'%88'\\tand\\tmgr\\tnot\\tlike\\t'%56');\\n208)\\t\\t\\tList\\tthe\\tempno,ename,sal,job,deptno&exp\\tof\\tall\\tthe\\temps\\tbelongs\\tto\\tdept\\n10\\tor\\t20\\twith\\tan\\texp\\t6\\tto\\t10\\ty\\tworking\\tunder\\tthe\\tsame\\tmgr\\twith\\tout\\tcomm.\\nWith\\ta\\tjob\\tnot\\tending\\tirrespective\\tof\\tthe\\tposition\\twith\\tcomm.>200\\twith\\nexp>=7y\\tand\\tsal<2500\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tsep\\tor\\tnov\\tworking\\tunder\\nthe\\tmgr\\twhose\\tno\\tis\\tnot\\thaving\\tdigits\\teither\\t9\\tor\\t0\\tin\\tthe\\tasc\\tdept&\\tdesc\\tdept\\nA)\\n209)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tworking\\tat\\tChicago.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\n‘CHICAGO’);\\n210)\\t\\t\\tList\\tthe\\tempno,ename,deptno,loc\\tof\\tall\\tthe\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t;\\n211)\\t\\t\\tList\\tthe\\tempno,ename,loc,dname\\tof\\tall\\tthe\\tdepts.,10\\tand\\t20.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc,d.dname\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 46, 'page_label': '47', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"where\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\\nwith\\tan\\texp>6ys.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\tand\\td.loc\\tin\\t('CHICAGO','DALLAS')\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 47, 'page_label': '48', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t(months_between(sysdate,hiredate)/12)>\\t6\\t;\\n213)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\tloc\\tof\\tthose\\twho\\tbelongs\\tto\\tdallas\\t,newyork\\twith\\nsal\\tranging\\tfrom\\t2000\\tto\\t5000\\tjoined\\tin\\t81.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.loc\\tin\\t('NEW\\tYORK','DALLAS')\\nand\\tto_char(e.hiredate,'YY')\\t=\\t'81'\\t\\tand\\t\\te.sal\\tbetween\\t2000\\tand\\t5000;\\n214)\\t\\t\\tList\\tthe\\tempno,ename,sal,grade\\tof\\tall\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,s.grade\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\nwhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\t;\\n215)\\t\\t\\tList\\tthe\\tgrade\\t2\\tand\\t3\\temp\\tof\\tChicago.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ns.hisal\\t\\tand\\ts.grade\\tin\\t(2,3));\\n216)\\t\\t\\tList\\tthe\\temps\\twith\\tloc\\tand\\tgrade\\tof\\taccounting\\tdept\\tor\\tthe\\tlocs\\tdallas\\tor\\nChicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 47, 'page_label': '48', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='Chicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\\nwheree.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\ts.grade\\tin\\t(3,5)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 48, 'page_label': '49', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"and\\t((months_between(sysdate,hiredate))/12)\\t>\\t6\\nand\\t(\\td.dname\\t=\\t'ACCOUNTING'\\tor\\tD.loc\\tin\\t('DALLAS','CHICAGO'))\\n217)\\t\\t\\tList\\tthe\\tgrades\\t3\\temps\\tof\\tresearch\\tand\\toperations\\tdepts..\\tjoined\\tafter\\t1987\\nand\\twhose\\tnames\\tshould\\tnot\\tbe\\teither\\tmiller\\tor\\tallen.\\nA)\\t\\t\\t\\tselect\\te.ename\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.dname\\tin\\t('OPERATIONS','RESEARCH')\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\te.ename\\tnot\\tin\\t('MILLER','ALLEN')\\nand\\tto_char(hiredate,'YYYY')\\t>1987;\\n218)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\tsmith.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n'SMITH');\\n219)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tmiller.\\nA)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\t\\twhere\\t\\thiredate\\t<(select\\thiredate\\tfrom\\temp\\twhere\\nename\\t=\\t‘MILLER’);\\n220)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\teither\\tallen\\tor\\tsal>allen.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN')\\nor\\tsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 49, 'page_label': '50', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"221)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tmanager.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate\\t<\\tm.hiredate;\\n222)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tgreater\\tthan\\tblakes\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’);\\n223)\\t\\t\\tList\\tthe\\tdept\\t10\\temps\\twhose\\tsal>allen\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\tand\\nsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\\n224)\\t\\t\\tList\\tthe\\tmgrs\\twho\\tare\\tsenior\\tto\\tking\\tand\\twho\\tare\\tjunior\\tto\\tsmith.\\nA)select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tmgr\\tfrom\\temp\\nwhere\\thiredate<(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'\\t)\\nand\\thiredate\\t>\\t(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t\\t'SMITH'))\\tand\\tmgr\\nis\\t\\t\\t\\t\\t\\t\\t\\nnot\\tnull;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 50, 'page_label': '51', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"225)\\t\\t\\tList\\tthe\\tempno,ename,loc,sal,dname,loc\\tof\\tthe\\tall\\tthe\\temps\\tbelonging\\tto\\nking\\tdept.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,d.loc,e.sal,d.dname\\tfrom\\temp\\te,dept\\td\\nwhere\\te.deptno=d.deptno\\tand\\te.deptno\\tin\\n(select\\tdeptno\\tfrom\\t\\temp\\twhere\\tename\\t=\\t'KING'and\\temp.empno\\t<>\\te.empno);\\n226)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalgrade\\tare\\tgreater\\tthan\\tthe\\tgrade\\tof\\tmiller.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t>\\n(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.ename\\t=\\t'MILLER')\\t;\\n227)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tbelonging\\tdallas\\tor\\tChicago\\twith\\tthe\\tgrade\\tsame\\tas\\nadamsor\\texp\\tmore\\tthan\\tsmith.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno=\\td.deptno\\tand\\td.loc\\tin\\t('DALLAS','CHICAGO')\\tand\\te.sal\\nbetween\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 50, 'page_label': '51', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"between\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\\nmonths_between(sysdate,hiredate)\\tfrom\\temp\\twhere\\tename\\t=\\t'SMITH'))\\t;\\n228)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tford\\tor\\tblake.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\te\\twhere\\te.ename\\tin\\n('FORD','BLAKE')and\\temp.empno\\t<>\\te.empno);\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 51, 'page_label': '52', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"229)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tany\\tone\\tof\\tthe\\tfollowing.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t\\tin\\t\\n(select\\tsal\\tfrom\\temp\\te\\twhere\\temp.empno\\t<>\\te.empno);\\n230)\\t\\t\\tSal\\tof\\tany\\tclerk\\tof\\temp1\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n231)\\t\\t\\tAny\\temp\\tof\\temp2\\tjoined\\tbefore\\t82.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t<\\t1982;\\n232)\\t\\t\\tThe\\ttotal\\tremuneration\\t(sal+comm.)\\tof\\tall\\tsales\\tperson\\tof\\tSales\\tdept\\nbelonging\\tto\\temp3\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\t(sal+nvl(comm,0))\\tin\\n(select\\tsal+nvl(comm,0)\\t\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno=d.deptno\\t\\nand\\td.dname\\t=\\t'SALES'and\\te.job\\t=\\t'SALESMAN');\\n233)\\t\\t\\tAny\\tGrade\\t4\\temps\\tSal\\tof\\temp\\t4\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp4\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t4;\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 52, 'page_label': '53', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content='234)\\t\\t\\tAny\\temp\\tSal\\tof\\temp5\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp5;\\n235)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp);\\n236)\\t\\t\\tList\\tthe\\tdetails\\tof\\tmost\\trecently\\thired\\temp\\tof\\tdept\\t30.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tdeptno\\t=\\t30);\\n237)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tof\\tChicago\\tjoined\\tbefore\\tthe\\tmost\\t\\trecently\\nhired\\temp\\tof\\tgrade\\t2.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal\\t=\\t(\\tselect\\tmax(sal)\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\t\\nd.deptno\\tand\\td.loc\\t=\\t‘CHICAGO’\\tand\\nhiredate\\t<(select\\tmax(hiredate)\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\t\\t\\t\\t\\t\\t\\t\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t2))\\n238)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tworking\\tunder\\tking.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\twhere\\tmgr\\tin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '', 'moddate': '2025-10-09T20:13:30+06:30', 'source': '..\\\\data\\\\pdf\\\\SQL Queries .pdf', 'total_pages': 54, 'page': 53, 'page_label': '54', 'source_file': 'SQL Queries .pdf', 'file_type': 'pdf'}, page_content=\"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a85dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock',\n",
       " 'C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii',\n",
       " 'C O N T E N T S\\n1 introduction 1\\n2 python and required packages 5\\n2.1 A note on Python & OpenCV Versions . . . . 6\\n2.2 NumPy and SciPy . . . . . . . . . . . . . . . . 7\\n2.2.1 Windows . . . . . . . . . . . . . . . . . 7\\n2.2.2 OSX . . . . . . . . . . . . . . . . . . . 7\\n2.2.3 Linux . . . . . . . . . . . . . . . . . . . 8\\n2.3 Matplotlib . . . . . . . . . . . . . . . . . . . . 8\\n2.3.1 All Platforms . . . . . . . . . . . . . . 8\\n2.4 OpenCV . . . . . . . . . . . . . . . . . . . . . . 9\\n2.4.1 Linux and OSX . . . . . . . . . . . . . 9\\n2.4.2 Windows . . . . . . . . . . . . . . . . . 10\\n2.5 Mahotas . . . . . . . . . . . . . . . . . . . . . . 10\\n2.5.1 All Platforms . . . . . . . . . . . . . . 10\\n2.6 scikit-learn . . . . . . . . . . . . . . . . . . . . 11\\n2.6.1 All Platforms . . . . . . . . . . . . . . 11\\n2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19',\n",
       " '2.7 scikit-image . . . . . . . . . . . . . . . . . . . . 11\\n2.8 Skip the Installation . . . . . . . . . . . . . . . 12\\n3 loading , displaying , and saving 14\\n4 image basics 19\\n4.1 So, What’s a Pixel? . . . . . . . . . . . . . . . 19\\n4.2 Overview of the Coordinate System . . . . . 22\\n4.3 Accessing and Manipulating Pixels . . . . . . 22\\n5 drawing 31\\n5.1 Lines and Rectangles . . . . . . . . . . . . . . 31\\n5.2 Circles . . . . . . . . . . . . . . . . . . . . . . 36\\n6 image processing 42\\n6.1 Image Transformations . . . . . . . . . . . . . 42\\niii',\n",
       " 'Contents\\n6.1.1 Translation . . . . . . . . . . . . . . . . 43\\n6.1.2 Rotation . . . . . . . . . . . . . . . . . 48\\n6.1.3 Resizing . . . . . . . . . . . . . . . . . 53\\n6.1.4 Flipping . . . . . . . . . . . . . . . . . 59\\n6.1.5 Cropping . . . . . . . . . . . . . . . . 62\\n6.2 Image Arithmetic . . . . . . . . . . . . . . . . 64\\n6.3 Bitwise Operations . . . . . . . . . . . . . . . 71\\n6.4 Masking . . . . . . . . . . . . . . . . . . . . . 74\\n6.5 Splitting and Merging Channels . . . . . . . . 81\\n6.6 Color Spaces . . . . . . . . . . . . . . . . . . . 85\\n7 histograms 89\\n7.1 Using OpenCV to Compute Histograms . . . 90\\n7.2 Grayscale Histograms . . . . . . . . . . . . . . 91\\n7.3 Color Histograms . . . . . . . . . . . . . . . . 93\\n7.4 Histogram Equalization . . . . . . . . . . . . . 99\\n7.5 Histograms and Masks . . . . . . . . . . . . . 101\\n8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112',\n",
       " '8 smoothing and blurring 108\\n8.1 Averaging . . . . . . . . . . . . . . . . . . . . . 110\\n8.2 Gaussian . . . . . . . . . . . . . . . . . . . . . 112\\n8.3 Median . . . . . . . . . . . . . . . . . . . . . . 113\\n8.4 Bilateral . . . . . . . . . . . . . . . . . . . . . . 116\\n9 thresholding 119\\n9.1 Simple Thresholding . . . . . . . . . . . . . . 119\\n9.2 Adaptive Thresholding . . . . . . . . . . . . . 123\\n9.3 Otsu and Riddler-Calvard . . . . . . . . . . . 127\\n10 gradients and edge detection 132\\n10.1 Laplacian and Sobel . . . . . . . . . . . . . . . 133\\n10.2 Canny Edge Detector . . . . . . . . . . . . . . 138\\n11 contours 142\\n11.1 Counting Coins . . . . . . . . . . . . . . . . . 142\\n11.2 Contours and OpenCV Version Caveats . . . 149\\n12 where to now ? 153\\niv',\n",
       " 'C O M PA N I O N W E B S I T E & S U P P L E M E N TA R Y\\nM AT E R I A L\\nThank you for picking up a copy of the 4th edition of\\nPractical Python and OpenCV!\\nIn this latest edition, I’m excited to announce the creation\\nof a companion website which includes supplementary mate-\\nrial that I could not ﬁt inside the book.\\nAt the end of nearly every chapter inside Practical Python\\nand OpenCV + Case Studies, you’ll ﬁnd a link to a supplemen-\\ntary webpage that includes additional information, such as\\nmy commentary on methods to extend your knowledge,\\ndiscussions of common error messages, recommendations\\non various algorithms to try, and optional quizzes to test\\nyour knowledge.\\nRegistration to the companion website is free with your\\npurchase of Practical Python and OpenCV.\\nTo create your companion website account, just use this\\nlink:\\nhttp://pyimg.co/o1y7e\\nTake a second to create your account now so you’ll have\\naccess to the supplementary materials as you work through\\nthe book.\\nv',\n",
       " 'P R E FA C E\\nWhen I ﬁrst set out to write this book, I wanted it to be\\nas hands-on as possible. I wanted lots of visual examples\\nwith lots of code. I wanted to write something that you\\ncould easily learn from, without all the rigor and detail of\\nmathematics associated with college level computer vision\\nand image processing courses.\\nI know from all my years spent in the classroom that the\\nway I learned best was from simply opening up an editor\\nand writing some code. Sure, the theory and examples in\\nmy textbooks gave me a solid starting point. But I never\\nreally “learned” something until I did it myself. I was very\\nhands-on. And that’s exactly how I wanted this book to be.\\nVery hands-on, with all the code easily modiﬁable and well\\ndocumented so you could play with it on your own. That’s\\nwhy I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst',\n",
       " 'why I’m giving you the full source code listings and images\\nused in this book.\\nMore importantly, I wanted this book to be accessible to\\na wide range of programmers. I remember when I ﬁrst\\nstarted learning computer vision – it was a daunting task.\\nBut I learned a lot. And I had a lot of fun.\\nI hope this book helps you in your journey into computer\\nvision. I had a blast writing it. If you have any questions,\\nsuggestions, or comments, or if you simply want to say\\nhello, shoot me an email at adrian@pyimagesearch.com, or\\nvi',\n",
       " 'Contents\\nyou can visit my website at www.PyImageSearch.com and\\nleave a comment. I look forward to hearing from you soon!\\n-Adrian Rosebrock\\nvii',\n",
       " 'P R E R E Q U I S I T E S\\nIn order to make the most of this, you will need to have\\na little bit of programming experience. All examples in this\\nbook are in the Python programming language. Familiarity\\nwith Python or other scripting languages is suggested, but\\nnot required.\\nYou’ll also need to know some basic mathematics. This\\nbook is hands-on and example driven: lots of examples and\\nlots of code, so even if your math skills are not up to par,\\ndo not worry! The examples are very detailed and heavily\\ndocumented to help you follow along.\\nviii',\n",
       " 'C O N V E N T I O N S U S E D I N T H I S B O O K\\nThis book includes many code listings and terms to aid\\nyou in your journey to learn computer vision and image\\nprocessing. Below are the typographical conventions used\\nin this book:\\nItalic\\nIndicates key terms and important information that\\nyou should take note of. May also denote mathemati-\\ncal equations or formulas based on connotation.\\nBold\\nImportant information that you should take note of.\\nConstant width\\nUsed for source code listings, as well as paragraphs\\nthat make reference to the source code, such as func-\\ntion and method names.\\nix',\n",
       " 'U S I N G T H E C O D E E X A M P L E S\\nThis book is meant to be a hands-on approach to com-\\nputer vision and machine learning. The code included in\\nthis book, along with the source code distributed with this\\nbook, are free for you to modify, explore, and share as you\\nwish.\\nIn general, you do not need to contact me for permis-\\nsion if you are using the source code in this book. Writing\\na script that uses chunks of code from this book is totally\\nand completely okay with me.\\nHowever, selling or distributing the code listings in this\\nbook, whether as information product or in your product’s\\ndocumentation, does require my permission.\\nIf you have any questions regarding the fair use of the\\ncode examples in this book, please feel free to shoot me an\\nemail. You can reach me at adrian@pyimagesearch.com.\\nx',\n",
       " 'H O W T O C O N TA C T M E\\nWant to ﬁnd me online? Look no further:\\nWebsite: www.PyImageSearch.com\\nEmail: adrian@pyimagesearch.com\\nTwitter: @PyImageSearch\\nGoogle+: +AdrianRosebrock\\nLinkedIn: Adrian Rosebrock\\nxi',\n",
       " '1\\nI N T R O D U C T I O N\\nThe goal of computer vision is to understand the story\\nunfolding in a picture. As humans, this is quite simple. But\\nfor computers, the task is extremely difﬁcult.\\nSo why bother learning computer vision?\\nWell, images are everywhere!\\nWhether it be personal photo albums on your smartphone,\\npublic photos on Facebook, or videos on YouTube, we now\\nhave more images than ever – and we need methods to an-\\nalyze, categorize, and quantify the contents of these images.\\nFor example, have you recently tagged a photo of your-\\nself or a friend on Facebook lately? How does Facebook\\nseem to “know” where the faces are in an image?\\nFacebook has implemented facial recognition algorithms\\ninto their website, meaning that they cannot only ﬁnd faces\\nin an image, they can also identify whose face it is as well!\\nFacial recognition is an application of computer vision in\\nthe real world.\\n1',\n",
       " 'introduction\\nWhat other types of useful applications of computer vi-\\nsion are there?\\nWell, we could build representations of our 3D world us-\\ning public image repositories like Flickr. We could down-\\nload thousands and thousands of pictures of Manhattan,\\ntaken by citizens with their smartphones and cameras, and\\nthen analyze them and organize them to construct a 3D rep-\\nresentation of the city. We would then virtually navigate\\nthis city through our computers. Sound cool?\\nAnother popular application of computer vision is surveil-\\nlance.\\nWhile surveillance tends to have a negative connotation\\nof sorts, there are many different types. One type of surveil-\\nlance is related to analyzing security videos, looking for\\npossible suspects after a robbery.\\nBut a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.',\n",
       " 'But a different type of surveillance can be seen in the re-\\ntail world. Department stores can use calibrated cameras to\\ntrack how you walk through their stores and which kiosks\\nyou stop at.\\nOn your last visit to your favorite clothing retailer, did\\nyou stop to examine the spring’s latest jeans trends? How\\nlong did you look at the jeans? What was your facial expres-\\nsion as you looked at the jeans? Did you then pick up a pair\\nand head to the dressing room? These are all types of ques-\\ntions that computer vision surveillance systems can answer.\\nComputer vision can also be applied to the medical ﬁeld.\\nA year ago, I consulted with the National Cancer Institute\\n2',\n",
       " 'introduction\\nto develop methods to automatically analyze breast histol-\\nogy images for cancer risk factors. Normally, a task like\\nthis would require a trained pathologist with years of expe-\\nrience – and it would be extremely time consuming!\\nOur research demonstrated that computer vision algo-\\nrithms could be applied to these images and could auto-\\nmatically analyze and quantify cellular structures – without\\nhuman intervention! Now, we can analyze breast histology\\nimages for cancer risk factors much faster.\\nOf course, computer vision can also be applied to other\\nareas of the medical ﬁeld. Analyzing X-rays, MRI scans,\\nand cellular structures all can be performed using computer\\nvision algorithms.\\nPerhaps the biggest success computer vision success story\\nyou may have heard of is the X-Box 360 Kinect. The Kinect\\ncan use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.',\n",
       " 'can use a stereo camera to understand the depth of an im-\\nage, allowing it to classify and recognize human poses, with\\nthe help of some machine learning, of course.\\nThe list doesn’t stop there.\\nComputer vision is now prevalent in many areas of your\\nlife, whether you realize it or not. We apply computer vi-\\nsion algorithms to analyze movies, football games, hand\\ngesture recognition (for sign language), license plates (just\\nin case you were driving too fast), medicine, surgery, mili-\\ntary, and retail.\\nWe even use computer visions in space! NASA’s Mars\\nRover includes capabilities to model the terrain of the planet,\\n3',\n",
       " 'introduction\\ndetect obstacles in its path, and stitch together panoramic\\nimages.\\nThis list will continue to grow in the coming years.\\nCertainly, computer vision is an exciting ﬁeld with end-\\nless possibilities.\\nWith this in mind, ask yourself: what does your imagina-\\ntion want to build? Let it run wild. And let the computer\\nvision techniques introduced in this book help you build it.\\nFurther Reading\\nWelcome to the supplementary material portion of the\\nchapter! If you haven’t already registered and created\\nyour account for the companion website, please do so\\nusing the following link:\\nhttp://pyimg.co/o1y7e\\nFrom there, you can ﬁnd the Chapter 1 supplemen-\\ntary material page here:\\nhttp://pyimg.co/rhsgi\\nThis page serves as an introduction to the companion\\nwebsite and details how to use it and what to expect\\nas you work through the rest of Practical Python and\\nOpenCV.\\n4',\n",
       " '2\\nP Y T H O N A N D R E Q U I R E D PA C K A G E S\\nIn order to explore the world of computer vision, we’ll\\nﬁrst need to install some packages and libraries. As a ﬁrst-\\ntimer in computer vision, installing some of these packages\\n(especially OpenCV) can be quite tedious, depending on\\nwhat operating system you are using. I’ve tried to consoli-\\ndate the installation instructions into a short how-to guide,\\nbut as you know, projects change, websites change, and in-\\nstallation instructions change! If you run into problems, be\\nsure to consult the package’s website for the most up-to-\\ndate installation instructions.\\nI highly recommend that you use either easy_install or\\npip to manage the installation of your packages. It will\\nmake your life much easier! You can read more about pip\\nhere: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image',\n",
       " 'here: http://pyimg.co/9quup.\\nFinally, if you don’t want to undertake installing these\\npackages by hand, I have put together an Ubuntu virtual\\nmachine with all the necessary computer vision and image\\nprocessing packages you need to run the examples in this\\nbook pre-installed! Using this virtual machine allows you\\nto jump right in to the examples in this book, without hav-\\ning to worry about package managers, installation instruc-\\n5',\n",
       " '2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1 a note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the',\n",
       " 'Inside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the\\nPython 2.7 and the Python 3+ environments!\\nIf you are looking for the OpenCV 2.4.X and Python 2.7\\nversion of this book, please look in the download directory\\nassociated with your purchase – inside you will ﬁnd the\\nOpenCV 2.4.X + Python 2.7 edition.\\n6',\n",
       " '2.2 numpy and scipy\\n2.2 numpy and scipy\\nNumPy is a library for the Python programming language\\nthat (among other things) provides support for large, multi-\\ndimensional arrays. Why is that important? Using NumPy,\\nwe can express images as multi-dimensional arrays. Repre-\\nsenting images as NumPy arrays is not only computation-\\nally and resource efﬁcient, many other image processing\\nand machine learning libraries use NumPy array represen-\\ntations as well. Furthermore, by using NumPy’s built-in\\nhigh-level mathematical functions, we can quickly and eas-\\nily perform numerical analysis on an image.\\nGoing hand-in-hand with NumPy, we also have SciPy.\\nSciPy adds further support for scientiﬁc and technical com-\\nputing.\\n2.2.1 Windows\\nBy far, the easiest way to install NumPy and SciPy on your\\nWindows system is to download and install the binary dis-\\ntribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.',\n",
       " 'tribution from: http://www.scipy.org/install.html.\\n2.2.2 OSX\\nIf you are running OSX 10.7.0 (Lion) or above, NumPy and\\nSciPy come pre-installed.\\nYou can also install NumPy and SciPy using pip:\\nListing 2.1: Install NumPy and SciPy on OSX\\n7',\n",
       " '2.3 matplotlib\\n$ pip install numpy\\n$ pip install scipy\\n2.2.3 Linux\\nOn many Linux distributions, such as Ubuntu, NumPy comes\\npre-installed and conﬁgured.\\nIf you want the latest versions of NumPy and SciPy, you\\ncan build the libraries from source, but the easiest method\\nis to use a pip:\\nListing 2.2: Install NumPy and SciPy on Linux\\n$ pip install numpy\\n$ pip install scipy\\n2.3 matplotlib\\nSimply put, matplotlib is a plotting library. If you’ve ever\\nused MATLAB before, you’ll probably feel very comfort-\\nable in the matplotlib environment. When analyzing im-\\nages, we’ll make use of matplotlib. Whether plotting image\\nhistograms or simply viewing the image itself, matplotlib\\nis a great tool to have in your toolbox.\\n2.3.1 All Platforms\\nMatplotlib is available from http://matplotlib.org/. The\\nmatplotlib package is also pip-installable:\\nListing 2.3: Install matplotlib\\n8',\n",
       " '2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4 opencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in',\n",
       " 'website at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in\\nprevious years, but has luckily gotten much easier. I have\\naccumulated OpenCV installation instructions on the PyIm-\\nageSearch blog for Debian-based Linux distributions (such\\nas Ubuntu) and OSX here:\\n9',\n",
       " '2.5 mahotas\\nhttp://pyimg.co/vvlpy\\nJust scroll down the “Install OpenCV 3 and Python” and\\n“Install OpenCV 4 and Python” sections, select the oper-\\nating system and Python version that you want to install\\nOpenCV for, and you’ll be on your way!\\n2.4.2 Windows\\nThe OpenCV Docs provide fantastic tutorials on how to in-\\nstall OpenCV in Windows using binary distributions. You\\ncan check out the installation instructions here:\\nhttp://pyimg.co/l2q6s\\n2.5 mahotas\\nMahotas, just like OpenCV , relies on NumPy arrays. Much\\nof the functionality implemented in Mahotas can be found\\nin OpenCV , but in some cases, the Mahotas interface is just\\neasier to use. We’ll use Mahotas to complement OpenCV .\\n2.5.1 All Platforms\\nInstalling Mahotas is extremely easy on all platforms. As-\\nsuming you already have NumPy and SciPy installed, all\\nyou need is a single call to the pip command:\\nListing 2.4: Install Mahotas\\n10',\n",
       " '2.6 scikit -learn\\n$ pip install mahotas\\n2.6 scikit -learn\\nAlright, you got me, scikit-learn isn’t an image processing\\nor computer vision library – it’s a machine learning library.\\nThat said, you can’t have advanced computer vision tech-\\nniques without some sort of machine learning, whether it\\nbe clustering, vector quantization, classiﬁcation models, etc.\\nScikit-learn also includes a handful of image feature extrac-\\ntion functions as well. We don’t use the scikit-learn library\\nin Practical Python and OpenCV, but it’s heavily used inCase\\nStudies.\\n2.6.1 All Platforms\\nInstalling scikit-learn on all platforms is dead-simple using\\npip:\\nListing 2.5: Install scikit-learn\\n$ pip install scikit-learn\\n2.7 scikit -image\\nThe algorithms included in scikit-image (I would argue) fol-\\nlow closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-',\n",
       " 'low closer to the state-of-the-art in computer vision. New\\nalgorithms right from academic papers can be found in\\nscikit-image, but in order to (effectively) use these algo-\\nrithms, you need to have developed some rigor and under-\\nstanding in the computer vision ﬁeld. If you already have\\nsome experience in computer vision and image processing,\\n11',\n",
       " '2.8 skip the installation\\ndeﬁnitely check out scikit-image; otherwise, I would con-\\ntinue working with OpenCV to start. Again, scikit-image\\nwon’t be used in of Practical Python and OpenCV, but it will\\nbe used in Case Studies, especially when we perform hand-\\nwritten digit recognition.\\nAssuming you already have NumPy and SciPy installed,\\nyou can install scikit-image using pip:\\nListing 2.6: Install scikit-image\\n$ pip install -U scikit-image\\nNow that we have all our packages installed, let’s start\\nexploring the world of computer vision!\\n2.8 skip the installation\\nAs I’ve mentioned above, installing all these packages can\\nbe time consuming and tedious. If you want to skip the\\ninstallation process and jump right into the world of im-\\nage processing and computer vision, I have set up a pre-\\nconﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine',\n",
       " 'conﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12',\n",
       " '2.8 skip the installation\\nFurther Reading\\nTo learn more about installing OpenCV , Python virtual\\nenvironments, and choosing a code editor, please see\\nthe Chapter 2 supplementary material webpage:\\nhttp://pyimg.co/f0sxq\\nIn particular, I think you’ll be interested in learning\\nhow the PyCharm IDE can be utilized with Python vir-\\ntual environments to create the perfect computer vision\\ndevelopment environment.\\n13',\n",
       " '3\\nL O A D I N G , D I S P L AY I N G , A N D S AV I N G\\nThis book is meant to be a hands-on, how-to guide to get-\\nting started with computer vision using Python and OpenCV .\\nWith that said, let’s not waste any time. We’ll get our feet\\nwet by writing some simple code to load an image off disk,\\ndisplay it on our screen, and write it to ﬁle in a different\\nformat. When executed, our Python script should show\\nour image on screen, like in Figure 3.1.\\nFirst, let’s create a ﬁle named load_display_save.py to\\ncontain our code. Now we can start writing some code:\\nListing 3.1: load_display_save.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\nThe ﬁrst thing we are going to do is import the packages\\nwe will need for this example.\\n14',\n",
       " 'loading , displaying , and saving\\nFigure 3.1: Example of loading and displaying\\na Tyrannosaurus Rex image on our\\nscreen.\\nThroughout this book you’ll see us importing the print_\\nfunction from the __future__ package. We’ll be using the\\nactual print() function rather than the print statement so\\nthat our code will work with both Python 2.7 and Python\\n3 – just something to keep in mind as we work through the\\nexamples!\\nWe’ll useargparse to handle parsing our command line\\narguments. Then, cv2 is imported – cv2 is our OpenCV li-\\nbrary and contains our image processing functions.\\nFrom there, Lines 5-8 handle parsing the command line\\narguments. The only argument we need is --image: the\\npath to our image on disk. Finally, we parse the arguments\\nand store them in a dictionary.\\n15',\n",
       " 'loading , displaying , and saving\\nListing 3.2: load_display_save.py\\n9 image = cv2.imread(args[\"image\"])\\n10 print(\"width: {} pixels\".format(image.shape[1]))\\n11 print(\"height: {} pixels\".format(image.shape[0]))\\n12 print(\"channels: {}\".format(image.shape[2]))\\n13\\n14 cv2.imshow(\"Image\", image)\\n15 cv2.waitKey(0)\\nNow that we have the path to the image, we can load it\\noff the disk using the cv2.imread function on Line 9. The\\ncv2.imread function returns a NumPy array representing\\nthe image.\\nLines 10-12 examine the dimensions of the image. Again,\\nsince images are represented as NumPy arrays, we can sim-\\nply use the shape attribute to examine the width, height,\\nand the number of channels.\\nFinally, Lines 14 and 15 handle displaying the actual\\nimage on our screen. The ﬁrst parameter is a string, the\\n“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until',\n",
       " '“name” of our window. The second parameter is a refer-\\nence to the image we loaded off disk on Line 9. Finally, a\\ncall to cv2.waitKey pauses the execution of the script until\\nwe press a key on our keyboard. Using a parameter of 0\\nindicates that any keypress will un-pause the execution.\\nThe last thing we are going to do is write our image to\\nﬁle in JPG format:\\nListing 3.3: load_display_save.py\\n16 cv2.imwrite(\"newimage.jpg\", image)\\nAll we are doing here is providing the path to the ﬁle\\n(the ﬁrst argument) and then the image we want to save\\n16',\n",
       " 'loading , displaying , and saving\\n(the second argument). It’s that simple.\\nTo run our script and display our image, we simply open\\nup a terminal window and execute the following command:\\nListing 3.4: load_display_save.py\\n$ python load_display_save.py --image ../images/trex.png\\nIf everything has worked correctly, you should see the T-\\nRex on your screen as in Figure 3.1. To stop the script from\\nexecuting, simply click on the image window and press any\\nkey.\\nExamining the output of the script, you should also see\\nsome basic information on our image. You’ll note that the\\nimage has a width of 350 pixels, a height of 228 pixels, and 3\\nchannels (the RGB components of the image). Represented\\nas a NumPy array, our image has a shape of (228,350,3).\\nThe NumPy shape may seem reversed to you (specifying\\nthe height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).',\n",
       " 'the height before the width), but in terms of a matrix deﬁni-\\ntion, it actually makes sense. When we deﬁne matrices, it is\\ncommon to write them in the form (# of rows × # of columns).\\nHere, our image has a height of 228 pixels (the number of\\nrows) and a width of 350 pixels (the number of columns) –\\nthus, the NumPy shape makes sense (although it may seen\\na bit confusing at ﬁrst).\\nFinally, note the contents of your directory. You’ll see a\\nnew ﬁle there: newimage.jpg. OpenCV has automatically\\nconverted our PNG image to JPG for us! No further effort\\nis needed on our part to convert between image formats.\\n17',\n",
       " 'loading , displaying , and saving\\nNext up, we’ll explore how to access and manipulate the\\npixel values in an image.\\nFurther Reading\\nYou can ﬁnd the Chapter 3 supplementary material, re-\\nsources, and quizzes here:\\nhttp://pyimg.co/xh73h\\nSpeciﬁcally, I discuss some common “gotchas” that may\\ntrip you up when utilizing OpenCV for the ﬁrst time –\\nthese tips and tricks are especially useful if this is your\\nﬁrst exposure to OpenCV .\\nBe sure to take the quiz to test your knowledge after\\nreading this chapter!\\n18',\n",
       " '4\\nI M A G E B A S I C S\\nIn this chapter we are going to review the building blocks\\nof an image – the pixel. We’ll discuss exactly what a pixel\\nis, how pixels are used to form an image, and then how to\\naccess and manipulate pixels in OpenCV .\\n4.1 so , what ’s a pixel?\\nEvery image consists of a set of pixels. Pixels are the raw\\nbuilding blocks of an image. There is no ﬁner granularity\\nthan the pixel.\\nNormally, we think of a pixel as the “color” or the “inten-\\nsity” of light that appears in a given place in our image.\\nIf we think of an image as a grid, each square in the grid\\ncontains a single pixel.\\nFor example, let’s pretend we have an image with a res-\\nolution of 500 × 300. This means that our image is repre-\\nsented as a grid of pixels, with 500 rows and 300 columns.\\nOverall, there are 500 × 300 = 150, 000 pixels in our image.\\n19',\n",
       " '4.1 so, what ’s a pixel?\\nMost pixels are represented in two ways: grayscale and\\ncolor. In a grayscale image, each pixel has a value between\\n0 and 255, where zero corresponds to “black” and 255 cor-\\nresponds to “white”. The values in between 0 and 255 are\\nvarying shades of gray, where values closer to 0 are darker\\nand values closer to 255 are lighter.\\nColor pixels are normally represented in the RGB color\\nspace – one value for the Red component, one for Green,\\nand one for Blue. Other color spaces exist, but let’s start\\nwith the basics and move our way up from there.\\nEach of the three colors is represented by an integer in\\nthe range 0 to 255, which indicates how “much” of the color\\nthere is. Given that the pixel value only needs to be in the\\nrange [0, 255], we normally use an 8-bit unsigned integer to\\nrepresent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.',\n",
       " 'represent each color intensity.\\nWe then combine these values into an RGB tuple in the\\nform (red, green, blue). This tuple represents our color.\\nTo construct a white color, we would ﬁll up each of the\\nred, green, and blue buckets completely, like this: (255,\\n255,255).\\nThen, to create a black color, we would empty each of the\\nbuckets out: (0,0,0).\\nTo create a pure red color, we would ﬁll up the red bucket\\n(and only the red bucket) up completely: (255,0,0).\\nAre you starting to see a pattern?\\n20',\n",
       " '4.1 so, what ’s a pixel?\\nFor your reference, here are some common colors repre-\\nsented as RGB tuples:\\n• Black: (0,0,0)\\n• White: (255,255,255)\\n• Red: (255,0,0)\\n• Green: (0,255,0)\\n• Blue: (0,0,255)\\n• Aqua: (0,255,255)\\n• Fuchsia: (255,0,255)\\n• Maroon: (128,0,0)\\n• Navy: (0,0,128)\\n• Olive: (128,128,0)\\n• Purple: (128,0,128)\\n• Teal: (0,128,128)\\n• Yellow: (255,255,0)\\nNow that we have a good understanding of pixels, let’s\\nhave a quick review of the coordinate system.\\n21',\n",
       " '4.2 overview of the coordinate system\\n4.2 overview of the coordinate system\\nAs I mentioned above, an image is represented as a grid of\\npixels. Imagine our grid as a piece of graph paper. Using\\nthis graph paper, the point (0, 0) corresponds to the upper\\nleft corner of the image. As we move down and to the right,\\nboth the x and y values increase.\\nLet’s take a look at the image in Figure 4.1 to make this\\npoint clearer.\\nHere we have the letter “I” on a piece of graph paper. We\\nsee that we have an 8 × 8 grid with a total of 64 pixels.\\nThe point (0, 0) corresponds to the top left pixel in our\\nimage, whereas the point (7, 7) corresponds to the bottom\\nright corner.\\nFinally, the point (3, 4) is the pixel three columns to the\\nright and four rows down, once again keeping in mind that\\nwe start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.',\n",
       " 'we start counting from zero rather than one.\\nThe Python language is zero indexed, meaning that we al-\\nways start counting from zero. Remember this and you’ll\\navoid a lot of confusion later on.\\n4.3 accessing and manipulating pixels\\nAdmittedly, the example from Chapter 3 wasn’t very excit-\\ning. All we did was load an image off disk, display it, and\\n22',\n",
       " '4.3 accessing and manipulating pixels\\nFigure 4.1: The letter “I” placed on a piece of\\ngraph paper. Pixels are accessed by\\ntheir (x, y) coordinates, where we go\\nx columns to the right and y rows\\ndown, keeping in mind that Python\\nis zero-indexed: we start counting\\nfrom zero rather than one.\\n23',\n",
       " '4.3 accessing and manipulating pixels\\nthen write it back to disk in a different image ﬁle format.\\nLet’s do something a little more exciting and see how we\\ncan access and manipulate the pixels in an image:\\nListing 4.1: getting_and_setting.py\\n1 from __future__ import print_function\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nSimilar to our example in the previous chapter, Lines 1-8\\nhandle importing the packages we need, along with setting\\nup our argument parser. There is only one command line\\nargument needed: the path to the image we are going to\\nwork with.\\nLines 10 and 11 handle loading the actual image off disk\\nand displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.',\n",
       " 'and displaying it to us.\\nSo now that we have the image loaded, how can we ac-\\ncess the actual pixel values?\\nRemember, OpenCV represents images as NumPy arrays.\\nConceptually, we can think of this representation as a ma-\\ntrix, as discussed in Section 4.1 above. In order to access a\\npixel value, we just need to supply the x and y coordinates\\nof the pixel we are interested in. From there, we are given\\na tuple representing the Red, Green, and Blue components\\n24',\n",
       " '4.3 accessing and manipulating pixels\\nof the image.\\nHowever, it’s important to note that OpenCV stores RGB\\nchannels in reverse order. While we normally think in terms\\nof Red, Green, and Blue, OpenCV actually stores them in\\nthe order of Blue, Green, and Red. This is important to\\nnote since it could cause some confusion later.\\nAlright, let’s explore some code that can be used to ac-\\ncess and manipulate pixels:\\nListing 4.2: getting_and_setting.py\\n12 (b, g, r) = image[0, 0]\\n13 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\n14\\n15 image[0, 0] = (0, 0, 255)\\n16 (b, g, r) = image[0, 0]\\n17 print(\"Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}\".format(r,\\ng, b))\\nOn Line 12, we grab the pixel located at (0, 0) – the top-\\nleft corner of the image. This pixel is represented as a tuple.\\nAgain, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out',\n",
       " 'Again, OpenCV stores RGB pixels in reverse order, so when\\nwe unpack and access each element in the tuple, we are ac-\\ntually viewing them in BGR order. Then, Line 13 prints out\\nthe values of each channel to our console.\\nAs you can see, accessing pixel values is quite easy! Num-\\nPy takes care of all the hard work for us. All we are doing\\nis providing indexes into the array.\\nJust as NumPy makes it easy to access pixel values, it also\\nmakes it easy to manipulate pixel values.\\n25',\n",
       " '4.3 accessing and manipulating pixels\\nOn Line 15 we manipulate the top-left pixel in the im-\\nage, which is located at coordinate (0, 0) and set it to have\\na value of (0, 0, 255). If we were reading this pixel value\\nin RGB format, we would have a value of 0 for red, 0 for\\ngreen, and 255 for blue, thus making it a pure blue color.\\nHowever, as I mentioned above, we need to take special\\ncare when working with OpenCV . Our pixels are actually\\nstored in BGR format, not RGB format.\\nWe actually read this pixel as255 for red, 0 for green, and\\n0 for blue, making it a red color, not a blue color.\\nAfter setting the top-left pixel to have a red color on Line\\n15, we then grab the pixel value and print it back to con-\\nsole on Lines 16 and 17, just to demonstrate that we have\\nindeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-',\n",
       " 'indeed successfully changed the color of the pixel.\\nAccessing and setting a single pixel value is simple enough,\\nbut what if we wanted to use NumPy’s array slicing capa-\\nbilities to access larger rectangular portions of the image?\\nThe code below demonstrates how we can do this:\\nListing 4.3: getting_and_setting.py\\n18 corner = image[0:100, 0:100]\\n19 cv2.imshow(\"Corner\", corner)\\n20\\n21 image[0:100, 0:100] = (0, 255, 0)\\n22\\n23 cv2.imshow(\"Updated\", image)\\n24 cv2.waitKey(0)\\nOn Line 18 we grab a 100 × 100 pixel region of the image.\\nIn fact, this is the top-left corner of the image! In order to\\ngrab chunks of an image, NumPy expects we provide four\\n26',\n",
       " '4.3 accessing and manipulating pixels\\nindexes:\\n1. Start y: The ﬁrst value is the starting y coordinate.\\nThis is where our array slice will start along the y-axis.\\nIn our example above, our slice starts at y = 0.\\n2. End y:Just as we supplied a starting y value, we must\\nprovide an ending y value. Our slice stops along the\\ny-axis when y = 100.\\n3. Start x:The third value we must supply is the starting\\nx coordinate for the slice. In order to grab the top-left\\nregion of the image, we start at x = 0.\\n4. End x:Finally, we need to provide an x-axis value for\\nour slice to stop. We stop when x = 100.\\nOnce we have extracted the top-left corner of the image,\\nLine 19 shows us the result of the cropping. Notice how\\nour image is just the 100 × 100 pixel region from the top-\\nleft corner of our original image.\\nThe last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the',\n",
       " 'The last thing we are going to do is use array slices to\\nchange the color of a region of pixels. On Line 21, you can\\nsee that we are again accessing the top-left corner of the\\nimage; however, this time we are setting this region to have\\na value of (0, 255, 0) (green).\\nLines 23 and 24 then show us the results of our work.\\nSo how do we run our Python script?\\nAssuming you have downloaded the source code listings\\nfor this book, simply navigate to the chapter-04 directory\\n27',\n",
       " '4.3 accessing and manipulating pixels\\nand execute the command below:\\nListing 4.4: getting_and_setting.py\\n$ python getting_and_setting.py --image ../images/trex.png\\nOnce our script starts running, you should see some out-\\nput printed to your console ( Line 13). The ﬁrst line of out-\\nput tells us that the pixel located at (0, 0) has a value of\\n254 for all three red, green, and blue channels. This pixel\\nappears to be almost pure white.\\nThe second line of output shows us that we have success-\\nfully changed the pixel located at (0, 0) to be red rather than\\nwhite (Lines 15-17).\\nListing 4.5: getting_and_setting.py\\nPixel at (0, 0) - Red: 254, Green: 254, Blue: 254\\nPixel at (0, 0) - Red: 255, Green: 0, Blue: 0\\nWe can see the results of our work in Figure 4.2. The Top-\\nLeft image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if',\n",
       " 'Left image is our original image we loaded off disk. The\\nimage on the Top-Right is the result of our array slicing and\\ncropping out a 100 × 100 pixel region of the image. And, if\\nyou look closely, you can see that the top-left pixel located\\nat (0, 0) is red!\\nFinally, the bottom image shows that we have successfully\\ndrawn a green square on our image.\\nIn this chapter, we have explored how to access and ma-\\nnipulate the pixels in an image using NumPy’s built-in ar-\\nray slicing functionality. We were even able to draw a green\\n28',\n",
       " '4.3 accessing and manipulating pixels\\nFigure 4.2: Top-Left: Our original image. Top-\\nRight: Cropping our image using\\nNumPy array slicing. Bottom: Draw-\\ning a 100 ×100 pixel green square on\\nour image by using basic NumPy in-\\ndexing.\\n29',\n",
       " '4.3 accessing and manipulating pixels\\nsquare using nothing but NumPy array manipulation!\\nHowever, we won’t get very far using only NumPy func-\\ntions. The next chapter will show you how to draw lines,\\nrectangles, and circles using OpenCV methods.\\nFurther Reading\\nOne of the most common errors I see with developers\\njust starting to learn OpenCV is the (x, y) -coordinate\\nordering passed into images. I also tend to see a lot of\\nconfusion regarding the BGR versus RGB channel or-\\ndering.\\nTo learn more about these common errors (and how\\nyou can avoid) then, be sure to refer to the Chapter 4\\nsupplementary material:\\nhttp://pyimg.co/mtemn\\nI’ve also included a quiz that you can use to test your\\nknowledge on image basics.\\n30',\n",
       " '5\\nD R AW I N G\\nUsing NumPy array slices in Chapter 4, we were able to\\ndraw a green square on our image. But what if we wanted\\nto draw a single line? Or a circle? NumPy does not provide\\nthat type of functionality – it’s only a numerical processing\\nlibrary after all!\\nLuckily, OpenCV provides convenient, easy-to-use meth-\\nods to draw shapes on an image. In this chapter, we’ll re-\\nview the three most basic methods to draw shapes: cv2.\\nline, cv2.rectangle, and cv2.circle.\\nWhile this chapter is by no means a complete, exhaus-\\ntive overview of the drawing capabilities of OpenCV , it will\\nnonetheless provide a quick, hands-on approach to get you\\nstarted drawing immediately.\\n5.1 lines and rectangles\\nBefore we start exploring the the drawing capabilities of\\nOpenCV , let’s ﬁrst deﬁne our canvas in which we will draw\\nour masterpieces.\\n31',\n",
       " '5.1 lines and rectangles\\nUp until this point, we have only loaded images off disk.\\nHowever, we can also deﬁne our images manually using\\nNumPy arrays. Given that OpenCV interprets an image as\\na NumPy array, there is no reason why we can’t manually\\ndeﬁne the image ourselves!\\nIn order to initialize our image, let’s examine the code\\nbelow:\\nListing 5.1: drawing.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\nLines 1 and 2 imports the packages we will be using.\\nAs a shortcut, we’ll create an alias for numpy as np. We’ll\\ncontinue this convention throughout the rest of the book.\\nIn fact, you’ll commonly see this convention in the Python\\ncommunity as well! We’ll also import cv2, so we can have\\naccess to the OpenCV library.\\nInitializing our image is handled on Line 4. We construct\\na NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,',\n",
       " 'a NumPy array using the np.zeros method with 300 rows\\nand 300 columns, yielding a 300 × 300 pixel image. We also\\nallocate space for 3 channels – one for Red, Green, and Blue,\\nrespectively. As the name suggests, the zeros method ﬁlls\\nevery element in the array with an initial value of zero.\\nIt’s important to draw your attention to the second argu-\\nment of the np.zeros method: the data type, dtype. Since\\nwe are representing our image as an RGB image with pixels\\nin the range [0, 255], it’s important that we use an 8-bit un-\\nsigned integer, or uint8. There are many other data types\\n32',\n",
       " '5.1 lines and rectangles\\nthat we can use (common ones include 32-bit integers, and\\n32-bit or 64-bit ﬂoats), but we’ll mainly be using uint8 for\\nthe majority of the examples in this book.\\nNow that we have our canvas initialized, we can do some\\ndrawing:\\nListing 5.2: drawing.py\\n5 green = (0, 255, 0)\\n6 cv2.line(canvas, (0, 0), (300, 300), green)\\n7 cv2.imshow(\"Canvas\", canvas)\\n8 cv2.waitKey(0)\\n9\\n10 red = (0, 0, 255)\\n11 cv2.line(canvas, (300, 0), (0, 300), red, 3)\\n12 cv2.imshow(\"Canvas\", canvas)\\n13 cv2.waitKey(0)\\nThe ﬁrst thing we do on Line 5 is deﬁne a tuple used to\\nrepresent the color “green”. Then, we draw a green line\\nfrom point (0, 0) (the top-left corner of the image) to point\\n(300, 300), the bottom-right corner of the image on Line 6.\\nIn order to draw the line, we make use of the cv2.line\\nmethod. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose',\n",
       " 'method. The ﬁrst argument to this method is the image we\\nare going to draw on. In this case, it’s our canvas. The sec-\\nond argument is the starting point of the line. We choose\\nto start our line from the top-left corner of the image, at\\npoint (0, 0). We also need to supply an ending point for the\\nline (the third argument). We deﬁne our ending point to be\\n(300, 300), the bottom-right corner of the image. The last ar-\\ngument is the color of our line, which, in this case, is green.\\nLines 7 and 8 show our image and then wait for a keypress.\\n33',\n",
       " '5.1 lines and rectangles\\nFigure 5.1: Examples of drawing lines and rect-\\nangles using OpenCV .\\nAs you can see, drawing a line is quite simple! But\\nthere is one other important argument to consider in the\\ncv2.line method: the thickness.\\nOn Lines 10-13 we deﬁne a red color as a tuple (again,\\nin BGR rather than RGB format). We then draw a red line\\nfrom the top-right corner of the image to the bottom left.\\nThe last parameter to the method controls the thickness of\\nthe line – we decide to make the thickness 3 pixels. Again,\\nwe show our image and wait for a keypress.\\nDrawing a line was simple enough. Now we can move on\\nto drawing rectangles. Check out the code below for more\\ndetails:\\nListing 5.3: drawing.py\\n14 cv2.rectangle(canvas, (10, 10), (60, 60), green)\\n15 cv2.imshow(\"Canvas\", canvas)\\n34',\n",
       " '5.1 lines and rectangles\\n16 cv2.waitKey(0)\\n17\\n18 cv2.rectangle(canvas, (50, 200), (200, 225), red, 5)\\n19 cv2.imshow(\"Canvas\", canvas)\\n20 cv2.waitKey(0)\\n21\\n22 blue = (255, 0, 0)\\n23 cv2.rectangle(canvas, (200, 50), (225, 125), blue, -1)\\n24 cv2.imshow(\"Canvas\", canvas)\\n25 cv2.waitKey(0)\\nOn Line 14 we make use of the cv2.rectangle method.\\nThe signature of this method is identical to the cv2.line\\nmethod above, but let’s explore each argument anyway.\\nThe ﬁrst argument is the image we want to draw our rect-\\nangle on. We want to draw on ourcanvas, so we pass it into\\nthe method. The second argument is the starting (x, y) po-\\nsition of our rectangle – here, we are starting our rectangle\\nat point (10, 10). Then, we must provide an ending (x, y)\\npoint for the rectangle. We decide to end our rectangle at\\n(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also',\n",
       " '(60, 60), deﬁning a region of 50 × 50 pixels. Finally, the last\\nargument is the color of the rectangle we want to draw.\\nJust as we can control the thickness of a line, we can also\\ncontrol the thickness of a rectangle. Line 18 provides one\\nadded argument: the thickness. Here, we draw a red rect-\\nangle that is 5 pixels thick, starting from point (50, 200) and\\nending at (200, 225).\\nAt this point, we have only drawn the outline of a rect-\\nangle. How do we draw a rectangle that is “ﬁlled in”, like\\nwhen using NumPy array slices in Chapter 4?\\n35',\n",
       " '5.2 circles\\nFigure 5.2: Drawing a simple bullseye with the\\ncv2.circle function.\\nSimple. We just pass in a negative value for the thickness\\nargument.\\nLine 23 demonstrates how to draw a rectangle of a solid\\ncolor. We draw a blue rectangle, starting from (200, 50) and\\nending at (225, 125). By specifying -1 as the thickness, our\\nrectangle is drawn as a solid blue.\\nCongratulations! You now have a solid grasp of drawing\\nrectangles. In the next section, we’ll move on to drawing\\ncircles.\\n5.2 circles\\nDrawing circles is just as simple as drawing rectangles, but\\nthe function arguments are a little different. Let’s go ahead\\nand get started:\\n36',\n",
       " '5.2 circles\\nListing 5.4: drawing.py\\n26 canvas = np.zeros((300, 300, 3), dtype = \"uint8\")\\n27 (centerX, centerY) = (canvas.shape[1] // 2, canvas.shape[0] // 2)\\n28 white = (255, 255, 255)\\n29\\n30 for r in range(0, 175, 25):\\n31 cv2.circle(canvas, (centerX, centerY), r, white)\\n32\\n33 cv2.imshow(\"Canvas\", canvas)\\n34 cv2.waitKey(0)\\nOn Line 26 we re-initialize our canvas to be blank. The\\nrectangles are gone! We need a fresh canvas to draw our\\ncircles.\\nLine 27 calculates two variables: centerX and centerY.\\nThese two variables represent the (x, y) coordinates of the\\ncenter of the image. We calculate the center by examining\\nthe shape of our NumPy array, and then dividing by two.\\nThe height of the image can be found in canvas.shape[0]\\nand the width in canvas.shape[1]. Finally, Line 28 deﬁnes\\na white pixel.\\nNow, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.',\n",
       " 'Now, let’s draw some circles!\\nOn Line 30 we loop over a number of radius values, start-\\ning from 0 and ending at 150 (since the range function is\\nexclusive), incrementing by 25 at each step.\\nLine 31 handles the actual drawing of the circle. The ﬁrst\\nparameter is our canvas, the image we want to draw the\\ncircle on. We then need to supply the point in which our\\ncircle will be drawn around. We pass in a tuple of(centerX,\\ncenterY) so that our circles will be centered at the middle\\nof the image. The third argument is the radius of the circle\\nwe wish to draw. Finally, we pass in the color of our circle,\\n37',\n",
       " '5.2 circles\\nin this case, white.\\nLines 33 and 34 then show our image and wait for a key-\\npress.\\nSo what does our image look like?\\nCheck out Figure 5.2 and you will see that we have drawn\\na simple bullseye! The “dot” in the very center of the image\\nis drawn with a radius of 0. The larger circles are drawn\\nwith every increasing radii sizes from our for loop.\\nNot too bad. But what else can we do?\\nLet’s do some abstract drawing:\\nListing 5.5: drawing.py\\n35 for i in range(0, 25):\\n36 radius = np.random.randint(5, high = 200)\\n37 color = np.random.randint(0, high = 256, size = (3,)).tolist\\n()\\n38 pt = np.random.randint(0, high = 300, size = (2,))\\n39\\n40 cv2.circle(canvas, tuple(pt), radius, color, -1)\\n41\\n42 cv2.imshow(\"Canvas\", canvas)\\n43 cv2.waitKey(0)\\nOur code starts off on Line 35 with more looping. This\\ntime we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.',\n",
       " 'time we aren’t looping over the size of our radii – we are\\ninstead going to draw 25 random circles, making use of\\nNumPy’s random number capabilities through thenp.random.\\nrandint function.\\nIn order to draw a random circle, we need to generate\\nthree values: the radius of the circle, the color of the circle,\\n38',\n",
       " '5.2 circles\\nFigure 5.3: The results of our masterpiece. No-\\ntice that each circle is randomly\\nplaced on the canvas with a random\\ncolor.\\nand the pt – the (x, y) coordinate of where the circle will be\\ndrawn.\\nWe generate a radius value in the range [5, 200) on Line\\n36. This value controls how large our circle will be.\\nNext, we randomly generate a color on Line 37. As we\\nknow, the color of an RGB pixel consists of three values in\\nthe range [0, 255]. In order to get three random integers\\nrather than only one integer, we pass the keyword argu-\\nment size=(3,), instructing NumPy to return a list of three\\nnumbers.\\n39',\n",
       " '5.2 circles\\nFinally, we need an (x, y) point to draw our circle. We’ll\\ngenerate a point in the range [0, 300), again using NumPy’s\\nnp.random.randint function.\\nThe drawing of our circle then takes place on Line 40,\\nusing the radius, color, and pt that we randomly gener-\\nated. Notice how we use a thickness of -1, so our circles\\nare drawn as a solid color and not just an outline.\\nOur masterpiece is then shown to us on Lines 42 and 43.\\nYou can check out our work in Figure 5.3. Notice how\\neach circle has a different size, color, and placement on our\\ncanvas.\\nIn this chapter, you were introduced to basic drawing\\nfunctions using OpenCV . We explored how to draw shapes\\nusing the cv2.line, cv2.rectangle, and cv2.circle meth-\\nods.\\nWhile these functions seem extremely basic and simple,\\nmake sure you understand them! They are essential build-\\ning blocks that will come in handy later in this book.\\n40',\n",
       " '5.2 circles\\nFurther Reading\\nWhy are we bothering learning how to draw rectangles,\\ncircles, and lines in a book on computer vision and im-\\nage processing?\\nIsn’t the point of computer vision to write software that\\nunderstands the contents of an image? And if so, why\\nin the world do we need to know how to draw various\\nshapes on images?\\nThese are excellent questions – and I address each of\\nthem (and provide examples of how drawing methods\\nare used in object detection and extraction) in side the\\nChapter 5 supplementary material:\\nhttp://pyimg.co/rlpak\\n41',\n",
       " '6\\nI M A G E P R O C E S S I N G\\nNow that you have a solid foundation to build upon, we\\ncan start to exploring simple image processing techniques.\\nFirst, we’ll start off with basic image transformations,\\nsuch as translation, rotation, resizing, ﬂipping, and crop-\\nping. Then, we’ll explore other types of image processing\\ntechniques, including image arithmetic, bitwise operations,\\nand masking.\\nFinally, we’ll explore how to split an image into its re-\\nspective channels and then merge them back together again.\\nWe’ll conclude this chapter with a discussion of different\\ncolor spaces that OpenCV supports and the beneﬁts and\\nlimitations of each of them.\\n6.1 image transformations\\nIn this section, we’ll cover basic image transformations. These\\nare common techniques that you’ll likely apply to images,\\nincluding translation, rotation, resizing, ﬂipping, and crop-\\nping. We’ll explore each of these techniques in detail.\\n42',\n",
       " '6.1 image transformations\\nMake sure you have a good grasp of these methods! They\\nare important in nearly all areas of computer vision.\\n6.1.1 Translation\\nThe ﬁrst method we are going to explore is translation.\\nTranslation is the shifting of an image along the x and y\\naxis. Using translation, we can shift an image up, down,\\nleft, or right, along with any combination of the above!\\nThis concept is better explained through some code:\\nListing 6.1: translation.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 M = np.float32([[1, 0, 25], [0, 1, 50]])\\n15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])',\n",
       " '15 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n16 cv2.imshow(\"Shifted Down and Right\", shifted)\\n17\\n18 M = np.float32([[1, 0, -50], [0, 1, -90]])\\n19 shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape\\n[0]))\\n20 cv2.imshow(\"Shifted Up and Left\", shifted)\\nOn Lines 1-4, we simply import the packages we will\\nmake use of. At this point, using numpy, argparse, and\\n43',\n",
       " '6.1 image transformations\\ncv2 should feel commonplace already. However, I am intro-\\nducing a new package here: imutils. This isn’t a package\\nincluded in NumPy or OpenCV . Rather, it’s a library that\\nwe are going to write ourselves and create “convenience”\\nmethods to do common tasks like translation, rotation, and\\nresizing.\\nAfter we have the necessary packages imported, we con-\\nstruct our argument parser and load our image on Lines\\n6-12.\\nThe actual translation takes place on Lines 14-16. We ﬁrst\\ndeﬁne our translation matrix M. This matrix tells us how\\nmany pixels to the left or right, and up or down, the image\\nwill be shifted.\\nOur translation matrix M is deﬁned as a ﬂoating point\\narray – this is important because OpenCV expects this ma-\\ntrix to be of ﬂoating point type. The ﬁrst row of the matrix\\nis [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to',\n",
       " 'is [1, 0,tx], where tx is the number of pixels we will shift\\nthe image left or right. Negative values of tx will shift the\\nimage to the left and positive values will shift the image to\\nthe right.\\nThen, we deﬁne the second row of the matrix as [0, 1,ty],\\nwhere ty is the number of pixels we will shift the image up\\nor down. Negative value of ty will shift the image up and\\npositive values will shift the image down.\\nUsing this notation, we can see on Line 14 that tx = 25\\nand ty = 50, implying that we are shifting the image 25 pix-\\nels to the right and 50 pixels down.\\n44',\n",
       " '6.1 image transformations\\nNow that we have our translation matrix deﬁned, the\\nactual translation takes place on Line 15 using the cv2.\\nwarpAffine function. The ﬁrst argument is the image we\\nwish to shift and the second argument is our translation ma-\\ntrix M. Finally, we manually supply the dimensions (width\\nand height) of our image as the third argument. Line 16\\nshows the results of the translation.\\nMoving on to Lines 18-20, we perform another transla-\\ntion. Here, we set tx = −50 and ty = −90, implying that\\nwe are shifting the image 50 pixels to the left and 90 pixels\\nup. The image is shifted left and up rather than right and\\ndown, because we are providing a negative values for both\\ntx and ty.\\nHowever, manually constructing this translation matrix\\nand calling the cv2.warpAffine method takes a fair amount\\nof code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently',\n",
       " 'of code – and it’s not pretty code either!\\nLet’s create a new ﬁle: imutils.py. This ﬁle will store ba-\\nsic image processing methods, allowing us to conveniently\\ncall them without writing a lot of code.\\nThe ﬁrst method we are going to deﬁne is a translate\\nfunction:\\nListing 6.2: imutils.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 def translate(image, x, y):\\n5 M = np.float32([[1, 0, x], [0, 1, y]])\\n6 shifted = cv2.warpAffine(image, M, (image.shape[1], image.\\nshape[0]))\\n45',\n",
       " '6.1 image transformations\\n7\\n8 return shifted\\nOur translate method takes three parameters: the image\\nwe are going to translate, the number of pixels that we are\\ngoing to shift along the x-axis, and the number of pixels we\\nare going to shift along the y-axis.\\nThis method then deﬁnes our translation matrix M on\\nLine 5 and then applies the actual shift on Line 6. Finally,\\nwe return the shifted image on Line 8.\\nLet’s apply our translate method and compare to the\\nmethods discussed above:\\nListing 6.3: translation.py\\n21 shifted = imutils.translate(image, 0, 100)\\n22 cv2.imshow(\"Shifted Down\", shifted)\\n23 cv2.waitKey(0)\\nUsing our convenience translate method, we are able\\nto shift the image 100 pixels down using a single line of\\ncode. Furthermore, this translate method is much easier\\nto use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.',\n",
       " 'to use – less code is required and based on the function\\nname, we conveniently know what image processing task\\nis being performed.\\nTo see our translation in action, take a look at Figure 6.1.\\nOur original image is on the top-left. On the top-right, we\\nshift our image 25 pixels to the right and 50 pixels down.\\nNext, we translate our image 50 pixels to the left and 90\\npixels up by using negative values for tx and ty. Finally, on\\nthe bottom-right, we shift our T-Rex 100 pixels down using\\n46',\n",
       " '6.1 image transformations\\nFigure 6.1: Top-Left: Our original T-Rex image.\\nTop-Right: Translating our image 25\\npixels to the right and 50 pixels\\ndown. Bottom-Left: Shifting T-Rex\\n50 pixels to the left and 90 pix-\\nels up. Bottom-Right: Shifting the\\nT-Rex down using our convenience\\nmethod.\\n47',\n",
       " '6.1 image transformations\\nour convenient translate method deﬁned above.\\nIn this section we explored how to shift an image up,\\ndown, left, and right. Next up, we’ll explore how to rotate\\nan image.\\n6.1.2 Rotation\\nRotation is exactly what it sounds like: rotating an image\\nby some angle θ. In this section, we’ll explore how to rotate\\nan image. We’ll use θ to represent by how many degrees\\nwe are rotating the image. Later, I’ll provide another con-\\nvenience method, rotate, to make performing rotations on\\nimages easier.\\nListing 6.4: rotate.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))',\n",
       " '12 cv2.imshow(\"Original\", image)\\n13\\n14 (h, w) = image.shape[:2]\\n15 center = (w // 2, h // 2)\\n16\\n17 M = cv2.getRotationMatrix2D(center, 45, 1.0)\\n18 rotated = cv2.warpAffine(image, M, (w, h))\\n19 cv2.imshow(\"Rotated by 45 Degrees\", rotated)\\n20\\n21 M = cv2.getRotationMatrix2D(center, -90, 1.0)\\n48',\n",
       " '6.1 image transformations\\n22 rotated = cv2.warpAffine(image, M, (w, h))\\n23 cv2.imshow(\"Rotated by -90 Degrees\", rotated)\\nLines 1-4 again import the packages we need. You should\\ntake note of imutils. Once again, we will be deﬁning a con-\\nvenience method to make our lives easier.\\nLines 6-12 construct our argument parser. We only need\\none argument: the path to the image we are going to use.\\nWe then load our image off disk and display it.\\nWhen we rotate an image, we need to specify around\\nwhich point we want to rotate. In most cases, you will want\\nto rotate around the center of an image; however, OpenCV\\nallows you to specify any arbitrary point you want to rotate\\naround. Let’s just go ahead and rotate around the center of\\nthe image. Lines 14 and 15 grabs the width and height of\\nthe image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.',\n",
       " 'the image, then divides each by 2 to determine the center\\nof the image. Integer division is used here, denoted as “ //”\\nto ensure we receive whole integer numbers.\\nJust as we deﬁned a matrix to translate an image, we\\nalso deﬁne a matrix to rotate the image. Instead of manu-\\nally constructing the matrix using NumPy, we’ll just make\\na call to the cv2.getRotationMatrix2D method on Line 17.\\nThe cv2.getRotationMatrix2D function takes three argu-\\nments: the point at which we want to rotate the image\\naround (in this case, the center of the image). We then\\nspecify θ, the number of degrees we are going to rotate the\\nimage by. In this case, we are going to rotate the image 45\\ndegrees. The last argument is the scale of the image. We\\nhaven’t discussed resizing an image yet, but here you can\\nspecify a ﬂoating point value, where 1.0 means the same di-\\n49',\n",
       " '6.1 image transformations\\nmensions of the image are used. However, if you speciﬁed\\na value of 2.0 the image would be doubled in size. Similarly,\\na value of 0.5 halves the size of the image.\\nOnce we have our rotation matrixM from the cv2.getRot\\nationMatrix2D function, we can apply the rotation to our\\nimage using the cv2.warpAffine method on Line 18. The\\nﬁrst argument to this function is the image we want to ro-\\ntate. We then specify our rotation matrix M along with the\\noutput dimensions (width and height) of our image. Line\\n19 then shows our image rotated by 45 degrees. Check out\\nFigure 6.2 Top-Right to see our rotated image.\\nLet’s not waste any time. We’ll go ahead and jump into\\nsome code to perform rotations:\\nOn Lines 21-23, we perform another rotation. The code\\nis identical to that in Lines 17-19, only this time we are ro-\\ntating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-',\n",
       " 'tating by -90 degrees rather than 45. Figure 6.2 Bottom-Left\\nshows our T-Rex rotated by -90 degrees.\\nJust as in translating an image, the code to rotate an im-\\nage isn’t the most pretty and Pythonic. Let’s change that\\nand deﬁne our own custom rotate method:\\nListing 6.5: imutils.py\\n27 def rotate(image, angle, center = None, scale = 1.0):\\n28 (h, w) = image.shape[:2]\\n29\\n30 if center is None:\\n31 center = (w // 2, h // 2)\\n32\\n33 M = cv2.getRotationMatrix2D(center, angle, scale)\\n34 rotated = cv2.warpAffine(image, M, (w, h))\\n50',\n",
       " '6.1 image transformations\\nFigure 6.2: Top-Left: Our original T-Rex image.\\nTop-Right: Rotating the image by 45\\ndegrees. Bottom-Left: Rotating the\\nimage by −90 degrees. Bottom-Right:\\nFlipping T-Rex upside down by rotat-\\ning the image by 180 degrees.\\n51',\n",
       " '6.1 image transformations\\n35\\n36 return rotated\\nOur rotate method takes four arguments. The ﬁrst is\\nour image. The second is the angle θ in which we want\\nto rotate the image. We provide two optional keyword ar-\\nguments, center and scale. The center parameter is the\\npoint which we wish to rotate our image around. If a value\\nof None is provided, the method automatically determines\\nthe center of the image on Lines 30-31. Finally, the scale\\nparameter is used to handle if the size of the image should\\nbe changed during the rotation. The scale parameter has\\na default value of 1.0, implying that no resizing should be\\ndone.\\nThe actual rotation of the image takes place on Lines 33\\nand 34, where we construct our rotation matrix M and ap-\\nply it to the image. Finally, our image is returned on Line\\n36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)',\n",
       " '36.\\nNow that we have deﬁned ourrotate method, let’s apply\\nit:\\nListing 6.6: rotate.py\\n24 rotated = imutils.rotate(image, 180)\\n25 cv2.imshow(\"Rotated by 180 Degrees\", rotated)\\n26 cv2.waitKey(0)\\nHere, we are rotating our image by 180 degrees. Fig-\\nure 6.2 Bottom-Right shows that our T-Rex has indeed been\\nﬂipped upside down. The code for our rotate method is\\nmuch easier to read and maintain than making calls to\\ncv2.getRotationMatrix2D and cv2.warpAffine each time\\nwe want to rotate an image.\\n52',\n",
       " '6.1 image transformations\\n6.1.3 Resizing\\nSo far we’ve covered two image transformations: transla-\\ntion and rotation. Now, we are going to explore how to\\nresize an image. We’ll also deﬁne one last method for our\\nimutils.py ﬁle, a convenience method to help us resize im-\\nages with ease.\\nPerhaps, not surprisingly, we will be using thecv2.resize\\nfunction to resize our images. But we need to keep in mind\\nthe aspect ratio of the image when we are using this func-\\ntion. Before we get too deep into the details, let’s jump right\\ninto an example:\\nListing 6.7: resize.py\\n1 import numpy as np\\n2 import argparse\\n3 import imutils\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)',\n",
       " '12 cv2.imshow(\"Original\", image)\\n13\\n14 r = 150.0 / image.shape[1]\\n15 dim = (150, int(image.shape[0] * r))\\n16\\n17 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n18 cv2.imshow(\"Resized (Width)\", resized)\\nLines 1-12 should start to feel quite redundant at this\\npoint. We are importing our packages, setting up our argu-\\nment parser, and ﬁnally loading our image and displaying\\n53',\n",
       " '6.1 image transformations\\nit.\\nThe actual interesting code doesn’t start until Lines 14\\nand 15. When resizing an image, we need to keep in mind\\nthe aspect ratio of the image. The aspect ratio is the propor-\\ntional relationship of the width and the height of the image.\\nIf we aren’t mindful of the aspect ratio, our resizing will\\nreturn results that don’t look correct.\\nComputing the aspect ratio is handled on Line 14. In\\nthis line of code, we deﬁne our new image width to be 150\\npixels. In order to compute the ratio of the new height to\\nthe old height, we simply deﬁne our ratio r to be the new\\nwidth (150 pixels) divided by the old width, which we ac-\\ncess using image.shape[1].\\nNow that we have our ratio, we can compute the new di-\\nmensions of the image on Line 15. Again, the width of the\\nnew image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.',\n",
       " 'new image will be 150 pixels. The height is then computed\\nby multiplying the old height by our ratio and converting\\nit to an integer.\\nThe actual resizing of the image takes place on Line 17.\\nThe ﬁrst argument is the image we wish to resize and the\\nsecond is our computed dimensions for the new image.The\\nlast parameter is our interpolation method, which is the\\nalgorithm working behind the scenes to handle how the\\nactual image is resized. In general, I ﬁnd that using cv2.\\nINTER_AREA obtains the best results when resizing; how-\\never, other appropriate choices include cv2.INTER_LINEAR,\\ncv2.INTER_CUBIC, and cv2.INTER_NEAREST.\\n54',\n",
       " '6.1 image transformations\\nFinally, we show our resized image on Line 18.\\nIn the example we just explored, we only resized the im-\\nage by specifying the width. But what if we wanted to\\nresize the image by specifying the height? All that requires\\nis a change to computing the aspect ratio:\\nListing 6.8: resize.py\\n19 r = 50.0 / image.shape[0]\\n20 dim = (int(image.shape[1] * r), 50)\\n21\\n22 resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n23 cv2.imshow(\"Resized (Height)\", resized)\\n24 cv2.waitKey(0)\\nOn Line 19 we deﬁne our ratio r. Our new image will\\nhave a height of 50 pixels. To determine the ratio of the new\\nheight to the old height, we divide 50 by the old height.\\nThen, we deﬁne the dimensions of our new image. We\\nalready know that the new image will have a height of 50\\npixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.',\n",
       " 'pixels. The new width is obtained by multiplying the old\\nwidth by the ratio.\\nWe then perform the actual resizing of the image on Line\\n22 and show it on Line 23.\\nResizing an image is simple enough, but having to com-\\npute the aspect ratio, deﬁne the dimensions of the new im-\\nage, and then perform the resizing takes three lines of code.\\nThis looks like the perfect time to deﬁne a resize method\\nin our imutils.py ﬁle:\\nListing 6.9: resize.py\\n25 resized = imutils.resize(image, width = 100)\\n55',\n",
       " '6.1 image transformations\\n26 cv2.imshow(\"Resized via Function\", resized)\\n27 cv2.waitKey(0)\\nIn this example, you can see that the resizing of the im-\\nage is handled by a single function: imutils.resize. The\\nﬁrst argument we pass in is the image we want to resize.\\nThen, we specify the keyword argument width, which is\\nthe width of our new image. The function then handles the\\nresizing for us.\\nOf course, we can also resize via the height of the image\\nby changing the function call to:\\nListing 6.10: resize.py\\n1 resized = imutils.resize(image, height = 50)\\nLet’s take this function apart and see what’s going on un-\\nder the hood:\\nListing 6.11: imutils.py\\n9 def resize(image, width = None, height = None, inter = cv2.\\nINTER_AREA):\\n10 dim = None\\n11 (h, w) = image.shape[:2]\\n12\\n13 if width is None and height is None:\\n14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23',\n",
       " '14 return image\\n15\\n16 if width is None:\\n17 r = height / float(h)\\n18 dim = (int(w * r), height)\\n19\\n20 else:\\n21 r = width / float(w)\\n22 dim = (width, int(h * r))\\n23\\n24 resized = cv2.resize(image, dim, interpolation = inter)\\n25\\n56',\n",
       " '6.1 image transformations\\n26 return resized\\nAs you can see, we have deﬁned our resize function.\\nThe ﬁrst argument is the image we want to resize. Then, we\\ndeﬁne two keyword arguments, width and height. Both of\\nthese arguments cannot be None, otherwise we won’t know\\nhow to resize the image. We also provide inter, which is\\nour interpolation method and defaults to cv2.INTER_AREA.\\nOn Lines 10 and 11, we deﬁne the dimensions of our new,\\nresized image and grab the dimensions of the original im-\\nage.\\nWe perform a quick check on Lines 13-14 to ensure that\\na numerical value has been provided for either the width\\nor the height.\\nThe computation of the ratio and new, resized image di-\\nmensions are handled on Lines 16-22, depending on whether\\nwe are resizing via width or via height.\\nLine 24 handles the actual resizing of the image, then\\nLine 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.',\n",
       " 'Line 26 returns our resized image to the user.\\nTo see the results of our image resizings, check out Fig-\\nure 6.3. On the Top-Left we have our original T-Rex image.\\nThen, on the Top-Right we have our T-Rex resized to have a\\nwidth of 150 pixels. The Middle-Right image then shows our\\nimage resized to have a height of 50 pixels. Finally, Bottom-\\nRight shows the output of our resize function – the T-Rex\\nis now resized to have a width of 100 pixels using only a\\nsingle line of code.\\n57',\n",
       " '6.1 image transformations\\nFigure 6.3: Top-Left: Our original T-Rex image.\\nTop-Right: The T-Rex resized to have\\na width of 150 pixels. Middle-Right:\\nOur image resized to have a height\\nof 50 pixels. Bottom-Right: Resizing\\nour image to have a width of 100 pix-\\nels using our helper function. In all\\ncases, the aspect ratio of the image is\\nmaintained.\\n58',\n",
       " '6.1 image transformations\\nTranslation, rotation, and resizing are certainly the more\\nchallenging and involved image transformation tasks. The\\nnext two we will explore, ﬂipping and cropping, are sub-\\nstantially easier.\\n6.1.4 Flipping\\nNext up on our image transformations to explore is ﬂip-\\nping an image. We can ﬂip an image around either the x or\\ny axis, or even both.\\nIn fact, I think explaining how to ﬂip an image is better\\nexplained by viewing the output of an image ﬂip, before\\nwe get into the code. Check out Figure 6.4 to see our T-Rex\\nimage ﬂipped horizontally, vertically, and both horizontally\\nand vertically at the same time.\\nNow that you see what an image ﬂip looks like, we can\\nexplore the code:\\nListing 6.12: ﬂipping.py\\n1 import argparse\\n2 import cv2\\n3\\n4 ap = argparse.ArgumentParser()\\n5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11',\n",
       " '5 ap.add_argument(\"-i\", \"--image\", required = True,\\n6 help = \"Path to the image\")\\n7 args = vars(ap.parse_args())\\n8\\n9 image = cv2.imread(args[\"image\"])\\n10 cv2.imshow(\"Original\", image)\\n11\\n12 flipped = cv2.flip(image, 1)\\n13 cv2.imshow(\"Flipped Horizontally\", flipped)\\n14\\n59',\n",
       " '6.1 image transformations\\nFigure 6.4: Top-Left: Our original T-Rex image.\\nTop-Right: Flipping the T-Rex image\\nhorizontally. Bottom-Left: Flipping\\nthe T-Rex vertically. Bottom-Right:\\nFlipping the image both horizontally\\nand vertically.\\n60',\n",
       " '6.1 image transformations\\n15 flipped = cv2.flip(image, 0)\\n16 cv2.imshow(\"Flipped Vertically\", flipped)\\n17\\n18 flipped = cv2.flip(image, -1)\\n19 cv2.imshow(\"Flipped Horizontally & Vertically\", flipped)\\n20 cv2.waitKey(0)\\nLines 1-10 handle our standard procedure of importing\\nour packages, parsing arguments, and loading our image\\nfrom disk.\\nFlipping an image is accomplished by making a call to\\nthe cv2.flip function on Line 12. The cv2.flip method\\nrequires two arguments: the image we want to ﬂip and a\\nﬂip code that is used to determine how we are going to ﬂip\\nthe image.\\nUsing a ﬂip code value of 1 indicates that we are going\\nto ﬂip the image horizontally, around the y-axis ( Line 12).\\nSpecifying a ﬂip code of 0 indicates that we want to ﬂip the\\nimage vertically, around the x-axis (Line 15). Finally, using\\na negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-',\n",
       " 'a negative ﬂip code ( Line 18) ﬂips the image around both\\naxes.\\nAgain, to see the output of our ﬂipping example, take a\\nlook at Figure 6.4. Here we can see the image ﬂipped hori-\\nzontally, vertically, and around both axes.\\nFlipping an image is very simple, perhaps one of the sim-\\nplest examples in this book! Next up, we’ll go over crop-\\nping an image and how to extract regions of an image using\\nNumPy array slices.\\n61',\n",
       " '6.1 image transformations\\nFigure 6.5: Top: Our original T-Rex image. Bot-\\ntom: Cropping the face of the T-Rex\\nusing NumPy array slices.\\n6.1.5 Cropping\\nWhen we crop an image, we want to remove the outer parts\\nof the image that we are not interested in. We can accom-\\nplish image cropping by using NumPy array slicing. In fact,\\nwe already performed image cropping in Chapter 4!\\nHowever, let’s review it again and make sure we under-\\nstand what is going on:\\nListing 6.13: crop.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n62',\n",
       " '6.1 image transformations\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 cropped = image[30:120 , 240:335]\\n14 cv2.imshow(\"T-Rex Face\", cropped)\\n15 cv2.waitKey(0)\\nLines 1-11 handle importing our packages, parsing our\\narguments, and loading our images. For our cropping ex-\\nample, we will use our T-Rex image.\\nThe actual cropping takes place on a single line of code:\\nLine 13. We are supplying NumPy array slices to extract\\na rectangular region of the image, starting at (240, 30) and\\nending at (335, 120). The order in which we supply the\\nindexes to the crop may seem counterintuitive; however, re-\\nmember that OpenCV represents images as NumPy arrays\\nwith the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:',\n",
       " 'with the the height ﬁrst and the width second. This means\\nthat we need to supply our y-axis values before our x-axis.\\nIn order to perform our cropping, NumPy expects four\\nindexes:\\n1. Start y: The starting y coordinate. In this case, we\\nstart at y = 30.\\n2. End y:The ending y coordinate. We will end our crop\\nat y = 120.\\n3. Start x:The starting x coordinate of the slice. We start\\nthe crop at x = 240.\\n63',\n",
       " '6.2 image arithmetic\\n4. End x: The ending x-axis coordinate of the slice. Our\\nslice ends at x = 335.\\nExecuting our code detailed above, we will see from Fig-\\nure 6.5 that we have cropped out the face of our T-Rex!\\nWhile the T-Rex might seem a little scary, cropping sure\\nisn’t! In fact, it’s quite simple when you consider all we are\\ndoing is performing array slices on NumPy arrays.\\n6.2 image arithmetic\\nWe all know basic arithmetic operations like addition and\\nsubtraction. But when working with images, we need to\\nkeep in mind the limits of our color space and data type.\\nFor example, RGB images have pixels that fall within the\\nrange [0, 255]. So what happens if we are examining a pixel\\nwith intensity 250 and we try to add 10 to it?\\nUnder normal arithmetic rules, we would end up with a\\nvalue of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check',\n",
       " 'value of 260. However, since RGB images are represented\\nas 8-bit unsigned integers, 260 is not a valid value.\\nSo, what should happen? Should we perform a check\\nof some sort to ensure no pixel falls outside the range of\\n[0, 255], thus clipping all pixels to have a minimum value of\\n0 and a maximum value of 255?\\nOr do we apply a modulus operation, and “wrap around”?\\nUnder modulus rules, adding 10 to 250 would simply wrap\\naround to a value of 4.\\n64',\n",
       " '6.2 image arithmetic\\nWhich way is the “correct” way to handle image addi-\\ntions and subtractions that fall outside the range of [0, 255]?\\nThe answer is there is no correct way – it simply depends\\non how you are manipulate your pixels and what you want\\nthe desired results to be.\\nHowever, be sure to keep in mind that there is a differ-\\nence between OpenCV and NumPy addition. NumPy will\\nperform modulo arithmetic and “wrap around”. OpenCV ,\\non the other hand, will perform clipping and ensure pixel\\nvalues never fall outside the range [0, 255].\\nBut don’t worry! These nuances will become clearer as\\nwe explore some code below.\\nListing 6.14: arithmetic.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13',\n",
       " '7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 cv2.imshow(\"Original\", image)\\n13\\n14 print(\"max of 255: {}\".format(cv2.add(np.uint8([200]), np.uint8\\n([100]))))\\n15 print(\"min of 0: {}\".format(cv2.subtract(np.uint8([50]), np.uint8\\n([100]))))\\n16\\n17 print(\"wrap around: {}\".format(np.uint8([200]) + np.uint8([100]))\\n)\\n18 print(\"wrap around: {}\".format(np.uint8([50]) - np.uint8([100])))\\n65',\n",
       " '6.2 image arithmetic\\nWe are going to perform our standard procedure onLines\\n1-12 by importing our packages, setting up our argument\\nparser, and loading our image.\\nRemember how I mentioned the difference between OpenCV\\nand NumPy addition above? Well, now we are going to ex-\\nplore it further and provide a concrete example to ensure\\nwe fully understand it.\\nOn Line 14, we deﬁne two NumPy arrays that are 8-\\nbit unsigned integers. The ﬁrst array has one element: a\\nvalue of 200. The second array also has only one element,\\nbut with a value of 100. We then use OpenCV’s cv2.add\\nmethod to add the values together.\\nWhat do you think the output is going to be?\\nWell, according to standard arithmetic rules, we would\\nthink the result should be 300, but, remember that we are\\nworking with 8-bit unsigned integers that only have a range\\nbetween [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-',\n",
       " 'between [0, 255]. Since we are using the cv2.add method,\\nOpenCV takes care of clipping for us, and ensures that the\\naddition produces a maximum value of 255. When we ex-\\necute this code, we can see the result on the ﬁrst line of\\nListing 6.15. Sure enough, the addition returned a value of\\n255.\\nLine 15 then performs subtraction using cv2.subtract.\\nAgain, we deﬁne two NumPy arrays, each with a single ele-\\nment, and of the 8-bit unsigned integer data type. The ﬁrst\\narray has a value of 50 and the second a value of 100.\\n66',\n",
       " '6.2 image arithmetic\\nAccording to our arithmetic rules, the subtraction should\\nreturn a value of −50; however, OpenCV once again per-\\nforms clipping for us. We ﬁnd that the value is clipped to a\\nvalue of 0. The second line of Listing 6.15 veriﬁes this: sub-\\ntracting 100 from 50 using cv2.subtract returns a value of\\n0.\\nListing 6.15: arithmetic.py\\nmax of 255: [[255]]\\nmin of 0: [[0]]\\nBut what happens if we use NumPy to perform the arith-\\nmetic instead of OpenCV?\\nLine 17 and 18 explore this question.\\nFirst, we deﬁne two NumPy arrays, each with a single\\nelement, and of the 8-bit unsigned integer data type. The\\nﬁrst array has a value of 200, and the second has a value\\nof 100. Using the cv2.add function, our addition would be\\nclipped and a value of 255 returned.\\nHowever, NumPy does not perform clipping – it instead\\nperforms modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been',\n",
       " 'performs modulo arithmetic and “wraps around”. Once a\\nvalue of 255 is reached, NumPy wraps around to zero, and\\nthen starts counting up again, until 100 steps have been\\nreached. You can see this is true via the ﬁrst line of output\\non Listing 6.16.\\nThen, we deﬁne two more NumPy arrays: one has a value\\nof 50 and the other 100. Using the cv2.subtract method,\\nthis subtraction would be clipped to return a value of 0.\\nHowever, we know that NumPy performs modulo arith-\\n67',\n",
       " '6.2 image arithmetic\\nmetic rather than clipping. Instead, once 0 is reached dur-\\ning the subtraction, the modulos operations wraps around\\nand starts counting backwards from 255 – thus the result\\non the second line of output on Listing 6.16.\\nListing 6.16: arithmetic.py\\nwrap around: [44]\\nwrap around: [206]\\nWhen performing integer arithmetic, it is important to\\nkeep in mind your desired output.\\nDo you want all values to be clipped if they fall outside\\nthe range [0, 255]? Then use OpenCV’s built-in methods for\\nimage arithmetic.\\nDo you want modulus arithmetic operations and have\\nvalues wrap around if they fall outside the range of [0, 255]?\\nThen simply add and subtract the NumPy arrays as you\\nnormally would.\\nNow that we have explored the caveats of image arith-\\nmetic in OpenCV and NumPy, let’s perform the arithmetic\\non actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)',\n",
       " 'on actual images and view the results:\\nListing 6.17: arithmetic.py\\n19 M = np.ones(image.shape, dtype = \"uint8\") * 100\\n20 added = cv2.add(image, M)\\n21 cv2.imshow(\"Added\", added)\\n22\\n23 M = np.ones(image.shape, dtype = \"uint8\") * 50\\n24 subtracted = cv2.subtract(image, M)\\n25 cv2.imshow(\"Subtracted\", subtracted)\\n26 cv2.waitKey(0)\\n68',\n",
       " '6.2 image arithmetic\\nFigure 6.6: Top-Left: Our original T-Rex image.\\nTop-Right: Adding 100 to every pixel\\nin the image. Notice how the image\\nlooks more “washed out” and is sub-\\nstantially brighter than the original.\\nBottom: Subtracting 50 from every\\npixel in the image. Notice that the\\nimage is now darker than the origi-\\nnal.\\n69',\n",
       " '6.2 image arithmetic\\nLine 19 deﬁnes a NumPy array of ones, with the same\\nsize as our image. Again, we are sure to use 8-bit unsigned\\nintegers as our data type. In order to ﬁll our matrix with\\nvalues of 100’s rather than 1’s, we simply multiply our ma-\\ntrix of 1’s by 100. Finally, we use the cv2.add function to\\nadd our matrix of 100’s to the original image – thus increas-\\ning every pixel intensity in the image by 100, but ensuring\\nall values are clipped to the range [0, 255] if they attempt to\\nexceed 255.\\nThe result of our operation can be found in Figure 6.6\\nTop-Right. Notice how the image looks more “washed out”\\nand is substantially brighter than the original. This is be-\\ncause we are increasing the pixel intensities by adding 100\\nto them and pushing them towards brighter colors.\\nWe then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image',\n",
       " 'We then create another NumPy array ﬁlled with 50’s on\\nLine 24 and use the cv2.subtract function to subtract 50\\nfrom each pixel intensity of the image. The Bottom image\\nin Figure 6.6 shows the results of this subtraction. Our im-\\nage now looks considerably darker than the original T-Rex.\\nPixels that were once white now look gray. This is because\\nwe are subtracting 50 from the pixels and pushing them to-\\nwards the darker regions of the RGB color space.\\nIn this section, we explored the peculiarities of image\\narithmetic using OpenCV and NumPy. These caveats are\\nimportant to keep in mind, otherwise you may get unwanted\\nresults when performing arithmetic operations on your im-\\nages.\\n70',\n",
       " '6.3 bitwise operations\\n6.3 bitwise operations\\nNow we will review four bitwise operations: AND, OR,\\nXOR, and NOT. These four operations, while very basic\\nand low level, are paramount to image processing, espe-\\ncially when we start working with masks in Section 6.4.\\nBitwise operations operate in a binary manner and are\\nrepresented as grayscale images. A given pixel is turned\\n“off” if it has a value of zero, and it is turned “on” if the\\npixel has a value greater than zero.\\nLet’s go ahead and jump into some code:\\nListing 6.18: bitwise.py\\n1 import numpy as np\\n2 import cv2\\n3\\n4 rectangle = np.zeros((300, 300), dtype = \"uint8\")\\n5 cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)\\n6 cv2.imshow(\"Rectangle\", rectangle)\\n7\\n8 circle = np.zeros((300, 300), dtype = \"uint8\")\\n9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image',\n",
       " '9 cv2.circle(circle, (150, 150), 150, 255, -1)\\n10 cv2.imshow(\"Circle\", circle)\\nThe ﬁrst two lines of code import the packages we will\\nneed: numpy and cv2. We initialize our rectangle image\\nas a 300 × 300 NumPy array on Line 4. We then draw a\\n250 × 250 white rectangle at the center of the image.\\nSimilarly, on Line 8, we initialize another image to con-\\ntain our circle, which we draw on Line 9, again centered at\\nthe center of the image, with a radius of 150 pixels.\\n71',\n",
       " '6.3 bitwise operations\\nFigure 6.7: Left: Our rectangle image. Right: Our\\ncircle image. We will explore how\\nthese two images can be combined\\nusing bitwise operations.\\nFigure 6.7 shows our two shapes. We will make use of\\nthese shapes to demonstrate our bitwise operations:\\nListing 6.19: bitwise.py\\n11 bitwiseAnd = cv2.bitwise_and(rectangle, circle)\\n12 cv2.imshow(\"AND\", bitwiseAnd)\\n13 cv2.waitKey(0)\\n14\\n15 bitwiseOr = cv2.bitwise_or(rectangle, circle)\\n16 cv2.imshow(\"OR\", bitwiseOr)\\n17 cv2.waitKey(0)\\n18\\n19 bitwiseXor = cv2.bitwise_xor(rectangle, circle)\\n20 cv2.imshow(\"XOR\", bitwiseXor)\\n21 cv2.waitKey(0)\\n22\\n23 bitwiseNot = cv2.bitwise_not(circle)\\n24 cv2.imshow(\"NOT\", bitwiseNot)\\n25 cv2.waitKey(0)\\n72',\n",
       " '6.3 bitwise operations\\nAs I mentioned above, a given pixel is turned “on” if it\\nhas a value greater than zero, and it is turned “off” if it has\\na value of zero. Bitwise functions operate on these binary\\nconditions.\\nIn order to utilize bitwise functions, we assume (in most\\ncases) that we are comparing two pixels (the only exception\\nis the NOT function). We’ll compare each of the pixels and\\nthen construct our bitwise representation.\\nLet’s quickly review our binary operations:\\n1. AND: A bitwise AND is true if and only if both pixels\\nare greater than zero.\\n2. OR: A bitwise OR is true if either of the two pixels\\nare greater than zero.\\n3. XOR: A bitwise XOR is true if and only if either of the\\ntwo pixels are greater than zero, but not both.\\n4. NOT: A bitwise NOT inverts the “on” and “off” pixels\\nin an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if',\n",
       " 'in an image.\\nOn Line 11 we apply a bitwise AND to our rectangle and\\ncircle images using the cv2.bitwise_and function. As the\\nlist above mentions, a bitwise AND is true if and only if\\nboth pixels are greater than zero. The output of our bitwise\\nAND can be seen in Figure 6.8 Top-Left. We can see that\\nedges of our square are lost – this makes sense because our\\nrectangle does not cover as large of an area as the circle,\\nand thus both pixels are not “on”.\\n73',\n",
       " '6.4 masking\\nWe then apply a bitwise OR on Line 15 using the cv2.\\nbitwise_or function. A bitwise OR is true if either of the\\ntwo pixels are greater than zero. Figure 6.8 Top-Right shows\\nthe output of our bitwise OR. In this case, our square and\\nrectangle have been combined together.\\nNext up is the bitwise XOR function, applied on Line 19\\nusing the cv2.bitwise_xor function. An XOR operation\\nis true if both pixels are greater than zero, but both pixels\\ncannot be greater than zero. The output of the XOR oper-\\nation is displayed on Figure 6.8 Bottom-Right. Here we see\\nthat the center of the square has been removed. Again, this\\nmakes sense because an XOR operation cannot have both\\npixels greater than zero.\\nFinally, we apply the NOT function on Line 23 using the\\ncv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are',\n",
       " 'cv2.bitwise_not function. Essentially, the bitwise NOT\\nfunction ﬂips pixel values. All pixels that are greater than\\nzero are set to zero, and all pixels that are set to zero are\\nset to 255. Figure 6.8 Bottom-Right ﬂips our white circle to a\\nblack circle.\\nOverall, bitwise functions are extremely simple, yet very\\npowerful. And they are absolutely essential when we start\\nto discuss masking in Section 6.4.\\n6.4 masking\\nIn the previous section, we explored bitwise functions. Now\\nwe are ready to explore masking, an extremely powerful\\nand useful technique in computer vision and image pro-\\n74',\n",
       " '6.4 masking\\nFigure 6.8: Top-Left: Applying a bitwise AND to\\nour rectangle and circle image. Top-\\nRight: A bitwise OR applied to our\\nsquare and circle. Bottom-Left: An\\nXOR applied to our shapes. Bottom-\\nRight: Flipping pixel values of our\\ncircle using a bitwise NOT.\\n75',\n",
       " '6.4 masking\\ncessing.\\nUsing a mask allows us to focus only on the portions of\\nthe image that interests us.\\nFor example, let’s say that we were building a computer\\nvision system to recognize faces. The only part of the image\\nwe are interested in ﬁnding and describing are the parts of\\nthe image that contain faces – we simply don’t care about\\nthe rest of the content of the image. Provided that we could\\nﬁnd the faces in the image, we might construct a mask to\\nshow only the faces in the image.\\nLet’s make this example a little more concrete.\\nIn Figure 6.9, we have an image of a beach on the Top-Left.\\nBut I’m not interested in the beach in the image. I’m only\\ninterested in the sky and the palm tree. We could apply a\\ncropping to extract that region of the image. Or, we could\\napply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-',\n",
       " 'apply a mask to the image.\\nThe image on the Top-Right is our mask – a white rectan-\\ngle at the center of the image. Applying our mask to our\\nbeach image, we arrive at the image on the Bottom. By us-\\ning our rectangle mask, we have focused only on the sky\\nand palm tree in the image.\\nLet’s examine the code to accomplish the masking in Fig-\\nure 6.9:\\nListing 6.20: masking.py\\n1 import numpy as np\\n76',\n",
       " '6.4 masking\\nFigure 6.9: Top-Left: Our image of a peaceful\\nbeach scene. Top-Right: Our mask im-\\nage – a white rectangle at the center\\nof the image. Bottom: Applying the\\nrectangular mask to the beach image.\\nOnly the parts of the image where\\nthe mask pixels are greater than zero\\nare shown.\\n77',\n",
       " '6.4 masking\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n14 (cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)\\n15 cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255,\\n-1)\\n16 cv2.imshow(\"Mask\", mask)\\n17\\n18 masked = cv2.bitwise_and(image, image, mask = mask)\\n19 cv2.imshow(\"Mask Applied to Image\", masked)\\n20 cv2.waitKey(0)\\nOn Lines 1-11 we import the packages we need, parse\\nour arguments, and load our image.\\nWe then construct a NumPy array, ﬁlled with zeros, with\\nthe same width and height as our beach image on Line 13.\\nIn order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-',\n",
       " 'In order to draw the white rectangle, we ﬁrst compute the\\ncenter of the image on Line 14 by dividing the width and\\nheight by two, using the // operator to indicate integer divi-\\nsion. Finally, we draw our white rectangle on Line 15.\\nRemember reviewing the cv2.bitwise_and function in\\nthe previous section? It’s a function that is used extensively\\nwhen applying masks to images.\\nWe apply our mask on Line 18 using the cv2.bitwise_\\nand function. The ﬁrst two parameters are the image it-\\nself. Obviously, the AND function will be True for all pix-\\nels in the image; however, the important part of this func-\\n78',\n",
       " '6.4 masking\\ntion is the mask keyword argument. By supplying a mask,\\nthe cv2.bitwise_and function only examines pixels that are\\n“on” in the mask. In this case, only pixels that are part of\\nthe white rectangle.\\nLet’s look at another example:\\nListing 6.21: masking.py\\n21 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n22 cv2.circle(mask, (cX, cY), 100, 255, -1)\\n23 masked = cv2.bitwise_and(image, image, mask = mask)\\n24 cv2.imshow(\"Mask\", mask)\\n25 cv2.imshow(\"Mask Applied to Image\", masked)\\n26 cv2.waitKey(0)\\nOn Line 21 we re-initialize our mask to be ﬁlled with ze-\\nros and the same dimensions as our beach image. Then, we\\ndraw a white circle on our mask image, starting at the cen-\\nter of the image and a radius of 100 pixels. Applying the\\ncircular mask is then performed on Line 23, again using the\\ncv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on',\n",
       " 'cv2.bitwise_and function.\\nThe results of our circular mask can be seen in Figure\\n6.10. Our beach image is shown on the Top-Left, our circle\\nmask on the Top-Right, and the application of the mask on\\nthe Bottom. Instead of a rectangular region of the beach be-\\ning shown, we now have a circular region.\\nRight now masking may not seem very interesting. But\\nwe’ll return to it once we start computing histograms in\\nChapter 7. Again, the key point of masks is that they allow\\nus to focus our computation only on regions of the image\\nthat interests us.\\n79',\n",
       " '6.4 masking\\nFigure 6.10: Applying the circular mask to the\\nbeach image. Only pixels within\\nthe circular white region are shown.\\n80',\n",
       " '6.5 splitting and merging channels\\n6.5 splitting and merging channels\\nA color image consists of multiple channels: a Red, a Green,\\nand a Blue component. We have seen that we can access\\nthese components via indexing into NumPy arrays. But\\nwhat if we wanted to split an image into its respective com-\\nponents?\\nAs you’ll see, we’ll make use of thecv2.split function.\\nFor the time being, let’s take a look at a sample image in\\nFigure 6.11.\\nWe have an image of a wave crashing down. This image\\nis very “blue” due to the ocean. How do we interpret the\\ndifferent channels of the image?\\nThe Red channel (Top-Left) is very dark. This makes sense,\\nbecause an ocean scene has very few red colors in it. The\\nred colors present are either very dark, and thus not repre-\\nsented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.',\n",
       " 'sented, or very light, and likely part of the white foam of\\nthe wave as it crashes down.\\nThe Green channel (Top-Right) is more represented in the\\nimage, since ocean water does contain greenish hues.\\nFinally, the Blue channel ( Bottom-Left) is extremely light,\\nand near pure white in some locations. This is because\\nshades of blue are heavily represented in our image.\\nNow that we have visualized our channels, let’s examine\\nsome code to accomplish this for us:\\n81',\n",
       " '6.5 splitting and merging channels\\nFigure 6.11: The three RGB channels of our\\nwave image are shown on the\\nBottom-Right. The Red channel is on\\nthe Top-Left, the Green channel on\\nthe Top-Right, and the Blue channel\\non the Bottom-Left.\\n82',\n",
       " '6.5 splitting and merging channels\\nListing 6.22: splitting_and_merging.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 (B, G, R) = cv2.split(image)\\n12\\n13 cv2.imshow(\"Red\", R)\\n14 cv2.imshow(\"Green\", G)\\n15 cv2.imshow(\"Blue\", B)\\n16 cv2.waitKey(0)\\n17\\n18 merged = cv2.merge([B, G, R])\\n19 cv2.imshow(\"Merged\", merged)\\n20 cv2.waitKey(0)\\n21 cv2.destroyAllWindows()\\nLines 1-10 imports our packages, sets up our argument\\nparser, and then loads our image. Splitting the channels is\\ndone using a call to cv2.split on Line 11.\\nNormally, we think of images in the RGB color space –\\nthe red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image',\n",
       " 'the red pixel ﬁrst, the green pixel second, and the blue pixel\\nthird. However, OpenCV stores RGB images as NumPy ar-\\nrays in reverse channel order. Instead of storing an image\\nin RGB order, it instead stores the image in BGR order; thus\\nwe unpack the tuple in reverse order.\\nLines 13-16 then show each channel individually, as in\\nFigure 6.11.\\nWe can also merge the channels back together again us-\\ning the cv2.merge function. We simply specify our chan-\\n83',\n",
       " '6.5 splitting and merging channels\\nFigure 6.12: Representing the Red, Green, and\\nBlue channels of our wave image.\\nnels, again in BGR order, and then cv2.merge takes care of\\nthe rest for us ( Line 18).\\nListing 6.23: splitting_and_merging.py\\n22 zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\\n23 cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\\n24 cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\\n25 cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\\n26 cv2.waitKey(0)\\nAn alternative method to visualize the channels of an im-\\nage can be seen in Figure 6.12. In order to show the actual\\n“color” of the channel, we ﬁrst need to take apart the image\\nusing cv2.split. Then, we need to re-construct the image,\\nbut this time setting all pixels but the current channel as zero.\\nOn Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-',\n",
       " 'On Line 22 we construct a NumPy array of zeros, with\\nthe same width and height as our original image. Then, in\\norder to construct the Red channel representation of the im-\\nage, we make a call to cv2.merge, but specifying our zeros\\narray for the Green and Blue channels. We take similar ap-\\nproaches to the other channels in Line 24 and 25.\\n84',\n",
       " '6.6 color spaces\\n6.6 color spaces\\nIn this book, we have only explored the RGB color space;\\nhowever, there are many other color spaces that we can uti-\\nlize.\\nThe Hue-Saturation-Value (HSV) color space is more sim-\\nilar to how humans think and conceive of color. Then there\\nis the L*a*b* color space, which is more tuned to how hu-\\nmans perceive color.\\nOpenCV provides support for many, many different color\\nspaces. And understanding how color is perceived by hu-\\nmans and represented by computers occupies an entire li-\\nbrary of literature itself.\\nIn order to not get bogged down in the details, I’ll just\\nshow you how to convert color spaces. If you think your\\napplication of image processing and computer vision might\\nneed a different color space than RGB, I will leave that as\\nan exercise to the reader to explore the peculiarities of each\\ncolor space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4',\n",
       " 'color space.\\nLet’s explore some code to change color spaces:\\nListing 6.24: colorspaces.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n85',\n",
       " '6.6 color spaces\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\n12\\n13 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Gray\", gray)\\n15\\n16 hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\\n17 cv2.imshow(\"HSV\", hsv)\\n18\\n19 lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\\n20 cv2.imshow(\"L*a*b*\", lab)\\n21 cv2.waitKey(0)\\nLines 1-11 imports the packages we need, parses our ar-\\nguments, and loads our image. Then, on Line 13, we con-\\nvert our image from the RGB color space to grayscale by\\nspecifying the cv2.COLOR_BGR2GRAY ﬂag.\\nConverting our image to the HSV color space is performed\\non Line 16 by specifying the cv2.COLOR_BGR2HSV ﬂag. Fi-\\nnally, on Line 19, we convert to the L*a*b* color space by\\nusing the cv2.COLOR_BGR2LAB ﬂag.\\nWe can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.',\n",
       " 'We can see the results of our color space conversions in\\nFigure 6.13.\\nThe role of color spaces in image processing and com-\\nputer vision is important, yet complicated at the same time.\\nIf you are just getting started in computer vision, it’s likely\\na good idea to stick to the RGB color space for the time\\nbeing. However, I have included this section as a matter\\nof completeness – it’s good to show an example of how to\\nconvert color spaces for when you decide the time is right!\\n86',\n",
       " '6.6 color spaces\\nFigure 6.13: Top-Left: An image of beach scenery.\\nTop-Right: The grayscale represen-\\ntation of the beach image. Bottom-\\nLeft: Converting the beach image to\\nthe HSV color space. Bottom-Right:\\nConverting our image to the L*a*b*\\ncolor space.\\n87',\n",
       " '6.6 color spaces\\nFurther Reading\\nChapter 6 is by far the longest chapter inPractical Python\\nand OpenCV – and with good reason. In this chapter,\\nwe covered a lot of important image processing con-\\ncepts that form the foundation on which the rest of\\nyour computer vision education will be built.\\nTo ensure that you have a thorough grasp on these con-\\ncepts, be sure to go through the Chapter 6 supplemen-\\ntary material:\\nhttp://pyimg.co/s3fm7\\n88',\n",
       " '7\\nH I S T O G R A M S\\nSo, what exactly is a histogram? A histogram represents\\nthe distribution of pixel intensities (whether color or gray-\\nscale) in an image. It can be visualized as a graph (or plot)\\nthat gives a high-level intuition of the intensity (pixel value)\\ndistribution. We are going to assume an RGB color space in\\nthis example, so these pixel values will be in the range of 0\\nto 255.\\nWhen plotting the histogram, the X-axis serves as our\\n“bins”. If we construct a histogram with 256 bins, then\\nwe are effectively counting the number of times each pixel\\nvalue occurs. In contrast, if we use only 2 (equally spaced)\\nbins, then we are counting the number of times a pixel is in\\nthe range [0, 128) or [128, 255]. The number of pixels binned\\nto the x-axis value is then plotted on the y-axis.\\nBy simply examining the histogram of an image, you get\\na general understanding regarding the contrast, brightness,\\n89',\n",
       " '7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1 using opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms. Before we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.',\n",
       " 'provided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.\\n4. histSize: This is the number of bins we want to use\\nwhen computing a histogram. Again, this is a list, one\\nfor each channel we are computing a histogram for.\\nThe bin sizes do not all have to be the same. Here is\\nan example of 32 bins for each channel: [32,32,32].\\n90',\n",
       " '7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use thecv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2 grayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet. All we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py',\n",
       " 'ment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 cv2.imshow(\"Original\", image)\\n91',\n",
       " '7.2 grayscale histograms\\n15\\n16 hist = cv2.calcHist([image], [0], None, [256], [0, 256])\\n17\\n18 plt.figure()\\n19 plt.title(\"Grayscale Histogram\")\\n20 plt.xlabel(\"Bins\")\\n21 plt.ylabel(\"# of Pixels\")\\n22 plt.plot(hist)\\n23 plt.xlim([0, 256])\\n24 plt.show()\\n25 cv2.waitKey(0)\\nNow things are getting a little more interesting. On Line\\n13, we convert the image from the RGB colorspace to graysc-\\nale. Line 16 computes the actual histogram. Go ahead and\\nmatch the arguments of the code up with the function docu-\\nmentation above. We can see that our ﬁrst parameter is the\\ngrayscale image. A grayscale image has only one channel,\\nhence we have a value of [0] for channels. We don’t have\\na mask, so we set the mask value to None. We will use 256\\nbins in our histogram, and the possible values range from\\n0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the',\n",
       " '0 to 256.\\nFinally, a call toplt.plot() plots our grayscale histogram,\\nthe results of which can be seen in Figure 7.1.\\nNot bad. How do we interpret this histogram? Well, the\\nbins (0-255) are plotted on the x-axis. And the y-axis counts\\nthe number of pixels in each bin. The majority of the pixels\\nfall in the range of roughly 60 to 120. Looking at the right\\ntail of the histogram, we see very few pixels in the range\\n200 to 255. This means that there are very few “white” pix-\\nels in the image.\\n92',\n",
       " '7.3 color histograms\\nFigure 7.1: Computing a grayscale histogram of\\nour beach image.\\n7.3 color histograms\\nIn the previous section, we explored grayscale histograms.\\nNow let’s move on to computing a histogram for each chan-\\nnel of the image.\\nListing 7.3: color_histograms.py\\n1 from __future__ import print_function\\n2 from matplotlib import pyplot as plt\\n3 import numpy as np\\n4 import argparse\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 cv2.imshow(\"Original\", image)\\n93',\n",
       " '7.3 color histograms\\nAgain, we’ll import the packages that we’ll need, utiliz-\\ning matplotlib once more to plot the histograms.\\nLet’s examine some code:\\nListing 7.4: color_histograms.py\\n14 chans = cv2.split(image)\\n15 colors = (\"b\", \"g\", \"r\")\\n16 plt.figure()\\n17 plt.title(\"’Flattened’ Color Histogram\")\\n18 plt.xlabel(\"Bins\")\\n19 plt.ylabel(\"# of Pixels\")\\n20\\n21 for (chan, color) in zip(chans, colors):\\n22 hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\\n23 plt.plot(hist, color = color)\\n24 plt.xlim([0, 256])\\nThe ﬁrst thing we are going to do is split the image into\\nits three channels: blue, green, and red. Normally, we read\\nthis is red, green, blue (RGB). However, OpenCV stores the\\nimage as a NumPy array in reverse order: BGR. This is\\nimportant to note. We then initialize a tuple of strings rep-\\nresenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into',\n",
       " 'resenting the colors. We take care of all this on Lines 14-15.\\nOn Lines 16-19 we set up our PyPlot ﬁgure. We’ll plot\\nthe bins on the x-axis and the number of pixels placed into\\neach bin on the y-axis.\\nWe then reach a for loop on Line 21, where we start loop-\\ning over each of the channels in the image.\\nThen, for each channel, we compute a histogram on Line\\n22. The code is identical to that of computing a histogram\\nfor the grayscale image; however, we are doing it for each\\nRed, Green, and Blue channel, allowing us to characterize\\n94',\n",
       " '7.3 color histograms\\nFigure 7.2: Color histograms for each Red,\\nGreen, and Blue channel of the beach\\nimage.\\nthe distribution of pixel intensities. We add our histogram\\nto the plot on Line 23.\\nWe can examine our color histogram in Figure 7.2. We\\nsee there is a sharp peak in the green histogram around bin\\n100. This indicates a darker green value, from the green\\nvegetation and trees in the beach image.\\nWe also see a lot of blue pixels in the range 170 to 225.\\nConsidering these pixels are much lighter, we know that\\nthey are from the blue sky in our beach image. Similarly,\\nwe see a much smaller range of blue pixels in the range 25\\nto 50 – these pixels are much darker, and are therefore the\\nocean pixels in the bottom-left corner of the image.\\nUp until this point, we have computed a histogram for\\nonly one channel at a time. Now we move on to multi-\\ndimensional histograms and take into consideration two\\n95',\n",
       " '7.3 color histograms\\nchannels at a time.\\nI like to explain multi-dimensional histograms by using\\nthe word AND.\\nFor example, we can ask a question such as, “How many\\npixels have a Red value of 10 AND a Blue value of 30?”.\\nHow many pixels have a Green value of 200 AND a Red\\nvalue of 130? By using the conjunctive AND, we are able to\\nconstruct multi-dimensional histograms.\\nIt’s that simple. Let’s check out some code to automate\\nthe process of building a 2D histogram:\\nListing 7.5: color_histograms.py\\n25 fig = plt.figure()\\n26\\n27 ax = fig.add_subplot(131)\\n28 hist = cv2.calcHist([chans[1], chans[0]], [0, 1], None,\\n29 [32, 32], [0, 256, 0, 256])\\n30 p = ax.imshow(hist, interpolation = \"nearest\")\\n31 ax.set_title(\"2D Color Histogram for G and B\")\\n32 plt.colorbar(p)\\n33\\n34 ax = fig.add_subplot(132)\\n35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")',\n",
       " '35 hist = cv2.calcHist([chans[1], chans[2]], [0, 1], None,\\n36 [32, 32], [0, 256, 0, 256])\\n37 p = ax.imshow(hist, interpolation = \"nearest\")\\n38 ax.set_title(\"2D Color Histogram for G and R\")\\n39 plt.colorbar(p)\\n40\\n41 ax = fig.add_subplot(133)\\n42 hist = cv2.calcHist([chans[0], chans[2]], [0, 1], None,\\n43 [32, 32], [0, 256, 0, 256])\\n44 p = ax.imshow(hist, interpolation = \"nearest\")\\n45 ax.set_title(\"2D Color Histogram for B and R\")\\n46 plt.colorbar(p)\\n47\\n48 print(\"2D histogram shape: {}, with {} values\".format(\\n96',\n",
       " '7.3 color histograms\\n49 hist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using. In previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-',\n",
       " 'The most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97',\n",
       " '7.3 color histograms\\nFigure 7.3: Computing 2D color histograms for\\neach combination of Red, Green, and\\nBlue channels.\\nof red represent large pixel counts (i.e., peaks in the 2D his-\\ntogram). We tend to see many peaks in the Green and Blue\\nhistogram, where x = 22 and y = 12. This corresponds to\\nthe green pixels of the vegetation and trees and the blue of\\nthe sky and ocean.\\nUsing a 2D histogram takes into account two channels at\\na time. But what if we wanted to account for all three RGB\\nchannels? You guessed it. We’re now going to build a 3D\\nhistogram.\\nListing 7.6: color_histograms.py\\n50 hist = cv2.calcHist([image], [0, 1, 2],\\n51 None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\\n52 print(\"3D histogram shape: {}, with {} values\".format(\\n53 hist.shape, hist.flatten().shape[0]))\\n54\\n55 plt.show()\\n98',\n",
       " '7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4 histogram equalization\\nHistogram equalization improves the contrast of an image\\nby “stretching” the distribution of pixels. Consider a his-\\ntogram with a large peak at the center of it. Applying his-\\ntogram equalization will stretch the peak out towards the\\ncorner of the image, thus improving the global contrast of\\nthe image. Histogram equalization is applied to grayscale\\nimages.\\nThis method is useful when an image contains foregroun-\\nds and backgrounds that are both dark or both light. It\\ntends to produce unrealistic effects in photographs; how-\\never, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-',\n",
       " 'ever, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n99',\n",
       " '7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12\\n13 eq = cv2.equalizeHist(image)\\n14\\n15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\\n16 cv2.waitKey(0)\\nLines 1-10 handle our standard practice of importing pack-\\nages, parsing arguments, and loading our image. We then\\nconvert our image to grayscale on Line 11.\\nPerforming histogram equalization is done using just a\\nsingle function: cv2.equalizeHist, which accepts a single\\nparameter, the grayscale image we want to perform his-\\ntogram equalization on. The last couple lines of code dis-\\nplay our histogram equalized image.\\n100',\n",
       " '7.5 histograms and masks\\nThe result of applying histogram equalization can be seen\\nin Figure 7.4. On the left, we have our original beach image.\\nThen, on the right, we have our histogram-equalized beach\\nimage. Notice how the contrast of the image has been radi-\\ncally changed and now spans the entire range of [0, 255].\\n7.5 histograms and masks\\nIn Chapter 6, Section 6.4, I mentioned that masks can be\\nused to focus on speciﬁc regions of an image that interest\\nus. We are now going to construct a mask and compute\\ncolor histograms for the masked region only.\\nFirst, we need to deﬁne a convenience function to save us\\nfrom writing repetitive lines of code:\\nListing 7.8: histogram_with_mask.py\\n1 from matplotlib import pyplot as plt\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13',\n",
       " '5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13\\n14 for (chan, color) in zip(chans, colors):\\n15 hist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16 plt.plot(hist, color = color)\\n17 plt.xlim([0, 256])\\n101',\n",
       " '7.5 histograms and masks\\nOn Lines 1-4 we import our packages; then on Line 6 we\\ndeﬁne plot_histogram. This function accepts three param-\\neters: an image, the title of our plot, and a mask. The mask\\ndefaults to None if we do not have a mask for the image.\\nThe body of our plot_histogram function simply com-\\nputes a histogram for each channel in the image and plots\\nit, just as in previous examples in this chapter.\\nNow that we have a function to help us easily plot his-\\ntograms, let’s move into the bulk of our code:\\nListing 7.9: histogram_with_mask.py\\n18 ap = argparse.ArgumentParser()\\n19 ap.add_argument(\"-i\", \"--image\", required = True,\\n20 help = \"Path to the image\")\\n21 args = vars(ap.parse_args())\\n22\\n23 image = cv2.imread(args[\"image\"])\\n24 cv2.imshow(\"Original\", image)\\n25 plot_histogram(image, \"Histogram for Original Image\")\\nLines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot',\n",
       " 'Lines 18-21 parse our command line arguments. Then\\nwe load our beach image on Line 23 and plot a histogram\\nfor each channel of the beach image on Line 25. The plot\\nfor our image can be seen in Figure 7.5. We will refer to\\nthis histogram again once we compute a histogram for the\\nmasked region.\\nListing 7.10: histogram_with_mask.py\\n26 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n27 cv2.rectangle(mask, (15, 15), (130, 100), 255, -1)\\n28 cv2.imshow(\"Mask\", mask)\\n29\\n30 masked = cv2.bitwise_and(image, image, mask = mask)\\n31 cv2.imshow(\"Applying the Mask\", masked)\\n102',\n",
       " '7.5 histograms and masks\\nFigure 7.5: Left: The original beach image. Right:\\nColor histograms for the red, green,\\nand blue channels. Compare these\\nhistograms to the histograms of the\\nmasked region of blue sky in Figure\\n7.7.\\n103',\n",
       " '7.5 histograms and masks\\nFigure 7.6: Left: Our rectangular mask. Right:\\nApplying our mask to the beach im-\\nage using a bitwise AND. Now we\\nsee only the blue sky – the rest of the\\nimage is ignored.\\nNow we are ready to construct a mask for the image. We\\ndeﬁne our mask as a NumPy array, with the same width\\nand height as our beach image on Line 26. We then draw a\\nwhite rectangle starting from point(15, 15) to point (130, 100)\\non Line 27. This rectangle will serve as our mask – only pix-\\nels in our original image belonging to the masked region\\nwill be considered in the histogram computation.\\nTo visualize our mask, we apply a bitwise AND to the\\nbeach image ( Line 30), the results of which can be seen in\\nFigure 7.6. Notice how the image on the left is simply a\\nwhite rectangle, but when we apply our mask to the beach\\nimage, we only see the blue sky ( right).\\nListing 7.11: histogram_with_mask.py\\n32 plot_histogram(image, \"Histogram for Masked Image\", mask = mask)\\n104',\n",
       " '7.5 histograms and masks\\n33\\n34 plt.show()\\nFinally, we compute a histogram for our masked image\\nusing our plot_histogram function and show our results\\n(Lines 32-34).\\nWe can see our masked histogram in Figure 7.7. Most\\nred pixels fall in the range [0, 80], indicating that red pixels\\ncontribute very little to our image. This makes sense, since\\nour sky is blue. Green pixels are then present, but again,\\nare towards the darker end of the RGB spectrum. Finally,\\nour blue pixels fall in the brighter range and are obviously\\nour blue sky.\\nMost importantly, compare our masked color histograms\\nin Figure 7.5 to the unmasked color histograms in Figure\\n7.7 above. Notice how dramatically different the color his-\\ntograms are. By utilizing masks, we are able to apply our\\ncomputation only to the speciﬁc regions of the image that\\ninterest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.',\n",
       " 'interest us – in this example, we simply wanted to examine\\nthe distribution of the blue sky.\\nIn this chapter, you have learned all about histograms.\\nHistograms are simple, but are used extensively in image\\nprocessing and computer vision. Make sure you have a\\ngood grasp of histograms; you’ll certainly be using them in\\nthe future!\\n105',\n",
       " '7.5 histograms and masks\\nFigure 7.7: The resulting histogram of the\\nmasked image in Figure 7.6. Red\\ncontributes little to our image and is\\ntowards the darker end of the spec-\\ntrum. Some lighter green values are\\npresent, and many light blue colors\\ncorrespond to the sky in the image.\\n106',\n",
       " '7.5 histograms and masks\\nFurther Reading\\nThe purpose of Chapter 7 was to learn how to extract\\nand visualize color histograms from an image. But\\nother than simply visualizing the color distributions of\\nan image, what else can we do? What are the actual\\napplications of utilizing color histograms?\\nTo learn how to compare color histograms for similar-\\nity, and even build an image search engine, take a look\\nat the Chapter 7 supplementary page:\\nhttp://pyimg.co/aa4ax\\n107',\n",
       " '8\\nS M O O T H I N G A N D B L U R R I N G\\nI’m pretty sure we all know what blurring is. It’s what\\nhappens when your camera takes a picture out of focus.\\nSharper regions in the image lose their detail, normally as\\na disc/circular shape.\\nPractically, this means that each pixel in the image is\\nmixed in with its surrounding pixel intensities. This “mix-\\nture” of pixels in a neighborhood becomes our blurred pixel.\\nWhile this effect is usually unwanted in our photographs,\\nit’s actually quite helpful when performing image process-\\ning tasks.\\nIn fact, many image processing and computer vision func-\\ntions, such as thresholding and edge detection, perform bet-\\nter if the image is ﬁrst smoothed or blurred.\\nIn order to explore different types of blurring methods,\\nlet’s start with a baseline of our original T-Rex image in Fig-\\nure 8.1.\\nListing 8.1: blurring.py\\n108',\n",
       " 'smoothing and blurring\\nFigure 8.1: Our original T-Rex image before ap-\\nplying any blurring effects.\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 cv2.imshow(\"Original\", image)\\nIn order to perform image blurring, we ﬁrst need to im-\\nport our packages and parse our arguments (Lines 1-8). We\\nthen load our image and show it as a baseline to compare\\nour blurring methods to on Lines 10 and 11.\\n109',\n",
       " '8.1 averaging\\nNow that our image is loaded, we can start blurring our\\nimages.\\n8.1 averaging\\nThe ﬁrst blurring method we are going to explore is averag-\\ning.\\nAs the name suggests, we are going to deﬁne a k × k slid-\\ning window on top of our image, where k is always an odd\\nnumber. This window is going to slide from left-to-right\\nand from top-to-bottom. The pixel at the center of this ma-\\ntrix (we have to use an odd number, otherwise there would\\nnot be a true “center”) is then set to be the average of all\\nother pixels surrounding it.\\nWe call this sliding window a “convolution kernel” or\\njust a “kernel”. We’ll continue to use this terminology throu-\\nghout this chapter.\\nAs we will see, as the size of the kernel increases, the\\nmore blurred our image will become.\\nLet’s check out some code to perform average blurring:\\nListing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)',\n",
       " 'Listing 8.2: blurring.py\\n12 blurred = np.hstack([\\n13 cv2.blur(image, (3, 3)),\\n14 cv2.blur(image, (5, 5)),\\n15 cv2.blur(image, (7, 7))])\\n16 cv2.imshow(\"Averaged\", blurred)\\n17 cv2.waitKey(0)\\n110',\n",
       " '8.1 averaging\\nFigure 8.2: Performing averaging blurring with\\na 3 × 3 kernel (left), 5 × 5 kernel (mid-\\ndle), and 7 × 7 kernel (right).\\nIn order to average blur an image, we use the cv2.blur\\nfunction. This function requires two arguments: the image\\nwe want to blur and the size of the kernel. As Lines 13-15\\nshow, we blur our image with increasing-sized kernels. The\\nlarger our kernel becomes, the more blurred our image will\\nappear.\\nWe make use of the np.hstack function to stack our out-\\nput images together. This method “horizontally stacks” our\\nthree images into a row. This is useful since we don’t want\\nto create three separate windows using thecv2.imshow func-\\ntion.\\nThe output of our averaged blur can be seen in Figure 8.2.\\nThe image on the left is barely blurred, but by the time we\\nreach a kernel of size 7 × 7, we see that our T-Rex is very\\nblurry indeed. Perhaps he was running at a high speed and\\nchasing a jeep?\\n111',\n",
       " '8.2 gaussian\\nFigure 8.3: Performing Gaussian blurring with a\\n3 × 3 kernel ( left), 5 × 5 kernel ( mid-\\ndle), and 7 × 7 kernel ( right). Again,\\nour image becomes more blurred as\\nthe kernel size increases, but is less\\nblurred than the average method in\\nFigure 8.2.\\n8.2 gaussian\\nNext up, we are going to review Gaussian blurring. Gaus-\\nsian blurring is similar to average blurring, but instead of\\nusing a simple mean, we are now using a weighted mean,\\nwhere neighborhood pixels that are closer to the central\\npixel contribute more “weight” to the average.\\nThe end result is that our image is less blurred, but more\\nnaturally blurred, than using the average method discussed\\nin the previous section.\\nLet’s look at some code to perform Gaussian blurring:\\nListing 8.3: blurring.py\\n18 blurred = np.hstack([\\n19 cv2.GaussianBlur(image, (3, 3), 0),\\n112',\n",
       " '8.3 median\\n20 cv2.GaussianBlur(image, (5, 5), 0),\\n21 cv2.GaussianBlur(image, (7, 7), 0)])\\n22 cv2.imshow(\"Gaussian\", blurred)\\n23 cv2.waitKey(0)\\nHere you can see that we are making use of the cv2.\\nGaussianBlur function on Lines 19-21. The ﬁrst argument\\nto the function is the image we want to blur. Then, simi-\\nlar to cv2.blur, we provide a tuple representing our kernel\\nsize. Again, we start with a small kernel size of 3 × 3 and\\nstart to increase it.\\nThe last parameter is our σ, the standard deviation in the\\nx-axis direction. By setting this value to 0, we are instruct-\\ning OpenCV to automatically compute them based on our\\nkernel size.\\nWe can see the output of our Gaussian blur in Figure 8.3.\\nOur images have less of a blur effect than when using the\\naveraging method in Figure 8.2; however, the blur itself is\\nmore natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median',\n",
       " 'more natural due to the computation of the weighted mean,\\nrather than allowing all pixels in the kernel neighborhood\\nto have equal weight.\\n8.3 median\\nTraditionally, the median blur method has been most ef-\\nfective when removing salt-and-pepper noise. This type of\\nnoise is exactly what it sounds like: imagine taking a photo-\\ngraph, putting it on your dining room table, and sprinkling\\nsalt and pepper on top of it. Using the median blur method,\\nyou could remove the salt and pepper from your image.\\n113',\n",
       " '8.3 median\\nWhen applying a median blur, we ﬁrst deﬁne our kernel\\nsize k. Then, as in the averaging blurring method, we con-\\nsider all pixels in the neighborhood of sizek ×k. But, unlike\\nthe averaging method, instead of replacing the central pixel\\nwith the average of the neighborhood, we instead replace\\nthe central pixel with the median of the neighborhood.\\nMedian blurring is more effective at removing salt-and-\\npepper style noise from an image because each central pixel\\nis always replaced with a pixel intensity that exists in the\\nimage.\\nAveraging and Gaussian methods can compute means or\\nweighted means for the neighborhood – this average pixel\\nintensity may or may not be present in the neighborhood.\\nBut by deﬁnition, the median pixel must exist in our neigh-\\nborhood. By replacing our central pixel with a median\\nrather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([',\n",
       " 'rather than an average, we can substantially reduce noise.\\nNow, it’s time to apply our median blur:\\nListing 8.4: blurring.py\\n24 blurred = np.hstack([\\n25 cv2.medianBlur(image, 3),\\n26 cv2.medianBlur(image, 5),\\n27 cv2.medianBlur(image, 7)])\\n28 cv2.imshow(\"Median\", blurred)\\n29 cv2.waitKey(0)\\nApplying a median blur is accomplished by making a call\\nto the cv2.medianBlur function. This method takes two pa-\\nrameters: the image we want to blur and the size of our\\nkernel. On Lines 25-27, we start off with a kernel size of\\n3, then increase it to 5 and 7. The resulting blurred images\\n114',\n",
       " '8.3 median\\nFigure 8.4: Applying the median blur method to\\nour T-Rex image with increasing ker-\\nnel sizes of 3 ( left), 5 ( middle), and\\n7 ( right), respectively. Notice that\\nwe are no longer creating a “motion\\nblur”.\\nare then stacked and displayed to us.\\nOur median blurred images can be seen in Figure 8.4.\\nNotice that we are no longer creating a “motion blur” ef-\\nfect like in averaging and Gaussian blurring – instead, we\\nare removing detail and noise.\\nFor example, take a look at the color of the scales of the\\nT-Rex. As our kernel size increases, the scales become less\\npronounced. The black and brown stripes on the legs and\\ntail of the T-Rex especially lose their detail, all without cre-\\nating a motion blur.\\n115',\n",
       " '8.4 bilateral\\n8.4 bilateral\\nThe last method we are going to explore is bilateral blur-\\nring.\\nThus far, the intention of our blurring methods has been\\nto reduce noise and detail in an image; however, we tend to\\nlose edges in the image.\\nIn order to reduce noise while still maintaining edges, we\\ncan use bilateral blurring. Bilateral blurring accomplishes\\nthis by introducing two Gaussian distributions.\\nThe ﬁrst Gaussian function only considers spatial neigh-\\nbors, that is, pixels that appear close together in the (x, y)\\ncoordinate space of the image. The second Gaussian then\\nmodels the pixel intensity of the neighborhood, ensuring\\nthat only pixels with similar intensity are included in the\\nactual computation of the blur.\\nOverall, this method is able to preserve edges of an im-\\nage, while still reducing noise. The largest downside to this\\nmethod is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py',\n",
       " 'method is that it is considerably slower than its averaging,\\nGaussian, and median blurring counterparts.\\nLet’s look at some code:\\nListing 8.5: blurring.py\\n30 blurred = np.hstack([\\n31 cv2.bilateralFilter(image, 5, 21, 21),\\n32 cv2.bilateralFilter(image, 7, 31, 31),\\n33 cv2.bilateralFilter(image, 9, 41, 41)])\\n34 cv2.imshow(\"Bilateral\", blurred)\\n35 cv2.waitKey(0)\\n116',\n",
       " '8.4 bilateral\\nFigure 8.5: Applying Bilateral blurring to our\\nbeach image. As the diameter of the\\nneighborhood, color σ, and space σ\\nincreases (from left to right), our im-\\nage has noise removed, yet still re-\\ntains edges and does not appear to\\nbe “motion blurred”.\\nWe apply bilateral blurring by calling thecv2.bilateralFil\\nter function on Lines 31-33. The ﬁrst parameter we supply\\nis the image we want to blur. Then, we need to deﬁne the\\ndiameter of our pixel neighborhood. The third argument\\nis our color σ. A larger value for color σ means that more\\ncolors in the neighborhood will be considered when com-\\nputing the blur. Finally, we need to supply the space σ. A\\nlarger value of space σ means that pixels farther out from\\nthe central pixel will inﬂuence the blurring calculation, pro-\\nvided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be',\n",
       " 'vided that their colors are similar enough.\\nWe obtain three separate results by increasing the neigh-\\nborhood sizes, color σ, and space σ. These results can be\\nseen in Figure 8.5. As the size of our parameters increases,\\nour image has noise removed, yet the edges still remain.\\n117',\n",
       " '8.4 bilateral\\nNow that we know how to blur our images, we can move\\non to thresholding in the next chapter. You can be sure that\\nwe’ll make use of blurring throughout the rest of this book!\\nFurther Reading\\nOne topic that I didn’t get a chance to cover in detail in-\\nside Practical Python and OpenCV is the convolution op-\\neration. Whether you are smoothing an image, sharp-\\nening details, or detecting edges, convolutions are being\\napplied.\\nTo learn more convolutions, and the role they play in\\ncomputer vision, image processing, and deep learning,\\nbe sure to refer to the Chapter 8 supplementary mate-\\nrial:\\nhttp://pyimg.co/y454z\\n118',\n",
       " '9\\nT H R E S H O L D I N G\\nThresholding is the binarization of an image. In general,\\nwe seek to convert a grayscale image to a binary image,\\nwhere the pixels are either 0 or 255.\\nA simple thresholding example would be selecting a pixel\\nvalue p, and then setting all pixel intensities less than p to\\nzero, and all pixel values greater than p to 255. In this way,\\nwe are able to create a binary representation of the image.\\nNormally, we use thresholding to focus on objects or ar-\\neas of particular interest in an image. In the examples in the\\nsections below, we will empty our pockets and look at our\\nspare change. Using thresholding methods, we’ll be able to\\nﬁnd the coins in an image.\\n9.1 simple thresholding\\nApplying simple thresholding methods requires human in-\\ntervention. We must specify a threshold value T. All pixel\\nintensities below T are set to 0. And all pixel intensities\\ngreater than T are set to 255.\\n119',\n",
       " '9.1 simple thresholding\\nWe can also apply the inverse of this binarization by set-\\nting all pixels below T to 255 and all pixel intensities greater\\nthan T to 0.\\nLet’s explore some code to apply simple thresholding\\nmethods:\\nListing 9.1: simple_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\nOn Lines 1-10 we import our packages, parse our argu-\\nments, and load our image. From there, we convert the\\nimage from the RGB color space to grayscale on Line 11.\\nAt this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.',\n",
       " 'At this point, we apply Gaussian blurring on Line 12\\nwith a σ = 5 radius. Applying Gaussian blurring helps re-\\nmove some of the high frequency edges in the image that\\nwe are not concerned with.\\nListing 9.2: simple_thresholding.py\\n14 (T, thresh) = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\\n15 cv2.imshow(\"Threshold Binary\", thresh)\\n16\\n17 (T, threshInv) = cv2.threshold(blurred, 155, 255, cv2.\\nTHRESH_BINARY_INV)\\n120',\n",
       " '9.1 simple thresholding\\nFigure 9.1: Top-Left: The original coins image in\\ngrayscale. Top-Right: Applying sim-\\nple binary thresholding. The coins\\nare shown in black and the back-\\nground in white. Bottom-Left: Apply-\\ning inverse binary thresholding. The\\ncoins are now white and the back-\\nground is black. Bottom-Right: Ap-\\nplying the inverse binary threshold\\nas a mask to the grayscale image. We\\nare now focused on only the coins in\\nthe image.\\n121',\n",
       " '9.1 simple thresholding\\n18 cv2.imshow(\"Threshold Binary Inverse\", threshInv)\\n19\\n20 cv2.imshow(\"Coins\", cv2.bitwise_and(image, image, mask =\\nthreshInv))\\n21 cv2.waitKey(0)\\nAfter the image is blurred, we compute the thresholded\\nimage on Line 14 using the cv2.threshold function. This\\nmethod requires four arguments. The ﬁrst is the grayscale\\nimage that we wish to threshold. We supply our blurred\\nimage here.\\nThen, we manually supply our T threshold value. We\\nuse a value of T = 155.\\nOur third argument is our maximum value applied dur-\\ning thresholding. Any pixel intensity p that is greater than\\nT, is set to this value. In our example, any pixel value that\\nis greater than 155 is set to 255. Any value that is less than\\n155 is set to zero.\\nFinally, we must provide a thresholding method. We use\\nthe cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst',\n",
       " 'the cv2.THRESH_BINARY method, which indicates that pixel\\nvalues p greater than T are set to the maximum value (the\\nthird argument).\\nThe cv2.threshold function returns two values. The ﬁrst\\nis T, the value we manually speciﬁed for thresholding. The\\nsecond is our actual thresholded image.\\nWe then show our thresholded image in Figure 9.1, Top-\\nRight. We can see that our coins are now black pixels and\\nthe white pixels are the background.\\n122',\n",
       " '9.2 adaptive thresholding\\nOn Line 17 we apply inverse thresholding rather than\\nnormal thresholding by using cv2.THRESH_BINARY_INV as\\nour thresholding method. As we can see in Figure 9.1,\\nBottom-Left, our coins are now white and the background\\nis black. This is convenient as we will see in a second.\\nThe last task we are going to perform is to reveal the\\ncoins in the image and hide everything else.\\nRemember when we discussed masking? That will come\\nin handy here.\\nOn Line 20 we perform masking by using thecv2.bitwise_\\nand function. We supply our original coin image as the ﬁrst\\ntwo arguments, and then our inverted thresholded image as\\nour mask. Remember, a mask only considers pixels in the\\noriginal image where the mask is greater than zero. Since\\nour inverted thresholded image on Line 17 does a good job\\nat approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our',\n",
       " 'at approximating the areas the coins are contained in, we\\ncan use this inverted thresholded image as our mask.\\nFigure 9.1, Bottom-Right, shows the result of applying our\\nmask – the coins are clearly revealed while the rest of the\\nimage is hidden.\\n9.2 adaptive thresholding\\nOne of the downsides of using simple thresholding meth-\\nods is that we need to manually supply our threshold value\\nT. Not only does ﬁnding a good value of T require a lot of\\nmanual experiments and parameter tunings, it’s not very\\n123',\n",
       " '9.2 adaptive thresholding\\nFigure 9.2: Left: The grayscale coins image. Mid-\\ndle: Applying adaptive thresholding\\nusing mean neighborhood values.\\nRight: Applying adaptive threshold-\\ning using Gaussian neighborhood\\nvalues.\\nhelpful if the image exhibits a lot of range in pixel intensi-\\nties.\\nSimply put, having just one value of T might not sufﬁce.\\nIn order to overcome this problem, we can use adap-\\ntive thresholding, which considers small neighbors of pixels\\nand then ﬁnds an optimal threshold value T for each neigh-\\nbor. This method allows us to handle cases where there\\nmay be dramatic ranges of pixel intensities and the optimal\\nvalue of T may change for different parts of the image.\\nLet’s go ahead and jump into some code that applies\\nadaptive thresholding:\\n124',\n",
       " '9.2 adaptive thresholding\\nListing 9.3: adaptive_thresholding.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Image\", image)\\n14\\n15 thresh = cv2.adaptiveThreshold(blurred, 255,\\n16 cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\\n17 cv2.imshow(\"Mean Thresh\", thresh)\\n18\\n19 thresh = cv2.adaptiveThreshold(blurred, 255,\\n20 cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 3)\\n21 cv2.imshow(\"Gaussian Thresh\", thresh)\\n22 cv2.waitKey(0)\\nLines 1-10 once again handle setting up our example. We\\nimport our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it',\n",
       " 'import our packages, construct our argument parser, and\\nload the image. Just as in our simple thresholding example\\nabove, we then convert the image to grayscale and blur it\\nslightly on Lines 11 and 12.\\nWe then apply adaptive thresholding to our blurred im-\\nage using the cv2.adaptiveThreshold function on Line 15.\\nThe ﬁrst parameter we supply is the image we want to\\nthreshold. Then, we supply our maximum value of 255,\\nsimilar to simple thresholding mentioned above.\\nThe third argument is our method to compute the thresh-\\nold for the current neighborhood of pixels. By supplying\\ncv2.ADAPTIVE_THRESH_MEAN_C, we indicate that we want to\\ncompute the mean of the neighborhood of pixels and treat\\n125',\n",
       " '9.2 adaptive thresholding\\nit as our T value.\\nNext, we need our thresholding method. Again, the de-\\nscription of this parameter is identical to the simple thresh-\\nolding method mentioned above. We usecv2.THRESH_BINAR\\nY_INV to indicate that any pixel intensity greater than T in\\nthe neighborhood should be set to 255, otherwise it should\\nbe set to 0.\\nThe next parameter is our neighborhood size. This inte-\\nger value must be odd and indicates how large our neigh-\\nborhood of pixels is going to be. We supply a value of 11,\\nindicating that we are going to examine 11 × 11 pixel re-\\ngions of the image, instead of trying to threshold the image\\nglobally, as in simple thresholding methods.\\nFinally, we supply a parameter simply called C. This\\nvalue is an integer that is subtracted from the mean, allow-\\ning us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.',\n",
       " 'ing us to ﬁne-tune our thresholding. We use C = 4 in this\\nexample.\\nThe results of applying mean weighted adaptive thresh-\\nolding can be seen in the middle image of Figure 9.2.\\nBesides applying standard mean thresholding, we can\\nalso apply Gaussian (weighted mean) thresholding, as we\\ndo on Line 19. The order of the parameters are identical to\\nLine 15, but now we are tuning a few of the values.\\nInstead of supplying a value of cv2.ADAPTIVE_THRESH_\\nMEAN_C, we instead use cv2.ADAPTIVE_THRESH_GAUSSIAN_C\\nto indicate we want to use the weighted mean. We are\\nalso using a 15 × 15 pixel neighborhood size rather than\\n126',\n",
       " '9.3 otsu and riddler -calvard\\nan 11 × 11 neighborhood size as in the previous example.\\nWe also alter our C value (the value we subtract from the\\nmean) slightly and use 3 rather than 4.\\nThe results of applying Gaussian adaptive thresholding\\ncan be seen in the right image of Figure 9.2. There is little\\ndifference between the two images.\\nIn general, choosing between mean adaptive threshold-\\ning and Gaussian adaptive thresholding requires a few ex-\\nperiments on your end. The most important parameters\\nto vary are the neighborhood size and C, the value you\\nsubtract from the mean. By experimenting with this value,\\nyou will be able to dramatically change the results of your\\nthresholding.\\n9.3 otsu and riddler -calvard\\nAnother way we can automatically compute the threshold\\nvalue of T is to use Otsu’s method.\\nOtsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.',\n",
       " 'Otsu’s method assumes there are two peaks in the grayscale\\nhistogram of the image. It then tries to ﬁnd an optimal\\nvalue to separate these two peaks – thus our value of T.\\nWhile OpenCV provides support for Otsu’s method, I\\nprefer the implementation by Luis Pedro Coelho in themahotas\\npackage since it is more Pythonic.\\nLet’s jump into some sample code:\\n127',\n",
       " '9.3 otsu and riddler -calvard\\nListing 9.4: otsu_and_riddler.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import mahotas\\n5 import cv2\\n6\\n7 ap = argparse.ArgumentParser()\\n8 ap.add_argument(\"-i\", \"--image\", required = True,\\n9 help = \"Path to the image\")\\n10 args = vars(ap.parse_args())\\n11\\n12 image = cv2.imread(args[\"image\"])\\n13 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n14 blurred = cv2.GaussianBlur(image, (5, 5), 0)\\n15 cv2.imshow(\"Image\", image)\\n16\\n17 T = mahotas.thresholding.otsu(blurred)\\n18 print(\"Otsu’s threshold: {}\".format(T))\\nOn Lines 1-5 we import the packages we will utilize. We\\nhave seen numpy, argparse, and cv2 before. We are now\\nintroducing mahotas, another image processing package.\\nLines 7-12 then handle our standard practice of parsing\\narguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-',\n",
       " 'arguments and loading our image.\\nAs in previous thresholding examples, we convert the im-\\nage to grayscale and then blur it slightly.\\nTo compute our optimal value of T, we use the otsu func-\\ntion in the mahotas.thresholding package. As our output\\nwill later show us, Otsu’s method ﬁnds a value of T = 137\\nthat we will use for thresholding.\\nListing 9.5: otsu_and_riddler.py\\n19 thresh = image.copy()\\n20 thresh[thresh > T] = 255\\n128',\n",
       " '9.3 otsu and riddler -calvard\\n21 thresh[thresh < 255] = 0\\n22 thresh = cv2.bitwise_not(thresh)\\n23 cv2.imshow(\"Otsu\", thresh)\\n24\\n25 T = mahotas.thresholding.rc(blurred)\\n26 print(\"Riddler-Calvard: {}\".format(T))\\n27 thresh = image.copy()\\n28 thresh[thresh > T] = 255\\n29 thresh[thresh < 255] = 0\\n30 thresh = cv2.bitwise_not(thresh)\\n31 cv2.imshow(\"Riddler-Calvard\", thresh)\\n32 cv2.waitKey(0)\\nApplying the thresholding is accomplished on Lines 19-\\n22. First, we make a copy of our grayscale image so that we\\nhave an image to threshold. Line 20 then makes any values\\ngreater than T white, whereas Line 21 makes all remaining\\npixels that are not white into black pixels. We then invert\\nour threshold by using cv2.bitwise_not. This is equivalent\\nto applying a cv2.THRESH_BINARY_INV thresholding type as\\nin previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.',\n",
       " 'in previous examples in this chapter.\\nThe results of Otsu’s method can be seen in the middle\\nimage of Figure 9.3. We can clearly see that the coins in the\\nimage have been highlighted.\\nAnother method to keep in mind when ﬁnding optimal\\nvalues for T is the Riddler-Calvard method. Just as in\\nOtsu’s method, the Riddler-Calvard method also computes\\nan optimal value of 137 for T. We apply this method on\\nLine 25 using the rc function in mahotas.thresholding. Fi-\\nnally, the actual thresholding of the image takes place on\\nLines 27-30, as in the previous example. Given that the\\nvalues of T are identical for Otsu and Riddler-Calvard, the\\nthresholded image in Figure 9.3 (right) is identical to the\\nthresholded image in the center.\\n129',\n",
       " '9.3 otsu and riddler -calvard\\nFigure 9.3: Left: The original grayscale coins\\nimage. Middle: Applying Otsu’s\\nmethod to ﬁnd an optimal value of T.\\nRight: Applying the Riddler-Calvard\\nmethod to ﬁnd an optimal value of\\nT.\\nListing 9.6: otsu_and_riddler.py\\nOtsu’s threshold: 137\\nRiddler-Calvard: 137\\nNow that we have explored thresholding, we will move\\non to another powerful image processing technique – edge\\ndetection.\\n130',\n",
       " '9.3 otsu and riddler -calvard\\nFurther Reading\\nThresholding is often used as a method to segment the\\nforeground of an image from the background. This\\nworks ﬁne for foreground objects that can be cleanly\\nsegmented. But what if your foreground objects “touch”,\\nthereby making segmentation more difﬁcult. What do\\nyou do then?\\nThe answer is to apply the watershed algorithm, which I\\ncover inside the Chapter 9 supplementary material:\\nhttp://pyimg.co/z1ef6\\n131',\n",
       " '10\\nG R A D I E N T S A N D E D G E D E T E C T I O N\\nThis chapter is primarily concerned with gradients and\\nedge detection. Formally, edge detection embodies math-\\nematical methods to ﬁnd points in an image where the\\nbrightness of pixel intensities changes distinctly.\\nThe ﬁrst thing we are going to do is ﬁnd the “gradient” of\\nthe grayscale image, allowing us to ﬁnd edge-like regions\\nin the x and y direction.\\nWe’ll then apply Canny edge detection, a multi-stage pro-\\ncess of noise reduction (blurring), ﬁnding the gradient of\\nthe image (utilizing the Sobel kernel in both the horizon-\\ntal and vertical direction), non-maximum suppression, and\\nhysteresis thresholding.\\nIf that sounds like a mouthful, it’s because it is. Again,\\nwe won’t jump too far into the details since this book is con-\\ncerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the',\n",
       " 'cerned with practical examples of computer vision; how-\\never, if you are interested in the mathematics behind gradi-\\nents and edge detection, I encourage you to read up on the\\nalgorithms. Overall, they are not complicated and can be\\n132',\n",
       " '10.1 laplacian and sobel\\nFigure 10.1: Left: The original coins image.\\nRight: Applying the Laplacian\\nmethod to obtain the gradient of the\\nimage.\\ninsightful to the behind-the-scenes action of OpenCV .\\n10.1 laplacian and sobel\\nLet’s go ahead and explore some code:\\nListing 10.1: sobel_and_laplacian.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 cv2.imshow(\"Original\", image)\\n133',\n",
       " '10.1 laplacian and sobel\\n13\\n14 lap = cv2.Laplacian(image, cv2.CV_64F)\\n15 lap = np.uint8(np.absolute(lap))\\n16 cv2.imshow(\"Laplacian\", lap)\\n17 cv2.waitKey(0)\\nLines 1-8 import our packages and set up our argument\\nparser. From there, we load our image and convert it to\\ngrayscale on Lines 10 and 11. When computing gradients\\nand edges, we (normally) compute them on a single chan-\\nnel – in this case, we are using the grayscale image; how-\\never, we can also compute gradients for each channel of\\nthe RGB image. For the sake of simplicity, let’s stick with\\nthe grayscale image since that is what you will use in most\\ncases.\\nOn Line 14, we use the Laplacian method to compute the\\ngradient magnitude image by calling the cv2.Laplacian\\nfunction. The ﬁrst argument is our grayscale image – the\\nimage we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-',\n",
       " 'image we want to compute the gradient magnitude repre-\\nsentation for. The second argument is our data type for the\\noutput image.\\nThroughout this book, we have mainly used 8-bit un-\\nsigned integers. Why are we using a 64-bit ﬂoat now?\\nThe reason involves the transition of black-to-white and\\nwhite-to-black in the image.\\nTransitioning from black-to-white is considered a posi-\\ntive slope, whereas a transition from white-to-black is a\\nnegative slope. If you remember our discussion of image\\narithmetic in Chapter 6, you’ll know that an 8-bit unsigned\\ninteger does not represent negative values. Either it will be\\nclipped to zero if you are using OpenCV or a modulus op-\\n134',\n",
       " '10.1 laplacian and sobel\\neration will be performed using NumPy.\\nThe short answer here is that if you don’t use a ﬂoating\\npoint data type when computing the gradient magnitude\\nimage, you will miss edges, speciﬁcally the white-to-black\\ntransitions.\\nIn order to ensure you catch all edges, use a ﬂoating point\\ndata type, then take the absolute value of the gradient im-\\nage and convert it back to an 8-bit unsigned integer, as in\\nLine 15. This is deﬁnitely an important technique to take\\nnote of – otherwise you’ll be missing edges in your image!\\nTo see the results of our gradient processing, take a look\\nat Figure 10.1.\\nLet’s move on to computing the Sobel gradient represen-\\ntation:\\nListing 10.2: sobel_and_laplacian.py\\n18 sobelX = cv2.Sobel(image, cv2.CV_64F, 1, 0)\\n19 sobelY = cv2.Sobel(image, cv2.CV_64F, 0, 1)\\n20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)',\n",
       " '20\\n21 sobelX = np.uint8(np.absolute(sobelX))\\n22 sobelY = np.uint8(np.absolute(sobelY))\\n23\\n24 sobelCombined = cv2.bitwise_or(sobelX, sobelY)\\n25\\n26 cv2.imshow(\"Sobel X\", sobelX)\\n27 cv2.imshow(\"Sobel Y\", sobelY)\\n28 cv2.imshow(\"Sobel Combined\", sobelCombined)\\n29 cv2.waitKey(0)\\nUsing the Sobel operator, we can compute gradient mag-\\nnitude representations along the x and y axis, allowing us\\n135',\n",
       " '10.1 laplacian and sobel\\nFigure 10.2: Top-Left: The original coins image.\\nTop-Right: Computing the Sobel gra-\\ndient magnitude along the x-axis\\n(ﬁnding vertical edges). Bottom-\\nLeft: Computing the Sobel gradient\\nalong the y-axis (ﬁnding horizontal\\nedges). Bottom-Right: Applying a\\nbitwise OR to combine the two So-\\nbel representations.\\n136',\n",
       " '10.1 laplacian and sobel\\nto ﬁnd both horizontal and vertical edge-like regions.\\nIn fact, that’s exactly what Lines 18 and 19 do by us-\\ning the cv2.Sobel method. The ﬁrst argument to the Sobel\\noperator is the image we want to compute the gradient rep-\\nresentation for. Then, just like in the Laplacian example\\nabove, we use a ﬂoating point data type. The last two argu-\\nments are the order of the derivatives in the x and y direc-\\ntion, respectively. Specify a value of 1 and 0 to ﬁnd vertical\\nedge-like regions and 0 and 1 to ﬁnd horizontal edge-like\\nregions\\nOn Lines 21 and 22 we then ensure we ﬁnd all edges by\\ntaking the absolute value of the ﬂoating point image and\\nthen converting it to an 8-bit unsigned integer.\\nIn order to combine the gradient images in both the x\\nand y direction, we can apply a bitwise OR. Remember, an\\nOR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.',\n",
       " 'OR operation is true when either pixel is greater than zero.\\nTherefore, a given pixel will be True if either a horizontal\\nor vertical edge is present.\\nFinally, we show our gradient images on Lines 26-29.\\nYou can see the result of our work in Figure 10.2. We\\nstart with our original image, Top-Left, and then ﬁnd vertical\\nedges, Top-Right, and horizontal edges, Bottom-Left. Finally,\\nwe compute a bitwise OR to combine the two directions\\ninto a single image, Bottom-Right.\\nOne thing you’ll notice is that the edges are very “noisy”.\\nThey are not clean and crisp. We’ll remedy that by using\\n137',\n",
       " '10.2 canny edge detector\\nFigure 10.3: Left: Our coins image in grayscale\\nand blurred slightly. Right: Apply-\\ning the Canny edge detector to the\\nblurred image to ﬁnd edges. No-\\ntice how our edges are more “crisp”\\nand the outlines of the coins are\\nfound.\\nthe Canny edge detector in the next section.\\n10.2 canny edge detector\\nThe Canny edge detector is a multi-step process. It involves\\nblurring the image to remove noise, computing Sobel gradi-\\nent images in the x and y direction, suppressing edges, and\\nﬁnally a hysteresis thresholding stage that determines if a\\npixel is “edge-like” or not.\\n138',\n",
       " '10.2 canny edge detector\\nWe won’t get into all these steps in detail. Instead, we’ll\\njust look at some code and show how it’s done:\\nListing 10.3: canny.py\\n1 import numpy as np\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\n11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n12 image = cv2.GaussianBlur(image, (5, 5), 0)\\n13 cv2.imshow(\"Blurred\", image)\\n14\\n15 canny = cv2.Canny(image, 30, 150)\\n16 cv2.imshow(\"Canny\", canny)\\n17 cv2.waitKey(0)\\nThe ﬁrst thing we do is import our packages and parse\\nour arguments. We then load our image, convert it to graysc-\\nale, and blur it using the Gaussian blurring method. By ap-\\nplying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.',\n",
       " 'plying a blur prior to edge detection, we will help remove\\n“noisy” edges in the image that are not of interest to us.\\nOur goal here is to ﬁnd only the outlines of the coins.\\nApplying the Canny edge detector is performed on Line\\n15 using the cv2.Canny function. The ﬁrst argument we\\nsupply is our blurred, grayscale image. Then, we need to\\nprovide two values: threshold1 and threshold2.\\nAny gradient value larger than threshold2 is considered\\nto be an edge. Any value below threshold1 is consid-\\nered not to be an edge. Values in between threshold1\\nand threshold2 are either classiﬁed as edges or non-edges\\n139',\n",
       " '10.2 canny edge detector\\nbased on how their intensities are “connected”. In this case,\\nany gradient values below 30 are considered non-edges wh-\\nereas any values above 150 are considered edges.\\nWe then show the results of our edge detection on Line\\n16.\\nFigure 10.3 shows the results of the Canny edge detector.\\nThe image on the left is the grayscale, blurred image that\\nwe pass into the Canny operator. The image on the right is\\nthe result of applying the Canny operator.\\nNotice how the edges are more “crisp”. We have substan-\\ntially less noise than when we used the Laplacian or Sobel\\ngradient images. Furthermore, the outline of our coins are\\nclearly revealed.\\nIn the next chapter, we’ll continue to make use of the\\nCanny edge detector and use it to count the number of\\ncoins in our image.\\n140',\n",
       " '10.2 canny edge detector\\nFurther Reading\\nJust like thresholding is a common method for seg-\\nmenting foreground objects from background objects,\\nthe same can be said for edge detection – only instead\\nof obtaining a large blob representing the foreground,\\nthe Canny detector gives us the outline.\\nHowever, a common challenge of using the Canny edge\\ndetector is getting the lower and upper edge thresh-\\nolds just right. In order to help you (automatically)\\ndetermine these lower and upper boundaries, be sure\\nto read about the automatic Canny edge detector in this\\nsupplementary material:\\nhttp://pyimg.co/91daw\\n141',\n",
       " '11\\nC O N T O U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in the curve. Contours are extremely useful for such\\nthings as shape approximation and analysis.\\nIn order to ﬁnd contours in an image, you need to ﬁrst ob-\\ntain a binarization of the image, using either edge detection\\nmethods or thresholding. In the examples below, we’ll use\\nthe Canny edge detector to ﬁnd the outlines of the coins,\\nand then ﬁnd the actual contours of the coins.\\nReady?\\nHere we go:\\n11.1 counting coins\\n142',\n",
       " '11.1 counting coins\\nListing 11.1: counting_coins.py\\n1 from __future__ import print_function\\n2 import numpy as np\\n3 import argparse\\n4 import cv2\\n5\\n6 ap = argparse.ArgumentParser()\\n7 ap.add_argument(\"-i\", \"--image\", required = True,\\n8 help = \"Path to the image\")\\n9 args = vars(ap.parse_args())\\n10\\n11 image = cv2.imread(args[\"image\"])\\n12 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n13 blurred = cv2.GaussianBlur(gray, (11, 11), 0)\\n14 cv2.imshow(\"Image\", image)\\n15\\n16 edged = cv2.Canny(blurred, 30, 150)\\n17 cv2.imshow(\"Edges\", edged)\\nThe ﬁrst 11 lines of code simply set up our environment\\nby importing packages, parsing arguments, and loading the\\nimage.\\nJust as in the edge detection methods discussed in the\\nprevious chapter, we are going to convert our image to\\ngrayscale and then apply a Gaussian blur, making it eas-\\nier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.',\n",
       " 'ier for the edge detector to ﬁnd the outline of the coins. We\\nuse a much larger blurring size this time, with σ = 11. All\\nthis is handled on Lines 11-13.\\nWe then obtain the edged image by applying the Canny\\nedge detector on Line 16. Again, just as in previous edge\\ndetection examples, any gradient values below 30 are con-\\nsidered non-edges whereas any values above 150 are con-\\nsidered sure edges.\\nListing 11.2: counting_coins.py\\n143',\n",
       " '11.1 counting coins\\n18 (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2\\n.CHAIN_APPROX_SIMPLE)\\n19\\n20 print(\"I count {} coins in this image\".format(len(cnts)))\\n21\\n22 coins = image.copy()\\n23 cv2.drawContours(coins, cnts, -1, (0, 255, 0), 2)\\n24 cv2.imshow(\"Coins\", coins)\\n25 cv2.waitKey(0)\\nNow that we have the outlines of the coins, we can ﬁnd\\nthe contours of the outlines. We do this using the cv2.\\nfindContours function on Line 18. This method returns\\na 3-tuple of: ( 1) our image after applying contour detec-\\ntion (which is modiﬁed and essentially destroyed), ( 2) the\\ncontours themselves, cnts, and (3) the hierarchy of the con-\\ntours (see below).\\nThe ﬁrst argument to cv2.findContours is our edged im-\\nage. It’s important to note that this function is destructive\\nto the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.',\n",
       " 'to the image you pass in. If you intend using that image\\nlater on in your code, it’s best to make a copy of it, using\\nthe NumPy copy method.\\nThe second argument is the type of contours we want.\\nWe use cv2.RETR_EXTERNAL to retrieve only the outermost\\ncontours (i.e., the contours that follow the outline of the\\ncoin). We can also pass in cv2.RETR_LIST to grab all con-\\ntours. Other methods include hierarchical contours using\\ncv2.RETR_COMP and cv2.RETR_TREE, but hierarchical con-\\ntours are outside the scope of this book.\\nOur last argument is how we want to approximate the\\ncontour. We use cv2.CHAIN_APPROX_SIMPLE to compress\\nhorizontal, vertical, and diagonal segments into their end-\\npoints only. This saves both computation and memory. If\\n144',\n",
       " '11.1 counting coins\\nwe wanted all the points along the contour, without com-\\npression, we can pass in cv2.CHAIN_APPROX_NONE; however,\\nbe very sparing when using this function. Retrieving all\\npoints along a contour is often unnecessary and is wasteful\\nof resources.\\nOur contours cnts is simply a Python list. We can use\\nthe len function on it to count the number of contours that\\nwere returned. We do this on Line 20 to show how many\\ncontours we have found.\\nWhen we execute our script, we will have the output “I\\ncount 9 coins in this image” printed out to our console.\\nNow, we are able to draw our contours. In order not to\\ndraw on our original image, we make a copy of the original\\nimage, called coins on Line 22.\\nA call to cv2.drawContours draws the actual contours on\\nour image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative',\n",
       " 'our image. The ﬁrst argument to the function is the image\\nwe want to draw on. The second is our list of contours.\\nNext, we have the contour index. By specifying a negative\\nvalue of −1, we are indicating that we want to draw all of\\nthe contours. However, we would also supply an index i,\\nwhich would be the i’th contour in cnts. This would allow\\nus to draw only a single contour rather than all of them.\\nFor example, here is some code to draw the ﬁrst, second,\\nand third contours, respectively:\\nListing 11.3: Drawing Contours via an Index\\n1 cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)\\n145',\n",
       " '11.1 counting coins\\n2 cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)\\n3 cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)\\nThe fourth argument to the cv2.drawContours function\\nis the color of the line we are going to draw. Here, we use\\na green color.\\nFinally, our last argument is the thickness of the line we\\nare drawing. We’ll draw the contour with a thickness of\\ntwo pixels.\\nNow that our contours are drawn on the image, we can\\nvisualize them on Line 24.\\nTake a look at Figure 11.1 to see the results of our work.\\nOn the left is our original image. Then, we apply Canny\\nedge detection to ﬁnd the outlines of the coins ( middle). Fi-\\nnally, we ﬁnd the contours of the coin outlines and draw\\nthem. You can see that each contour has been drawn with\\na two-pixel thick green line.\\nBut we’re not done yet!\\nLet’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))',\n",
       " 'Let’s crop each individual coin from the image:\\nListing 11.4: counting_coins.py\\n26 for (i, c) in enumerate(cnts):\\n27 (x, y, w, h) = cv2.boundingRect(c)\\n28\\n29 print(\"Coin #{}\".format(i + 1))\\n30 coin = image[y:y + h, x:x + w]\\n31 cv2.imshow(\"Coin\", coin)\\n32\\n33 mask = np.zeros(image.shape[:2], dtype = \"uint8\")\\n34 ((centerX, centerY), radius) = cv2.minEnclosingCircle(c)\\n146',\n",
       " '11.1 counting coins\\nFigure 11.1: Left: The original coin image. Mid-\\ndle: Applying the Canny edge detec-\\ntor to ﬁnd the outlines of the coins.\\nRight: Finding the contours of the\\ncoin outlines and then drawing the\\ncontours. We have now success-\\nfully found the coins and are able\\nto count them.\\n147',\n",
       " '11.1 counting coins\\n35 cv2.circle(mask, (int(centerX), int(centerY)), int(radius),\\n255, -1)\\n36 mask = mask[y:y + h, x:x + w]\\n37 cv2.imshow(\"Masked Coin\", cv2.bitwise_and(coin, coin, mask =\\nmask))\\n38 cv2.waitKey(0)\\nWe start off on Line 26 by looping over our contours.\\nWe then use the cv2.boundingRect function on the cur-\\nrent contour. This method ﬁnds the “enclosing box” that\\nour contour will ﬁt into, allowing us to crop it from the\\nimage. The function takes a single parameter, a contour,\\nand then returns a tuple of the x and y position that the\\nrectangle starts at, followed by the width and height of the\\nrectangle.\\nWe then crop the coin from the image using our bound-\\ning box coordinates and NumPy array slicing on Line 30.\\nThe coin itself is shown to us on Line 31.\\nIf we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array',\n",
       " 'If we can ﬁnd the bounding box of a contour, why not ﬁt\\na circle to the contour as well? Coins are circles, after all.\\nWe ﬁrst initialize our mask on Line 33 as a NumPy array\\nof zeros, with the same width and height of our original\\nimage.\\nA call to cv2.minEnclosingCircle on Line 34 ﬁts a circle\\nto our contour. We pass in a circle variable, the current\\ncontour, and are given the x and y coordinates of the circle,\\nalong with its radius.\\nUsing the (x, y) coordinates and the radius, we can draw\\na circle on our mask, representing the coin. Drawing circles\\n148',\n",
       " '11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work. The\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!',\n",
       " 'ages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2 contours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149',\n",
       " '11.2 contours and opencv version caveats\\nFigure 11.2: Top: Cropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing. Bottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150',\n",
       " '11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, thegrab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6 if len(cnts) == 2:\\n7 cnts = cnts[0]\\n8\\n9 elif len(cnts) == 3:\\n10 cnts = cnts[1]\\n11\\n12 else:\\n13 raise Exception((\"Contours tuple must have length 2 or \"\\n14 \"3, otherwise OpenCV changed their cv2.findContours \"\\n15 \"return signature yet again. Refer to OpenCV’s\\n16 documentation in that case.\"))\\n17\\n18 return cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)',\n",
       " '1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)\\nOn Line 1 we call the cv2.findContours function to de-\\ntect contours in an image.\\nFrom there, Line 2 utilizes the grab_contours function\\nto inspect the tuple returned by cv2.findContours and ex-\\n151',\n",
       " '11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-',\n",
       " 'a clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplementary material for this chap-\\nter – be sure to take a look:\\nhttp://pyimg.co/saz76\\n152',\n",
       " '12\\nW H E R E T O N O W ?\\nIn this book, we’ve explored many image processing and\\ncomputer vision techniques, including basic image process-\\ning, such as translation, rotating, and resizing. We learned\\nall about image arithmetic and how to apply bitwise op-\\nerations. Then, we explored how a simple technique like\\nmasking can be used to focus our attention and computa-\\ntion to only a single part of an image.\\nTo better understand the pixel intensity distribution of an\\nimage, we then explored histograms. We started by com-\\nputing grayscale histograms, then worked our way up to\\ncolor, including 2D and 3D color histograms. We adjusted\\nthe contrast of images using histogram equalization, then\\nmoved on to blurring our images, using different methods,\\nsuch as averaging, Gaussian, and median ﬁltering.\\nWe thresholded our images to ﬁnd objects of interest,\\nthen applied edge detection.\\nFinally we learned how to use contours to count the num-\\nber of coins in the image.\\n153',\n",
       " 'where to now ?\\nSo, where do you go from here?\\nYou continue learning, exploring, and experimenting!\\nUse the source code and images provided in this book to\\ncreate projects of your own. That’s the best way to learn!\\nIf you need project ideas, be sure to contact me. I love\\ntalking with readers and helping out when I can. You can\\nreach me at adrian@pyimagesearch.com.\\nFinally, I constantly post on my blog, www.PyImageSear\\nch.com, sharing new and interesting techniques related to\\ncomputer vision and image search engines. Be sure to fol-\\nlow the blog for new posts, as well as new books and courses\\nas I write them.\\n154',\n",
       " 'SQL-QUERIES\\nTables\\nYou\\tneed\\tto\\tcreate\\tand\\tpopulate\\tthe\\tfollowing\\ttables\\tto\\tstart\\tworking\\ton\\tthe\\nqueries.\\n1.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEmp\\ttable\\tdata',\n",
       " '2.\\t\\t\\t\\tExercises\\twith\\tAnswers\\n2.1.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tinformation\\tof\\tthe\\tEMP\\ttable?\\nA)\\tselect\\t*\\tfrom\\temp;\\n2.2.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tunique\\tJobs\\tfrom\\tEMP\\ttable?\\nA)\\t\\t\\t\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp;\\nB)\\t\\t\\t\\tselect\\tunique\\tjob\\tfrom\\temp;\\n2.3.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\ttheir\\tSalaries?\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\torder\\tby\\tsal\\tasc;\\n2.4.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tasc\\torder\\tof\\tthe\\tDptnos\\tand\\tdesc\\tof\\nJobs?\\nA)select\\t*\\tfrom\\temp\\torder\\tby\\tdeptno\\tasc,job\\tdesc;\\n2.5.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tunique\\tjob\\tgroups\\tin\\tthe\\tdescending\\torder?\\nA)select\\tdistinct\\tjob\\tfrom\\temp\\torder\\tby\\tjob\\tdesc;\\n2.6.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tall\\t‘Mgrs’\\nA)Select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(\\tselect\\t\\tmgr\\t\\tfrom\\temp)\\t;\\n2.7.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tbefore\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(’01-jan-81’);\\n2.8.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDaily\\tsal\\tof\\tall\\temps\\tin\\tthe\\tasc\\torder\\tof\\nAnnsal.\\nA)\\tselect\\tempno\\t,ename\\t,sal,sal/30,12*sal\\tannsal\\tfrom\\temp\\torder\\tby\\tannsal\\tasc;',\n",
       " '2.9.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tjob,\\tHiredate,\\tExp\\tof\\tall\\tMgrs\\t\\nA)\\tselect\\t\\tempno,ename\\t,job,hiredate,\\tmonths_between(sysdate,hiredate)\\t\\texp\\nfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n2.10.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tExp\\tof\\tall\\temps\\tworking\\tfor\\tMgr\\t7369.\\nA)\\tselect\\tempno,ename,sal,exp\\tfrom\\temp\\twhere\\tmgr\\t=\\t7369;\\n2.11.\\t\\t\\t\\t\\tDisplay\\tall\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tComm.\\tIs\\tmore\\tthan\\ttheir\\tSal.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tcomm.\\t>\\tsal;\\n2.12.\\t\\t\\t\\t\\tList\\tthe\\temps\\tin\\tthe\\tasc\\torder\\tof\\tDesignations\\tof\\tthose\\tjoined\\tafter\\tthe\\nsecond\\thalf\\tof\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t>\\t(’30-jun-81’)\\tand\\nto_char(hiredate,’YYYY’)\\t=\\t1981\\torder\\tby\\tjob\\tasc;\\n2.13.\\t\\t\\t\\t\\tList\\tthe\\temps\\talong\\twith\\ttheir\\tExp\\tand\\tDaily\\tSal\\tis\\tmore\\tthan\\tRs.100.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;',\n",
       " 'A)\\tselect\\t*\\tfrom\\temp\\twhere\\t(sal/30)\\t>100;\\n2.14.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\t‘CLERK’\\tor\\t‘ANALYST’\\tin\\tthe\\tDesc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tor\\tjob\\t=\\t‘ANALYST’\\torder\\tby\\tjob\\ndesc;\\n2.15.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\ton\\t1-MAY-81,3-DEC-81,17-DEC-81,19-JAN-\\n80\\tin\\tasc\\torder\\tof\\tseniority.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\tin\\t(’01-may-81’,’03-dec-81’,’17-dec-\\n81’,’19-jan-80’)\\t\\torder\\tby\\thiredate\\tasc;\\n2.16.\\t\\t\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tworking\\tfor\\tthe\\tDeptno\\t10\\tor20.',\n",
       " 'A)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\t\\tor\\tdeptno\\t=\\t20\\t;\\n2.17.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\thiredate\\tbetween\\t’01-jan-81’\\tand\\t’31-dec-81’;\\n2.18.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tjoined\\tin\\tthe\\tmonth\\tof\\tAug\\t1980.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-aug-80’\\tand\\t’31-aug-80’;\\t\\t\\n(OR)\\nselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon-yyyy’)\\t=’aug-1980;\\n2.19.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWho\\tAnnual\\tsal\\tranging\\tfrom\\t22000\\tand\\t45000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t12*sal\\tbetween\\t22000\\tand\\t45000;\\n2.20.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\thaving\\tfive\\tcharacters\\tin\\ttheir\\tNames.\\nA)\\tselect\\t\\tename\\tfrom\\temp\\twhere\\t\\tlength\\t(ename)\\t=\\t5;\\n2.21.\\t\\t\\t\\t\\tList\\tthe\\tEnames\\tthose\\tare\\tstarting\\twith\\t‘S’\\tand\\twith\\tfive\\tcharacters.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘S%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;',\n",
       " '2.22.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\tare\\thaving\\tfour\\tchars\\tand\\tthird\\tcharacter\\tmust\\tbe\\t‘r’.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t4\\tand\\tename\\tlike\\t‘__R%’;\\n2.23.\\t\\t\\t\\t\\tList\\tthe\\tFive\\tcharacter\\tnames\\tstarting\\twith\\t‘S’\\tand\\tending\\twith\\t‘H’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength(ename)\\t=\\t5\\tand\\tename\\tlike\\t\\t‘S%H’;\\n2.24.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tJanuary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’mon’)\\t=\\t‘jan’;\\n2.25.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\twhich\\tsecond\\tcharacter\\tis\\t‘a’.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\t\\tlike\\t‘_a_’;\\t(OR)',\n",
       " 'B)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’mon’)\\tlike\\t‘_a%’;\\n2.26.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tSal\\tis\\tfour\\tdigit\\tnumber\\tending\\twith\\tZero.\\nA)\\tselect\\t\\t*\\t\\tfrom\\t\\temp\\twhere\\t\\tlength\\t(sal)\\t=\\t4\\tand\\tsal\\tlike\\t‘%0’;\\n2.27.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\thaving\\ta\\tcharacter\\tset\\t‘ll’\\ttogether.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\t\\tename\\tlike\\t‘%LL%’;\\n2.28.\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\t80’s.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’yy’)\\t\\tlike\\t‘8%’;\\n2.29.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tdoes\\tnot\\tbelong\\tto\\tDeptno\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\tnot\\tin\\t(20);\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tdeptno\\t!=\\t20;\\t(OR)\\nC)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t<>20;\\t(OR)\\nD)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tlike\\t‘20’;\\n2.30.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\texcept\\t‘PRESIDENT’\\t&\\t‘MGR”\\tin\\tasc\\torder\\tof\\nSalaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;',\n",
       " 'Salaries.\\nSelect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tnot\\tin\\t(‘PRESIDENT’,’MANAGER’)\\t\\torder\\tby\\nsal\\t\\tasc;\\nselect\\t*\\tfrom\\temp\\twhere\\tjob\\tnot\\tlike\\t‘PRESIDENT’\\tand\\tjob\\tnot\\tlike\\n‘MANAGER’\\t\\torder\\tby\\tsal\\t\\tasc;\\nC)\\tSelect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t‘PRESIDENT’\\tand\\tjob\\t<>\\t‘MANAGER’\\t\\norder\\t\\tby\\t\\tsal\\t\\tasc;\\n2.31.\\t\\t\\t\\t\\tList\\tall\\tthe\\temps\\twho\\tjoined\\tbefore\\tor\\tafter\\t1981.',\n",
       " 'A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’YYYY’)\\t\\tnot\\tin\\t(‘1981’);\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\t(\\thiredate,’YYYY’)\\t\\t!=\\t\\t‘1981’;\\t\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t\\t<>\\t\\t‘1981’\\t;\\t(OR)\\nD)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate\\t,’YYYY’)\\t\\tnot\\tlike\\t‘1981’;\\n2.32.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tEmpno\\tnot\\tstarting\\twith\\tdigit78.\\nA)\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tnot\\tlike\\t‘78%’;\\n2.33.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tunder\\t‘MGR’.\\nA)\\tselect\\te.ename\\t||\\t‘\\tworks\\tfor\\t‘\\t||\\tm.ename\\t\\tfrom\\temp\\te\\t,emp\\tm\\twhere\\te.mgr\\t=\\nm.empno\\t;\\t\\t\\t\\t\\t\\t\\t\\t(OR)\\nB)\\tselect\\t\\te.ename\\t||\\t‘\\thas\\tan\\temployee\\t‘||\\tm.ename\\tfrom\\temp\\te\\t,\\temp\\tm\\twhere\\ne.empno\\t=\\tm.mgr;\\n2.34.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tany\\tyear\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tof\\nMarch.\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\t\\tto_char\\t(hiredate,’MON’)\\tnot\\tin\\t(‘MAR’);\\t\\t(OR)\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)',\n",
       " 'F)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MON’)\\t\\t!=\\t\\t‘MAR’;\\t(OR)\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tto_char(hiredate,’MONTH’)\\tnot\\tlike\\t‘MAR%’\\t;\\t\\n(OR)\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\t<>\\t‘MAR’;\\n2.35.\\t\\t\\t\\t\\tList\\tall\\tthe\\tClerks\\tof\\tDeptno\\t20.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\t=‘CLERK’\\tand\\tdeptno\\t=\\t20;\\n2.36.\\t\\t\\t\\t\\tList\\tthe\\temps\\tof\\tDeptno\\t30\\tor\\t10\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’\\tand\\t(deptno',\n",
       " '=30\\tor\\tdeptno\\t=10)\\t;\\t\\t(OR)\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char\\n(hiredate,’YYYY’)\\t\\tin\\t(‘1981’)\\t\\tand\\t\\t(deptno\\t=\\t30\\tor\\tdeptno\\t=10\\t)\\t;\\n2.37.\\t\\t\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tSMITH.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’\\t;\\n2.38.\\t\\t\\t\\t\\tDisplay\\tthe\\tlocation\\tof\\t\\tSMITH.\\nA)\\tselect\\tloc\\tfrom\\temp\\t\\te\\t,\\tdept\\td\\twhere\\t\\te.ename\\t=\\t‘SMITH’\\tand\\t\\te.deptno\\t=\\nd.deptno\\t;\\n2.39.\\t\\t\\t\\t\\tList\\tthe\\ttotal\\tinformation\\tof\\tEMP\\ttable\\talong\\twith\\tDNAME\\tand\\tLoc\\tof\\nall\\tthe\\temps\\tWorking\\tUnder\\t‘ACCOUNTING’\\t&\\t‘RESEARCH’\\tin\\tthe\\tasc\\nDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t(dname\\t=\\t‘ACCOUNTING’\\tor\\tdname\\n=’RESEARCH’\\t)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\tasc;\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.dname\\tin\\n(‘ACCOUNTING’,’RESEARCH’)\\tand\\te.deptno\\t=\\td.deptno\\torder\\tby\\te.deptno\\nasc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.',\n",
       " 'asc;\\n2.40.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname\\tof\\tall\\tthe\\t‘MGRS’\\tand\\t‘ANALYST’\\nworking\\tin\\tNew\\tYork,\\tDallas\\twith\\tan\\texp\\tmore\\tthan\\t7\\tyears\\twithout\\treceiving\\nthe\\tComm\\tasc\\torder\\tof\\tLoc.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,d.dname\\t\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\n(‘NEW\\tYORK’,’DALLAS’)\\tand\\te.deptno\\t=\\td.deptno\\tand\\te.empno\\tin\\t(select\\ne.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\t(‘MANAGER’,’ANALYST’)\\tand\\t\\n(months_between(sysdate,e.hiredate)/12)>\\t7\\t\\tand\\t\\te.comm.\\tis\\tnull)\\norder\\tby\\td.loc\\t\\tasc;',\n",
       " \"2.41.\\t\\t\\t\\t\\tDisplay\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tLoc,\\tDeptno,\\tJob\\tof\\tall\\temps\\nworking\\tat\\tCJICAGO\\tor\\tworking\\tfor\\tACCOUNTING\\tdept\\twith\\tAnn\\nSal>28000,\\tbut\\tthe\\tSal\\tshould\\tnot\\tbe=3000\\tor\\t2800\\twho\\tdoesn’t\\tbelongs\\tto\\tthe\\nMgr\\tand\\twhose\\tno\\tis\\thaving\\ta\\tdigit\\t‘7’\\tor\\t‘8’\\tin\\t3rd\\tposition\\tin\\tthe\\tasc\\torder\\tof\\nDeptno\\tand\\tdesc\\torder\\tof\\tjob.\\nA)\\tselect\\tE.empno,E.ename,E.sal,D.dname,D.loc,E.deptno,E.job\\nfrom\\temp\\tE,dept\\tD\\nwhere\\t(D.loc\\t=\\t'CHICAGO'\\tor\\tD.dname\\t=\\t'ACCOUNTING')\\tand\\nE.deptno=D.deptno\\tand\\tE.empno\\tin\\n(select\\tE.empno\\tfrom\\temp\\tE\\twhere\\t(12*E.sal)\\t>\\t28000\\tand\\t\\tE.sal\\tnot\\tin\\n(3000,2800)\\t\\tand\\tE.job\\t!='MANAGER'\\nand\\t(\\tE.empno\\tlike\\t'__7%'\\tor\\tE.empno\\tlike\\t'__8%'))\\norder\\tby\\tE.deptno\\tasc\\t,\\tE.job\\tdesc;\\n2.42.\\t\\t\\t\\t\\tDisplay\\tthe\\ttotal\\tinformation\\tof\\tthe\\temps\\talong\\twith\\tGrades\\tin\\tthe\\tasc\\norder.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\",\n",
       " 'order.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\torder\\nby\\tgrade\\tasc;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\t>=\\ts.losal\\tand\\te.sal\\t<=\\ts.hisal\\t\\norder\\tby\\ts.grade\\t\\tasc;\\t\\t\\t\\t\\t\\t\\t\\t(using\\tbetween\\tand\\tis\\ta\\tbit\\tsimple)\\n2.43.\\t\\t\\t\\t\\tList\\tall\\tthe\\tGrade2\\tand\\tGrade\\t3\\temps.\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ns\\twhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin(2,3));\\t(OR)\\t\\nB)\\tselect\\t*\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand',\n",
       " 's.grade\\tin\\t(2,3)\\t;\\n2.44.\\t\\t\\t\\t\\tDisplay\\tall\\tGrade\\t4,5\\tAnalyst\\tand\\tMgr.\\nA)\\tselect\\t*\\tfrom\\temp\\te,\\tsalgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tand\\ns.grade\\tin\\t(4,5)\\tand\\te.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\twhere\\te.job\\tin\\n(‘MANAGER’,’ANALYST’)\\t);\\n2.45.\\t\\t\\t\\t\\tList\\tthe\\tEmpno,\\tEname,\\tSal,\\tDname,\\tGrade,\\tExp,\\tand\\tAnn\\tSal\\tof\\temps\\nworking\\tfor\\tDept10\\tor20.\\nA)\\nselectE.empno,E.ename,E.sal,S.grade,D.dname,\\n(months_between(sysdate,E.hiredate)/12)\\t\"EXP\"\\t,12*E.sal\\t\\t“ANN\\tSAL”\\nfrom\\temp\\tE,dept\\tD\\t,salgrade\\tS\\nwhere\\tE.deptno\\tin\\t(10,20)\\tand\\tE.deptno\\t=\\tD.deptno\\t\\tand\\tE.sal\\tbetween\\tS.losal\\nand\\tS.hisal\\t;\\n2.46.\\t\\t\\t\\t\\tList\\tall\\tthe\\tinformation\\tof\\temp\\twith\\tLoc\\tand\\tthe\\tGrade\\tof\\tall\\tthe\\temps\\nbelong\\tto\\tthe\\tGrade\\trange\\tfrom\\t2\\tto\\t4\\tworking\\tat\\tthe\\tDept\\tthose\\tare\\tnot\\tstarting\\nwith\\tchar\\tset\\t‘OP’\\tand\\tnot\\tending\\twith\\t‘S’\\twith\\tthe\\tdesignation\\thaving\\ta\\tchar\\t‘a’\\nany\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades',\n",
       " \"any\\twhere\\tjoined\\tin\\tthe\\tyear\\t1981\\tbut\\tnot\\tin\\tthe\\tmonth\\tof\\tMar\\tor\\tSep\\tand\\tSal\\nnot\\tend\\twith\\t‘00’\\tin\\tthe\\tasc\\torder\\tof\\tGrades\\nA)\\t\\tselect\\te.empno,e.ename,d.loc,s.grade,e.sal\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\nand\\t(d.dname\\tnot\\tlike\\t'OP%'\\tand\\td.dname\\tnot\\tlike\\t'%S')\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\tand\\ts.grade\\tin\\t(2,3,4)\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tjob\\tlike\\t'%A%'and\\tsal\\tnot\\tlike\\n'%00'\\tand\\t(to_char\\t(hiredate,'YYYY')\\t=\\t'1981'\\nand\\tto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP')));\",\n",
       " '2.47.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tDepts\\talong\\twith\\tEmpno,\\tEname\\tor\\twithout\\tthe\\nemps\\nA)\\tselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno(+)=\\td.deptno;\\n2.48.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tSalaries\\tmore\\tthan\\tthe\\temployee\\nBLAKE.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>\\t(select\\t\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\n‘BLAKE’);\\n2.49.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tJobs\\tare\\tsame\\tas\\tALLEN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘ALLEN’);\\n2.50.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tKing.\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\n=\\t‘KING’);\\n2.51.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tMGRS.\\nD)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\t\\tand\\tw.hiredate\\t<\\t\\nm.hiredate\\t;\\t(OR)\\nE)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.empno=\\tm.mgr\\tand\\nw.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand',\n",
       " 'w.hiredate>\\tm.hiredate;\\n2.52.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tDeptno\\t20\\twhose\\tJobs\\tare\\tsame\\tas\\tDeptno10.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\td.deptno\\t=\\t20\\tand\\te.deptno\\t=\\td.deptno\\tand\\ne.job\\tin\\t(\\tselect\\te.job\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\tand\\td.deptno\\n=10);\\n2.53.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\tsame\\tas\\tFORD\\tor\\tSMITH\\tin\\tdesc\\torder\\tof',\n",
       " 'Sal.\\nA)\\nSelect\\t*\\t\\tfrom\\t\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\t(\\tename\\t=\\t‘SMITH’\\nor\\t\\tename\\t=\\t‘FORD’\\t))\\t\\torder\\tby\\tsal\\tdesc;\\n2.54.\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\tJobs\\tare\\tsame\\tas\\tMILLER\\tor\\tSal\\tis\\tmore\\tthan\\nALLEN.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\t\\twhere\\tjob\\t=\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘MILLER’\\t)\\tor\\t\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’);\\n2.55.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\twhose\\tSal\\tis\\t>\\tthe\\ttotal\\tremuneration\\tof\\tthe\\tSALESMAN.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t>(select\\tsum(nvl2(comm,sal+comm,sal))\\tfrom\\nemp\\t\\twhere\\tjob\\t=\\t‘SALESMAN’);\\n2.56.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tBLAKE\\tworking\\tat\\tCHICAGO\\t&\\nBOSTON.\\nF)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td\\twhere\\t\\td.loc\\tin\\t(‘CHICAGO’,’BOSTON’)\\tand\\ne.deptno\\t=\\td.deptno\\tand\\te.hiredate\\t<(select\\te.hiredate\\tfrom\\temp\\te\\twhere\\te.ename\\n=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.',\n",
       " '=\\t‘BLAKE’)\\t;\\n2.57.\\t\\t\\t\\t\\tList\\tthe\\tEmps\\tof\\tGrade\\t3,4\\tbelongs\\tto\\tthe\\tdept\\tACCOUNTING\\tand\\nRESEARCH\\twhose\\tSal\\tis\\tmore\\tthan\\tALLEN\\tand\\texp\\tmore\\tthan\\tSMITH\\tin\\tthe\\nasc\\torder\\tof\\tEXP.\\nG)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\te.deptno\\tin\\t(select\\td.deptno\\t\\tfrom\\tdept\\td\\twhere\\nd.dname\\t\\tin\\t(‘ACCOUNTING’,’RESEARCH’)\\t)\\tand\\t\\ne.sal\\t>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘ALLEN’)\\t\\tand\\t\\ne.hiredate\\t<(\\tselect\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t‘SMITH’)\\tand\\ne.empno\\tin\\t(select\\te.empno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\t\\tand\\ts.grade\\tin\\t(3,4)\\t)',\n",
       " 'order\\tby\\te.hiredate\\tdesc;\\n2.58.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tjobs\\tsame\\tas\\tSMITH\\tor\\tALLEN.\\nH)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n‘SMITH’\\tor\\tename\\t=\\t‘ALLEN’);\\t\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\tin\\n(‘SMITH’,’ALLEN’);\\n2.59.\\t\\t\\t\\t\\tWrite\\ta\\tQuery\\tto\\tdisplay\\tthe\\tdetails\\tof\\temps\\twhose\\tSal\\tis\\tsame\\tas\\tof\\nb)\\t\\t\\t\\t\\tEmployee\\tSal\\tof\\tEMP1\\ttable.\\nc)\\t\\t\\t\\t\\t\\t¾\\tSal\\tof\\tany\\tMgr\\tof\\tEMP2\\ttable.\\nd)\\t\\t\\t\\t\\tThe\\tsal\\tof\\tany\\tperson\\twith\\texp\\tof\\t5\\tyears\\tbelongs\\tto\\tthe\\tsales\\tdept\\tof\\temp3\\ntable.\\ne)\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\temployee\\tof\\temp4\\ttable.\\nf)\\t\\t\\t\\t\\t\\t\\tAny\\tgrade\\t2\\tand\\t3\\temployee\\tworking\\tfro\\tsales\\tdept\\tor\\toperations\\tdept\\njoined\\tin\\t89.\\n2.60.\\t\\t\\t\\t\\tAny\\tjobs\\tof\\tdeptno\\t10\\tthose\\tthat\\tare\\tnot\\tfound\\tin\\tdeptno\\t20.\\nA)\\tselect\\t\\te.job\\tfrom\\temp\\te\\twhere\\te.deptno\\t=\\t10\\tand\\te.job\\tnot\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=20);\\n2.61.\\t\\t\\t\\t\\tList\\tof\\temps\\tof\\temp1\\twho\\tare\\tnot\\tfound\\tin\\temp2.\\n2.62.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tsal\\tof\\tEMP\\ttable.\\nA)\\tselect\\tmax(sal)\\tfrom\\temp;',\n",
       " \"2.63.\\t\\t\\t\\t\\tFind\\tdetails\\tof\\thighest\\tpaid\\temployee.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\t\\tmax(sal)\\tfrom\\temp);\\n2.64.\\t\\t\\t\\t\\tFind\\tthe\\thighest\\tpaid\\temployee\\tof\\tsales\\tdepartment.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp\\twhere\\tdeptno\\tin\\n(select\\td.deptno\\tfrom\\ndept\\td\\twhere\\td.dname\\t=\\t'SALES'));\\n2.65.\\t\\t\\t\\t\\tList\\tthe\\tmost\\trecently\\thired\\temp\\tof\\tgrade3\\tbelongs\\tto\\t\\tlocation\\nCHICAGO.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t\\te.deptno\\tin\\t(\\tselect\\t\\td.deptno\\tfrom\\tdept\\td\\twhere\\nd.loc\\t=\\t'CHICAGO')\\tand\\ne.hiredate\\tin\\t\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tempno\\nfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3))\\t;\\t(or)\\nselect\\t*\\tfrom\\temp\\te,dept\\td\\twhere\\td.loc='chicago'\\nand\\thiredate\\tin(select\\tmax(hiredate)\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\tsal\\tbetween\\tlosal\\tand\\thisal\\tand\\tgrade=3);\\n2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\",\n",
       " \"2.66.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tare\\tsenior\\tto\\tmost\\trecently\\thired\\temployee\\nworking\\tunder\\tking.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t<\\t(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\nmgr\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'))\\t;\",\n",
       " \"2.67.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temployee\\tbelongs\\tto\\tnewyork\\twith\\tgrade\\t3\\tto\\t5\\nexcept\\t‘PRESIDENT’\\twhose\\tsal>\\tthe\\thighest\\tpaid\\temployee\\tof\\tChicago\\tin\\ta\\ngroup\\twhere\\tthere\\tis\\tmanager\\tand\\tsalesman\\tnot\\tworking\\tunder\\tking\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\n='NEW\\tYORK')\\nand\\tempno\\tin\\t(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\nand\\ts.hisal\\tand\\ns.grade\\tin\\t(3,4,5)\\t)\\tand\\tjob\\t!=\\t'PRESIDENT'\\tand\\tsal\\t>(select\\tmax(sal)\\tfrom\\temp\\nwhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\t'CHICAGO')\\tand\\tjob\\tin\\n('MANAGER','SALESMAN')\\tand\\nmgr\\tnot\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\\n2.68.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tsenior\\temployee\\tbelongs\\tto\\t1981.\\nB)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\t\\nwhere\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\",\n",
       " 'where\\t\\tto_char(\\thiredate,’YYYY’)\\t=\\t‘1981’);\\t\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t\\t=\\t(select\\tmin(hiredate)\\tfrom\\temp\\t\\twhere\\nto_char(hiredate,’YYYY’)\\t=\\t‘1981’);\\n2.69.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twho\\tjoined\\tin\\t1981\\twith\\tthe\\tjob\\tsame\\tas\\tthe\\tmost\\nsenior\\tperson\\tof\\tthe\\tyear\\t1981.\\nA)select\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(select\\t\\tjob\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=’1981’));',\n",
       " \"2.70.\\t\\t\\t\\t\\tList\\tthe\\tmost\\tsenior\\templ\\tworking\\tunder\\tthe\\tking\\tand\\tgrade\\tis\\tmore\\t\\nthan\\t3.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\t(select\\tmin(hiredate)\\tfrom\\temp\\twhere\\nempno\\tin\\n(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\tin\\t(4,5)))\\nand\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING');\\n2.71.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tsal\\tgiven\\tto\\tthe\\tMGR.\\nD)\\t\\t\\t\\tselect\\tsum\\t(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(OR)\\nB)\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp);\\n2.72.\\t\\t\\t\\t\\tFind\\tthe\\ttotal\\tannual\\tsal\\tto\\tdistribute\\tjob\\twise\\tin\\tthe\\tyear\\t81.\\nA)\\tselect\\tjob,sum(12*sal)\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t=\\t'1981'\\ngroup\\tby\\tjob\\t;\\n2.73.\\t\\t\\t\\t\\tDisplay\\ttotal\\tsal\\temployee\\tbelonging\\tto\\tgrade\\t3.\\nE)\\t\\t\\t\\t\\tselect\\tsum(sal)\\tfrom\\temp\\twhere\\tempno\\nin\\t\\t(select\\tempno\\tfrom\\temp\\te\\t,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t3)\\n2.74.\\t\\t\\t\\t\\tDisplay\\tthe\\taverage\\tsalaries\\tof\\tall\\tthe\\tclerks.\",\n",
       " 'A)\\tselect\\tavg(sal)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n2.75.\\t\\t\\t\\t\\tList\\tthe\\temployeein\\tdept\\t20\\twhose\\tsal\\tis\\t>the\\taverage\\tsal\\t0f\\tdept\\t10\\nemps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=20\\tand\\tsal\\t>(select\\tavg\\t(sal)\\tfrom\\temp\\nwhere\\t\\tdeptno\\t=\\t10);\\n2.76.\\t\\t\\t\\t\\tDisplay\\tthe\\tnumber\\tof\\temployee\\t\\tfor\\teach\\tjob\\tgroup\\tdeptno\\twise.\\nF)\\t\\t\\t\\t\\tselect\\t\\tdeptno\\t,job\\t,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\t\\tdeptno,job;\\t(or)\\nB)\\tselect\\td.deptno,e.job,count(e.job)\\tfrom\\temp\\te,dept\\td\\twhere\\ne.deptno(+)=d.deptno\\tgroup\\tby\\te.job,d.deptno;\\n2.77.\\t\\t\\t\\t\\tList\\tthe\\tmanage\\trno\\tand\\tthe\\tnumber\\tof\\temployees\\tworking\\tfor\\tthose\\nmgrs\\tin\\tthe\\tascending\\tMgrno.\\nG)\\t\\t\\t\\tselect\\tw.mgr\\t,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\ngroup\\tby\\tw.mgr\\norder\\tby\\tw.mgr\\tasc;\\n2.78.\\t\\t\\t\\t\\tList\\tthe\\tdepartment,details\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tworking\\nH)\\t\\t\\t\\tselect\\tdeptno\\t,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tcount(*)\\t>=\\t2;',\n",
       " \"2.79.\\t\\t\\t\\t\\tDisplay\\tthe\\tGrade,\\tNumber\\tof\\temps,\\tand\\tmax\\tsal\\tof\\teach\\tgrade.\\nA)\\tselect\\ts.grade\\t,count(*),max(sal)\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\ngroup\\tby\\ts.grade;\\n2.80.\\t\\t\\t\\t\\tDisplay\\tdname,\\tgrade,\\tNo.\\tof\\temps\\twhere\\tat\\tleast\\ttwo\\temps\\tare\\tclerks.\\nA)\\tselect\\td.dname,s.grade,count(*)\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\twhere\\te.deptno\\n=\\td.deptno\\tand\\ne.job\\t=\\t'CLERK'\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\t\\tgroup\\tby\\td.dname,s.grade\\nhaving\\tcount(*)\\t>=\\t2;\\n2.81.\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\tdepartment\\twhere\\tmaximum\\tnumber\\tof\\temps\\tare\\nworking.\\nI)\\t\\t\\t\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\n(select\\tdeptno\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\t(OR)\\nJ)\\t\\t\\t\\t\\t\\tselect\\td.deptno,d.dname,d.loc,count(*)\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\",\n",
       " 'where\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\\nK)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin',\n",
       " \"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\t(OR)\\nL)\\t\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\t=\\n(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t‘JONES’);\\n2.83.\\t\\t\\t\\t\\tList\\tthe\\temployees\\twhose\\tsalary\\tis\\tmore\\tthan\\t3000\\tafter\\tgiving\\t20%\\nincrement.\\nM)\\t\\tSELECT\\t*\\tFROM\\tEMP\\tWHERE\\t(1.2*SAL)\\t>\\t3000\\t;\\n2.84.\\t\\t\\t\\t\\tList\\tthe\\temps\\twith\\tdept\\tnames.\\nA)\\tselect\\ne.empno,e.ename,e.job,e.mgr,e.hiredate,e.sal,e.comm,e.deptno,d.dname\\nfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno;\\n2.85.\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tnot\\tworking\\tin\\tsales\\tdept.\\nN)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tnot\\tin\\n(select\\tdeptno\\tfrom\\temp\\twhere\\tdname\\t=\\t‘SALES’);\\n2.86.\\t\\t\\t\\t\\tList\\tthe\\temps\\tname\\t,dept,\\tsal\\tand\\tcomm.\\tFor\\tthose\\twhose\\tsalary\\tis\\nbetween\\t2000\\tand\\t5000\\twhile\\tloc\\tis\\tChicago.\\nA)\\tselect\\te.ename,e.deptno,e.sal,e.comm\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\nd.deptno\\tand\\nd.loc\\t=\\t'CHICAGO'\\tand\\te.sal\\tbetween\\t2000\\tand\\t5000;\",\n",
       " \"2.87.\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tgreater\\tthan\\this\\tmanagers\\tsalary\\nA)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n2.88.\\t\\t\\t\\t\\tList\\tthe\\tgrade,\\tEMP\\tname\\tfor\\tthe\\tdeptno\\t10\\tor\\tdeptno\\t30\\tbut\\tsal\\tgrade\\tis\\nnot\\t4\\twhile\\tthey\\tjoined\\tthe\\tcompany\\tbefore\\t’31-dec-82’.\\nA)\\tselect\\ts.grade\\t,e.ename\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.deptno\\tin\\t(10,20)\\tand\\nhiredate\\t<\\t('31-DEC-82')\\tand\\t(e.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\tnot\\tin\\n(4));\\n2.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\t,job,\\tdname,\\tlocation\\tfor\\tthose\\twho\\tare\\tworking\\tas\\tMGRS.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\ne.empno\\tin\\t(select\\tmgr\\tfrom\\temp\\t)\\t;\\n3.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tmgr\\tname\\tis\\tjones\\tand\\talso\\tlist\\ttheir\\tmanager\\tname.\\nA)\\tselect\\tw.empno,w.ename,w.job,w.mgr,w.hiredate,w.sal,w.deptno,m.ename\\nfrom\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\",\n",
       " \"from\\temp\\tw\\t,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t'JONES';\\n4.\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tand\\tsalary\\tof\\tford\\tif\\this\\tsalary\\tis\\tequal\\tto\\thisal\\tof\\this\\tgrade.\\nA)\\tselect\\te.ename,e.sal\\tfrom\\temp\\te\\t,salgrade\\ts\\twhere\\te.ename\\t=\\t'FORD'\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\te.sal\\t=\\ts.hisal\\t;\",\n",
       " \"5.\\t\\t\\t\\t\\t\\tLit\\tthe\\tname,\\tjob,\\tdname\\t,sal,\\tgrade\\tdept\\twise\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,d.dname,e.sal,s.grade\\tfrom\\temp\\te,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\norder\\tby\\te.deptno\\t;\\n6.\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\tname,\\tjob,\\tsal,\\tgrade\\tand\\tdname\\texcept\\tclerks\\tand\\tsort\\ton\\tthe\\nbasis\\tof\\thighest\\tsal.\\nA)\\t\\t\\t\\tselect\\te.ename,e.job,e.sal,s.grade,d.dname\\tfrom\\temp\\te\\t,dept\\td\\t,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.job\\tnot\\tin('CLERK')\\norder\\tby\\te.sal\\tdesc;\\n7.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tname,\\tjob\\t\\twho\\tare\\twith\\tout\\tmanager.\\nA)\\tselect\\te.ename,e.job\\tfrom\\temp\\te\\twhere\\tmgr\\tis\\tnull;\\n8.\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tthe\\temps\\twho\\tare\\tgetting\\tthe\\thighest\\tsal\\tdept\\twise.\\nA)\\t\\t\\t\\tselect\\te.ename,e.deptno\\tfrom\\temp\\te\\twhere\\te.sal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t;\\n9.\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tequal\\tto\\tthe\\taverage\\tof\\tmax\\tand\\tminimum\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=(select\\t(max(sal)+min(sal))/2\\tfrom\\temp);\",\n",
       " '10.\\t\\tList\\tthe\\tno.\\tof\\temps\\tin\\teach\\tdepartment\\twhere\\tthe\\tno.\\tis\\tmore\\tthan\\t3.\\nA)\\tselect\\tdeptno,count(*)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\thaving\\tcount(*)\\t<\\t3;\\n11.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tnames\\tof\\tdepts.\\tWhere\\tatleast\\t3\\tare\\tworking\\tin\\tthat\\tdepartment.\\nA)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\\nhaving\\tcount(*)\\t>=\\t3\\t\\t;\\n12.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twhose\\tsal\\tis\\tmore\\tthan\\this\\temployess\\tavg\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tm\\t\\twhere\\tm.empno\\tin\\t(select\\tmgr\\tfrom\\temp)\\nand\\tm.sal\\t>\\t(select\\tavg(e.sal)\\tfrom\\temp\\te\\twhere\\te.mgr\\t=\\tm.empno\\n)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\nThe\\tsubquery\\tdoes\\tthe\\tsame\\tas\\t\\t\\t(select\\t(avg(e.sal)),m.ename\\tfrom\\temp\\te,emp\\tm\\nwhere\\te.mgr=m.empno\\tgroup\\tby\\te.mgr,m.ename);\\n13.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname,salary,comm.\\tFor\\tthose\\temployees\\twhose\\tnet\\tpay\\tis\\ngreater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)',\n",
       " 'greater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\tename,sal,comm.\\tfrom\\temp\\twhere\\tsal+nvl(comm.,0)\\t>=\\tany\\t(select\\nsal\\tfrom\\temp);/\\n14.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp\\twhose\\tsal<his\\tmanager\\tbut\\tmore\\tthan\\tany\\tother\\tmanager.\\na)select\\t\\tdistinct\\tW.empno,W.ename,W.sal',\n",
       " 'from\\t(select\\tw.empno,w.ename,w.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\t\\nw.mgr\\t=\\tm.empno\\tand\\tw.sal<m.sal)\\tW,\\n(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp))\\tA\\nwhere\\tW.sal\\t>\\tA.sal;\\t(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t<\\tm.sal\\nand\\tw.sal\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp));\\n15.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temployee\\tnames\\tand\\this\\taverage\\tsalary\\tdepartment\\twise.\\nA)\\nselect\\td.deptno,\\tround(avg(nvl2(e1.comm,\\te1.sal+e1.comm,\\te1.sal)))\\tavg,\\ne2.ename\\tfrom\\temp\\te1,\\temp\\te2,\\tdept\\td\\twhere\\td.deptno\\t=e1.deptno\\tand\\td.deptno\\n=\\te2.deptno\\tgroup\\tby\\td.deptno,\\te2.ename;\\t(or)\\nB)\\tselect\\td.maxsal,e.ename,e.deptno\\tas\\t\"current\\tsal\"\\tfrom\\temp\\te,\\n(select\\tavg(Sal)\\tmaxsal,deptno\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\td\\nwhere\\te.deptno=d.deptno;\\n16.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\tleast\\t5\\tearners\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\t5>\\t(select\\tcount(*)\\tfrom\\temp\\twhere\\te.sal\\t>sal);\\n(or)\\nB)\\t\\t\\t\\tselect\\trownum\\trank,empno,ename,job,sal\\tfrom\\t(select\\t*\\tfrom\\temp\\torder\\tby\\nsal\\tasc)\\twhere\\trownum\\t<\\t6\\t;\\t(or)',\n",
       " \"C)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t\\twhere\\t5\\t>(select\\tcount(distinct\\tsal)\\tfrom\\temp\\twhere\\ne.sal\\t>\\tsal);\\n17.\\t\\t\\t\\t\\t\\t\\t\\tFind\\tout\\temps\\twhose\\tsalaries\\tgreater\\tthan\\tsalaries\\tof\\ttheir\\tmanagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal>\\tm.sal;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,(select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\nemp))\\ta\\nwhere\\te.sal\\t>a.sal\\tand\\te.mgr\\t=\\ta.empno\\n18.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tmanagers\\twho\\tare\\tnot\\tworking\\tunder\\tthe\\tpresident.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin(select\\tmgr\\tfrom\\temp)\\tand\\tmgr\\tnot\\tin\\n(select\\tempno\\tfrom\\temp\\twhere\\tjob\\t=\\t'PRESIDENT')\\n19.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\trecords\\tfrom\\temp\\twhose\\tdeptno\\tisnot\\tin\\tdept.\\n20.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tName\\t,\\tSalary,\\tComm\\tand\\tNet\\tPay\\tis\\tmore\\tthan\\tany\\tother\\nemployee.\\nA)\\t\\t\\t\\tSelect\\te.ename,e.sal,e.comm,nvl2(comm,sal+comm,sal)\\tNETPAY\\nfrom\\temp\\te\\t\\nwhere\\tnvl2(comm,sal+comm,sal)\\t>\\tany\\t(select\\tsal\\tfrom\\temp\\twhere\\tempno\\n=e.empno)\\t;\",\n",
       " \"21.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEnames\\twho\\tare\\tretiring\\tafter\\t31-Dec-89\\tthe\\tmax\\tJob\\tperiod\\tis\\n20Y.\\nA)\\tselect\\tename\\tfrom\\temp\\twhere\\tadd_months(hiredate,240)\\t>\\t'31-DEC-89';\\nB)\\tselect\\tename\\tfrom\\temp\\nwhere\\tadd_months(hiredate,240)\\t>\\tto_date(’31-DEC-89’,’DD-MON-RR’);\\t\\n22.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthose\\tEmps\\twhose\\tSalary\\tis\\todd\\tvalue.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tmod(sal,2)\\t=\\t1;\\n23.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temp’s\\twhose\\tSalary\\tcontain\\t3\\tdigits.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\t\\twhere\\tlength\\t(sal)\\t=\\t3;\\n24.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tDEC.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=’DEC’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t\\tin\\t(‘DEC’);\\t(OR)\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MONTH’)\\tlike\\t‘DEC%’;\\n25.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tnames\\tcontains\\t‘A’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%A%’;\\n26.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tDeptno\\tis\\tavailable\\tin\\this\\tSalary.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(sal,deptno)\\t>\\t0;\",\n",
       " \"27.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twhose\\tfirst\\t2\\tchars\\tfrom\\tHiredate=last\\t2\\tcharacters\\tof\\nSalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsubstr(hiredate,1,2)\\t=\\tsubstr(sal,length(sal)-1,length(sal));\\n28.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tWhose\\t10%\\tof\\tSalary\\tis\\tequal\\tto\\tyear\\tof\\tjoining.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YY')\\tin\\t(select\\t.1*sal\\tfrom\\temp);\\n29.\\t\\t\\t\\t\\t\\t\\t\\tList\\tfirst\\t50%\\tof\\tchars\\tof\\tEname\\tin\\tLower\\tCase\\tand\\tremaining\\tare\\tupper\\nCase.\\nA)\\t\\t\\t\\t\\t\\t\\t\\t\\nselect\\tlower(substr(ename,1,round(length(ename)/2)))\\n||substr(ename,round(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\t\\t(OR)\\nB)\\tselect\\tlower(substr(ename,1,ciel(length(ename)/2)))\\n||\\tsubstr(ename,ciel(length(ename)/2)+1,length(ename))\\tfrom\\temp\\t;\\n30.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname\\twhose\\tNo.\\tof\\tEmps\\tis\\t=to\\tnumber\\tof\\tchars\\tin\\tthe\\nDname.\",\n",
       " 'A)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\te\\nwhere\\te.deptno\\t=\\td.deptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\td.dname,count(*)\\tfrom\\temp\\te\\t,dept\\td\\twhere\\te.deptno\\t=\\td.deptno\\t\\ngroup\\tby\\td.dname\\thaving\\tcount(*)\\t=\\tlength\\t(d.dname);\\n31.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\tthose\\twho\\tjoined\\tin\\tcompany\\tbefore\\t15th\\tof\\tthe\\tmonth.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,\\'DD\\')\\t<\\t\\'15\\';\\n32.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tDname,\\tno\\tof\\tchars\\tof\\twhich\\tis\\t=\\tno.\\tof\\temp’s\\tin\\tany\\tother\\nDept.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\twhere\\tlength(dname)\\tin\\t(select\\tcount(*)\\tfrom\\temp\\t\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno\\t);\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\twhere\\tlength(dname)\\t=\\tany\\t(select\\tcount(*)\\tfrom\\temp\\nwhere\\td.deptno\\t<>\\tdeptno\\tgroup\\tby\\tdeptno);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\tdept\\td\\t,\\t(select\\tcount(*)\\ts,e.deptno\\t\\t\"M\"from\\temp\\te\\tgroup\\tby\\ne.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)',\n",
       " 'e.deptno)\\td1\\nwhere\\tlength(dname)=d1.s\\tand\\td1.M\\t<>d.deptno;\\n33.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp\\t);\\n34.\\t\\t\\t\\t\\t\\t\\t\\tList\\tTHE\\tName\\tof\\tdept\\twhere\\thighest\\tno.of\\temps\\tare\\tworking.\\nA)\\tselect\\tdname\\tfrom\\tdept\\twhere\\tdeptno\\tin',\n",
       " \"(select\\tdeptno\\t\\tfrom\\temp\\tgroup\\tby\\tdeptno\\t\\t\\t\\t\\t\\t\\t\\t\\nhaving\\tcount(*)\\tin\\n(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t);\\n35.\\t\\t\\t\\t\\t\\t\\t\\tCount\\tthe\\tNo.of\\temps\\twho\\tare\\tworking\\tas\\t‘Managers’(using\\tset\\toption).\\nA)select\\tcount(*)\\nfrom(select\\t*\\tfrom\\temp\\tminus\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t!=\\t'MANAGER')\\n36.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\ton\\tthe\\tsame\\tdate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\tin\\n(select\\thiredate\\tfrom\\temp\\twhere\\te.empno\\t<>\\tempno);\\n37.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\twhose\\tGrade\\tis\\tequal\\tto\\tone\\ttenth\\tof\\tSales\\nDept.\\nA)\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t0.1*\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdname\\t=\\t'SALES');\\n38.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tname\\tof\\tthe\\tdept\\twhere\\tmore\\tthan\\taverage\\tno.\\tof\\temps\\tare\\nworking.\\nA)\\tselect\\td.dname\\tfrom\\tdept\\td,\\temp\\te\\twhere\\te.deptno\\t=\\td.deptno\\ngroup\\tby\\td.dname\",\n",
       " 'having\\tcount(*)\\t>\\t(select\\tavg(count(*))\\tfrom\\temp\\t\\tgroup\\tby\\tdeptno);\\n39.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tManagers\\tname\\twho\\tis\\thaving\\tmax\\tno.of\\temps\\tworking\\tunder\\nhim.\\nA)select\\tm.ename,count(*)\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\t\\ngroup\\tby\\tm.ename\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr);\\t\\t\\t\\t\\t\\n(OR)\\nB)\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\t=\\t(select\\tmgr\\tfrom\\temp\\tgroup\\tby\\tmgr\\thaving\\ncount(*)\\t=\\t(select\\tmax(count(*))\\tfrom\\temp\\tgroup\\tby\\tmgr))\\t;\\n40.\\t\\t\\t\\t\\t\\t\\t\\tList\\tthe\\tEname\\tand\\tSal\\tis\\tincreased\\tby\\t15%\\tand\\texpressed\\tas\\tno.of\\nDollars.\\nA)\\tselect\\tename,to_char(1.15*sal,\\'$99,999\\')\\tas\\t\"SAL\"\\t\\tfrom\\temp;\\t(only\\tfor\\t$\\tit\\nworks)\\nB)\\tselect\\tename,\\'$\\'||1.15*sal\\t\\t“SAL”\\tfrom\\temp;\\n41.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\toutput\\tof\\tEMP\\ttable\\t‘EMP_AND_JOB’\\tfor\\tEname\\tand\\tJob.\\nA)\\tselect\\tename||\\tjob\\tas\\t\"EMP_AND_JOB\"\\tfrom\\temp\\t;\\n42.\\t\\t\\t\\t\\t\\t\\t\\tProduce\\tthe\\tfollowing\\toutput\\tfrom\\tEMP.',\n",
       " 'I.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tEMPLOYEE\\nSMITH\\t(clerk)\\nALLEN\\t(Salesman)\\nA)\\t\\tselect\\tename\\t||\\t‘(‘||\\tlower(job)||’)’\\tas\\t“EMPLOYEE”\\tfrom\\temp;\\n130)\\t\\t\\tList\\tthe\\temps\\twith\\tHire\\tdate\\tin\\tformat\\tJune\\t4,\\t1988.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal,\\tto_char(hiredate,\\'MONTH\\tDD,YYYY\\')\\tfrom\\temp;\\n131)\\t\\t\\tPrint\\ta\\tlist\\tof\\temp’s\\tListing\\t‘just\\tsalary’\\tif\\tSalary\\tis\\tmore\\tthan\\t1500,\\ton\\ntarget\\tif\\tSalary\\tis\\t1500\\tand\\t‘Below\\t1500’\\tif\\tSalary\\tis\\tless\\tthan\\t1500.\\nA)\\t\\t\\t\\tselect\\tempno,ename,sal||\\t‘JUST\\tSALARY’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t>\\n1500\\tunion\\nselect\\tempno,ename,\\tsal||\\t‘ON\\tTARGET’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t=\\t1500\\t\\t\\t\\t\\t\\t\\t\\nunion\\nselect\\tempno,ename,\\tsal||\\t‘BELOW\\t1500’\\t\"SAL\"\\tfrom\\temp\\twhere\\tsal\\t<\\t1500;\\t\\n(OR)\\nB)select\\tempno,ename,sal,job,\\ncase\\nwhen\\tsal\\t=\\t1500\\tthen\\t\\'ON\\tTARGET\\'\\nwhen\\tsal\\t<\\t1500\\tthen\\t\\'BELOW\\t1500\\'\\nwhen\\tsal\\t>\\t1500\\tthen\\t\\'JUST\\tSALARY\\'\\nelse\\t\\'nothing\\'\\nend\\t\\t\"REVISED\\tSALARY\"\\nfrom\\temp;',\n",
       " \"132)\\t\\t\\tWrite\\ta\\tquery\\twhich\\treturn\\tthe\\tday\\tof\\tthe\\tweek\\tfor\\tany\\tdate\\tentered\\tin\\nformat\\t‘DD-MM-YY’.\\nA)\\tselect\\tto_char(to_date('&\\ts','dd-mm-yy'),'day')\\tfrom\\tdual\\t;\\n133)\\t\\t\\tWrite\\ta\\tquery\\tto\\tcalculate\\tthe\\tlength\\tof\\tservice\\tof\\tany\\temployee\\twith\\tthe\\ncompany,\\tuse\\tDEFINE\\tto\\tavoid\\trepetitive\\ttyping\\tof\\tfunctions.\\nA)\\t\\t\\t\\tDEFINE\\t\\tservice\\t=\\t((months_between(sysdate,hiredate))/12)\\nB)\\t\\t\\t\\tSelect\\t\\tempno,ename,&service\\tfrom\\temp\\twhere\\tename\\t=\\t‘&\\tname’;\\n134)\\t\\t\\tGive\\ta\\tstring\\tof\\tformat\\t‘NN/NN’,\\tverify\\tthat\\tthe\\tfirst\\tand\\tlast\\ttwo\\ncharacters\\tare\\tnumbers\\tand\\tthat\\tthe\\tmiddle\\tcharacter\\tis’/’.\\tPrint\\tthe\\texpression\\n‘YES’\\tif\\tvalid,\\t‘NO’\\tif\\tnot\\tvalid.\\tUse\\tthe\\tfollowing\\tvalues\\tto\\ttest\\tyour\\tsolution.\\n‘12/34’,’01/1a’,\\t‘99/98’.\\nA)\\n135)\\t\\t\\tEmps\\thired\\ton\\tor\\tbefore\\t15th\\tof\\tany\\tmonth\\tare\\tpaid\\ton\\tthe\\tlast\\tFriday\\tof\\nthat\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\",\n",
       " \"that\\tmonth\\tthose\\thired\\tafter\\t15th\\tare\\tpaid\\ton\\tthe\\tfirst\\tFriday\\tof\\tthe\\tfollowing\\nmonth.\\tPrint\\ta\\tlist\\tof\\temps\\ttheir\\thire\\tdate\\tand\\tthe\\tfirst\\tpay\\tdate.\\tSort\\ton\\thire\\tdate.\\nA)\\tselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')-7\\tfrom\\temp\\nwhere\\tto_char(hiredate,'DD')\\t<=15\\nunion\\nselect\\tename,hiredate,next_day(last_day(hiredate),'FRIDAY')\\tfrom\\temp\\twhere\\nto_char(hiredate,'DD')\\t>\\t15;\",\n",
       " \"136)\\t\\t\\tCount\\tthe\\tno.\\tof\\tcharacters\\twith\\tout\\tconsidering\\tspaces\\tfor\\teach\\tname.\\nA)\\t\\t\\t\\tselect\\tlength(replace(ename,’\\t‘,null))\\tfrom\\temp;\\n137)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tare\\tgetting\\tdecimal\\tvalue\\tin\\ttheir\\tSal\\twithout\\tusing\\nlike\\toperator.\\nA)\\tselect\\t\\t*\\tfrom\\temp\\twhere\\tinstr(sal,’.’,1,1)\\t>\\t0;\\n138)\\t\\t\\tList\\tthose\\temps\\twhose\\tSalary\\tcontains\\tfirst\\tfour\\tdigit\\tof\\ttheir\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(sal,,9999),deptno,1,1)>0\\tand\\ninstr(to_char(sal,9999),deptno,1,2)>\\t0\\t;\\n139)\\t\\t\\tList\\tthose\\tManagers\\twho\\tare\\tgetting\\tless\\tthan\\this\\temps\\tSalary.\\nA)\\t\\t\\t\\tselect\\tdistinct\\tm.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\nand\\tw.sal>m.sal;\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tsal\\t\\t<\\tany\\t(\\tselect\\tsal\\tfrom\\temp\\twhere\\nw.empno=mgr);\\nC)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw\\twhere\\tempno\\tin\\t\\t(\\tselect\\tmgr\\tfrom\\temp\\twhere\\t\\t\\t\\nw.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\",\n",
       " \"w.sal<sal);\\n140)\\t\\t\\tPrint\\tthe\\tdetails\\tof\\tall\\tthe\\temps\\twho\\tare\\tsub-ordinates\\tto\\tBlake.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tmgr\\tin\\t(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\n'BLAKE');\\n141)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tManagers\\tusing\\tco-related\\tsub-query.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\n142)\\t\\t\\tList\\tthe\\temps\\twhose\\tMgr\\tname\\tis\\t‘Jones’\\tand\\talso\\twith\\this\\tManager\\nname.\",\n",
       " 'A)\\t\\t\\t\\tselect\\tw.ename,m.ename,(select\\tename\\tfrom\\temp\\twhere\\tm.mgr\\t=\\tempno)\\n\"his\\tMANAGER\"\\nfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\tm.ename\\t=\\t\\'JONES\\';\\t(or)\\nB)\\tselect\\te.ename,w.ename,m.ename\\tfrom\\temp\\te,emp\\tw,emp\\tm\\twhere\\te.mgr\\t=\\nw.empno\\tand\\tw.ename\\t=\\t‘JONES’\\tand\\tw.mgr\\t=\\tm.empno;\\n143)\\t\\t\\tDefine\\ta\\tvariable\\trepresenting\\tthe\\texpression\\tused\\tto\\tcalculate\\ton\\temps\\ntotal\\tannual\\tremuneration\\tuse\\tthe\\tvariable\\tin\\ta\\tstatement,\\twhich\\tfinds\\tall\\temps\\nwho\\tcan\\tearn\\t30000\\ta\\tyear\\tor\\tmore.\\nA)\\t\\t\\t\\tSet\\tdefine\\ton\\nB)\\t\\t\\t\\tDefine\\t\\tannual\\t=\\t12*nvl2(comm.,sal+comm.,sal)\\t\\t(here\\tdefine\\tvariable\\tis\\ta\\nsession\\tvariable)\\nC)\\t\\t\\t\\tSelect\\t*\\tfrom\\temp\\twhere\\t&annual\\t>\\t30000;\\n144)\\t\\t\\tFind\\tout\\thow\\tmay\\tManagers\\tare\\ttheir\\tin\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\t(or)\\nB)\\t\\t\\t\\tselect\\tcount(*)\\tfrom\\temp\\twhere\\tempno\\tin\\t(select\\tmgr\\tfrom\\temp);\\t(or)\\nC)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.',\n",
       " 'C)\\t\\t\\t\\tselect\\tcount(distinct\\tm.empno)\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\nm.empno\\t;\\n145)\\t\\t\\tFind\\tAverage\\tsalary\\tand\\tAverage\\ttotal\\tremuneration\\tfor\\teach\\tJob\\ttype.\\nRemember\\tSalesman\\tearn\\tcommission.secommm\\nA)\\tselect\\tavg(sal),avg(sal+nvl(comm,0))\\tfrom\\temp;\\n146)\\t\\t\\tCheck\\twhether\\tall\\tthe\\temps\\tnumbers\\tare\\tindeed\\tunique.',\n",
       " 'A)\\tselect\\t\\t\\tempno,count(*)\\t\\tfrom\\temp\\tgroup\\tby\\tempno;\\n147)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tdrawing\\tless\\tthan\\t1000\\tSort\\tthe\\toutput\\tby\\tSalary.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\t<\\t1000\\torder\\tby\\tsal;\\n148)\\t\\t\\tList\\tthe\\temployee\\tName,\\tJob,\\tAnnual\\tSalary,\\tdeptno,\\tDept\\tname\\tand\\ngrade\\twho\\tearn\\t36000\\ta\\tyear\\tor\\twho\\tare\\tnot\\tCLERKS.\\nA)selecte.ename,e.job,(12*e.sal)\"ANNUALSALARY\",\\ne.deptno,d.dname,s.grade\\nfrom\\temp\\te,dept\\td\\t,salgrade\\ts\\twhere\\te.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ns.losal\\tand\\ts.hisal\\nand\\t(((12*e.sal)>=\\t36000)\\tor\\t(e.job\\t!=\\t\\'CLERK\\'))\\n149)\\t\\t\\tFind\\tout\\tthe\\tJob\\tthat\\twas\\tfilled\\tin\\tthe\\tfirst\\thalf\\tof\\t1983\\tand\\tsame\\tjob\\tthat\\nwas\\tfilled\\tduring\\tthe\\tsame\\tperiod\\tof\\t1984.\\nA)\\tselect\\t*\\t\\tfrom\\temp\\twhere\\t(to_char(hiredate,\\'MM\\t\\')\\t<=\\t06\\t\\tand\\nto_char(hiredate,\\'YYYY\\')\\t=\\t1984)\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\temp\\twhere\\nto_char(hiredate,\\'MM\\'\\t)\\t<=\\t06\\tand\\tto_char(hiredate,\\'YYYY\\')\\t<=\\t1983)\\t;\\t\\n150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand',\n",
       " '150)\\t\\t\\tFind\\tout\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tcompany\\tbefore\\ttheir\\tManagers.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate<\\tm.hiredate;(or)\\nB)\\tselect\\t*\\tfrom\\temp\\te\\twhere\\thiredate\\t<\\t(select\\t\\thiredate\\tfrom\\temp\\twhere\\nempno\\t=\\te.mgr)\\n151)\\t\\t\\tList\\tall\\tthe\\temps\\tby\\tname\\tand\\tnumber\\talong\\twith\\ttheir\\tManager’s\\tname\\nand\\tnumber.\\tAlso\\tList\\tKING\\twho\\thas\\tno\\t‘Manager’.\\nA)\\tselect\\tw.empno,w.ename,m.empno,m.ename\\tfrom\\temp\\tw,emp\\tm\\twhere',\n",
       " 'w.mgr=\\tm.empno(+);\\n152)\\t\\t\\tFind\\tall\\tthe\\temps\\twho\\tearn\\tthe\\tminimum\\tSalary\\tfor\\teach\\tjob\\twise\\tin\\nascending\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmin(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tasc;\\n153)\\t\\t\\tFind\\tout\\tall\\tthe\\temps\\twho\\tearn\\thighest\\tsalary\\tin\\teach\\tjob\\ttype.\\tSort\\tin\\ndescending\\tsalary\\torder.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\tgroup\\tby\\tjob)\\norder\\tby\\tsal\\tdesc;\\n154)\\t\\t\\tFind\\tout\\tthe\\tmost\\trecently\\thired\\temps\\tin\\teach\\tDept\\torder\\tby\\tHiredate.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\te\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\te.deptno\\t=\\t\\tdeptno\\t)\\norder\\tby\\thiredate;\\n155)\\t\\t\\tList\\tthe\\temployee\\tname,Salary\\tand\\tDeptno\\tfor\\teach\\temployee\\twho\\tearns\\na\\tsalary\\tgreater\\tthan\\tthe\\taverage\\tfor\\ttheir\\tdepartment\\torder\\tby\\tDeptno.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\tsal\\t>\\t\\t(select\\tavg(sal)\\tfrom\\temp\\twhere\\te.deptno\\t=\\tdeptno\\t);\\nB)\\t\\t\\t\\tselect\\te.ename,e.sal,e.deptno\\tfrom\\temp\\te,(select\\tavg(sal)\\tA,deptno\\tD\\tfrom\\t\\t\\nemp\\tgroup\\tby\\tdeptno)\\tD1\\twhere\\tD1.D\\t=\\te.deptno\\tand\\te.sal\\t>\\tD1.A;',\n",
       " \"156)\\t\\t\\tList\\tthe\\tDeptno\\twhere\\tthere\\tare\\tno\\temps.\\nA)\\t\\t\\t\\tselect\\t\\tdeptno\\t,count(*)\\tfrom\\temp\\ngroup\\tby\\tdeptno\\t\\nhaving\\tcount(*)\\t=\\t0;\\n157)\\t\\t\\tList\\tthe\\tNo.of\\temp’s\\tand\\tAvg\\tsalary\\twithin\\teach\\tdepartment\\tfor\\teach\\tjob.\\nA)\\t\\t\\t\\tselect\\tcount(*),avg(sal),deptno,job\\tfrom\\temp\\ngroup\\tby\\tdeptno,job;\\n158)\\t\\t\\tFind\\tthe\\tmaximum\\taverage\\tsalary\\tdrawn\\tfor\\teach\\tjob\\texcept\\tfor\\n‘President’.\\nA)\\tselect\\tmax(avg(sal))\\tfrom\\temp\\t\\twhere\\tjob\\t!=\\t'PRESIDENT'\\tgroup\\tby\\tjob;\\n159)\\t\\t\\tFind\\tthe\\tname\\tand\\tJob\\tof\\tthe\\temps\\twho\\tearn\\tMax\\tsalary\\tand\\tCommission.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t=\\t(select\\tmax(sal)\\tfrom\\temp)\\tand\\tcomm.\\tis\\tnot\\nnull;\\n160)\\t\\t\\tList\\tthe\\tName,\\tJob\\tand\\tSalary\\tof\\tthe\\temps\\twho\\tare\\tnot\\tbelonging\\tto\\tthe\\ndepartment\\t10\\tbut\\twho\\thave\\tthe\\tsame\\tjob\\tand\\tSalary\\tas\\tthe\\temps\\tof\\tdept\\t10.\\nA)\\tselect\\tename,job,sal\\tfrom\\temp\\twhere\\tdeptno\\t!=\\t10\\tand\\tjob\\tin\\t(select\\tjob\\tfrom\\nemp\\twhere\\tdeptno\\t=\\t10)\\nand\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10);\\n161)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\tSALESMAN\",\n",
       " 'who\\tare\\tearning\\tmaximum\\tsalary\\tand\\tcommission\\tin\\tdescending\\torder.\\nA)select\\t\\tdeptno,name,job,sal,sal+nvl(comm.,0)\\tfrom\\temp\\twhere\\tjob\\t=\\n‘SALESMAN’\\tand\\tsal\\tin\\t(select\\tmax(sal+nvl(comm.,0))\\tfrom\\temp\\twhere\\ncomm.\\tis\\tnot\\tnull)\\nOrder\\tby\\t(sal\\t+nvl(comm.,0))\\tdesc;\\n162)\\t\\t\\tList\\tthe\\tDeptno,\\tName,\\tJob,\\tSalary\\tand\\tSal+Comm\\tof\\tthe\\temps\\twho\\tearn\\nthe\\tsecond\\thighest\\tearnings\\t(sal\\t+\\tcomm.).\\nA)\\tselect\\tdeptno,ename,sal,job,sal+nvl(comm,0)\\tfrom\\temp\\te\\twhere\\t\\t2\\t=\\t(select\\ncount(distinct\\tsal+nvl(comm,0))\\tfrom\\temp\\twhere\\t(e.sal+nvl(comm.,0))\\n<(sal+nvl(comm.,0));\\n163)\\t\\t\\tList\\tthe\\tDeptno\\tand\\ttheir\\taverage\\tsalaries\\tfor\\tdept\\twith\\tthe\\taverage\\tsalary\\nless\\tthan\\tthe\\taverages\\tfor\\tall\\tdepartment\\nA)\\t\\t\\t\\tselect\\tdeptno,avg(sal)\\tfrom\\temp\\tgroup\\tby\\tdeptno\\nhaving\\tavg(sal)\\t<(select\\tavg(Sal)\\tfrom\\temp);\\n164)\\t\\t\\tList\\tout\\tthe\\tNames\\tand\\tSalaries\\tof\\tthe\\temps\\talong\\twith\\ttheir\\tmanager\\nnames\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm',\n",
       " 'names\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n165)\\t\\t\\tList\\tout\\tthe\\tName,\\tJob,\\tSalary\\tof\\tthe\\temps\\tin\\tthe\\tdepartment\\twith\\tthe\\nhighest\\taverage\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin',\n",
       " '(select\\tdeptno\\tfrom\\temp\\te\\t\\nhaving\\tavg(sal)\\t=(select\\tmax(avg(sal))\\tfrom\\temp\\tgroup\\tby\\tdeptno)\\t\\t\\ngroup\\tby\\tdeptno);\\n166)\\t\\t\\tList\\tthe\\tempno,sal,comm.\\tOf\\temps.\\nA)\\tselect\\tempno,sal,comm.\\tfrom\\temp;\\n167)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tsal.\\nA)\\tselect\\t*\\tfrom\\temp\\torder\\tby\\tsal\\tasc;\\n168)\\t\\t\\tList\\tthe\\tdept\\tin\\tthe\\tascending\\torder\\tof\\tthe\\tjob\\tand\\tthe\\tdesc\\torder\\tof\\tthe\\nemps\\tprint\\tempno,\\tename.\\nA)\\tselect\\t*\\tfrom\\temp\\te\\t\\torder\\tby\\te.job\\tasc,e.empno\\tdesc\\t;\\n169)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\tof\\tthe\\temps.\\nA)select\\t*\\tfrom\\tdept\\twhere\\tdeptno\\tin\\t(select\\tunique\\tdeptno\\tfrom\\temp);\\n170)\\t\\t\\tDisplay\\tthe\\tunique\\tdept\\twith\\tjobs.\\nA)\\tselect\\tunique\\tdeptno\\t,job\\tfrom\\temp\\t;',\n",
       " '171)\\t\\t\\tDisplay\\tthe\\tdetails\\tof\\tthe\\tblake.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’;\\n172)\\t\\t\\tList\\tall\\tthe\\tclerks.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n173)\\t\\t\\tlist\\tall\\tthe\\temployees\\tjoined\\ton\\t1st\\tmay\\t81.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\t=\\t’01-MAY-81’;\\n174)\\t\\t\\tList\\tthe\\tempno,ename,sal,deptno\\tof\\tthe\\tdept\\t10\\temps\\tin\\tthe\\tascending\\norder\\tof\\tsalary.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,e.deptno\\tfrom\\temp\\twhere\\te.deptno\\t=\\t10\\norder\\tby\\te.sal\\tasc;\\n175)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalaries\\tare\\tless\\tthan\\t3500.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t<3500;\\n176)\\t\\t\\tList\\tthe\\tempno,ename,sal\\tof\\tall\\tthe\\temp\\tjoined\\tbefore\\t1\\tapr\\t81.\\nA)\\tselect\\te.empno\\t,e.ename\\t.e.sal\\tfrom\\temp\\twhere\\thiredate\\t<’01-APR-81’;',\n",
       " '177)\\t\\t\\tList\\tthe\\temp\\twhose\\tannual\\tsal\\tis\\t<25000\\tin\\tthe\\tasc\\torder\\tof\\tthe\\tsalaries.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*sal)\\t<\\t25000\\torder\\tby\\tsal\\tasc;\\n178)\\t\\t\\tList\\tthe\\tempno,ename,annsal,dailysal\\t\\tof\\tall\\tthe\\tsalesmen\\tin\\tthe\\tasc\\tann\\nsal\\nA)\\tselect\\te.empno,e.ename\\t,12*sal\\t\"ANN\\tSAL\"\\t,\\t(12*sal)/365\\t\"DAILY\\tSAL\"\\nfrom\\temp\\te\\nwhere\\te.job\\t=\\t\\'SALESMAN\\'\\norder\\tby\\t\"ANN\\tSAL\"\\tasc\\t;\\n179)\\t\\t\\tList\\tthe\\tempno,ename,hiredate,current\\tdate\\t&\\texp\\tin\\tthe\\tascending\\torder\\nof\\tthe\\texp.\\nA)\\t\\t\\t\\tselect\\tempno,ename,hiredate,(select\\tsysdate\\tfrom\\tdual),\\n((months_between(sysdate,hiredate))/12)\\tEXP\\nfrom\\temp\\norder\\tby\\tEXP\\tasc;\\n180)\\t\\t\\tList\\tthe\\temps\\twhose\\texp\\tis\\tmore\\tthan\\t10\\tyears.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t((months_between(sysdate,hiredate))/12)\\t>\\t10;\\n181)\\t\\t\\tList\\tthe\\tempno,ename,sal,TA30%,DA\\t40%,HRA\\n50%,GROSS,LIC,PF,net,deduction,net\\tallow\\tand\\tnet\\tsal\\tin\\tthe\\tascending\\torder\\nof\\tthe\\tnet\\tsalary.',\n",
       " '182)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’;\\n183)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\teither\\tclerks\\tor\\tmanagers.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\tin\\t(‘CLERK’,’MANAGER’);\\n184)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\ton\\tthe\\tfollowing\\tdates\\t1\\tmay\\t81,17\\tnov\\n81,30\\tdec\\t81\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’DD-MON-YY’)\\t\\tin\\n(’01-MAY-81’,’17-NOV-81’,’30-DEC-81’);\\n185)\\t\\t\\tList\\tthe\\temps\\twho\\thave\\tjoined\\tin\\tthe\\tyear\\t1981.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YYYY’)\\t=\\t‘1981’;\\n186)\\t\\t\\tList\\tthe\\temps\\twhose\\tannual\\tsal\\tranging\\tfrom\\t23000\\tto\\t40000.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\t(12*\\tsal)\\tbetween\\t23000\\tand\\t40000;\\n187)\\t\\t\\tList\\tthe\\temps\\tworking\\tunder\\tthe\\tmgrs\\t7369,7890,7654,7900.',\n",
       " 'A)\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin\\t(\\t7369,7890,7654,7900);\\n188)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tsecond\\thalf\\tof\\t82.\\nA)select\\t*\\tfrom\\temp\\twhere\\thiredate\\tbetween\\t’01-JUL-82’\\tand\\t’31-DEC-82’;\\n189)\\t\\t\\tList\\tall\\tthe\\t4char\\temps.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(ename)\\t=\\t4;\\n190)\\t\\t\\tList\\tthe\\temp\\tnames\\tstarting\\twith\\t‘M’\\twith\\t5\\tchars.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’\\tand\\tlength\\t(ename)\\t=\\t5;\\n191)\\t\\t\\tList\\tthe\\temps\\tend\\twith\\t‘H’\\tall\\ttogether\\t5\\tchars.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘%H’\\tand\\tlength\\t(ename)\\t=\\t5;\\n192)\\t\\t\\tList\\tnames\\tstart\\twith\\t‘M’.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tename\\tlike\\t‘M%’;\\n193)\\t\\t\\tList\\tthe\\temps\\twho\\tjoined\\tin\\tthe\\tyear\\t81.',\n",
       " 'A)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t=\\t‘81’;\\n194)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tending\\twith\\t00.\\nA)\\t\\tselect\\t*\\tfrom\\twhere\\t\\tsal\\t\\tlike\\t\\t‘%00’;\\n195)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\tthe\\tmonth\\tof\\tJAN.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MM’)\\t=\\t1;\\n196)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tchar\\t‘a’.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char\\t(hiredate,’MONTH’)\\tlike’%A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MONTH’),’A’)\\t>0;\\n197)\\t\\t\\tWho\\tjoined\\tin\\tthe\\tmonth\\thaving\\tsecond\\tchar\\t‘a’\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\tlike\\t‘_A%’;\\t(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tinstr(to_char(hiredate,’MON’),’A’)\\t=\\t2;\\n198)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalary\\tis\\t4\\tdigit\\tnumber.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tlength\\t(sal)\\t=\\t4;(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\t\\twhere\\tsal\\tbetween\\t999\\tand\\t9999;',\n",
       " '199)\\t\\t\\tList\\tthe\\temp\\twho\\tjoined\\tin\\t80’s.\\nA)\\t\\t\\t\\tselect\\t*\\t\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t\\tbetween\\t‘80’\\tand\\t’89’;\\n(OR)\\nB)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’YY’)\\t>=\\t‘80’\\tand\\nto_char(hiredate,’YY’)\\t<\\t‘90’;\\n200)\\t\\t\\tList\\tthe\\temp\\twho\\tare\\tclerks\\twho\\thave\\texp\\tmore\\tthan\\t8ys.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’\\tand\\n(months_between(sysdate,hiredate)\\t/12)\\t>\\t8;\\n201)\\t\\t\\tList\\tthe\\tmgrs\\tof\\tdept\\t10\\tor\\t20.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘MANAGER’\\tand\\t(deptno\\t=\\t10\\tor\\tdeptno\\n=20);\\n202)\\t\\t\\tList\\tthe\\temps\\tjoined\\tin\\tjan\\twith\\tsalary\\tranging\\tfrom\\t1500\\tto\\t4000.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,’MON’)\\t=\\t‘JAN’\\tand\\tsal\\nbetween\\t1500\\tand\\t4000;\\n203)\\t\\t\\tList\\tthe\\tunique\\tjobs\\tof\\tdept\\t20\\tand\\t30\\tin\\tdesc\\torder.\\nA)\\tselect\\t\\tdistinct\\tjob\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(20,30)\\torder\\tby\\tjob\\tdesc;\\n204)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\texp\\tof\\tthose\\tworking\\tunder\\tthe\\tmgr\\twhose\\nnumber\\tis\\tstarting\\twith\\t7\\tbut\\tshould\\tnot\\thave\\ta\\t9\\tjoined\\tbefore\\t1983.',\n",
       " \"A)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t(mgr\\tlike\\t'7%'\\tand\\tmgr\\tnot\\tlike\\t'%9%')\\nand\\tto_char(hiredate,'YY')\\t<\\t'83';\\n205)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tas\\teither\\tmgr\\tor\\tanalyst\\twith\\tthe\\tsalary\\nranging\\tfrom\\t2000\\tto\\t5000\\tand\\twith\\tout\\tcomm.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\t\\t(job\\t\\tin\\t(‘MANAGER’\\t,’ANALYST’)\\t)\\tand\\tsal\\nbetween\\t\\t2000\\tand\\t5000\\tand\\tcomm\\tis\\tnull;\\n206)\\t\\t\\tList\\tthe\\tempno,ename,sal,job\\tof\\tthe\\temps\\twith\\t/ann\\tsal\\t<34000\\tbut\\nreceiving\\tsome\\tcomm.\\tWhich\\tshould\\tnot\\tbe>sal\\tand\\tdesg\\tshould\\tbe\\tsales\\tman\\nworking\\tfor\\tdept\\t30.\\nA)\\tselect\\tempno,ename,sal,job\\tfrom\\temp\\twhere\\n12*(sal+nvl(comm,0))\\t<\\t34000\\tand\\tcomm\\tis\\tnot\\tnull\\tand\\tcomm<sal\\tand\\tjob\\t=\\n'SALESMAN'\\tand\\tdeptno\\t=\\t30;\\t\\t\\n207)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tworking\\tfor\\tdept\\t10\\tor\\t20\\twith\\tdesgs\\tas\\tclerk\\tor\\nanalyst\\twith\\ta\\tsal\\tis\\teither\\t3\\tor\\t4\\tdigits\\twith\\tan\\texp>8ys\\tbut\\tdoes\\tnot\\tbelong\\tto\\nmons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\",\n",
       " \"mons\\tof\\tmar,apr,sep\\tand\\tworking\\tfor\\tmgrs\\t&no\\tis\\tnot\\tending\\twith\\t88\\tand\\t56.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\ndeptno\\tin\\t(10,20)\\tand\\njob\\tin\\t('CLERK','ANALYST')\\tand\\n(length(sal)\\tin\\t(3,4))\\tand\\n((months_between(sysdate,hiredate))/12)>\\t8\\tand\\nto_char(hiredate,'MON')\\tnot\\tin\\t('MAR','SEP','APR')\\tand\",\n",
       " \"(mgr\\tnot\\tlike\\t'%88'\\tand\\tmgr\\tnot\\tlike\\t'%56');\\n208)\\t\\t\\tList\\tthe\\tempno,ename,sal,job,deptno&exp\\tof\\tall\\tthe\\temps\\tbelongs\\tto\\tdept\\n10\\tor\\t20\\twith\\tan\\texp\\t6\\tto\\t10\\ty\\tworking\\tunder\\tthe\\tsame\\tmgr\\twith\\tout\\tcomm.\\nWith\\ta\\tjob\\tnot\\tending\\tirrespective\\tof\\tthe\\tposition\\twith\\tcomm.>200\\twith\\nexp>=7y\\tand\\tsal<2500\\tbut\\tnot\\tbelongs\\tto\\tthe\\tmonth\\tsep\\tor\\tnov\\tworking\\tunder\\nthe\\tmgr\\twhose\\tno\\tis\\tnot\\thaving\\tdigits\\teither\\t9\\tor\\t0\\tin\\tthe\\tasc\\tdept&\\tdesc\\tdept\\nA)\\n209)\\t\\t\\tList\\tthe\\tdetails\\tof\\tthe\\temps\\tworking\\tat\\tChicago.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\tin\\t(select\\tdeptno\\tfrom\\tdept\\twhere\\tdept.loc\\t=\\n‘CHICAGO’);\\n210)\\t\\t\\tList\\tthe\\tempno,ename,deptno,loc\\tof\\tall\\tthe\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t;\\n211)\\t\\t\\tList\\tthe\\tempno,ename,loc,dname\\tof\\tall\\tthe\\tdepts.,10\\tand\\t20.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,d.loc,d.dname\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\",\n",
       " \"where\\te.deptno\\t=\\td.deptno\\t\\t\\t\\tand\\t\\te.deptno\\tin\\t(10,20);\\n212)\\t\\t\\tList\\tthe\\tempno,\\tename,\\tsal,\\tloc\\tof\\tthe\\temps\\tworking\\tat\\tChicago\\tdallas\\nwith\\tan\\texp>6ys.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\t\\tand\\td.loc\\tin\\t('CHICAGO','DALLAS')\",\n",
       " \"and\\t(months_between(sysdate,hiredate)/12)>\\t6\\t;\\n213)\\t\\t\\tList\\tthe\\temps\\talong\\twith\\tloc\\tof\\tthose\\twho\\tbelongs\\tto\\tdallas\\t,newyork\\twith\\nsal\\tranging\\tfrom\\t2000\\tto\\t5000\\tjoined\\tin\\t81.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.deptno,e.sal,d.loc\\tfrom\\temp\\te\\t,dept\\td\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.loc\\tin\\t('NEW\\tYORK','DALLAS')\\nand\\tto_char(e.hiredate,'YY')\\t=\\t'81'\\t\\tand\\t\\te.sal\\tbetween\\t2000\\tand\\t5000;\\n214)\\t\\t\\tList\\tthe\\tempno,ename,sal,grade\\tof\\tall\\temps.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,e.sal,s.grade\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\nwhere\\te.sal\\t\\tbetween\\ts.losal\\tand\\ts.hisal\\t;\\n215)\\t\\t\\tList\\tthe\\tgrade\\t2\\tand\\t3\\temp\\tof\\tChicago.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tempno\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ns.hisal\\t\\tand\\ts.grade\\tin\\t(2,3));\\n216)\\t\\t\\tList\\tthe\\temps\\twith\\tloc\\tand\\tgrade\\tof\\taccounting\\tdept\\tor\\tthe\\tlocs\\tdallas\\tor\\nChicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\",\n",
       " 'Chicago\\twith\\tthe\\tgrades\\t3\\tto\\t5\\t&exp\\t>6y\\nA)\\t\\t\\t\\tselect\\te.deptno,e.empno,e.ename,e.sal,d.dname,d.loc,s.grade\\tfrom\\temp\\ne,salgrade\\ts,dept\\td\\nwheree.deptno\\t=\\td.deptno\\tand\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\ts.grade\\tin\\t(3,5)',\n",
       " \"and\\t((months_between(sysdate,hiredate))/12)\\t>\\t6\\nand\\t(\\td.dname\\t=\\t'ACCOUNTING'\\tor\\tD.loc\\tin\\t('DALLAS','CHICAGO'))\\n217)\\t\\t\\tList\\tthe\\tgrades\\t3\\temps\\tof\\tresearch\\tand\\toperations\\tdepts..\\tjoined\\tafter\\t1987\\nand\\twhose\\tnames\\tshould\\tnot\\tbe\\teither\\tmiller\\tor\\tallen.\\nA)\\t\\t\\t\\tselect\\te.ename\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno\\t=\\td.deptno\\tand\\td.dname\\tin\\t('OPERATIONS','RESEARCH')\\tand\\ne.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\nand\\te.ename\\tnot\\tin\\t('MILLER','ALLEN')\\nand\\tto_char(hiredate,'YYYY')\\t>1987;\\n218)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\tsmith.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\n'SMITH');\\n219)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\tmiller.\\nA)\\t\\t\\t\\tselect\\t\\t*\\t\\tfrom\\temp\\t\\twhere\\t\\thiredate\\t<(select\\thiredate\\tfrom\\temp\\twhere\\nename\\t=\\t‘MILLER’);\\n220)\\t\\t\\tList\\tthe\\temps\\twhose\\tjob\\tis\\tsame\\tas\\teither\\tallen\\tor\\tsal>allen.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tjob\\t=\\t(select\\tjob\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN')\\nor\\tsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\",\n",
       " \"221)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tsenior\\tto\\ttheir\\town\\tmanager.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw,emp\\tm\\twhere\\tw.mgr\\t=\\tm.empno\\tand\\nw.hiredate\\t<\\tm.hiredate;\\n222)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tgreater\\tthan\\tblakes\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal>(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t‘BLAKE’);\\n223)\\t\\t\\tList\\tthe\\tdept\\t10\\temps\\twhose\\tsal>allen\\tsal.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tdeptno\\t=\\t10\\tand\\nsal\\t>\\t(select\\tsal\\tfrom\\temp\\twhere\\tename\\t=\\t'ALLEN');\\n224)\\t\\t\\tList\\tthe\\tmgrs\\twho\\tare\\tsenior\\tto\\tking\\tand\\twho\\tare\\tjunior\\tto\\tsmith.\\nA)select\\t*\\tfrom\\temp\\twhere\\tempno\\tin\\n(select\\tmgr\\tfrom\\temp\\nwhere\\thiredate<(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'\\t)\\nand\\thiredate\\t>\\t(select\\thiredate\\tfrom\\temp\\twhere\\tename\\t=\\t\\t'SMITH'))\\tand\\tmgr\\nis\\t\\t\\t\\t\\t\\t\\t\\nnot\\tnull;\",\n",
       " \"225)\\t\\t\\tList\\tthe\\tempno,ename,loc,sal,dname,loc\\tof\\tthe\\tall\\tthe\\temps\\tbelonging\\tto\\nking\\tdept.\\nA)\\t\\t\\t\\tselect\\te.empno,e.ename,d.loc,e.sal,d.dname\\tfrom\\temp\\te,dept\\td\\nwhere\\te.deptno=d.deptno\\tand\\te.deptno\\tin\\n(select\\tdeptno\\tfrom\\t\\temp\\twhere\\tename\\t=\\t'KING'and\\temp.empno\\t<>\\te.empno);\\n226)\\t\\t\\tList\\tthe\\temps\\twhose\\tsalgrade\\tare\\tgreater\\tthan\\tthe\\tgrade\\tof\\tmiller.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te,salgrade\\ts\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t>\\n(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ne.ename\\t=\\t'MILLER')\\t;\\n227)\\t\\t\\tList\\tthe\\temps\\twho\\tare\\tbelonging\\tdallas\\tor\\tChicago\\twith\\tthe\\tgrade\\tsame\\tas\\nadamsor\\texp\\tmore\\tthan\\tsmith.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\t,dept\\td,salgrade\\ts\\nwhere\\te.deptno=\\td.deptno\\tand\\td.loc\\tin\\t('DALLAS','CHICAGO')\\tand\\te.sal\\nbetween\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\",\n",
       " \"between\\ts.losal\\tand\\ts.hisal\\tand\\n(s.grade\\tin\\t(select\\ts.grade\\tfrom\\temp\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ns.hisal\\tand\\te.ename\\t=\\t'ADAMS')\\nor\\tmonths_between\\t(sysdate,hiredate)\\t>\\t(select\\nmonths_between(sysdate,hiredate)\\tfrom\\temp\\twhere\\tename\\t=\\t'SMITH'))\\t;\\n228)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tford\\tor\\tblake.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tsal\\tfrom\\temp\\te\\twhere\\te.ename\\tin\\n('FORD','BLAKE')and\\temp.empno\\t<>\\te.empno);\",\n",
       " \"229)\\t\\t\\tList\\tthe\\temps\\twhose\\tsal\\tis\\tsame\\tas\\tany\\tone\\tof\\tthe\\tfollowing.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\t\\tin\\t\\n(select\\tsal\\tfrom\\temp\\te\\twhere\\temp.empno\\t<>\\te.empno);\\n230)\\t\\t\\tSal\\tof\\tany\\tclerk\\tof\\temp1\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tjob\\t=\\t‘CLERK’;\\n231)\\t\\t\\tAny\\temp\\tof\\temp2\\tjoined\\tbefore\\t82.\\nA)\\tselect\\t*\\tfrom\\temp\\twhere\\tto_char(hiredate,'YYYY')\\t<\\t1982;\\n232)\\t\\t\\tThe\\ttotal\\tremuneration\\t(sal+comm.)\\tof\\tall\\tsales\\tperson\\tof\\tSales\\tdept\\nbelonging\\tto\\temp3\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\te\\nwhere\\t(sal+nvl(comm,0))\\tin\\n(select\\tsal+nvl(comm,0)\\t\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno=d.deptno\\t\\nand\\td.dname\\t=\\t'SALES'and\\te.job\\t=\\t'SALESMAN');\\n233)\\t\\t\\tAny\\tGrade\\t4\\temps\\tSal\\tof\\temp\\t4\\ttable.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp4\\te,salgrade\\ts\\twhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ns.grade\\t=\\t4;\",\n",
       " '234)\\t\\t\\tAny\\temp\\tSal\\tof\\temp5\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp5;\\n235)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp);\\n236)\\t\\t\\tList\\tthe\\tdetails\\tof\\tmost\\trecently\\thired\\temp\\tof\\tdept\\t30.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tdeptno\\t=\\t30);\\n237)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tof\\tChicago\\tjoined\\tbefore\\tthe\\tmost\\t\\trecently\\nhired\\temp\\tof\\tgrade\\t2.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\nwhere\\tsal\\t=\\t(\\tselect\\tmax(sal)\\tfrom\\temp\\te,dept\\td\\twhere\\te.deptno\\t=\\t\\nd.deptno\\tand\\td.loc\\t=\\t‘CHICAGO’\\tand\\nhiredate\\t<(select\\tmax(hiredate)\\tfrom\\temp\\te\\t,salgrade\\ts\\t\\t\\t\\t\\t\\t\\t\\t\\nwhere\\te.sal\\tbetween\\ts.losal\\tand\\ts.hisal\\tand\\ts.grade\\t=\\t2))\\n238)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp\\tworking\\tunder\\tking.\\nA)select\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\n(select\\tmax(sal)\\tfrom\\temp\\twhere\\tmgr\\tin',\n",
       " \"(select\\tempno\\tfrom\\temp\\twhere\\tename\\t=\\t'KING'));\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b48a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 335 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (335, 384)\n",
      "Adding 335 documents to vector store...\n",
      "Successfully added 335 documents to vector store\n",
      "Total documents in collection: 335\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b9e4f",
   "metadata": {},
   "source": [
    "## Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01033ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0284df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x18ba9d20830>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624e2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is practical python and openCV'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_6e86b48c_1',\n",
       "  'content': 'C O P Y R I G H T\\nThe contents of this book, unless otherwise indicated, are\\nCopyright c⃝2018 Adrian Rosebrock, PyImageSearch.com.\\nAll rights reserved.\\nThis version of the book was published on 14 December\\n2018.\\nBooks like this are made possible by the time invested by\\nthe authors. If you received this book and did not purchase\\nit, please consider making future books possible by buy-\\ning a copy at https://www.pyimagesearch.com/practical-\\npython-opencv/ today.\\nii',\n",
       "  'metadata': {'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'page_label': 'ii',\n",
       "   'author': '',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'page': 2,\n",
       "   'total_pages': 166,\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': '/False',\n",
       "   'subject': '',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'keywords': '',\n",
       "   'title': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'content_length': 466,\n",
       "   'doc_index': 1},\n",
       "  'similarity_score': 0.5089291930198669,\n",
       "  'distance': 0.49107080698013306,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_39d28cce_33',\n",
       "  'content': 'conﬁgured Ubuntu virtual machine with all of the above\\nlibraries mentioned already installed.\\nIf you are interested in downloading this virtual machine\\n(and saving yourself a lot of time and hassle), you can\\nhead on over to http://www.pyimagesearch.com/practical-\\npython-opencv/.\\n12',\n",
       "  'metadata': {'total_pages': 166,\n",
       "   'page_label': '12',\n",
       "   'doc_index': 33,\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'content_length': 282,\n",
       "   'keywords': '',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'trapped': '/False',\n",
       "   'file_type': 'pdf',\n",
       "   'subject': '',\n",
       "   'page': 23,\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'author': '',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'title': ''},\n",
       "  'similarity_score': 0.4788179397583008,\n",
       "  'distance': 0.5211820602416992,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_3e432d38_27',\n",
       "  'content': '2.4 opencv\\n$ pip install matplotlib\\nOtherwise, a binary installer is provided for Windows.\\n2.4 opencv\\nIf NumPy’s main goal is large, efﬁcient, multi-dimensional\\narray representations, then, the main goal of OpenCV is\\nreal-time image processing. This library has been around\\nsince 1999, but it wasn’t until the 2.0 release in 2009 that\\nwe saw the incredible NumPy support. The library itself is\\nwritten in C/C++, but Python bindings are provided when\\nrunning the installer. OpenCV is hands down my favorite\\ncomputer vision library, and we’ll use it a lot in this book.\\nAs OpenCV evolves and changes, so does the installa-\\ntion process. Since the library is written in C/C++, special\\ncare has to be taken when compiling and ensuring that the\\nprerequisites are installed. Be sure to check the OpenCV\\nwebsite at http://opencv.org/ for the latest installation in-\\nstructions since they do (and will) change in the future.\\n2.4.1 Linux and OSX\\nInstalling OpenCV in Linux and OSX has been a pain in',\n",
       "  'metadata': {'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'title': '',\n",
       "   'file_type': 'pdf',\n",
       "   'trapped': '/False',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'content_length': 990,\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'doc_index': 27,\n",
       "   'keywords': '',\n",
       "   'page_label': '9',\n",
       "   'author': '',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'page': 20,\n",
       "   'producer': 'pdfTeX-1.40.16'},\n",
       "  'similarity_score': 0.389556348323822,\n",
       "  'distance': 0.610443651676178,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_5cdbd953_0',\n",
       "  'content': 'Practical Python and\\nOpenCV: An Introductory,\\nExample Driven Guide to\\nImage Processing and\\nComputer Vision\\n4th Edition\\nDr. Adrian Rosebrock',\n",
       "  'metadata': {'keywords': '',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'trapped': '/False',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'doc_index': 0,\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'page_label': 'i',\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'content_length': 139,\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'page': 1,\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.37127792835235596,\n",
       "  'distance': 0.628722071647644,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_eb2192eb_22',\n",
       "  'content': '2.1 a note on python & opencv versions\\ntions, and compiling errors.\\nTo ﬁnd out more about this pre-conﬁgured virtual ma-\\nchine, head on over to: http://www.pyimagesearch.com\\n/practical-python-opencv/.\\nIn the rest of this chapter, I will discuss the various Python\\npackages that are useful for computer vision and image pro-\\ncessing. I’ll also provide instructions on how to install each\\nof these packages.\\nIt is worth mentioning that I have collected OpenCV in-\\nstallation tutorials for various Python versions and operat-\\ning systems on PyImageSearch: http://pyimg.co/vvlpy.\\nBe sure to take a look as I’m sure the install guides will\\nbe helpful to you! In the meantime, let’s review some im-\\nportant Python packages that we’ll use for computer vision.\\n2.1 a note on python & opencv versions\\nInside this book, you’ll ﬁnd that all chapters, code samples,\\nand datasets are compatible with OpenCV 3 and OpenCV\\n4. Furthermore, all code examples will run in both the',\n",
       "  'metadata': {'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'page_label': '6',\n",
       "   'trapped': '/False',\n",
       "   'content_length': 961,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'page': 17,\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'author': '',\n",
       "   'doc_index': 22,\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'keywords': '',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'file_type': 'pdf',\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'title': ''},\n",
       "  'similarity_score': 0.37003862857818604,\n",
       "  'distance': 0.629961371421814,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is practical python and openCV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f18abf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'using opencv to compute histograms'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_624b227f_171',\n",
       "  'content': 'The most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-\\nnels: the Green and Blue channels. And that’s all there is\\nto it.\\nSo, how is a 2D histogram stored in OpenCV? It’s actually\\na 2D NumPy array. Since I used 32 bins for each channel, I\\nnow have a 32 × 32 histogram.\\nHow do we visualize a 2D histogram? Let’s take a look\\nat Figure 7.3 where we see three graphs. The ﬁrst is a 2D\\ncolor histogram for the Green and Blue channels, the sec-\\nond for Green and Red, and the third for Blue and Red.\\nShades of blue represent low pixel counts, whereas shades\\n97',\n",
       "  'metadata': {'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'content_length': 673,\n",
       "   'title': '',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'trapped': '/False',\n",
       "   'keywords': '',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'page_label': '97',\n",
       "   'author': '',\n",
       "   'doc_index': 171,\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'page': 108},\n",
       "  'similarity_score': 0.3932763338088989,\n",
       "  'distance': 0.6067236661911011,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_a012858b_158',\n",
       "  'content': '7.1 using opencv to compute histograms\\nand intensity distribution.\\n7.1 using opencv to compute histograms\\nNow, let’s start building some histograms of our own.\\nWe will be using the cv2.calcHist function to build our\\nhistograms. Before we get into any code examples, let’s\\nquickly review the function:\\ncv2.calcHist(images,channels,mask,histSize,ranges)\\n1. images: This is the image that we want to compute a\\nhistogram for. Wrap it as a list: [myImage].\\n2. channels: This is a list of indexes, where we specify\\nthe index of the channel we want to compute a his-\\ntogram for. To compute a histogram of a grayscale\\nimage, the list would be [0]. To compute a histogram\\nfor all three red, green, and blue channels, the chan-\\nnels list would be [0,1,2].\\n3. mask: Remember learning about masks in Chapter\\n6? Well, here we can supply a mask. If a mask is\\nprovided, a histogram will be computed for masked\\npixels only. If we do not have a mask or do not want\\nto apply one, we can just provide a value of None.',\n",
       "  'metadata': {'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'page_label': '90',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'title': '',\n",
       "   'subject': '',\n",
       "   'trapped': '/False',\n",
       "   'page': 101,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'keywords': '',\n",
       "   'file_type': 'pdf',\n",
       "   'total_pages': 166,\n",
       "   'content_length': 998,\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'doc_index': 158,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'author': ''},\n",
       "  'similarity_score': 0.34055089950561523,\n",
       "  'distance': 0.6594491004943848,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_64389bba_177',\n",
       "  'content': '5\\n6 def plot_histogram(image, title, mask = None):\\n7 chans = cv2.split(image)\\n8 colors = (\"b\", \"g\", \"r\")\\n9 plt.figure()\\n10 plt.title(title)\\n11 plt.xlabel(\"Bins\")\\n12 plt.ylabel(\"# of Pixels\")\\n13\\n14 for (chan, color) in zip(chans, colors):\\n15 hist = cv2.calcHist([chan], [0], mask, [256], [0, 256])\\n16 plt.plot(hist, color = color)\\n17 plt.xlim([0, 256])\\n101',\n",
       "  'metadata': {'title': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'page': 112,\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'author': '',\n",
       "   'content_length': 355,\n",
       "   'doc_index': 177,\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'page_label': '101',\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'trapped': '/False',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.2590109705924988,\n",
       "  'distance': 0.7409890294075012,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_cc75e3b0_160',\n",
       "  'content': '7.2 grayscale histograms\\n5. ranges: Here we specify The range of possible pixel\\nvalues. Normally, this is [0, 256] for each channel, but\\nif you are using a color space other than RGB (such as\\nHSV), the ranges might be different.\\nNext up, we’ll use thecv2.calcHist function to compute\\nour ﬁrst histogram.\\n7.2 grayscale histograms\\nNow that we have an understanding of the cv2.calcHist\\nfunction, let’s write some actual code.\\nListing 7.1: grayscale_histogram.py\\n1 from matplotlib import pyplot as plt\\n2 import argparse\\n3 import cv2\\n4\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.imread(args[\"image\"])\\nThis code isn’t very exciting yet. All we are doing is\\nimporting the packages we will need, setting up an argu-\\nment parser, and loading our image. We’ll make use of the\\nmatplotlib package to make plotting our histograms eas-\\nier.\\nListing 7.2: grayscale_histogram.py',\n",
       "  'metadata': {'page_label': '91',\n",
       "   'trapped': '/False',\n",
       "   'title': '',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'page': 102,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'doc_index': 160,\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'content_length': 982,\n",
       "   'keywords': '',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'total_pages': 166,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.25835633277893066,\n",
       "  'distance': 0.7416436672210693,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_7c717900_170',\n",
       "  'content': '7.3 color histograms\\n49 hist.shape, hist.flatten().shape[0]))\\nYes, this is a fair amount of code. But that’s only because\\nwe are computing a 2D color histogram for each combina-\\ntion of RGB channels: Red and Green, Red and Blue, and\\nGreen and Blue.\\nNow that we are working with multi-dimensional his-\\ntograms, we need to keep in mind the number of bins we\\nare using. In previous examples, I’ve used 256 bins for\\ndemonstration purposes. However, if we used a256 bins for\\neach dimension in a 2D histogram, our resulting histogram\\nwould have 256 × 256 = 65, 536 separate pixel counts. Not\\nonly is this wasteful of resources, it’s not practical. Most\\napplications use somewhere between 8 and 64 bins when\\ncomputing multi-dimensional histograms. As Lines 28 and\\n29 show, I am now using 32 bins instead of 256.\\nThe most important takeaway from this code can be seen\\nby inspecting the ﬁrst arguments to the cv2.calcHist func-\\ntion. Here we see that we are passing in a list of two chan-',\n",
       "  'metadata': {'producer': 'pdfTeX-1.40.16',\n",
       "   'title': '',\n",
       "   'author': '',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'keywords': '',\n",
       "   'subject': '',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'content_length': 979,\n",
       "   'total_pages': 166,\n",
       "   'file_type': 'pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'page': 108,\n",
       "   'trapped': '/False',\n",
       "   'page_label': '97',\n",
       "   'doc_index': 170,\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf'},\n",
       "  'similarity_score': 0.2528200149536133,\n",
       "  'distance': 0.7471799850463867,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"using opencv to compute histograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555e295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'contours and opencv version caveats'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_8ee0344a_255',\n",
       "  'content': '11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to use\\nthe grab_contours function or simply make the assump-\\ntion that your end user is utilizing a speciﬁc version of\\nOpenCV and hard-code the return tuple. I have provided\\nyou with examples of both inside the text and source code of\\nthis book so you can see both in action (and make whatever\\ndecision you feel is best based on your particular situation).\\nFurther Reading\\nWhenever you are working on a new problem, consider\\nhow contours and the associated properties of contours\\ncan help you solve the problem. More often than not,\\na clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-',\n",
       "  'metadata': {'title': '',\n",
       "   'author': '',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'page_label': '152',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'keywords': '',\n",
       "   'doc_index': 255,\n",
       "   'trapped': '/False',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'page': 163,\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'subject': '',\n",
       "   'total_pages': 166,\n",
       "   'content_length': 988,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00'},\n",
       "  'similarity_score': 0.6397204697132111,\n",
       "  'distance': 0.36027953028678894,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_933a8b52_252',\n",
       "  'content': '11.2 contours and opencv version caveats\\nFigure 11.2: Top: Cropping the coin by ﬁnd-\\ning the bounding box and apply-\\ning NumPy array slicing. Bottom:\\nFitting a circle to the contour and\\nmasking the coin.\\nated hierarchy.\\nIn OpenCV 3.0, we have a third value added to the return\\ntuple: the image itself after applying the contour detection\\nalgorithm.\\nWith the latest release of OpenCV 4, the return signature\\nis a 2-tuple, just like OpenCV 2.4.\\nThis is a small, minor change (and one that I’m person-\\nally not crazy about since it breaks backwards compatibility\\nwith so many scripts), but something that can deﬁnitely trip\\nyou up when working between OpenCV versions.\\nIn order to make it easier for you to work with the cv2.\\nfindContours function, I have included a convenience method\\ninside the source code of this book/the imutils.py ﬁles\\n150',\n",
       "  'metadata': {'subject': '',\n",
       "   'content_length': 842,\n",
       "   'trapped': '/False',\n",
       "   'author': '',\n",
       "   'total_pages': 166,\n",
       "   'title': '',\n",
       "   'keywords': '',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'page': 161,\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '150',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'doc_index': 252,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1'},\n",
       "  'similarity_score': 0.4968632459640503,\n",
       "  'distance': 0.5031367540359497,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_63c31229_251',\n",
       "  'content': 'ages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!\\nIt’s the best way to learn!\\n11.2 contours and opencv version caveats\\nThe length of the return tuple of the cv2.findContours\\nfunction has changed between OpenCV 2.4, OpenCV 3, and\\nOpenCV 4.\\nOriginally, in OpenCV 2.4, this tuple was only a 2-tuple,\\nconsisting of just the contours themselves and the associ-\\n149',\n",
       "  'metadata': {'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'file_type': 'pdf',\n",
       "   'content_length': 487,\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'author': '',\n",
       "   'trapped': '/False',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'total_pages': 166,\n",
       "   'title': '',\n",
       "   'doc_index': 251,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'page': 160,\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'page_label': '149'},\n",
       "  'similarity_score': 0.4262216091156006,\n",
       "  'distance': 0.5737783908843994,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_5e5991aa_253',\n",
       "  'content': '11.2 contours and opencv version caveats\\ncalled grab_contours.\\nInternally, thegrab_contours function inspects the length\\nof the tuple returned by cv2.findContours and then parses\\nout the contours variable, ignoring the hierarchy and the re-\\nturned image (if applicable).\\nHere is an example of using the grab_contours function:\\nListing 11.5: counting_coins.py\\n5 def grab_contours(cnts):\\n6 if len(cnts) == 2:\\n7 cnts = cnts[0]\\n8\\n9 elif len(cnts) == 3:\\n10 cnts = cnts[1]\\n11\\n12 else:\\n13 raise Exception((\"Contours tuple must have length 2 or \"\\n14 \"3, otherwise OpenCV changed their cv2.findContours \"\\n15 \"return signature yet again. Refer to OpenCV’s\\n16 documentation in that case.\"))\\n17\\n18 return cnts\\nYou can use the grab_contours function like this:\\nListing 11.6: counting_coins.py\\n1 cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.\\nCHAIN_APPROX_SIMPLE)\\n2 cnts = imutils.grab_contours(cnts)\\n3 cv2.drawContours(image, cnts, -1, (0, 255, 0), 2)',\n",
       "  'metadata': {'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'trapped': '/False',\n",
       "   'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'page': 162,\n",
       "   'file_type': 'pdf',\n",
       "   'author': '',\n",
       "   'keywords': '',\n",
       "   'page_label': '151',\n",
       "   'title': '',\n",
       "   'doc_index': 253,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'subject': '',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'content_length': 953,\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'total_pages': 166},\n",
       "  'similarity_score': 0.30909550189971924,\n",
       "  'distance': 0.6909044981002808,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_4592de71_250',\n",
       "  'content': '11.2 contours and opencv version caveats\\nwas covered in Chapter 5, Section 5.2.\\nWe then crop the mask in the exact same manner as we\\ncropped the coin on Line 36.\\nIn order to show only the foreground of the coin and ig-\\nnore the background, we make a call to our trusty bitwise\\nAND function using the coin image and the mask for the\\ncoin. The coin, with the background removed, is shown to\\nus on Line 37.\\nFigure 11.2 shows the output of our hard work. The\\ntop ﬁgure shows that we cropped the coin by ﬁnding the\\nbounding box and applying NumPy array slicing. The bot-\\ntom image then shows our masking of the coin by ﬁtting a\\ncircle to the contour. The background is removed and only\\nthe coin is shown.\\nAs you can see, contours are extremely powerful tools to\\nhave in our toolbox. They allow us to count objects in im-\\nages and allow us to extract these objects from images. We\\nare just scratching the surface of what contours can do, so\\nbe sure to play around with them and explore for yourself!',\n",
       "  'metadata': {'moddate': '2025-10-09T20:13:54+06:30',\n",
       "   'page': 160,\n",
       "   'creationdate': '2019-01-06T06:31:50-05:00',\n",
       "   'total_pages': 166,\n",
       "   'page_label': '149',\n",
       "   'keywords': '',\n",
       "   'trapped': '/False',\n",
       "   'creator': 'LaTeX with hyperref package',\n",
       "   'title': '',\n",
       "   'content_length': 993,\n",
       "   'producer': 'pdfTeX-1.40.16',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.16 (TeX Live 2015) kpathsea version 6.2.1',\n",
       "   'source': '..\\\\data\\\\pdf\\\\Practical Python and OpenCV.pdf',\n",
       "   'source_file': 'Practical Python and OpenCV.pdf',\n",
       "   'doc_index': 250,\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'file_type': 'pdf'},\n",
       "  'similarity_score': 0.23260444402694702,\n",
       "  'distance': 0.767395555973053,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"contours and opencv version caveats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b02fea",
   "metadata": {},
   "source": [
    "### RAG Pipeline- VectorDB To LLM Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe34fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (set your GROQ_API_KEY in environment)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "# Use a supported model - gemma2-9b-it was decommissioned.\n",
    "# Recommended: llama3-8b-8192 (or another current model from your provider).\n",
    "# The code falls back to a safe default if the env var MODEL_NAME is set.\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"llama3-8b-8192\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=model_name, temperature=0.1, max_tokens=1024)\n",
    "\n",
    "## 2. Simple RAG function: retrieve context + generate response\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    \"\"\"Retrieve top_k contexts and ask llm to answer using only that context.\"\"\"\n",
    "    # retrieve the context\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "\n",
    "    # build a clear prompt\n",
    "    prompt = (\n",
    "        \"You are a helpful assistant. Use ONLY the information in the Context to answer the Question.\\n\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    "        \"Question: {query}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    # Use the llm.invoke API and handle different response shapes robustly\n",
    "    try:\n",
    "        raw = llm.invoke([prompt.format(context=context, query=query)])\n",
    "        # Some LLM wrappers return an object with .content, others return a list or string\n",
    "        if hasattr(raw, \"content\"):\n",
    "            return raw.content\n",
    "        elif isinstance(raw, list) and raw:\n",
    "            first = raw[0]\n",
    "            if hasattr(first, \"content\"):\n",
    "                return first.content\n",
    "            else:\n",
    "                return str(raw)\n",
    "        else:\n",
    "            return str(raw)\n",
    "    except Exception as e:\n",
    "        return f\"Error invoking LLM: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db9fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is attention mechanism?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n",
      "No relevant context found to answer the question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"What is attention mechanism?\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ad0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant context found to answer the question.\n"
     ]
    }
   ],
   "source": [
    "# Re-initialize LLM using same environment-driven model_name variable\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\", \"llama3-8b-8192\")\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=model_name, temperature=0.1, max_tokens=1024)\n",
    "print(f\"LLM initialized with model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e141e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates helper (copy-ready strings)\\nPROMPT_RAG_QA = (\\n    \"You are a helpful assistant. Use ONLY the information in the Context to answer the Question. \"\\n    \"If the answer is not present, reply 'I don't know from these documents.' and offer to search more.\\n\\n\"\\n    \"Context:\\n{context}\\n\\n\"\\n    \"Question: {question}\\n\\n\"\\n    \"Answer:\"\\n)\\n\\nPROMPT_SUMMARY_SHORT = (\\n    \"Summarize the following content in {sentences} sentences. Keep it factual and concise.\\n\\nContent:\\n{context}\\n\"\\n)\\n\\nPROMPT_EXTRACTION_JSON = (\\n    \"Extract the following fields and return valid JSON that matches the schema: {schema}. \"\\n    \"If a field is missing, use null. Return ONLY JSON with these keys.\\n\\nContent:\\n{context}\\n\"\\n)\\n\\n# Example usage:\\n# llm.invoke([PROMPT_RAG_QA.format(context=context, question=user_q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is the main topic introduced in the first chapters of the uploaded PDF documents?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 0 documents (after filtering)\n",
      "Prompt Question: What is the main topic introduced in the first chapters of the uploaded PDF documents?\n",
      "\n",
      "Answer: No relevant context found to answer the question.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e12d1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize with a currently available Groq model\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",  # Use this currently available model\n",
    "    # model=\"llama-3.1-70b-versatile\",  # Or this more powerful model\n",
    "    temperature=0,\n",
    "    groq_api_key=groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ae66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is the Canny edge detector? Explain its steps and provide examples.'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Canny edge detector is a multi-step process used to detect edges in an image. Its steps include:\n",
      "\n",
      "1. **Blurring the image**: Removing noise by blurring the image.\n",
      "2. **Computing Sobel gradient images**: Calculating the gradient of the image in the x and y directions.\n",
      "3. **Suppressing edges**: Reducing the number of edges detected to reduce noise.\n",
      "4. **Hysteresis thresholding**: Determining if a pixel is an edge or not based on its intensity value.\n",
      "\n",
      "The Canny edge detector is useful for detecting the outline of objects in an image, such as the outline of coins in a grayscale image. It produces more \"crisp\" edges compared to other edge detection methods like the Laplacian or Sobel gradient images.\n",
      "\n",
      "For example, in the given context, the Canny edge detector is applied to a grayscale image of coins, resulting in a more \"crisp\" edge detection with less noise. The lower and upper edge thresholds are typically set to determine if a pixel is an edge or not, with values below 30 considered non-edges and values above 150 considered edges.\n"
     ]
    }
   ],
   "source": [
    "# Your question about Canny edge detector is perfect for this context\n",
    "answer = rag_simple(\n",
    "    \"What is the Canny edge detector? Explain its steps and provide examples.\", \n",
    "    \"Explain image thresholding methods in OpenCV\",\n",
    "    rag_retriever, \n",
    "    llm\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b2f03ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain image thresholding methods in OpenCV'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image thresholding in OpenCV is a process of converting an image into a binary image, where pixels are either black (0) or white (255). There are two main types of thresholding methods:\n",
      "\n",
      "1. **Simple Thresholding**: This method involves setting a fixed threshold value (T) and comparing each pixel intensity with it. If the pixel intensity is greater than T, it is set to the maximum value (255), otherwise it is set to 0.\n",
      "\n",
      "   Example: `cv2.threshold(image, T, 255, cv2.THRESH_BINARY)`\n",
      "\n",
      "2. **Adaptive Thresholding**: This method involves dividing the image into small neighborhoods and applying the thresholding process to each neighborhood separately. The threshold value is calculated based on the mean intensity of the neighborhood.\n",
      "\n",
      "   Example: `cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 4)`\n",
      "\n",
      "   In the example, `11` is the neighborhood size and `4` is the constant subtracted from the mean intensity.\n",
      "\n",
      "There are also two types of adaptive thresholding methods:\n",
      "\n",
      "*   **Mean Adaptive Thresholding**: This method calculates the threshold value based on the mean intensity of the neighborhood.\n",
      "*   **Gaussian Adaptive Thresholding**: This method calculates the threshold value based on the weighted mean intensity of the neighborhood.\n",
      "\n",
      "In addition to these methods, there is also a **Binary Inverse** thresholding method, which sets any pixel intensity greater than T to 0 and any pixel intensity less than T to 255.\n",
      "\n",
      "   Example: `cv2.threshold(image, T, 255, cv2.THRESH_BINARY_INV)`\n"
     ]
    }
   ],
   "source": [
    "# Your question about Canny edge detector is perfect for this context\n",
    "answer = rag_simple(\n",
    "    #\"What is the Canny edge detector? Explain its steps and provide examples.\", \n",
    "    \"Explain image thresholding methods in OpenCV\",\n",
    "    rag_retriever, \n",
    "    llm\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22d933d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Explain image transformations like rotation and translation'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image transformations are operations that modify the position, orientation, or size of an image. Two common types of image transformations are rotation and translation.\n",
      "\n",
      "**Rotation:**\n",
      "Rotation is the process of rotating an image by a specified angle around a certain point. This can be useful for various applications such as:\n",
      "\n",
      "* Changing the orientation of an image\n",
      "* Creating a sense of movement or action\n",
      "* Enhancing the visual appeal of an image\n",
      "\n",
      "In the context of the provided code, rotation is achieved using the `cv2.getRotationMatrix2D` function, which generates a rotation matrix based on the specified angle and center point. The `cv2.warpAffine` function is then used to apply the rotation to the image.\n",
      "\n",
      "**Translation:**\n",
      "Translation is the process of shifting an image by a specified amount in the x and y directions. This can be useful for various applications such as:\n",
      "\n",
      "* Aligning an image with another image or object\n",
      "* Creating a sense of movement or action\n",
      "* Enhancing the visual appeal of an image\n",
      "\n",
      "In the context of the provided code, translation is not explicitly demonstrated, but it can be achieved using the `cv2.translate` function, which shifts the image by a specified amount in the x and y directions.\n",
      "\n",
      "**Key concepts:**\n",
      "\n",
      "* Rotation matrix: a mathematical representation of the rotation transformation\n",
      "* Center point: the point around which the image is rotated\n",
      "* Angle: the amount of rotation applied to the image\n",
      "* Translation: the amount of shift applied to the image in the x and y directions\n",
      "\n",
      "**Code snippets:**\n",
      "\n",
      "* Rotation: `M = cv2.getRotationMatrix2D(center, 45, 1.0)` and `rotated = cv2.warpAffine(image, M, (w, h))`\n",
      "* Translation: `translated = cv2.translate(image, (dx, dy))` (not explicitly demonstrated in the provided code)\n"
     ]
    }
   ],
   "source": [
    "# Your question about Canny edge detector is perfect for this context\n",
    "answer = rag_simple(\n",
    "   # \"What is the Canny edge detector? Explain its steps and provide examples.\", \n",
    "   # \"Explain image thresholding methods in OpenCV\",\n",
    "   \"Explain image transformations like rotation and translation\",\n",
    "    rag_retriever, \n",
    "    llm\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecde63",
   "metadata": {},
   "source": [
    "## Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02a9a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'How does histogram equalization improve image contrast?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Histogram equalization improves image contrast by \"stretching\" the distribution of pixels. This is done by taking a histogram with a large peak at the center and stretching it out towards the corners of the image. This process helps to improve the global contrast of the image by making the darker areas darker and the lighter areas lighter.\n",
      "\n",
      "In other words, histogram equalization redistributes the pixel values in the image so that the entire range of possible values is used, rather than having a large peak in the middle of the histogram. This results in a more even distribution of pixel values, which can make the image appear more visually appealing and easier to interpret.\n",
      "\n",
      "For example, if an image has a large peak in the middle of the histogram, it means that most of the pixels in the image have similar values, resulting in a lack of contrast. By applying histogram equalization, the peak is stretched out towards the corners of the histogram, resulting in a more even distribution of pixel values and improved contrast.\n",
      "Sources: [{'source': 'Practical Python and OpenCV.pdf', 'page': 110, 'score': 0.6063262522220612, 'preview': '7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing an 8 × 8 × 8 histogram\\nfor each of the RGB channels. We can’t visualize this his-\\ntogram, but we can see that the shape is indeed (8,8,8)\\nwith 512 values.\\n7.4 histogram equalizati...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 110, 'score': 0.47982001304626465, 'preview': 'ever, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are applying histogram equaliza-\\ntion to a photograph, a satellite image, or an X-ray, we ﬁrst\\nneed to see some code so we can understand what is going\\non:\\nListing 7.7: equalize.py\\n1 import...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 111, 'score': 0.12199676036834717, 'preview': '7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram equalization.\\n5 ap = argparse.ArgumentParser()\\n6 ap.add_argument(\"-i\", \"--image\", required = True,\\n7 help = \"Path to the image\")\\n8 args = vars(ap.parse_args())\\n9\\n10 image = cv2.im...'}]\n",
      "Confidence: 0.6063262522220612\n",
      "Context Preview: 7.4 histogram equalization\n",
      "The code here is very simple – it’s just an extension of the\n",
      "code above. We are now computing an 8 × 8 × 8 histogram\n",
      "for each of the RGB channels. We can’t visualize this his-\n",
      "togram, but we can see that the shape is indeed (8,8,8)\n",
      "with 512 values.\n",
      "7.4 histogram equalizati\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"     \"How does histogram equalization improve image contrast?\"\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(   \"How does histogram equalization improve image contrast?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71d9c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'How do contours work in computer vision?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Contours in computer vision are curves of points with no gaps in the curve, used for shape approximation and analysis. They are found in an image by first obtaining a binarization of the image, typically using edge detection methods or thresholding.\n",
      "Sources: [{'source': 'Practical Python and OpenCV.pdf', 'page': 163, 'score': 0.2251429557800293, 'preview': 'a clever use of contours can save you a lot of time and\\navoid more advanced (and tedious) techniques.\\nOf course, contours can’t help you detect objects in im-\\nages in all situations. But in certain circumstances, con-\\ntours are all you need. I’ve included examples of such\\nsituations in the supplemen...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 163, 'score': 0.12646496295928955, 'preview': '11.2 contours and opencv version caveats\\ntract the actual contours list.\\nFinally,Line 3 takes the parsed contours fromgrab_contours\\nand draws them on our image. By using grab_contours we\\ncan be sure our script will work across all OpenCV versions.\\nIt is entirely up to you whether or not you want to ...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 153, 'score': 0.11324083805084229, 'preview': '11\\nC O N T O U R S\\nPreviously, we explored how to detect edges in an image\\nof coins.\\nNow we are going to use these edges to help us ﬁnd the\\nactual coins in the image and count them.\\nOpenCV provides methods to ﬁnd “curves” in an image,\\ncalled contours. A contour is a curve of points, with no\\ngaps in ...'}]\n",
      "Confidence: 0.2251429557800293\n",
      "Context Preview: a clever use of contours can save you a lot of time and\n",
      "avoid more advanced (and tedious) techniques.\n",
      "Of course, contours can’t help you detect objects in im-\n",
      "ages in all situations. But in certain circumstances, con-\n",
      "tours are all you need. I’ve included examples of such\n",
      "situations in the supplemen\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"How do contours work in computer vision?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0863a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Find employees earning more than their managers?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: To find employees earning more than their managers, you can use the following SQL query:\n",
      "\n",
      "```sql\n",
      "select w.ename, w.sal, m.ename, m.sal\n",
      "from emp w, emp m\n",
      "where w.mgr = m.empno and w.sal > m.sal;\n",
      "```\n",
      "\n",
      "This query joins the `emp` table with itself, where the first instance (`w`) represents the employee and the second instance (`m`) represents the manager. The `where` clause filters the results to include only rows where the employee's salary is greater than their manager's salary.\n",
      "Sources: [{'source': 'SQL Queries .pdf', 'page': 22, 'score': 0.1497424840927124, 'preview': 'greater\\tthan\\tor\\tequal\\tto\\tany\\tother\\temployee\\tsalary\\tof\\tthe\\tcompany.\\nA)\\t\\t\\t\\tselect\\te.ename,e.sal,e.comm\\tfrom\\temp\\te\\t\\twhere\\nnvl2(e.comm.,e.sal+e.comm.,e.sal)\\t>=\\tany\\t(select\\tsal\\tfrom\\temp);\\t\\t\\t(OR)\\nB)\\t\\t\\t\\tselect\\tename,sal,comm.\\tfrom\\temp\\twhere\\tsal+nvl(comm.,0)\\t>=\\tany\\t(select\\nsal\\tfrom\\temp);/\\n14.\\t\\t\\t\\t\\t\\t\\t\\tList\\tth...'}, {'source': 'SQL Queries .pdf', 'page': 37, 'score': 0.10474944114685059, 'preview': 'names\\tand\\tsalaries\\tfor\\tthose\\temps\\twho\\tearn\\tmore\\tsalary\\tthan\\ttheir\\tManager.\\nA)\\t\\t\\t\\tselect\\tw.ename,w.sal,m.ename,m.sal\\tfrom\\temp\\tw,emp\\tm\\nwhere\\tw.mgr\\t=\\tm.empno\\tand\\tw.sal\\t>\\tm.sal;\\n165)\\t\\t\\tList\\tout\\tthe\\tName,\\tJob,\\tSalary\\tof\\tthe\\temps\\tin\\tthe\\tdepartment\\twith\\tthe\\nhighest\\taverage\\tsalary.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\tw...'}]\n",
      "Confidence: 0.1497424840927124\n",
      "Context Preview: greater\tthan\tor\tequal\tto\tany\tother\temployee\tsalary\tof\tthe\tcompany.\n",
      "A)\t\t\t\tselect\te.ename,e.sal,e.comm\tfrom\temp\te\t\twhere\n",
      "nvl2(e.comm.,e.sal+e.comm.,e.sal)\t>=\tany\t(select\tsal\tfrom\temp);\t\t\t(OR)\n",
      "B)\t\t\t\tselect\tename,sal,comm.\tfrom\temp\twhere\tsal+nvl(comm.,0)\t>=\tany\t(select\n",
      "sal\tfrom\temp);/\n",
      "14.\t\t\t\t\t\t\t\tList\tth\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"     \"How does histogram equalization improve image contrast?\"\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced( \"Find employees earning more than their managers?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb7400fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'List department with highest number of employees'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: select * from emp group by deptno having count(*) = (select max(count(*)) from emp group by deptno);\n",
      "Sources: [{'source': 'SQL Queries .pdf', 'page': 18, 'score': 0.1564648151397705, 'preview': 'where\\te.deptno\\t=\\td.deptno\\tgroup\\tby\\td.deptno,d.dname,d..loc\\nhaving\\tcount(*)\\t=\\t(select\\tmax(count(*)\\t)\\tfrom\\temp\\tgroup\\tby\\tdeptno);\\n2.82.\\t\\t\\t\\t\\tDisplay\\tthe\\temps\\twhose\\tmanager\\tname\\tis\\tjones.\\nK)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tmgr\\tin...'}, {'source': 'SQL Queries .pdf', 'page': 52, 'score': 0.10592901706695557, 'preview': '234)\\t\\t\\tAny\\temp\\tSal\\tof\\temp5\\ttable.\\nA)\\tselect\\t*\\tfrom\\temp5;\\n235)\\t\\t\\tList\\tthe\\thighest\\tpaid\\temp.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\tsal\\tin\\t(select\\tmax(sal)\\tfrom\\temp);\\n236)\\t\\t\\tList\\tthe\\tdetails\\tof\\tmost\\trecently\\thired\\temp\\tof\\tdept\\t30.\\nA)\\t\\t\\t\\tselect\\t*\\tfrom\\temp\\twhere\\thiredate\\tin\\n(select\\tmax(hiredate)\\tfrom\\temp\\twhere\\tde...'}]\n",
      "Confidence: 0.1564648151397705\n",
      "Context Preview: where\te.deptno\t=\td.deptno\tgroup\tby\td.deptno,d.dname,d..loc\n",
      "having\tcount(*)\t=\t(select\tmax(count(*)\t)\tfrom\temp\tgroup\tby\tdeptno);\n",
      "2.82.\t\t\t\t\tDisplay\tthe\temps\twhose\tmanager\tname\tis\tjones.\n",
      "K)\t\t\t\tselect\t*\tfrom\temp\twhere\tmgr\tin\n",
      "\n",
      "234)\t\t\tAny\temp\tSal\tof\temp5\ttable.\n",
      "A)\tselect\t*\tfrom\temp5;\n",
      "235)\t\t\tList\tthe\thighes\n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"List department with highest number of employees\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "939fc32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'How does histogram equalization improve image contrast?'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "7.4 histogram equalization\n",
      "The code here is very simple – it’s just an extension of the\n",
      "code above. We are now computing an 8 × 8 × 8 histogram\n",
      "for each of the RGB channel"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s. We can’t visualize this his-\n",
      "togram, but we can see that the shape is indeed (8,8,8)\n",
      "with 512 values.\n",
      "7.4 histogram equalization\n",
      "Histogram equalization improves the contrast of an image\n",
      "by “stretching” the distribution of pixels. Consider a his-\n",
      "togram with a large peak at the center of it. Applying his-\n",
      "togram equalization will stretch the peak out towards the\n",
      "corner of the image, thus improving the global contrast of\n",
      "the image. Histogram equalization is applied to grayscale\n",
      "images.\n",
      "This method is useful when an image contains foregroun-\n",
      "ds and backgrounds that are both dark or both light. It\n",
      "tends to produce unrealistic effects in photographs; how-\n",
      "ever, it is normally useful when enhancing the contrast of\n",
      "medical or satellite images.\n",
      "Regardless whether you are applying histogram equaliza-\n",
      "\n",
      "ever, it is normally useful when enhancing the contrast of\n",
      "medical or satellite images.\n",
      "Regardless whether you are applying histogram equaliza-\n",
      "tion to a photograph, a satellite image, or an X-ray, we ﬁrst\n",
      "need to see some code so we can understand what is going\n",
      "on:\n",
      "Listing 7.7: equalize.py\n",
      "1 import numpy as np\n",
      "2 import argparse\n",
      "3 import cv2\n",
      "4\n",
      "99\n",
      "\n",
      "7.4 histogram equalization\n",
      "Figure 7.4: Left: The original beach image. Right:\n",
      "The beach image after applying his-\n",
      "togram equalization.\n",
      "5 ap = argparse.ArgumentParser()\n",
      "6 ap.add_argument(\"-i\", \"--image\", required = True,\n",
      "7 help = \"Path to the image\")\n",
      "8 args = vars(ap.parse_args())\n",
      "9\n",
      "10 image = cv2.imread(args[\"image\"])\n",
      "11 image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "12\n",
      "13 eq = cv2.equalizeHist(image)\n",
      "14\n",
      "15 cv2.imshow(\"Histogram Equalization\", np.hstack([image, eq]))\n",
      "16 cv2.waitKey(0)\n",
      "Lines 1-10 handle our standard practice of importing pack-\n",
      "ages, parsing arguments, and loading our image. We then\n",
      "convert our image to grayscale on Line 11.\n",
      "Performing histogram equalization is done using just a\n",
      "single function: cv2.equalizeHist, which accepts a single\n",
      "parameter, the grayscale image we want to perform his-\n",
      "togram equalization on. The last couple lines of code dis-\n",
      "play our histogram equalized image.\n",
      "100\n",
      "\n",
      "Question: How does histogram equalization improve image contrast?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: Histogram equalization improves image contrast by \"stretching\" the distribution of pixels, particularly by moving a large peak at the center of the histogram out towards the corners, thus increasing the global contrast of the image.\n",
      "\n",
      "Citations:\n",
      "[1] Practical Python and OpenCV.pdf (page 110)\n",
      "[2] Practical Python and OpenCV.pdf (page 110)\n",
      "[3] Practical Python and OpenCV.pdf (page 111)\n",
      "Summary: Histogram equalization is a technique used to improve image contrast by redistributing pixel values to create a more even distribution. This process \"stretches\" the histogram, moving a central peak towards the corners, resulting in increased global contrast in the image.\n",
      "History: {'question': 'How does histogram equalization improve image contrast?', 'answer': 'Histogram equalization improves image contrast by \"stretching\" the distribution of pixels, particularly by moving a large peak at the center of the histogram out towards the corners, thus increasing the global contrast of the image.', 'sources': [{'source': 'Practical Python and OpenCV.pdf', 'page': 110, 'score': 0.6063262522220612, 'preview': '7.4 histogram equalization\\nThe code here is very simple – it’s just an extension of the\\ncode above. We are now computing...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 110, 'score': 0.47982001304626465, 'preview': 'ever, it is normally useful when enhancing the contrast of\\nmedical or satellite images.\\nRegardless whether you are apply...'}, {'source': 'Practical Python and OpenCV.pdf', 'page': 111, 'score': 0.12199676036834717, 'preview': '7.4 histogram equalization\\nFigure 7.4: Left: The original beach image. Right:\\nThe beach image after applying his-\\ntogram...'}], 'summary': 'Histogram equalization is a technique used to improve image contrast by redistributing pixel values to create a more even distribution. This process \"stretches\" the histogram, moving a central peak towards the corners, resulting in increased global contrast in the image.'}\n"
     ]
    }
   ],
   "source": [
    "## # --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"How does histogram equalization improve image contrast?\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
